
	/**
     * Auto-generated by moveme-dma.py
	 *
	 * This file is licensed under the MIT License. See LICENSE in the root directory
	 * of the prohect for the license text.
	 */

	/* Emit a DMA descriptor for a byte copy operation */
	.macro Dma_ByteCopy dst, src, size, lli
	.long (\src)
	.long (\dst)
	.long (\lli)
	.long (0x0C000000 + \size)
	.endm

	/* Emit a DMA descriptor for a byte fill operation */
	.macro Dma_ByteFill dst, src, size, lli
	.long (\src)
	.long (\dst)
	.long (\lli)
	.long (0x08000000 + \size)
	.endm

	/* Patch srcaddr[7:0] of the descriptor given by dst */
	.macro Dma_PatchSrcLo8 dst, src, lli
	Dma_ByteCopy (\dst+0), (\src), 1, \lli
	.endm

	/* Patch srcaddr[15:8] of the descriptor given by dst */
	.macro Dma_PatchSrcHi8 dst, src, lli
	Dma_ByteCopy (\dst+1), (\src), 1, \lli
	.endm

	/* Patch srcaddr[15:0] of the descriptor given by dst */
	.macro Dma_PatchSrcLo16 dst, src, lli
	Dma_ByteCopy (\dst+0), (\src), 2, \lli
	.endm

	/* Patch srcaddr[31:16] of the descriptor given by dst */
	.macro Dma_PatchSrcHi16 dst, src, lli
	Dma_ByteCopy (\dst+2), (\src), 2, \lli
	.endm

	/* Patch dstaddr[7:0] of the descriptor given by dst */
	.macro Dma_PatchDstLo8 dst, src, lli
	Dma_ByteCopy (\dst+4), (\src), 1, \lli
	.endm

	/* Patch dstaddr[15:0] of the descriptor given by dst */
	.macro Dma_PatchDstHi8 dst, src, lli
	Dma_ByteCopy (\dst+5), (\src), 1, \lli
	.endm

	/* Patch dstaddr[15:0] of the descriptor given by dst */
	.macro Dma_PatchDstLo16 dst, src, lli
	Dma_ByteCopy (\dst+4), (\src), 2, \lli
	.endm

	/* Patch dstaddr[31:16] of the descriptor given by dst */
	.macro Dma_PatchDstHi16 dst, src, lli
	Dma_ByteCopy (\dst+6), (\src), 2, \lli
	.endm

	/* Patch the destination location */
	.macro Dma_PatchDst dst, src, lli
	Dma_ByteCopy (\dst+4), (\src), 4, \lli
	.endm

	/* Patch the source location */
	.macro Dma_PatchSrc dst, src, lli
	Dma_ByteCopy (\dst+0), (\src), 4, \lli
	.endm

    /* Patch the LLI location */
	.macro Dma_PatchLink dst, src, lli
	Dma_ByteCopy (\dst+8), (\src), 4, \lli
	.endm

    /* Assume data segment by default -*/
    .data

	// LABEL print
	print:
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.0: Dma_PatchSrc (.L__pc.0.LD), (.L__movme_cp.0), (.L__pc.0.LD)
	.p2align 4
	.L__pc.0.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2
	
	.L__pc.2: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3
	
	.p2align 4
	.L__pc.3: Dma_PatchDst (.L__pc.3.ST), (.L__movme_cp.1), (.L__pc.3.ST)
	.L__pc.3.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.4: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.5
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.6: Dma_PatchSrc (.L__pc.6.LD), (.L__movme_cp.3), (.L__pc.6.LD)
	.p2align 4
	.L__pc.6.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8
	
	.L__pc.8: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9
	
	.p2align 4
	.L__pc.9: Dma_PatchDst (.L__pc.9.ST), (.L__movme_cp.4), (.L__pc.9.ST)
	.L__pc.9.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12: Dma_PatchSrc (.L__pc.12.LD), (.L__movme_tmp.1), (.L__pc.12.LD)
	.p2align 4
	.L__pc.12.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.14: Dma_PatchSrc (.L__pc.14.LD), (.L__movme_cp.2), (.L__pc.14.LD)
	.p2align 4
	.L__pc.14.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.16: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17: Dma_PatchSrc (.L__pc.17.LD), (.L__movme_tmp.1), (.L__pc.17.LD)
	.p2align 4
	.L__pc.17.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19
	
	.L__pc.19: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20
	
	.p2align 4
	.L__pc.20: Dma_PatchDst (.L__pc.20.ST), ((.L__movme.reg.eax+0)), (.L__pc.20.ST)
	.L__pc.20.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.21: Dma_PatchSrc (.L__pc.21.LD), (.L__movme_cp.2), (.L__pc.21.LD)
	.p2align 4
	.L__pc.21.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23: Dma_PatchSrc (.L__pc.23.LD), (.L__movme_cp.3), (.L__pc.23.LD)
	.p2align 4
	.L__pc.23.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.24
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.24: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.25
	
	.L__pc.25: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.26
	
	.p2align 4
	.L__pc.26: Dma_PatchDst (.L__pc.26.ST), (.L__movme_cp.4), (.L__pc.26.ST)
	.L__pc.26.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.27
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.27: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.28: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.29: Dma_PatchSrc (.L__pc.29.LD), (.L__movme_tmp.1), (.L__pc.29.LD)
	.p2align 4
	.L__pc.29.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.30
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.30: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.31
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.31: Dma_PatchSrc (.L__pc.31.LD), (.L__movme_cp.1), (.L__pc.31.LD)
	.p2align 4
	.L__pc.31.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.32
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.32: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.33
	
	.L__pc.33: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.34
	
	.p2align 4
	.L__pc.34: Dma_PatchDst (.L__pc.34.ST), ((.L__movme.reg.eax+0)), (.L__pc.34.ST)
	.L__pc.34.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.35
	
	// CG.LOAD4 [.L__movme_cp.7} => .L__movme_tmp.0
	.L__pc.35: Dma_PatchSrc (.L__pc.35.LD), (.L__movme_cp.7), (.L__pc.35.LD)
	.p2align 4
	.L__pc.35.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.36
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.36: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.37
	
	.L__pc.37: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.38
	
	.p2align 4
	.L__pc.38: Dma_PatchDst (.L__pc.38.ST), (.L__movme_cp.1), (.L__pc.38.ST)
	.L__pc.38.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.39
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.39: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.40
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.40: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.41
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.41: Dma_PatchSrc (.L__pc.41.LD), (.L__movme_cp.3), (.L__pc.41.LD)
	.p2align 4
	.L__pc.41.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.42
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.42: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.43
	
	.L__pc.43: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.44
	
	.p2align 4
	.L__pc.44: Dma_PatchDst (.L__pc.44.ST), (.L__movme_cp.4), (.L__pc.44.ST)
	.L__pc.44.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.45
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.45: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.46: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.47: Dma_PatchSrc (.L__pc.47.LD), (.L__movme_tmp.1), (.L__pc.47.LD)
	.p2align 4
	.L__pc.47.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.48
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.48: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.49
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.49: Dma_PatchSrc (.L__pc.49.LD), (.L__movme_cp.2), (.L__pc.49.LD)
	.p2align 4
	.L__pc.49.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.50
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.50: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.51
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.51: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.52: Dma_PatchSrc (.L__pc.52.LD), (.L__movme_tmp.1), (.L__pc.52.LD)
	.p2align 4
	.L__pc.52.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.53
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.53: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.54
	
	.L__pc.54: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.55
	
	.p2align 4
	.L__pc.55: Dma_PatchDst (.L__pc.55.ST), ((.L__movme.reg.eax+0)), (.L__pc.55.ST)
	.L__pc.55.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.56
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.56: Dma_PatchSrc (.L__pc.56.LD), (.L__movme_cp.2), (.L__pc.56.LD)
	.p2align 4
	.L__pc.56.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.57
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.57: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.58
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.58: Dma_PatchSrc (.L__pc.58.LD), (.L__movme_cp.3), (.L__pc.58.LD)
	.p2align 4
	.L__pc.58.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.59
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.59: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.60
	
	.L__pc.60: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.61
	
	.p2align 4
	.L__pc.61: Dma_PatchDst (.L__pc.61.ST), (.L__movme_cp.4), (.L__pc.61.ST)
	.L__pc.61.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.62
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.62: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.63: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.64: Dma_PatchSrc (.L__pc.64.LD), (.L__movme_tmp.1), (.L__pc.64.LD)
	.p2align 4
	.L__pc.64.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.65
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.65: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.66
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.66: Dma_PatchSrc (.L__pc.66.LD), (.L__movme_cp.1), (.L__pc.66.LD)
	.p2align 4
	.L__pc.66.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.67
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.67: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.68
	
	.L__pc.68: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.69
	
	.p2align 4
	.L__pc.69: Dma_PatchDst (.L__pc.69.ST), ((.L__movme.reg.eax+0)), (.L__pc.69.ST)
	.L__pc.69.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.70
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.70: Dma_PatchSrc (.L__pc.70.LD), (.L__movme_cp.8), (.L__pc.70.LD)
	.p2align 4
	.L__pc.70.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.71
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.71: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.72
	
	.L__pc.72: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.73
	
	.p2align 4
	.L__pc.73: Dma_PatchDst (.L__pc.73.ST), (.L__movme_cp.1), (.L__pc.73.ST)
	.L__pc.73.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.74
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.74: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.75
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.75: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.76
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.76: Dma_PatchSrc (.L__pc.76.LD), (.L__movme_cp.3), (.L__pc.76.LD)
	.p2align 4
	.L__pc.76.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.77
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.77: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.78
	
	.L__pc.78: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.79
	
	.p2align 4
	.L__pc.79: Dma_PatchDst (.L__pc.79.ST), (.L__movme_cp.4), (.L__pc.79.ST)
	.L__pc.79.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.80
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.80: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.81: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.82: Dma_PatchSrc (.L__pc.82.LD), (.L__movme_tmp.1), (.L__pc.82.LD)
	.p2align 4
	.L__pc.82.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.83
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.83: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.84
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.84: Dma_PatchSrc (.L__pc.84.LD), (.L__movme_cp.2), (.L__pc.84.LD)
	.p2align 4
	.L__pc.84.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.85
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.85: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.86
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.86: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.87: Dma_PatchSrc (.L__pc.87.LD), (.L__movme_tmp.1), (.L__pc.87.LD)
	.p2align 4
	.L__pc.87.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.88
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.88: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.89
	
	.L__pc.89: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.90
	
	.p2align 4
	.L__pc.90: Dma_PatchDst (.L__pc.90.ST), ((.L__movme.reg.eax+0)), (.L__pc.90.ST)
	.L__pc.90.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.91
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.91: Dma_PatchSrc (.L__pc.91.LD), (.L__movme_cp.2), (.L__pc.91.LD)
	.p2align 4
	.L__pc.91.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.92
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.92: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.93
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.93: Dma_PatchSrc (.L__pc.93.LD), (.L__movme_cp.3), (.L__pc.93.LD)
	.p2align 4
	.L__pc.93.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.94
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.94: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.95
	
	.L__pc.95: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.96
	
	.p2align 4
	.L__pc.96: Dma_PatchDst (.L__pc.96.ST), (.L__movme_cp.4), (.L__pc.96.ST)
	.L__pc.96.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.97
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.97: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.98: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.99: Dma_PatchSrc (.L__pc.99.LD), (.L__movme_tmp.1), (.L__pc.99.LD)
	.p2align 4
	.L__pc.99.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.100
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.100: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.101
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.101: Dma_PatchSrc (.L__pc.101.LD), (.L__movme_cp.1), (.L__pc.101.LD)
	.p2align 4
	.L__pc.101.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.102
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.102: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.103
	
	.L__pc.103: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.104
	
	.p2align 4
	.L__pc.104: Dma_PatchDst (.L__pc.104.ST), ((.L__movme.reg.eax+0)), (.L__pc.104.ST)
	.L__pc.104.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.105
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.105: Dma_PatchSrc (.L__pc.105.LD), (.L__movme_cp.9), (.L__pc.105.LD)
	.p2align 4
	.L__pc.105.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.106
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.106: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.107
	
	.L__pc.107: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.108
	
	.p2align 4
	.L__pc.108: Dma_PatchDst (.L__pc.108.ST), (.L__movme_cp.1), (.L__pc.108.ST)
	.L__pc.108.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.109
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.109: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.110
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.110: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.111
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.111: Dma_PatchSrc (.L__pc.111.LD), (.L__movme_cp.3), (.L__pc.111.LD)
	.p2align 4
	.L__pc.111.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.112
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.112: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.113
	
	.L__pc.113: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.114
	
	.p2align 4
	.L__pc.114: Dma_PatchDst (.L__pc.114.ST), (.L__movme_cp.4), (.L__pc.114.ST)
	.L__pc.114.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.115
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.115: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.116: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.117: Dma_PatchSrc (.L__pc.117.LD), (.L__movme_tmp.1), (.L__pc.117.LD)
	.p2align 4
	.L__pc.117.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.118
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.118: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.119
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.119: Dma_PatchSrc (.L__pc.119.LD), (.L__movme_cp.2), (.L__pc.119.LD)
	.p2align 4
	.L__pc.119.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.120
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.120: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.121
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.121: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.122: Dma_PatchSrc (.L__pc.122.LD), (.L__movme_tmp.1), (.L__pc.122.LD)
	.p2align 4
	.L__pc.122.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.123
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.123: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.124
	
	.L__pc.124: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.125
	
	.p2align 4
	.L__pc.125: Dma_PatchDst (.L__pc.125.ST), ((.L__movme.reg.eax+0)), (.L__pc.125.ST)
	.L__pc.125.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.126
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.126: Dma_PatchSrc (.L__pc.126.LD), (.L__movme_cp.2), (.L__pc.126.LD)
	.p2align 4
	.L__pc.126.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.127
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.127: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.128
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.128: Dma_PatchSrc (.L__pc.128.LD), (.L__movme_cp.3), (.L__pc.128.LD)
	.p2align 4
	.L__pc.128.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.129
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.129: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.130
	
	.L__pc.130: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.131
	
	.p2align 4
	.L__pc.131: Dma_PatchDst (.L__pc.131.ST), (.L__movme_cp.4), (.L__pc.131.ST)
	.L__pc.131.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.132
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.132: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.133: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.134: Dma_PatchSrc (.L__pc.134.LD), (.L__movme_tmp.1), (.L__pc.134.LD)
	.p2align 4
	.L__pc.134.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.135
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.135: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.136
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.136: Dma_PatchSrc (.L__pc.136.LD), (.L__movme_cp.1), (.L__pc.136.LD)
	.p2align 4
	.L__pc.136.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.137
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.137: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.138
	
	.L__pc.138: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.139
	
	.p2align 4
	.L__pc.139: Dma_PatchDst (.L__pc.139.ST), ((.L__movme.reg.eax+0)), (.L__pc.139.ST)
	.L__pc.139.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.140
	
	// CG.LOAD4 [.L__movme_cp.10} => .L__movme_tmp.0
	.L__pc.140: Dma_PatchSrc (.L__pc.140.LD), (.L__movme_cp.10), (.L__pc.140.LD)
	.p2align 4
	.L__pc.140.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.141
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.141: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.142
	
	.L__pc.142: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.143
	
	.p2align 4
	.L__pc.143: Dma_PatchDst (.L__pc.143.ST), (.L__movme_cp.1), (.L__pc.143.ST)
	.L__pc.143.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.144
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.144: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.145
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.145: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.146
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.146: Dma_PatchSrc (.L__pc.146.LD), (.L__movme_cp.3), (.L__pc.146.LD)
	.p2align 4
	.L__pc.146.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.147
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.147: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.148
	
	.L__pc.148: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.149
	
	.p2align 4
	.L__pc.149: Dma_PatchDst (.L__pc.149.ST), (.L__movme_cp.4), (.L__pc.149.ST)
	.L__pc.149.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.150
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.150: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.151: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.152: Dma_PatchSrc (.L__pc.152.LD), (.L__movme_tmp.1), (.L__pc.152.LD)
	.p2align 4
	.L__pc.152.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.153
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.153: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.154
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.154: Dma_PatchSrc (.L__pc.154.LD), (.L__movme_cp.2), (.L__pc.154.LD)
	.p2align 4
	.L__pc.154.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.155
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.155: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.156
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.156: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.157: Dma_PatchSrc (.L__pc.157.LD), (.L__movme_tmp.1), (.L__pc.157.LD)
	.p2align 4
	.L__pc.157.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.158
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.158: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.159
	
	.L__pc.159: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.160
	
	.p2align 4
	.L__pc.160: Dma_PatchDst (.L__pc.160.ST), ((.L__movme.reg.eax+0)), (.L__pc.160.ST)
	.L__pc.160.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.161
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.161: Dma_PatchSrc (.L__pc.161.LD), (.L__movme_cp.2), (.L__pc.161.LD)
	.p2align 4
	.L__pc.161.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.162
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.162: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.163
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.163: Dma_PatchSrc (.L__pc.163.LD), (.L__movme_cp.3), (.L__pc.163.LD)
	.p2align 4
	.L__pc.163.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.164
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.164: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.165
	
	.L__pc.165: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.166
	
	.p2align 4
	.L__pc.166: Dma_PatchDst (.L__pc.166.ST), (.L__movme_cp.4), (.L__pc.166.ST)
	.L__pc.166.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.167
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.167: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.168: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.169: Dma_PatchSrc (.L__pc.169.LD), (.L__movme_tmp.1), (.L__pc.169.LD)
	.p2align 4
	.L__pc.169.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.170
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.170: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.171
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.171: Dma_PatchSrc (.L__pc.171.LD), (.L__movme_cp.1), (.L__pc.171.LD)
	.p2align 4
	.L__pc.171.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.172
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.172: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.173
	
	.L__pc.173: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.174
	
	.p2align 4
	.L__pc.174: Dma_PatchDst (.L__pc.174.ST), ((.L__movme.reg.eax+0)), (.L__pc.174.ST)
	.L__pc.174.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.175
	
	// CG.LOAD4 [.L__movme_cp.11} => .L__movme_tmp.0
	.L__pc.175: Dma_PatchSrc (.L__pc.175.LD), (.L__movme_cp.11), (.L__pc.175.LD)
	.p2align 4
	.L__pc.175.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.176
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.176: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.177
	
	.L__pc.177: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.178
	
	.p2align 4
	.L__pc.178: Dma_PatchDst (.L__pc.178.ST), (.L__movme_cp.1), (.L__pc.178.ST)
	.L__pc.178.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.179
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.179: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.180
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.180: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.181
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.181: Dma_PatchSrc (.L__pc.181.LD), (.L__movme_cp.3), (.L__pc.181.LD)
	.p2align 4
	.L__pc.181.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.182
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.182: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.183
	
	.L__pc.183: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.184
	
	.p2align 4
	.L__pc.184: Dma_PatchDst (.L__pc.184.ST), (.L__movme_cp.4), (.L__pc.184.ST)
	.L__pc.184.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.185
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.185: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.186: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.187: Dma_PatchSrc (.L__pc.187.LD), (.L__movme_tmp.1), (.L__pc.187.LD)
	.p2align 4
	.L__pc.187.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.188
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.188: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.189
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.189: Dma_PatchSrc (.L__pc.189.LD), (.L__movme_cp.2), (.L__pc.189.LD)
	.p2align 4
	.L__pc.189.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.190
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.190: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.191
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.191: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.192: Dma_PatchSrc (.L__pc.192.LD), (.L__movme_tmp.1), (.L__pc.192.LD)
	.p2align 4
	.L__pc.192.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.193
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.193: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.194
	
	.L__pc.194: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.195
	
	.p2align 4
	.L__pc.195: Dma_PatchDst (.L__pc.195.ST), ((.L__movme.reg.eax+0)), (.L__pc.195.ST)
	.L__pc.195.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.196
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.196: Dma_PatchSrc (.L__pc.196.LD), (.L__movme_cp.2), (.L__pc.196.LD)
	.p2align 4
	.L__pc.196.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.197
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.197: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.198
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.198: Dma_PatchSrc (.L__pc.198.LD), (.L__movme_cp.3), (.L__pc.198.LD)
	.p2align 4
	.L__pc.198.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.199
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.199: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.200
	
	.L__pc.200: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.201
	
	.p2align 4
	.L__pc.201: Dma_PatchDst (.L__pc.201.ST), (.L__movme_cp.4), (.L__pc.201.ST)
	.L__pc.201.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.202
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.202: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.203: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.204: Dma_PatchSrc (.L__pc.204.LD), (.L__movme_tmp.1), (.L__pc.204.LD)
	.p2align 4
	.L__pc.204.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.205
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.205: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.206
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.206: Dma_PatchSrc (.L__pc.206.LD), (.L__movme_cp.1), (.L__pc.206.LD)
	.p2align 4
	.L__pc.206.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.207
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.207: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.208
	
	.L__pc.208: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.209
	
	.p2align 4
	.L__pc.209: Dma_PatchDst (.L__pc.209.ST), ((.L__movme.reg.eax+0)), (.L__pc.209.ST)
	.L__pc.209.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.210
	
	// CG.LOAD4 [.L__movme_cp.12} => .L__movme_tmp.0
	.L__pc.210: Dma_PatchSrc (.L__pc.210.LD), (.L__movme_cp.12), (.L__pc.210.LD)
	.p2align 4
	.L__pc.210.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.211
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.211: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.212
	
	.L__pc.212: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.213
	
	.p2align 4
	.L__pc.213: Dma_PatchDst (.L__pc.213.ST), (.L__movme_cp.1), (.L__pc.213.ST)
	.L__pc.213.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.214
	
	// CG.LOAD4 [.L__movme_cp.13} => .L__movme_tmp.0
	.L__pc.214: Dma_PatchSrc (.L__pc.214.LD), (.L__movme_cp.13), (.L__pc.214.LD)
	.p2align 4
	.L__pc.214.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.215
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.215: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.216
	
	.L__pc.216: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.217
	
	.p2align 4
	.L__pc.217: Dma_PatchDst (.L__pc.217.ST), (.L__movme_cp.14), (.L__pc.217.ST)
	.L__pc.217.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.218
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.218: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.219
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.219: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.220
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.220: Dma_PatchSrc (.L__pc.220.LD), (.L__movme_cp.3), (.L__pc.220.LD)
	.p2align 4
	.L__pc.220.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.221
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.221: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.222
	
	.L__pc.222: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.223
	
	.p2align 4
	.L__pc.223: Dma_PatchDst (.L__pc.223.ST), (.L__movme_cp.4), (.L__pc.223.ST)
	.L__pc.223.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.224
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.224: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.225: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.226: Dma_PatchSrc (.L__pc.226.LD), (.L__movme_tmp.1), (.L__pc.226.LD)
	.p2align 4
	.L__pc.226.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.227
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.227: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.228
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.228: Dma_PatchSrc (.L__pc.228.LD), (.L__movme_cp.2), (.L__pc.228.LD)
	.p2align 4
	.L__pc.228.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.229
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.229: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.230
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.230: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.231: Dma_PatchSrc (.L__pc.231.LD), (.L__movme_tmp.1), (.L__pc.231.LD)
	.p2align 4
	.L__pc.231.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.232
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.232: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.233
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.233: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.234: Dma_PatchSrc (.L__pc.234.LD), (.L__movme_tmp.1), (.L__pc.234.LD)
	.p2align 4
	.L__pc.234.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.235
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.235: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.236
	
	.L__pc.236: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.237
	
	.p2align 4
	.L__pc.237: Dma_PatchDst (.L__pc.237.ST), ((.L__movme.reg.eax+0)), (.L__pc.237.ST)
	.L__pc.237.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.238
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.238: Dma_PatchSrc (.L__pc.238.LD), (.L__movme_cp.2), (.L__pc.238.LD)
	.p2align 4
	.L__pc.238.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.239
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.239: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.240
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.240: Dma_PatchSrc (.L__pc.240.LD), (.L__movme_cp.3), (.L__pc.240.LD)
	.p2align 4
	.L__pc.240.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.241
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.241: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.242
	
	.L__pc.242: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.243
	
	.p2align 4
	.L__pc.243: Dma_PatchDst (.L__pc.243.ST), (.L__movme_cp.4), (.L__pc.243.ST)
	.L__pc.243.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.244
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.244: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.245: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.246: Dma_PatchSrc (.L__pc.246.LD), (.L__movme_tmp.1), (.L__pc.246.LD)
	.p2align 4
	.L__pc.246.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.247
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.247: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.248
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.248: Dma_PatchSrc (.L__pc.248.LD), (.L__movme_cp.1), (.L__pc.248.LD)
	.p2align 4
	.L__pc.248.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.249
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.249: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.250
	
	.L__pc.250: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.251
	
	.p2align 4
	.L__pc.251: Dma_PatchDst (.L__pc.251.ST), ((.L__movme.reg.eax+0)), (.L__pc.251.ST)
	.L__pc.251.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.252
	
	// CG.LOAD4 [.L__movme_cp.14} => .L__movme_tmp.0
	.L__pc.252: Dma_PatchSrc (.L__pc.252.LD), (.L__movme_cp.14), (.L__pc.252.LD)
	.p2align 4
	.L__pc.252.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.253
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.253: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.254
	
	.L__pc.254: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.255
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.255: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	.p2align 4
	.L__pc.256: Dma_PatchDst (.L__pc.256.ST), (.L__movme_tmp.1), (.L__pc.256.ST)
	.L__pc.256.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.257
	
	// CG.LOAD4 [.L__movme_cp.16} => .L__movme_tmp.0
	.L__pc.257: Dma_PatchSrc (.L__pc.257.LD), (.L__movme_cp.16), (.L__pc.257.LD)
	.p2align 4
	.L__pc.257.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.258
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.258: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.259
	
	.L__pc.259: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.260
	
	.p2align 4
	.L__pc.260: Dma_PatchDst (.L__pc.260.ST), (.L__movme_cp.1), (.L__pc.260.ST)
	.L__pc.260.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.261
	
	// CG.LOAD4 [.L__movme_cp.17} => .L__movme_tmp.0
	.L__pc.261: Dma_PatchSrc (.L__pc.261.LD), (.L__movme_cp.17), (.L__pc.261.LD)
	.p2align 4
	.L__pc.261.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.262
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.262: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.263
	
	.L__pc.263: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.264
	
	.p2align 4
	.L__pc.264: Dma_PatchDst (.L__pc.264.ST), (.L__movme_cp.14), (.L__pc.264.ST)
	.L__pc.264.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.265
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.265: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.266
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.266: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.267
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.267: Dma_PatchSrc (.L__pc.267.LD), (.L__movme_cp.3), (.L__pc.267.LD)
	.p2align 4
	.L__pc.267.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.268
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.268: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.269
	
	.L__pc.269: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.270
	
	.p2align 4
	.L__pc.270: Dma_PatchDst (.L__pc.270.ST), (.L__movme_cp.4), (.L__pc.270.ST)
	.L__pc.270.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.271
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.271: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.272: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.273: Dma_PatchSrc (.L__pc.273.LD), (.L__movme_tmp.1), (.L__pc.273.LD)
	.p2align 4
	.L__pc.273.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.274
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.274: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.275
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.275: Dma_PatchSrc (.L__pc.275.LD), (.L__movme_cp.2), (.L__pc.275.LD)
	.p2align 4
	.L__pc.275.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.276
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.276: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.277
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.277: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.278: Dma_PatchSrc (.L__pc.278.LD), (.L__movme_tmp.1), (.L__pc.278.LD)
	.p2align 4
	.L__pc.278.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.279
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.279: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.280
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.280: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.281: Dma_PatchSrc (.L__pc.281.LD), (.L__movme_tmp.1), (.L__pc.281.LD)
	.p2align 4
	.L__pc.281.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.282
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.282: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.283
	
	.L__pc.283: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.284
	
	.p2align 4
	.L__pc.284: Dma_PatchDst (.L__pc.284.ST), ((.L__movme.reg.eax+0)), (.L__pc.284.ST)
	.L__pc.284.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.285
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.285: Dma_PatchSrc (.L__pc.285.LD), (.L__movme_cp.2), (.L__pc.285.LD)
	.p2align 4
	.L__pc.285.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.286
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.286: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.287
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.287: Dma_PatchSrc (.L__pc.287.LD), (.L__movme_cp.3), (.L__pc.287.LD)
	.p2align 4
	.L__pc.287.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.288
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.288: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.289
	
	.L__pc.289: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.290
	
	.p2align 4
	.L__pc.290: Dma_PatchDst (.L__pc.290.ST), (.L__movme_cp.4), (.L__pc.290.ST)
	.L__pc.290.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.291
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.291: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.292: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.293: Dma_PatchSrc (.L__pc.293.LD), (.L__movme_tmp.1), (.L__pc.293.LD)
	.p2align 4
	.L__pc.293.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.294
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.294: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.295
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.295: Dma_PatchSrc (.L__pc.295.LD), (.L__movme_cp.1), (.L__pc.295.LD)
	.p2align 4
	.L__pc.295.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.296
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.296: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.297
	
	.L__pc.297: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.298
	
	.p2align 4
	.L__pc.298: Dma_PatchDst (.L__pc.298.ST), ((.L__movme.reg.eax+0)), (.L__pc.298.ST)
	.L__pc.298.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.299
	
	// CG.LOAD4 [.L__movme_cp.14} => .L__movme_tmp.0
	.L__pc.299: Dma_PatchSrc (.L__pc.299.LD), (.L__movme_cp.14), (.L__pc.299.LD)
	.p2align 4
	.L__pc.299.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.300
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.300: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.301
	
	.L__pc.301: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.302
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.302: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	.p2align 4
	.L__pc.303: Dma_PatchDst (.L__pc.303.ST), (.L__movme_tmp.1), (.L__pc.303.ST)
	.L__pc.303.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.304
	
	// CG.COPY4 .L__movme_cp.0 => .L__movme_tmp.0
	.L__pc.304: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.0), 4, .L__pc.305
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.305: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.306
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.306: Dma_PatchSrc (.L__pc.306.LD), (.L__movme_cp.3), (.L__pc.306.LD)
	.p2align 4
	.L__pc.306.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.307
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.307: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.308
	
	.L__pc.308: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.309
	
	.p2align 4
	.L__pc.309: Dma_PatchDst (.L__pc.309.ST), (.L__movme_cp.4), (.L__pc.309.ST)
	.L__pc.309.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.310
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.310: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.311: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.312: Dma_PatchSrc (.L__pc.312.LD), (.L__movme_tmp.1), (.L__pc.312.LD)
	.p2align 4
	.L__pc.312.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.313
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.313: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.314
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.314: Dma_PatchSrc (.L__pc.314.LD), (.L__movme_cp.2), (.L__pc.314.LD)
	.p2align 4
	.L__pc.314.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.315
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.315: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.316
	
	.L__pc.316: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.317
	
	.p2align 4
	.L__pc.317: Dma_PatchDst (.L__pc.317.ST), ((.L__movme.reg.eax+0)), (.L__pc.317.ST)
	.L__pc.317.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.318
	
	// JMP imm.4(.LCI4)
	.L__pc.318: Dma_PatchLink (.L__pc.318.J), (.L__movme_cp.18), (.L__pc.318.J)
	.p2align 4
	.L__pc.318.J: Dma_ByteCopy  (.L__movme_tmp.0), (.L__movme_tmp.0), 1, .L__pc.319
	
	// LABEL .LCI3
	.LCI3:
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.319: Dma_PatchSrc (.L__pc.319.LD), (.L__movme_cp.0), (.L__pc.319.LD)
	.p2align 4
	.L__pc.319.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.320
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.320: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.321
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.321: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.322: Dma_PatchSrc (.L__pc.322.LD), (.L__movme_tmp.1), (.L__pc.322.LD)
	.p2align 4
	.L__pc.322.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.323
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.323: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.324
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.324: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.325: Dma_PatchSrc (.L__pc.325.LD), (.L__movme_tmp.1), (.L__pc.325.LD)
	.p2align 4
	.L__pc.325.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.326
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.326: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.327
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.327: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.328: Dma_PatchSrc (.L__pc.328.LD), (.L__movme_tmp.1), (.L__pc.328.LD)
	.p2align 4
	.L__pc.328.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.329
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.329: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.330
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.330: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.331: Dma_PatchSrc (.L__pc.331.LD), (.L__movme_tmp.1), (.L__pc.331.LD)
	.p2align 4
	.L__pc.331.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.332
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.332: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.333
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.333: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.334: Dma_PatchSrc (.L__pc.334.LD), (.L__movme_tmp.1), (.L__pc.334.LD)
	.p2align 4
	.L__pc.334.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.335
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.335: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.336
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.336: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.337: Dma_PatchSrc (.L__pc.337.LD), (.L__movme_tmp.1), (.L__pc.337.LD)
	.p2align 4
	.L__pc.337.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.338
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.338: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.339
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.339: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.340: Dma_PatchSrc (.L__pc.340.LD), (.L__movme_tmp.1), (.L__pc.340.LD)
	.p2align 4
	.L__pc.340.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.341
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.341: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.342
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.342: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.343: Dma_PatchSrc (.L__pc.343.LD), (.L__movme_tmp.1), (.L__pc.343.LD)
	.p2align 4
	.L__pc.343.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.344
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.344: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.345
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.345: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.346: Dma_PatchSrc (.L__pc.346.LD), (.L__movme_tmp.1), (.L__pc.346.LD)
	.p2align 4
	.L__pc.346.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.347
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.347: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.348
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.348: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.349: Dma_PatchSrc (.L__pc.349.LD), (.L__movme_tmp.1), (.L__pc.349.LD)
	.p2align 4
	.L__pc.349.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.350
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.350: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.351
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.351: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.352: Dma_PatchSrc (.L__pc.352.LD), (.L__movme_tmp.1), (.L__pc.352.LD)
	.p2align 4
	.L__pc.352.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.353
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.353: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.354
	
	.L__pc.354: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.355
	
	.p2align 4
	.L__pc.355: Dma_PatchDst (.L__pc.355.ST), (.L__movme_cp.9), (.L__pc.355.ST)
	.L__pc.355.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.356
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.356: Dma_PatchSrc (.L__pc.356.LD), (.L__movme_cp.9), (.L__pc.356.LD)
	.p2align 4
	.L__pc.356.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.357
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.357: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.358
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.358: Dma_PatchSrc (.L__pc.358.LD), (.L__movme_cp.3), (.L__pc.358.LD)
	.p2align 4
	.L__pc.358.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.359
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.359: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.360
	
	.L__pc.360: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.361
	
	.p2align 4
	.L__pc.361: Dma_PatchDst (.L__pc.361.ST), (.L__movme_cp.4), (.L__pc.361.ST)
	.L__pc.361.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.362
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.362: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.363: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.364: Dma_PatchSrc (.L__pc.364.LD), (.L__movme_tmp.1), (.L__pc.364.LD)
	.p2align 4
	.L__pc.364.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.365
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.365: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.366
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.366: Dma_PatchSrc (.L__pc.366.LD), ((.L__movme.reg.eax+0)), (.L__pc.366.LD)
	.p2align 4
	.L__pc.366.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.367
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.367: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.368
	
	.L__pc.368: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.369
	
	.p2align 4
	.L__pc.369: Dma_PatchDst (.L__pc.369.ST), (.L__movme_cp.9), (.L__pc.369.ST)
	.L__pc.369.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.370
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.370: Dma_PatchSrc (.L__pc.370.LD), (.L__movme_cp.0), (.L__pc.370.LD)
	.p2align 4
	.L__pc.370.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.371
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.371: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.372
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.372: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.373: Dma_PatchSrc (.L__pc.373.LD), (.L__movme_tmp.1), (.L__pc.373.LD)
	.p2align 4
	.L__pc.373.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.374
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.374: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.375
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.375: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.376: Dma_PatchSrc (.L__pc.376.LD), (.L__movme_tmp.1), (.L__pc.376.LD)
	.p2align 4
	.L__pc.376.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.377
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.377: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.378
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.378: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.379: Dma_PatchSrc (.L__pc.379.LD), (.L__movme_tmp.1), (.L__pc.379.LD)
	.p2align 4
	.L__pc.379.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.380
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.380: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.381
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.381: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.382: Dma_PatchSrc (.L__pc.382.LD), (.L__movme_tmp.1), (.L__pc.382.LD)
	.p2align 4
	.L__pc.382.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.383
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.383: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.384
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.384: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.385: Dma_PatchSrc (.L__pc.385.LD), (.L__movme_tmp.1), (.L__pc.385.LD)
	.p2align 4
	.L__pc.385.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.386
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.386: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.387
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.387: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.388: Dma_PatchSrc (.L__pc.388.LD), (.L__movme_tmp.1), (.L__pc.388.LD)
	.p2align 4
	.L__pc.388.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.389
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.389: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.390
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.390: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.391: Dma_PatchSrc (.L__pc.391.LD), (.L__movme_tmp.1), (.L__pc.391.LD)
	.p2align 4
	.L__pc.391.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.392
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.392: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.393
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.393: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.394: Dma_PatchSrc (.L__pc.394.LD), (.L__movme_tmp.1), (.L__pc.394.LD)
	.p2align 4
	.L__pc.394.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.395
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.395: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.396
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.396: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.397: Dma_PatchSrc (.L__pc.397.LD), (.L__movme_tmp.1), (.L__pc.397.LD)
	.p2align 4
	.L__pc.397.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.398
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.398: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.399
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.399: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.400: Dma_PatchSrc (.L__pc.400.LD), (.L__movme_tmp.1), (.L__pc.400.LD)
	.p2align 4
	.L__pc.400.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.401
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.401: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.402
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.402: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.403: Dma_PatchSrc (.L__pc.403.LD), (.L__movme_tmp.1), (.L__pc.403.LD)
	.p2align 4
	.L__pc.403.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.404
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.404: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.405
	
	.L__pc.405: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.406
	
	.p2align 4
	.L__pc.406: Dma_PatchDst (.L__pc.406.ST), (.L__movme_cp.8), (.L__pc.406.ST)
	.L__pc.406.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.407
	
	// CG.COPY4 .L__movme_cp.20 => .L__movme_tmp.0
	.L__pc.407: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.20), 4, .L__pc.408
	
	.p2align 4
	.L__pc.408: Dma_PatchDst (.L__pc.408.ST), (.L__movme_cp.7), (.L__pc.408.ST)
	.L__pc.408.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.409
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.409: Dma_PatchSrc (.L__pc.409.LD), (.L__movme_cp.9), (.L__pc.409.LD)
	.p2align 4
	.L__pc.409.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.410
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.410: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.411
	
	// CG.LOAD4 [.L__movme_cp.7} => .L__movme_tmp.0
	.L__pc.411: Dma_PatchSrc (.L__pc.411.LD), (.L__movme_cp.7), (.L__pc.411.LD)
	.p2align 4
	.L__pc.411.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.412
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.412: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.413
	
	.L__pc.413: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.414
	
	.p2align 4
	.L__pc.414: Dma_PatchDst (.L__pc.414.ST), (.L__movme_cp.21), (.L__pc.414.ST)
	.L__pc.414.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.415
	
	.L__pc.415: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.416
	
	.p2align 4
	.L__pc.416: Dma_PatchDst (.L__pc.416.ST), (.L__movme_cp.22), (.L__pc.416.ST)
	.L__pc.416.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.417
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.417: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.418
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.418: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.419
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.419: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.420
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.420: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.421
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.421: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.422
	
	.p2align 4
	.L__pc.422: Dma_PatchDst (.L__pc.422.ST), (.L__movme_cp.24), (.L__pc.422.ST)
	.L__pc.422.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.423
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.423: Dma_PatchSrc (.L__pc.423.LD), (.L__movme_cp.25), (.L__pc.423.LD)
	.p2align 4
	.L__pc.423.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.424
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.424: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.425
	.L__pc.425: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.426
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.426: Dma_PatchSrc (.L__pc.426.LD), (.L__movme_cp.26), (.L__pc.426.LD)
	.p2align 4
	.L__pc.426.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.427
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.427: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.428
	.L__pc.428: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.429
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.429: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.430: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.431: Dma_PatchSrc (.L__pc.431.LD), (.L__movme_tmp.1), (.L__pc.431.LD)
	.p2align 4
	.L__pc.431.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.432
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.432: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.433
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.433: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.434: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.435: Dma_PatchSrc (.L__pc.435.LD), (.L__movme_tmp.1), (.L__pc.435.LD)
	.p2align 4
	.L__pc.435.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.436
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.436: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.437
	
	// CG.LOAD4 [.L__movme_cp.28} => .L__movme_tmp.0
	.L__pc.437: Dma_PatchSrc (.L__pc.437.LD), (.L__movme_cp.28), (.L__pc.437.LD)
	.p2align 4
	.L__pc.437.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.438
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.438: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.439
	.L__pc.439: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.440
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.440: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.441: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.442: Dma_PatchSrc (.L__pc.442.LD), (.L__movme_tmp.1), (.L__pc.442.LD)
	.p2align 4
	.L__pc.442.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.443
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.443: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.444
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.444: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.445: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.446: Dma_PatchSrc (.L__pc.446.LD), (.L__movme_tmp.1), (.L__pc.446.LD)
	.p2align 4
	.L__pc.446.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.447
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.447: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.448
	
	.L__pc.448: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.449
	
	.p2align 4
	.L__pc.449: Dma_PatchDst (.L__pc.449.ST), (.L__movme_cp.29), (.L__pc.449.ST)
	.L__pc.449.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.450
	
	.L__pc.450: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.451
	
	.p2align 4
	.L__pc.451: Dma_PatchDst (.L__pc.451.ST), (.L__movme_cp.24), (.L__pc.451.ST)
	.L__pc.451.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.452
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.452: Dma_PatchSrc (.L__pc.452.LD), (.L__movme_cp.30), (.L__pc.452.LD)
	.p2align 4
	.L__pc.452.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.453
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.453: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.454
	.L__pc.454: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.455
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.455: Dma_PatchSrc (.L__pc.455.LD), (.L__movme_cp.31), (.L__pc.455.LD)
	.p2align 4
	.L__pc.455.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.456
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.456: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.457
	.L__pc.457: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.458
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.458: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.459: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.460: Dma_PatchSrc (.L__pc.460.LD), (.L__movme_tmp.1), (.L__pc.460.LD)
	.p2align 4
	.L__pc.460.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.461
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.461: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.462
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.462: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.463: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.464: Dma_PatchSrc (.L__pc.464.LD), (.L__movme_tmp.1), (.L__pc.464.LD)
	.p2align 4
	.L__pc.464.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.465
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.465: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.466
	
	// CG.LOAD4 [.L__movme_cp.28} => .L__movme_tmp.0
	.L__pc.466: Dma_PatchSrc (.L__pc.466.LD), (.L__movme_cp.28), (.L__pc.466.LD)
	.p2align 4
	.L__pc.466.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.467
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.467: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.468
	.L__pc.468: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.469
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.469: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.470: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.471: Dma_PatchSrc (.L__pc.471.LD), (.L__movme_tmp.1), (.L__pc.471.LD)
	.p2align 4
	.L__pc.471.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.472
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.472: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.473
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.473: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.474: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.475: Dma_PatchSrc (.L__pc.475.LD), (.L__movme_tmp.1), (.L__pc.475.LD)
	.p2align 4
	.L__pc.475.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.476
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.476: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.477
	
	.L__pc.477: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.478
	
	.p2align 4
	.L__pc.478: Dma_PatchDst (.L__pc.478.ST), (.L__movme_cp.32), (.L__pc.478.ST)
	.L__pc.478.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.479
	
	.L__pc.479: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.480
	
	.p2align 4
	.L__pc.480: Dma_PatchDst (.L__pc.480.ST), (.L__movme_cp.24), (.L__pc.480.ST)
	.L__pc.480.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.481
	
	// CG.LOAD4 [.L__movme_cp.33} => .L__movme_tmp.0
	.L__pc.481: Dma_PatchSrc (.L__pc.481.LD), (.L__movme_cp.33), (.L__pc.481.LD)
	.p2align 4
	.L__pc.481.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.482
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.482: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.483
	
	.L__pc.483: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.484
	
	.p2align 4
	.L__pc.484: Dma_PatchDst (.L__pc.484.ST), (.L__movme_cp.7), (.L__pc.484.ST)
	.L__pc.484.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.485
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.485: Dma_PatchSrc (.L__pc.485.LD), (.L__movme_cp.8), (.L__pc.485.LD)
	.p2align 4
	.L__pc.485.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.486
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.486: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.487
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.487: Dma_PatchSrc (.L__pc.487.LD), (.L__movme_cp.3), (.L__pc.487.LD)
	.p2align 4
	.L__pc.487.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.488
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.488: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.489
	
	.L__pc.489: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.490
	
	.p2align 4
	.L__pc.490: Dma_PatchDst (.L__pc.490.ST), (.L__movme_cp.4), (.L__pc.490.ST)
	.L__pc.490.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.491
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.491: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.492: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.493: Dma_PatchSrc (.L__pc.493.LD), (.L__movme_tmp.1), (.L__pc.493.LD)
	.p2align 4
	.L__pc.493.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.494
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.494: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.495
	
	// CG.LOAD4 [.L__movme_cp.7} => .L__movme_tmp.0
	.L__pc.495: Dma_PatchSrc (.L__pc.495.LD), (.L__movme_cp.7), (.L__pc.495.LD)
	.p2align 4
	.L__pc.495.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.496
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.496: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.497
	
	.L__pc.497: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.498
	
	.p2align 4
	.L__pc.498: Dma_PatchDst (.L__pc.498.ST), ((.L__movme.reg.eax+0)), (.L__pc.498.ST)
	.L__pc.498.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.499
	
	// CG.COPY4 .L__movme_cp.34 => .L__movme_tmp.0
	.L__pc.499: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.34), 4, .L__pc.500
	
	.p2align 4
	.L__pc.500: Dma_PatchDst (.L__pc.500.ST), (.L__movme_cp.8), (.L__pc.500.ST)
	.L__pc.500.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.501
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.501: Dma_PatchSrc (.L__pc.501.LD), (.L__movme_cp.9), (.L__pc.501.LD)
	.p2align 4
	.L__pc.501.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.502
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.502: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.503
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.503: Dma_PatchSrc (.L__pc.503.LD), (.L__movme_cp.3), (.L__pc.503.LD)
	.p2align 4
	.L__pc.503.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.504
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.504: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.505
	
	.L__pc.505: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.506
	
	.p2align 4
	.L__pc.506: Dma_PatchDst (.L__pc.506.ST), (.L__movme_cp.4), (.L__pc.506.ST)
	.L__pc.506.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.507
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.507: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.508: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.509: Dma_PatchSrc (.L__pc.509.LD), (.L__movme_tmp.1), (.L__pc.509.LD)
	.p2align 4
	.L__pc.509.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.510
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.510: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.511
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.511: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.512
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.512: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.513
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.513: Dma_PatchSrc (.L__pc.513.LD), ((.L__movme.reg.eax+0)), (.L__pc.513.LD)
	.p2align 4
	.L__pc.513.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.514
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.514: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.515
	.L__pc.515: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.516
	
	.L__pc.516: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.517
	
	.p2align 4
	.L__pc.517: Dma_PatchDst (.L__pc.517.ST), (.L__movme_cp.35), (.L__pc.517.ST)
	.L__pc.517.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.518
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.518: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.519
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.519: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.520
	
	// CG.LOAD4 [.L__movme_cp.35} => .L__movme_tmp.0
	.L__pc.520: Dma_PatchSrc (.L__pc.520.LD), (.L__movme_cp.35), (.L__pc.520.LD)
	.p2align 4
	.L__pc.520.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.521
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.521: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.522
	.L__pc.522: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.523
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.523: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.36 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.524: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.525: Dma_PatchSrc (.L__pc.525.LD), (.L__movme_tmp.1), (.L__pc.525.LD)
	.p2align 4
	.L__pc.525.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.526
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.526: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.527
	
	.L__pc.527: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.528
	
	.p2align 4
	.L__pc.528: Dma_PatchDst (.L__pc.528.ST), (.L__movme_cp.9), (.L__pc.528.ST)
	.L__pc.528.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.529
	
	// CG.COPY4 .L__movme_cp.37 => .L__movme_tmp.0
	.L__pc.529: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.37), 4, .L__pc.530
	
	.p2align 4
	.L__pc.530: Dma_PatchDst (.L__pc.530.ST), (.L__movme_cp.7), (.L__pc.530.ST)
	.L__pc.530.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.531
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.531: Dma_PatchSrc (.L__pc.531.LD), (.L__movme_cp.9), (.L__pc.531.LD)
	.p2align 4
	.L__pc.531.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.532
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.532: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.533
	
	// CG.LOAD4 [.L__movme_cp.7} => .L__movme_tmp.0
	.L__pc.533: Dma_PatchSrc (.L__pc.533.LD), (.L__movme_cp.7), (.L__pc.533.LD)
	.p2align 4
	.L__pc.533.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.534
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.534: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.535
	
	.L__pc.535: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.536
	
	.p2align 4
	.L__pc.536: Dma_PatchDst (.L__pc.536.ST), (.L__movme_cp.21), (.L__pc.536.ST)
	.L__pc.536.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.537
	
	.L__pc.537: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.538
	
	.p2align 4
	.L__pc.538: Dma_PatchDst (.L__pc.538.ST), (.L__movme_cp.22), (.L__pc.538.ST)
	.L__pc.538.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.539
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.539: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.540
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.540: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.541
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.541: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.542
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.542: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.543
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.543: Dma_PatchSrc (.L__pc.543.LD), (.L__movme_cp.25), (.L__pc.543.LD)
	.p2align 4
	.L__pc.543.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.544
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.544: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.545
	.L__pc.545: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.546
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.546: Dma_PatchSrc (.L__pc.546.LD), (.L__movme_cp.26), (.L__pc.546.LD)
	.p2align 4
	.L__pc.546.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.547
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.547: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.548
	.L__pc.548: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.549
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.549: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.38 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.550: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.551: Dma_PatchSrc (.L__pc.551.LD), (.L__movme_tmp.1), (.L__pc.551.LD)
	.p2align 4
	.L__pc.551.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.552
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.552: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.553
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.eax+0) + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.553: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.554: Dma_PatchSrc (.L__pc.554.LD), (.L__movme_tmp.1), (.L__pc.554.LD)
	.p2align 4
	.L__pc.554.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.555
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.555: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.556
	.L__pc.556: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.557
	
	.L__pc.557: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.558
	
	.p2align 4
	.L__pc.558: Dma_PatchDst (.L__pc.558.ST), (.L__movme_cp.29), (.L__pc.558.ST)
	.L__pc.558.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.559
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.559: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.560
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.560: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.561
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.561: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.562
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.562: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.563
	
	// CG.LOAD4 [.L__movme_cp.39} => .L__movme_tmp.0
	.L__pc.563: Dma_PatchSrc (.L__pc.563.LD), (.L__movme_cp.39), (.L__pc.563.LD)
	.p2align 4
	.L__pc.563.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.564
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.564: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.565
	.L__pc.565: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.566
	
	// CG.LOAD4 [.L__movme_cp.40} => .L__movme_tmp.0
	.L__pc.566: Dma_PatchSrc (.L__pc.566.LD), (.L__movme_cp.40), (.L__pc.566.LD)
	.p2align 4
	.L__pc.566.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.567
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.567: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.568
	.L__pc.568: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.569
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.569: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.38 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.570: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.571: Dma_PatchSrc (.L__pc.571.LD), (.L__movme_tmp.1), (.L__pc.571.LD)
	.p2align 4
	.L__pc.571.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.572
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.572: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.573
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.eax+0) + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.573: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.574: Dma_PatchSrc (.L__pc.574.LD), (.L__movme_tmp.1), (.L__pc.574.LD)
	.p2align 4
	.L__pc.574.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.575
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.575: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.576
	.L__pc.576: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.577
	
	.L__pc.577: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.578
	
	.p2align 4
	.L__pc.578: Dma_PatchDst (.L__pc.578.ST), (.L__movme_cp.41), (.L__pc.578.ST)
	.L__pc.578.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.579
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.579: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.580
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.580: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.581
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.581: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.582
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.582: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.583
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.583: Dma_PatchSrc (.L__pc.583.LD), (.L__movme_cp.30), (.L__pc.583.LD)
	.p2align 4
	.L__pc.583.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.584
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.584: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.585
	.L__pc.585: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.586
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.586: Dma_PatchSrc (.L__pc.586.LD), (.L__movme_cp.31), (.L__pc.586.LD)
	.p2align 4
	.L__pc.586.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.587
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.587: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.588
	.L__pc.588: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.589
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.589: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.38 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.590: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.591: Dma_PatchSrc (.L__pc.591.LD), (.L__movme_tmp.1), (.L__pc.591.LD)
	.p2align 4
	.L__pc.591.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.592
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.592: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.593
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.eax+0) + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.593: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.594: Dma_PatchSrc (.L__pc.594.LD), (.L__movme_tmp.1), (.L__pc.594.LD)
	.p2align 4
	.L__pc.594.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.595
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.595: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.596
	.L__pc.596: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.597
	
	.L__pc.597: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.598
	
	.p2align 4
	.L__pc.598: Dma_PatchDst (.L__pc.598.ST), (.L__movme_cp.32), (.L__pc.598.ST)
	.L__pc.598.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.599
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.599: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.600
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.600: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.601
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.601: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.602
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.602: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.603
	
	// CG.LOAD4 [.L__movme_cp.42} => .L__movme_tmp.0
	.L__pc.603: Dma_PatchSrc (.L__pc.603.LD), (.L__movme_cp.42), (.L__pc.603.LD)
	.p2align 4
	.L__pc.603.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.604
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.604: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.605
	.L__pc.605: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.606
	
	// CG.LOAD4 [.L__movme_cp.43} => .L__movme_tmp.0
	.L__pc.606: Dma_PatchSrc (.L__pc.606.LD), (.L__movme_cp.43), (.L__pc.606.LD)
	.p2align 4
	.L__pc.606.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.607
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.607: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.608
	.L__pc.608: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.609
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.609: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.38 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.610: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.611: Dma_PatchSrc (.L__pc.611.LD), (.L__movme_tmp.1), (.L__pc.611.LD)
	.p2align 4
	.L__pc.611.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.612
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.612: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.613
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.eax+0) + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.613: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.614: Dma_PatchSrc (.L__pc.614.LD), (.L__movme_tmp.1), (.L__pc.614.LD)
	.p2align 4
	.L__pc.614.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.615
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.615: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.616
	.L__pc.616: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.617
	
	.L__pc.617: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.618
	
	.p2align 4
	.L__pc.618: Dma_PatchDst (.L__pc.618.ST), (.L__movme_cp.44), (.L__pc.618.ST)
	.L__pc.618.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.619
	
	// CG.LOAD4 [.L__movme_cp.33} => .L__movme_tmp.0
	.L__pc.619: Dma_PatchSrc (.L__pc.619.LD), (.L__movme_cp.33), (.L__pc.619.LD)
	.p2align 4
	.L__pc.619.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.620
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.620: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.621
	
	.L__pc.621: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.622
	
	.p2align 4
	.L__pc.622: Dma_PatchDst (.L__pc.622.ST), (.L__movme_cp.9), (.L__pc.622.ST)
	.L__pc.622.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.623
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.623: Dma_PatchSrc (.L__pc.623.LD), (.L__movme_cp.9), (.L__pc.623.LD)
	.p2align 4
	.L__pc.623.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.624
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.624: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.625
	
	.L__pc.625: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.626
	
	.p2align 4
	.L__pc.626: Dma_PatchDst (.L__pc.626.ST), (.L__movme_cp.9), (.L__pc.626.ST)
	.L__pc.626.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.627
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.627: Dma_PatchSrc (.L__pc.627.LD), (.L__movme_cp.8), (.L__pc.627.LD)
	.p2align 4
	.L__pc.627.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.628
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.628: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.629
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.629: Dma_PatchSrc (.L__pc.629.LD), (.L__movme_cp.3), (.L__pc.629.LD)
	.p2align 4
	.L__pc.629.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.630
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.630: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.631
	
	.L__pc.631: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.632
	
	.p2align 4
	.L__pc.632: Dma_PatchDst (.L__pc.632.ST), (.L__movme_cp.4), (.L__pc.632.ST)
	.L__pc.632.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.633
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.633: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.634: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.635: Dma_PatchSrc (.L__pc.635.LD), (.L__movme_tmp.1), (.L__pc.635.LD)
	.p2align 4
	.L__pc.635.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.636
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.636: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.637
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.637: Dma_PatchSrc (.L__pc.637.LD), (.L__movme_cp.9), (.L__pc.637.LD)
	.p2align 4
	.L__pc.637.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.638
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.638: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.639
	
	.L__pc.639: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.640
	
	.p2align 4
	.L__pc.640: Dma_PatchDst (.L__pc.640.ST), ((.L__movme.reg.eax+0)), (.L__pc.640.ST)
	.L__pc.640.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.641
	
	// LABEL .LCI4
	.LCI4:
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.641: Dma_PatchSrc (.L__pc.641.LD), (.L__movme_cp.0), (.L__pc.641.LD)
	.p2align 4
	.L__pc.641.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.642
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.642: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.643
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.643: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.644: Dma_PatchSrc (.L__pc.644.LD), (.L__movme_tmp.1), (.L__pc.644.LD)
	.p2align 4
	.L__pc.644.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.645
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.645: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.646
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.646: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.647: Dma_PatchSrc (.L__pc.647.LD), (.L__movme_tmp.1), (.L__pc.647.LD)
	.p2align 4
	.L__pc.647.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.648
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.648: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.649
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.649: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.650: Dma_PatchSrc (.L__pc.650.LD), (.L__movme_tmp.1), (.L__pc.650.LD)
	.p2align 4
	.L__pc.650.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.651
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.651: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.652
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.652: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.653: Dma_PatchSrc (.L__pc.653.LD), (.L__movme_tmp.1), (.L__pc.653.LD)
	.p2align 4
	.L__pc.653.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.654
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.654: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.655
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.655: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.656: Dma_PatchSrc (.L__pc.656.LD), (.L__movme_tmp.1), (.L__pc.656.LD)
	.p2align 4
	.L__pc.656.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.657
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.657: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.658
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.658: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.659: Dma_PatchSrc (.L__pc.659.LD), (.L__movme_tmp.1), (.L__pc.659.LD)
	.p2align 4
	.L__pc.659.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.660
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.660: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.661
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.661: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.662: Dma_PatchSrc (.L__pc.662.LD), (.L__movme_tmp.1), (.L__pc.662.LD)
	.p2align 4
	.L__pc.662.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.663
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.663: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.664
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.664: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.665: Dma_PatchSrc (.L__pc.665.LD), (.L__movme_tmp.1), (.L__pc.665.LD)
	.p2align 4
	.L__pc.665.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.666
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.666: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.667
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.667: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.668: Dma_PatchSrc (.L__pc.668.LD), (.L__movme_tmp.1), (.L__pc.668.LD)
	.p2align 4
	.L__pc.668.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.669
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.669: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.670
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.670: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.671: Dma_PatchSrc (.L__pc.671.LD), (.L__movme_tmp.1), (.L__pc.671.LD)
	.p2align 4
	.L__pc.671.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.672
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.672: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.673
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.673: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.674: Dma_PatchSrc (.L__pc.674.LD), (.L__movme_tmp.1), (.L__pc.674.LD)
	.p2align 4
	.L__pc.674.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.675
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.675: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.676
	
	.L__pc.676: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.677
	
	.p2align 4
	.L__pc.677: Dma_PatchDst (.L__pc.677.ST), (.L__movme_cp.9), (.L__pc.677.ST)
	.L__pc.677.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.678
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.678: Dma_PatchSrc (.L__pc.678.LD), (.L__movme_cp.9), (.L__pc.678.LD)
	.p2align 4
	.L__pc.678.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.679
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.679: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.680
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.680: Dma_PatchSrc (.L__pc.680.LD), (.L__movme_cp.3), (.L__pc.680.LD)
	.p2align 4
	.L__pc.680.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.681
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.681: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.682
	
	.L__pc.682: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.683
	
	.p2align 4
	.L__pc.683: Dma_PatchDst (.L__pc.683.ST), (.L__movme_cp.4), (.L__pc.683.ST)
	.L__pc.683.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.684
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.684: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.685: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.686: Dma_PatchSrc (.L__pc.686.LD), (.L__movme_tmp.1), (.L__pc.686.LD)
	.p2align 4
	.L__pc.686.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.687
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.687: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.688
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.688: Dma_PatchSrc (.L__pc.688.LD), ((.L__movme.reg.eax+0)), (.L__pc.688.LD)
	.p2align 4
	.L__pc.688.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.689
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.689: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.690
	
	.L__pc.690: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.691
	
	.p2align 4
	.L__pc.691: Dma_PatchDst (.L__pc.691.ST), (.L__movme_cp.9), (.L__pc.691.ST)
	.L__pc.691.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.692
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.692: Dma_PatchSrc (.L__pc.692.LD), (.L__movme_cp.9), (.L__pc.692.LD)
	.p2align 4
	.L__pc.692.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.693
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.693: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.694
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.694: Dma_PatchSrc (.L__pc.694.LD), (.L__movme_cp.3), (.L__pc.694.LD)
	.p2align 4
	.L__pc.694.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.695
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.695: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.696
	
	.L__pc.696: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.697
	
	.p2align 4
	.L__pc.697: Dma_PatchDst (.L__pc.697.ST), (.L__movme_cp.4), (.L__pc.697.ST)
	.L__pc.697.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.698
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.698: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.699: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.700: Dma_PatchSrc (.L__pc.700.LD), (.L__movme_tmp.1), (.L__pc.700.LD)
	.p2align 4
	.L__pc.700.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.701
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.701: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.702
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.702: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.703
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.703: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.704
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.704: Dma_PatchSrc (.L__pc.704.LD), ((.L__movme.reg.eax+0)), (.L__pc.704.LD)
	.p2align 4
	.L__pc.704.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.705
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.705: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.706
	.L__pc.706: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.707
	
	.L__pc.707: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.708
	
	.p2align 4
	.L__pc.708: Dma_PatchDst (.L__pc.708.ST), (.L__movme_cp.35), (.L__pc.708.ST)
	.L__pc.708.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.709
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.709: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.710
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.710: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.711
	
	// CG.LOAD4 [.L__movme_cp.35} => .L__movme_tmp.0
	.L__pc.711: Dma_PatchSrc (.L__pc.711.LD), (.L__movme_cp.35), (.L__pc.711.LD)
	.p2align 4
	.L__pc.711.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.712
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.712: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.713
	.L__pc.713: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.714
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.714: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.36 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.715: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.716: Dma_PatchSrc (.L__pc.716.LD), (.L__movme_tmp.1), (.L__pc.716.LD)
	.p2align 4
	.L__pc.716.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.717
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.717: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.718
	
	.L__pc.718: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.719
	
	.p2align 4
	.L__pc.719: Dma_PatchDst (.L__pc.719.ST), (.L__movme_cp.9), (.L__pc.719.ST)
	.L__pc.719.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.720
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.720: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.721
	
	.p2align 4
	.L__pc.721: Dma_PatchDst (.L__pc.721.ST), (.L__movme_cp.8), (.L__pc.721.ST)
	.L__pc.721.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.722
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.722: Dma_PatchSrc (.L__pc.722.LD), (.L__movme_cp.9), (.L__pc.722.LD)
	.p2align 4
	.L__pc.722.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.723
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.723: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.724
	
	// CG.UNIMPLEMENTED: CMP.4 mem.4(imm.4(R2)) ?= reg.4(eax)
	.L__pc.724: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: COND JMP jne TO imm.4(.LCI3)
	.L__pc.725: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// LABEL .LCI2
	.LCI2:
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.726: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.727
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.727: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.728
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.728: Dma_PatchSrc (.L__pc.728.LD), (.L__movme_cp.3), (.L__pc.728.LD)
	.p2align 4
	.L__pc.728.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.729
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.729: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.730
	
	.L__pc.730: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.731
	
	.p2align 4
	.L__pc.731: Dma_PatchDst (.L__pc.731.ST), (.L__movme_cp.4), (.L__pc.731.ST)
	.L__pc.731.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.732
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.732: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.733: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.734: Dma_PatchSrc (.L__pc.734.LD), (.L__movme_tmp.1), (.L__pc.734.LD)
	.p2align 4
	.L__pc.734.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.735
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.735: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.736
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.736: Dma_PatchSrc (.L__pc.736.LD), (.L__movme_cp.0), (.L__pc.736.LD)
	.p2align 4
	.L__pc.736.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.737
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.737: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.738
	
	.L__pc.738: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.739
	
	.p2align 4
	.L__pc.739: Dma_PatchDst (.L__pc.739.ST), ((.L__movme.reg.eax+0)), (.L__pc.739.ST)
	.L__pc.739.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.740
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.740: Dma_PatchSrc (.L__pc.740.LD), (.L__movme_cp.2), (.L__pc.740.LD)
	.p2align 4
	.L__pc.740.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.741
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.741: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.742
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.742: Dma_PatchSrc (.L__pc.742.LD), ((.L__movme.reg.eax+0)), (.L__pc.742.LD)
	.p2align 4
	.L__pc.742.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.743
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.743: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.744
	
	.L__pc.744: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.745
	
	.p2align 4
	.L__pc.745: Dma_PatchDst (.L__pc.745.ST), (.L__movme_cp.1), (.L__pc.745.ST)
	.L__pc.745.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.746
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.746: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.747: Dma_PatchSrc (.L__pc.747.LD), (.L__movme_tmp.1), (.L__pc.747.LD)
	.p2align 4
	.L__pc.747.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.748
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.748: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.749
	
	.L__pc.749: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.750
	
	.p2align 4
	.L__pc.750: Dma_PatchDst (.L__pc.750.ST), (.L__movme_cp.14), (.L__pc.750.ST)
	.L__pc.750.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.751
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.751: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.752
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.752: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.753
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.753: Dma_PatchSrc (.L__pc.753.LD), (.L__movme_cp.3), (.L__pc.753.LD)
	.p2align 4
	.L__pc.753.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.754
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.754: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.755
	
	.L__pc.755: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.756
	
	.p2align 4
	.L__pc.756: Dma_PatchDst (.L__pc.756.ST), (.L__movme_cp.4), (.L__pc.756.ST)
	.L__pc.756.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.757
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.757: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.758: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.759: Dma_PatchSrc (.L__pc.759.LD), (.L__movme_tmp.1), (.L__pc.759.LD)
	.p2align 4
	.L__pc.759.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.760
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.760: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.761
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.761: Dma_PatchSrc (.L__pc.761.LD), (.L__movme_cp.2), (.L__pc.761.LD)
	.p2align 4
	.L__pc.761.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.762
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.762: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.763
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.763: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.764: Dma_PatchSrc (.L__pc.764.LD), (.L__movme_tmp.1), (.L__pc.764.LD)
	.p2align 4
	.L__pc.764.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.765
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.765: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.766
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.766: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.767: Dma_PatchSrc (.L__pc.767.LD), (.L__movme_tmp.1), (.L__pc.767.LD)
	.p2align 4
	.L__pc.767.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.768
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.768: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.769
	
	.L__pc.769: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.770
	
	.p2align 4
	.L__pc.770: Dma_PatchDst (.L__pc.770.ST), ((.L__movme.reg.eax+0)), (.L__pc.770.ST)
	.L__pc.770.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.771
	
	// CG.COPY4 .L__movme_cp.16 => .L__movme_tmp.0
	.L__pc.771: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.16), 4, .L__pc.772
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.772: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.773
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.773: Dma_PatchSrc (.L__pc.773.LD), (.L__movme_cp.3), (.L__pc.773.LD)
	.p2align 4
	.L__pc.773.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.774
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.774: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.775
	
	.L__pc.775: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.776
	
	.p2align 4
	.L__pc.776: Dma_PatchDst (.L__pc.776.ST), (.L__movme_cp.4), (.L__pc.776.ST)
	.L__pc.776.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.777
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.777: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.778: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.779: Dma_PatchSrc (.L__pc.779.LD), (.L__movme_tmp.1), (.L__pc.779.LD)
	.p2align 4
	.L__pc.779.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.780
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.780: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.781
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.781: Dma_PatchSrc (.L__pc.781.LD), (.L__movme_cp.1), (.L__pc.781.LD)
	.p2align 4
	.L__pc.781.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.782
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.782: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.783
	
	.L__pc.783: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.784
	
	.p2align 4
	.L__pc.784: Dma_PatchDst (.L__pc.784.ST), ((.L__movme.reg.eax+0)), (.L__pc.784.ST)
	.L__pc.784.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.785
	
	// CG.LOAD4 [.L__movme_cp.14} => .L__movme_tmp.0
	.L__pc.785: Dma_PatchSrc (.L__pc.785.LD), (.L__movme_cp.14), (.L__pc.785.LD)
	.p2align 4
	.L__pc.785.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.786
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.786: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.787
	
	.L__pc.787: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.788
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.788: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	.p2align 4
	.L__pc.789: Dma_PatchDst (.L__pc.789.ST), (.L__movme_tmp.1), (.L__pc.789.ST)
	.L__pc.789.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.790
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.790: Dma_PatchSrc (.L__pc.790.LD), (.L__movme_cp.2), (.L__pc.790.LD)
	.p2align 4
	.L__pc.790.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.791
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.791: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.792
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.792: Dma_PatchSrc (.L__pc.792.LD), ((.L__movme.reg.eax+0)), (.L__pc.792.LD)
	.p2align 4
	.L__pc.792.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.793
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.793: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.794
	
	.L__pc.794: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.795
	
	.p2align 4
	.L__pc.795: Dma_PatchDst (.L__pc.795.ST), (.L__movme_cp.1), (.L__pc.795.ST)
	.L__pc.795.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.796
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.796: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.797: Dma_PatchSrc (.L__pc.797.LD), (.L__movme_tmp.1), (.L__pc.797.LD)
	.p2align 4
	.L__pc.797.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.798
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.798: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.799
	
	.L__pc.799: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.800
	
	.p2align 4
	.L__pc.800: Dma_PatchDst (.L__pc.800.ST), (.L__movme_cp.14), (.L__pc.800.ST)
	.L__pc.800.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.801
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.801: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.802
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.802: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.803
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.803: Dma_PatchSrc (.L__pc.803.LD), (.L__movme_cp.3), (.L__pc.803.LD)
	.p2align 4
	.L__pc.803.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.804
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.804: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.805
	
	.L__pc.805: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.806
	
	.p2align 4
	.L__pc.806: Dma_PatchDst (.L__pc.806.ST), (.L__movme_cp.4), (.L__pc.806.ST)
	.L__pc.806.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.807
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.807: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.808: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.809: Dma_PatchSrc (.L__pc.809.LD), (.L__movme_tmp.1), (.L__pc.809.LD)
	.p2align 4
	.L__pc.809.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.810
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.810: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.811
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.811: Dma_PatchSrc (.L__pc.811.LD), (.L__movme_cp.2), (.L__pc.811.LD)
	.p2align 4
	.L__pc.811.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.812
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.812: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.813
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.813: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.814: Dma_PatchSrc (.L__pc.814.LD), (.L__movme_tmp.1), (.L__pc.814.LD)
	.p2align 4
	.L__pc.814.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.815
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.815: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.816
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.816: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.817: Dma_PatchSrc (.L__pc.817.LD), (.L__movme_tmp.1), (.L__pc.817.LD)
	.p2align 4
	.L__pc.817.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.818
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.818: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.819
	
	.L__pc.819: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.820
	
	.p2align 4
	.L__pc.820: Dma_PatchDst (.L__pc.820.ST), ((.L__movme.reg.eax+0)), (.L__pc.820.ST)
	.L__pc.820.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.821
	
	// CG.COPY4 .L__movme_cp.12 => .L__movme_tmp.0
	.L__pc.821: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.12), 4, .L__pc.822
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.822: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.823
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.823: Dma_PatchSrc (.L__pc.823.LD), (.L__movme_cp.3), (.L__pc.823.LD)
	.p2align 4
	.L__pc.823.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.824
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.824: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.825
	
	.L__pc.825: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.826
	
	.p2align 4
	.L__pc.826: Dma_PatchDst (.L__pc.826.ST), (.L__movme_cp.4), (.L__pc.826.ST)
	.L__pc.826.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.827
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.827: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.828: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.829: Dma_PatchSrc (.L__pc.829.LD), (.L__movme_tmp.1), (.L__pc.829.LD)
	.p2align 4
	.L__pc.829.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.830
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.830: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.831
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.831: Dma_PatchSrc (.L__pc.831.LD), (.L__movme_cp.1), (.L__pc.831.LD)
	.p2align 4
	.L__pc.831.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.832
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.832: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.833
	
	.L__pc.833: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.834
	
	.p2align 4
	.L__pc.834: Dma_PatchDst (.L__pc.834.ST), ((.L__movme.reg.eax+0)), (.L__pc.834.ST)
	.L__pc.834.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.835
	
	// CG.LOAD4 [.L__movme_cp.14} => .L__movme_tmp.0
	.L__pc.835: Dma_PatchSrc (.L__pc.835.LD), (.L__movme_cp.14), (.L__pc.835.LD)
	.p2align 4
	.L__pc.835.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.836
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.836: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.837
	
	.L__pc.837: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.838
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.838: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	.p2align 4
	.L__pc.839: Dma_PatchDst (.L__pc.839.ST), (.L__movme_tmp.1), (.L__pc.839.ST)
	.L__pc.839.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.840
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.840: Dma_PatchSrc (.L__pc.840.LD), (.L__movme_cp.2), (.L__pc.840.LD)
	.p2align 4
	.L__pc.840.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.841
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.841: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.842
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.842: Dma_PatchSrc (.L__pc.842.LD), ((.L__movme.reg.eax+0)), (.L__pc.842.LD)
	.p2align 4
	.L__pc.842.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.843
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.843: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.844
	
	.L__pc.844: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.845
	
	.p2align 4
	.L__pc.845: Dma_PatchDst (.L__pc.845.ST), (.L__movme_cp.1), (.L__pc.845.ST)
	.L__pc.845.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.846
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.846: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.847
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.847: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.848
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.848: Dma_PatchSrc (.L__pc.848.LD), (.L__movme_cp.3), (.L__pc.848.LD)
	.p2align 4
	.L__pc.848.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.849
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.849: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.850
	
	.L__pc.850: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.851
	
	.p2align 4
	.L__pc.851: Dma_PatchDst (.L__pc.851.ST), (.L__movme_cp.4), (.L__pc.851.ST)
	.L__pc.851.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.852
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.852: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.853: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.854: Dma_PatchSrc (.L__pc.854.LD), (.L__movme_tmp.1), (.L__pc.854.LD)
	.p2align 4
	.L__pc.854.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.855
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.855: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.856
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.856: Dma_PatchSrc (.L__pc.856.LD), (.L__movme_cp.2), (.L__pc.856.LD)
	.p2align 4
	.L__pc.856.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.857
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.857: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.858
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.858: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.859: Dma_PatchSrc (.L__pc.859.LD), (.L__movme_tmp.1), (.L__pc.859.LD)
	.p2align 4
	.L__pc.859.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.860
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.860: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.861
	
	.L__pc.861: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.862
	
	.p2align 4
	.L__pc.862: Dma_PatchDst (.L__pc.862.ST), ((.L__movme.reg.eax+0)), (.L__pc.862.ST)
	.L__pc.862.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.863
	
	// CG.COPY4 .L__movme_cp.11 => .L__movme_tmp.0
	.L__pc.863: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.11), 4, .L__pc.864
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.864: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.865
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.865: Dma_PatchSrc (.L__pc.865.LD), (.L__movme_cp.3), (.L__pc.865.LD)
	.p2align 4
	.L__pc.865.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.866
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.866: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.867
	
	.L__pc.867: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.868
	
	.p2align 4
	.L__pc.868: Dma_PatchDst (.L__pc.868.ST), (.L__movme_cp.4), (.L__pc.868.ST)
	.L__pc.868.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.869
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.869: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.870: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.871: Dma_PatchSrc (.L__pc.871.LD), (.L__movme_tmp.1), (.L__pc.871.LD)
	.p2align 4
	.L__pc.871.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.872
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.872: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.873
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.873: Dma_PatchSrc (.L__pc.873.LD), (.L__movme_cp.1), (.L__pc.873.LD)
	.p2align 4
	.L__pc.873.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.874
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.874: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.875
	
	.L__pc.875: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.876
	
	.p2align 4
	.L__pc.876: Dma_PatchDst (.L__pc.876.ST), ((.L__movme.reg.eax+0)), (.L__pc.876.ST)
	.L__pc.876.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.877
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.877: Dma_PatchSrc (.L__pc.877.LD), (.L__movme_cp.2), (.L__pc.877.LD)
	.p2align 4
	.L__pc.877.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.878
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.878: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.879
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.879: Dma_PatchSrc (.L__pc.879.LD), ((.L__movme.reg.eax+0)), (.L__pc.879.LD)
	.p2align 4
	.L__pc.879.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.880
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.880: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.881
	
	.L__pc.881: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.882
	
	.p2align 4
	.L__pc.882: Dma_PatchDst (.L__pc.882.ST), (.L__movme_cp.1), (.L__pc.882.ST)
	.L__pc.882.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.883
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.883: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.884
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.884: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.885
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.885: Dma_PatchSrc (.L__pc.885.LD), (.L__movme_cp.3), (.L__pc.885.LD)
	.p2align 4
	.L__pc.885.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.886
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.886: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.887
	
	.L__pc.887: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.888
	
	.p2align 4
	.L__pc.888: Dma_PatchDst (.L__pc.888.ST), (.L__movme_cp.4), (.L__pc.888.ST)
	.L__pc.888.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.889
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.889: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.890: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.891: Dma_PatchSrc (.L__pc.891.LD), (.L__movme_tmp.1), (.L__pc.891.LD)
	.p2align 4
	.L__pc.891.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.892
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.892: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.893
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.893: Dma_PatchSrc (.L__pc.893.LD), (.L__movme_cp.2), (.L__pc.893.LD)
	.p2align 4
	.L__pc.893.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.894
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.894: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.895
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.895: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.896: Dma_PatchSrc (.L__pc.896.LD), (.L__movme_tmp.1), (.L__pc.896.LD)
	.p2align 4
	.L__pc.896.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.897
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.897: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.898
	
	.L__pc.898: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.899
	
	.p2align 4
	.L__pc.899: Dma_PatchDst (.L__pc.899.ST), ((.L__movme.reg.eax+0)), (.L__pc.899.ST)
	.L__pc.899.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.900
	
	// CG.COPY4 .L__movme_cp.10 => .L__movme_tmp.0
	.L__pc.900: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.10), 4, .L__pc.901
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.901: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.902
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.902: Dma_PatchSrc (.L__pc.902.LD), (.L__movme_cp.3), (.L__pc.902.LD)
	.p2align 4
	.L__pc.902.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.903
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.903: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.904
	
	.L__pc.904: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.905
	
	.p2align 4
	.L__pc.905: Dma_PatchDst (.L__pc.905.ST), (.L__movme_cp.4), (.L__pc.905.ST)
	.L__pc.905.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.906
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.906: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.907: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.908: Dma_PatchSrc (.L__pc.908.LD), (.L__movme_tmp.1), (.L__pc.908.LD)
	.p2align 4
	.L__pc.908.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.909
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.909: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.910
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.910: Dma_PatchSrc (.L__pc.910.LD), (.L__movme_cp.1), (.L__pc.910.LD)
	.p2align 4
	.L__pc.910.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.911
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.911: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.912
	
	.L__pc.912: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.913
	
	.p2align 4
	.L__pc.913: Dma_PatchDst (.L__pc.913.ST), ((.L__movme.reg.eax+0)), (.L__pc.913.ST)
	.L__pc.913.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.914
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.914: Dma_PatchSrc (.L__pc.914.LD), (.L__movme_cp.2), (.L__pc.914.LD)
	.p2align 4
	.L__pc.914.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.915
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.915: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.916
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.916: Dma_PatchSrc (.L__pc.916.LD), ((.L__movme.reg.eax+0)), (.L__pc.916.LD)
	.p2align 4
	.L__pc.916.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.917
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.917: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.918
	
	.L__pc.918: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.919
	
	.p2align 4
	.L__pc.919: Dma_PatchDst (.L__pc.919.ST), (.L__movme_cp.1), (.L__pc.919.ST)
	.L__pc.919.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.920
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.920: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.921
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.921: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.922
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.922: Dma_PatchSrc (.L__pc.922.LD), (.L__movme_cp.3), (.L__pc.922.LD)
	.p2align 4
	.L__pc.922.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.923
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.923: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.924
	
	.L__pc.924: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.925
	
	.p2align 4
	.L__pc.925: Dma_PatchDst (.L__pc.925.ST), (.L__movme_cp.4), (.L__pc.925.ST)
	.L__pc.925.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.926
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.926: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.927: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.928: Dma_PatchSrc (.L__pc.928.LD), (.L__movme_tmp.1), (.L__pc.928.LD)
	.p2align 4
	.L__pc.928.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.929
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.929: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.930
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.930: Dma_PatchSrc (.L__pc.930.LD), (.L__movme_cp.2), (.L__pc.930.LD)
	.p2align 4
	.L__pc.930.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.931
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.931: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.932
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.932: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.933: Dma_PatchSrc (.L__pc.933.LD), (.L__movme_tmp.1), (.L__pc.933.LD)
	.p2align 4
	.L__pc.933.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.934
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.934: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.935
	
	.L__pc.935: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.936
	
	.p2align 4
	.L__pc.936: Dma_PatchDst (.L__pc.936.ST), ((.L__movme.reg.eax+0)), (.L__pc.936.ST)
	.L__pc.936.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.937
	
	// CG.COPY4 .L__movme_cp.9 => .L__movme_tmp.0
	.L__pc.937: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.9), 4, .L__pc.938
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.938: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.939
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.939: Dma_PatchSrc (.L__pc.939.LD), (.L__movme_cp.3), (.L__pc.939.LD)
	.p2align 4
	.L__pc.939.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.940
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.940: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.941
	
	.L__pc.941: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.942
	
	.p2align 4
	.L__pc.942: Dma_PatchDst (.L__pc.942.ST), (.L__movme_cp.4), (.L__pc.942.ST)
	.L__pc.942.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.943
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.943: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.944: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.945: Dma_PatchSrc (.L__pc.945.LD), (.L__movme_tmp.1), (.L__pc.945.LD)
	.p2align 4
	.L__pc.945.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.946
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.946: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.947
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.947: Dma_PatchSrc (.L__pc.947.LD), (.L__movme_cp.1), (.L__pc.947.LD)
	.p2align 4
	.L__pc.947.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.948
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.948: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.949
	
	.L__pc.949: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.950
	
	.p2align 4
	.L__pc.950: Dma_PatchDst (.L__pc.950.ST), ((.L__movme.reg.eax+0)), (.L__pc.950.ST)
	.L__pc.950.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.951
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.951: Dma_PatchSrc (.L__pc.951.LD), (.L__movme_cp.2), (.L__pc.951.LD)
	.p2align 4
	.L__pc.951.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.952
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.952: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.953
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.953: Dma_PatchSrc (.L__pc.953.LD), ((.L__movme.reg.eax+0)), (.L__pc.953.LD)
	.p2align 4
	.L__pc.953.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.954
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.954: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.955
	
	.L__pc.955: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.956
	
	.p2align 4
	.L__pc.956: Dma_PatchDst (.L__pc.956.ST), (.L__movme_cp.1), (.L__pc.956.ST)
	.L__pc.956.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.957
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.957: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.958
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.958: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.959
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.959: Dma_PatchSrc (.L__pc.959.LD), (.L__movme_cp.3), (.L__pc.959.LD)
	.p2align 4
	.L__pc.959.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.960
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.960: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.961
	
	.L__pc.961: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.962
	
	.p2align 4
	.L__pc.962: Dma_PatchDst (.L__pc.962.ST), (.L__movme_cp.4), (.L__pc.962.ST)
	.L__pc.962.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.963
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.963: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.964: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.965: Dma_PatchSrc (.L__pc.965.LD), (.L__movme_tmp.1), (.L__pc.965.LD)
	.p2align 4
	.L__pc.965.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.966
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.966: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.967
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.967: Dma_PatchSrc (.L__pc.967.LD), (.L__movme_cp.2), (.L__pc.967.LD)
	.p2align 4
	.L__pc.967.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.968
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.968: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.969
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.969: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.970: Dma_PatchSrc (.L__pc.970.LD), (.L__movme_tmp.1), (.L__pc.970.LD)
	.p2align 4
	.L__pc.970.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.971
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.971: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.972
	
	.L__pc.972: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.973
	
	.p2align 4
	.L__pc.973: Dma_PatchDst (.L__pc.973.ST), ((.L__movme.reg.eax+0)), (.L__pc.973.ST)
	.L__pc.973.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.974
	
	// CG.COPY4 .L__movme_cp.8 => .L__movme_tmp.0
	.L__pc.974: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.8), 4, .L__pc.975
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.975: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.976
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.976: Dma_PatchSrc (.L__pc.976.LD), (.L__movme_cp.3), (.L__pc.976.LD)
	.p2align 4
	.L__pc.976.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.977
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.977: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.978
	
	.L__pc.978: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.979
	
	.p2align 4
	.L__pc.979: Dma_PatchDst (.L__pc.979.ST), (.L__movme_cp.4), (.L__pc.979.ST)
	.L__pc.979.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.980
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.980: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.981: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.982: Dma_PatchSrc (.L__pc.982.LD), (.L__movme_tmp.1), (.L__pc.982.LD)
	.p2align 4
	.L__pc.982.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.983
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.983: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.984
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.984: Dma_PatchSrc (.L__pc.984.LD), (.L__movme_cp.1), (.L__pc.984.LD)
	.p2align 4
	.L__pc.984.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.985
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.985: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.986
	
	.L__pc.986: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.987
	
	.p2align 4
	.L__pc.987: Dma_PatchDst (.L__pc.987.ST), ((.L__movme.reg.eax+0)), (.L__pc.987.ST)
	.L__pc.987.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.988
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.988: Dma_PatchSrc (.L__pc.988.LD), (.L__movme_cp.2), (.L__pc.988.LD)
	.p2align 4
	.L__pc.988.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.989
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.989: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.990
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.990: Dma_PatchSrc (.L__pc.990.LD), ((.L__movme.reg.eax+0)), (.L__pc.990.LD)
	.p2align 4
	.L__pc.990.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.991
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.991: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.992
	
	.L__pc.992: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.993
	
	.p2align 4
	.L__pc.993: Dma_PatchDst (.L__pc.993.ST), (.L__movme_cp.1), (.L__pc.993.ST)
	.L__pc.993.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.994
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.994: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.995
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.995: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.996
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.996: Dma_PatchSrc (.L__pc.996.LD), (.L__movme_cp.3), (.L__pc.996.LD)
	.p2align 4
	.L__pc.996.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.997
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.997: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.998
	
	.L__pc.998: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.999
	
	.p2align 4
	.L__pc.999: Dma_PatchDst (.L__pc.999.ST), (.L__movme_cp.4), (.L__pc.999.ST)
	.L__pc.999.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1000
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1000: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1001: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1002: Dma_PatchSrc (.L__pc.1002.LD), (.L__movme_tmp.1), (.L__pc.1002.LD)
	.p2align 4
	.L__pc.1002.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1003
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1003: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1004
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1004: Dma_PatchSrc (.L__pc.1004.LD), (.L__movme_cp.2), (.L__pc.1004.LD)
	.p2align 4
	.L__pc.1004.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1005
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1005: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1006
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1006: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1007: Dma_PatchSrc (.L__pc.1007.LD), (.L__movme_tmp.1), (.L__pc.1007.LD)
	.p2align 4
	.L__pc.1007.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1008
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1008: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1009
	
	.L__pc.1009: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1010
	
	.p2align 4
	.L__pc.1010: Dma_PatchDst (.L__pc.1010.ST), ((.L__movme.reg.eax+0)), (.L__pc.1010.ST)
	.L__pc.1010.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1011
	
	// CG.COPY4 .L__movme_cp.7 => .L__movme_tmp.0
	.L__pc.1011: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.7), 4, .L__pc.1012
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1012: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1013
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1013: Dma_PatchSrc (.L__pc.1013.LD), (.L__movme_cp.3), (.L__pc.1013.LD)
	.p2align 4
	.L__pc.1013.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1014
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1014: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1015
	
	.L__pc.1015: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1016
	
	.p2align 4
	.L__pc.1016: Dma_PatchDst (.L__pc.1016.ST), (.L__movme_cp.4), (.L__pc.1016.ST)
	.L__pc.1016.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1017
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1017: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1018: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1019: Dma_PatchSrc (.L__pc.1019.LD), (.L__movme_tmp.1), (.L__pc.1019.LD)
	.p2align 4
	.L__pc.1019.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1020
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1020: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1021
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1021: Dma_PatchSrc (.L__pc.1021.LD), (.L__movme_cp.1), (.L__pc.1021.LD)
	.p2align 4
	.L__pc.1021.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1022
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1022: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1023
	
	.L__pc.1023: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1024
	
	.p2align 4
	.L__pc.1024: Dma_PatchDst (.L__pc.1024.ST), ((.L__movme.reg.eax+0)), (.L__pc.1024.ST)
	.L__pc.1024.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1025
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1025: Dma_PatchSrc (.L__pc.1025.LD), (.L__movme_cp.2), (.L__pc.1025.LD)
	.p2align 4
	.L__pc.1025.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1026
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1026: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1027
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.1027: Dma_PatchSrc (.L__pc.1027.LD), ((.L__movme.reg.eax+0)), (.L__pc.1027.LD)
	.p2align 4
	.L__pc.1027.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1028
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1028: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1029
	
	.L__pc.1029: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1030
	
	.p2align 4
	.L__pc.1030: Dma_PatchDst (.L__pc.1030.ST), (.L__movme_cp.1), (.L__pc.1030.ST)
	.L__pc.1030.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1031
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1031: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1032
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1032: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1033
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1033: Dma_PatchSrc (.L__pc.1033.LD), (.L__movme_cp.3), (.L__pc.1033.LD)
	.p2align 4
	.L__pc.1033.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1034
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1034: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1035
	
	.L__pc.1035: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1036
	
	.p2align 4
	.L__pc.1036: Dma_PatchDst (.L__pc.1036.ST), (.L__movme_cp.4), (.L__pc.1036.ST)
	.L__pc.1036.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1037
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1037: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1038: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1039: Dma_PatchSrc (.L__pc.1039.LD), (.L__movme_tmp.1), (.L__pc.1039.LD)
	.p2align 4
	.L__pc.1039.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1040
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1040: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1041
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1041: Dma_PatchSrc (.L__pc.1041.LD), (.L__movme_cp.2), (.L__pc.1041.LD)
	.p2align 4
	.L__pc.1041.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1042
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1042: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1043
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1043: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1044: Dma_PatchSrc (.L__pc.1044.LD), (.L__movme_tmp.1), (.L__pc.1044.LD)
	.p2align 4
	.L__pc.1044.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1045
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1045: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1046
	
	.L__pc.1046: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1047
	
	.p2align 4
	.L__pc.1047: Dma_PatchDst (.L__pc.1047.ST), ((.L__movme.reg.eax+0)), (.L__pc.1047.ST)
	.L__pc.1047.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1048
	
	// CG.COPY4 .L__movme_cp.0 => .L__movme_tmp.0
	.L__pc.1048: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.0), 4, .L__pc.1049
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1049: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1050
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1050: Dma_PatchSrc (.L__pc.1050.LD), (.L__movme_cp.3), (.L__pc.1050.LD)
	.p2align 4
	.L__pc.1050.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1051
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1051: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1052
	
	.L__pc.1052: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1053
	
	.p2align 4
	.L__pc.1053: Dma_PatchDst (.L__pc.1053.ST), (.L__movme_cp.4), (.L__pc.1053.ST)
	.L__pc.1053.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1054
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1054: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1055: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1056: Dma_PatchSrc (.L__pc.1056.LD), (.L__movme_tmp.1), (.L__pc.1056.LD)
	.p2align 4
	.L__pc.1056.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1057
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1057: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1058
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1058: Dma_PatchSrc (.L__pc.1058.LD), (.L__movme_cp.1), (.L__pc.1058.LD)
	.p2align 4
	.L__pc.1058.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1059
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1059: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1060
	
	.L__pc.1060: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1061
	
	.p2align 4
	.L__pc.1061: Dma_PatchDst (.L__pc.1061.ST), ((.L__movme.reg.eax+0)), (.L__pc.1061.ST)
	.L__pc.1061.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1062
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1062: Dma_PatchSrc (.L__pc.1062.LD), (.L__movme_cp.2), (.L__pc.1062.LD)
	.p2align 4
	.L__pc.1062.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1063
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1063: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1064
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.1064: Dma_PatchSrc (.L__pc.1064.LD), ((.L__movme.reg.eax+0)), (.L__pc.1064.LD)
	.p2align 4
	.L__pc.1064.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1065
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1065: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1066
	
	.L__pc.1066: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1067
	
	.p2align 4
	.L__pc.1067: Dma_PatchDst (.L__pc.1067.ST), (.L__movme_cp.1), (.L__pc.1067.ST)
	.L__pc.1067.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1068
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1068: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1069
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1069: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1070
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1070: Dma_PatchSrc (.L__pc.1070.LD), (.L__movme_cp.3), (.L__pc.1070.LD)
	.p2align 4
	.L__pc.1070.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1071
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1071: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1072
	
	.L__pc.1072: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1073
	
	.p2align 4
	.L__pc.1073: Dma_PatchDst (.L__pc.1073.ST), (.L__movme_cp.4), (.L__pc.1073.ST)
	.L__pc.1073.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1074
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1074: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1075: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1076: Dma_PatchSrc (.L__pc.1076.LD), (.L__movme_tmp.1), (.L__pc.1076.LD)
	.p2align 4
	.L__pc.1076.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1077
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1077: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1078
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1078: Dma_PatchSrc (.L__pc.1078.LD), (.L__movme_cp.2), (.L__pc.1078.LD)
	.p2align 4
	.L__pc.1078.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1079
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1079: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1080
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1080: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1081: Dma_PatchSrc (.L__pc.1081.LD), (.L__movme_tmp.1), (.L__pc.1081.LD)
	.p2align 4
	.L__pc.1081.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1082
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1082: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1083
	
	.L__pc.1083: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1084
	
	.p2align 4
	.L__pc.1084: Dma_PatchDst (.L__pc.1084.ST), ((.L__movme.reg.eax+0)), (.L__pc.1084.ST)
	.L__pc.1084.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1085
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1085: Dma_PatchSrc (.L__pc.1085.LD), (.L__movme_cp.1), (.L__pc.1085.LD)
	.p2align 4
	.L__pc.1085.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1086
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1086: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1087
	
	.L__pc.1087: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1088
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1088: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1089
	
	// JMP reg.4(eax)
	.L__pc.1089: Dma_PatchLink (.L__pc.1089.J), ((.L__movme.reg.eax+0)), (.L__pc.1089.J)
	.p2align 4
	.L__pc.1089.J: Dma_ByteCopy  (.L__movme_tmp.0), (.L__movme_tmp.0), 1, .L__pc.1090
	
	// LABEL .Lf6
	.Lf6:
	
	// GLOBAL Dma_UCode_Main
	.global Dma_UCode_Main
	
	// LABEL Dma_UCode_Main
	Dma_UCode_Main:
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.1090: Dma_PatchSrc (.L__pc.1090.LD), (.L__movme_cp.0), (.L__pc.1090.LD)
	.p2align 4
	.L__pc.1090.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1091
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1091: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1092
	
	.L__pc.1092: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1093
	
	.p2align 4
	.L__pc.1093: Dma_PatchDst (.L__pc.1093.ST), (.L__movme_cp.1), (.L__pc.1093.ST)
	.L__pc.1093.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1094
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1094: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1095
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1095: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1096
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1096: Dma_PatchSrc (.L__pc.1096.LD), (.L__movme_cp.3), (.L__pc.1096.LD)
	.p2align 4
	.L__pc.1096.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1097
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1097: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1098
	
	.L__pc.1098: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1099
	
	.p2align 4
	.L__pc.1099: Dma_PatchDst (.L__pc.1099.ST), (.L__movme_cp.4), (.L__pc.1099.ST)
	.L__pc.1099.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1100
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1100: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1101: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1102: Dma_PatchSrc (.L__pc.1102.LD), (.L__movme_tmp.1), (.L__pc.1102.LD)
	.p2align 4
	.L__pc.1102.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1103
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1103: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1104
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1104: Dma_PatchSrc (.L__pc.1104.LD), (.L__movme_cp.2), (.L__pc.1104.LD)
	.p2align 4
	.L__pc.1104.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1105
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1105: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1106
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1106: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1107: Dma_PatchSrc (.L__pc.1107.LD), (.L__movme_tmp.1), (.L__pc.1107.LD)
	.p2align 4
	.L__pc.1107.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1108
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1108: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1109
	
	.L__pc.1109: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1110
	
	.p2align 4
	.L__pc.1110: Dma_PatchDst (.L__pc.1110.ST), ((.L__movme.reg.eax+0)), (.L__pc.1110.ST)
	.L__pc.1110.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1111
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1111: Dma_PatchSrc (.L__pc.1111.LD), (.L__movme_cp.2), (.L__pc.1111.LD)
	.p2align 4
	.L__pc.1111.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1112
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1112: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1113
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1113: Dma_PatchSrc (.L__pc.1113.LD), (.L__movme_cp.3), (.L__pc.1113.LD)
	.p2align 4
	.L__pc.1113.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1114
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1114: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1115
	
	.L__pc.1115: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1116
	
	.p2align 4
	.L__pc.1116: Dma_PatchDst (.L__pc.1116.ST), (.L__movme_cp.4), (.L__pc.1116.ST)
	.L__pc.1116.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1117
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1117: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1118: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1119: Dma_PatchSrc (.L__pc.1119.LD), (.L__movme_tmp.1), (.L__pc.1119.LD)
	.p2align 4
	.L__pc.1119.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1120
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1120: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1121
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1121: Dma_PatchSrc (.L__pc.1121.LD), (.L__movme_cp.1), (.L__pc.1121.LD)
	.p2align 4
	.L__pc.1121.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1122
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1122: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1123
	
	.L__pc.1123: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1124
	
	.p2align 4
	.L__pc.1124: Dma_PatchDst (.L__pc.1124.ST), ((.L__movme.reg.eax+0)), (.L__pc.1124.ST)
	.L__pc.1124.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1125
	
	// CG.LOAD4 [.L__movme_cp.7} => .L__movme_tmp.0
	.L__pc.1125: Dma_PatchSrc (.L__pc.1125.LD), (.L__movme_cp.7), (.L__pc.1125.LD)
	.p2align 4
	.L__pc.1125.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1126
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1126: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1127
	
	.L__pc.1127: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1128
	
	.p2align 4
	.L__pc.1128: Dma_PatchDst (.L__pc.1128.ST), (.L__movme_cp.1), (.L__pc.1128.ST)
	.L__pc.1128.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1129
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1129: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1130
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1130: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1131
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1131: Dma_PatchSrc (.L__pc.1131.LD), (.L__movme_cp.3), (.L__pc.1131.LD)
	.p2align 4
	.L__pc.1131.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1132
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1132: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1133
	
	.L__pc.1133: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1134
	
	.p2align 4
	.L__pc.1134: Dma_PatchDst (.L__pc.1134.ST), (.L__movme_cp.4), (.L__pc.1134.ST)
	.L__pc.1134.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1135
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1135: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1136: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1137: Dma_PatchSrc (.L__pc.1137.LD), (.L__movme_tmp.1), (.L__pc.1137.LD)
	.p2align 4
	.L__pc.1137.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1138
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1138: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1139
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1139: Dma_PatchSrc (.L__pc.1139.LD), (.L__movme_cp.2), (.L__pc.1139.LD)
	.p2align 4
	.L__pc.1139.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1140
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1140: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1141
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1141: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1142: Dma_PatchSrc (.L__pc.1142.LD), (.L__movme_tmp.1), (.L__pc.1142.LD)
	.p2align 4
	.L__pc.1142.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1143
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1143: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1144
	
	.L__pc.1144: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1145
	
	.p2align 4
	.L__pc.1145: Dma_PatchDst (.L__pc.1145.ST), ((.L__movme.reg.eax+0)), (.L__pc.1145.ST)
	.L__pc.1145.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1146
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1146: Dma_PatchSrc (.L__pc.1146.LD), (.L__movme_cp.2), (.L__pc.1146.LD)
	.p2align 4
	.L__pc.1146.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1147
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1147: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1148
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1148: Dma_PatchSrc (.L__pc.1148.LD), (.L__movme_cp.3), (.L__pc.1148.LD)
	.p2align 4
	.L__pc.1148.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1149
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1149: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1150
	
	.L__pc.1150: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1151
	
	.p2align 4
	.L__pc.1151: Dma_PatchDst (.L__pc.1151.ST), (.L__movme_cp.4), (.L__pc.1151.ST)
	.L__pc.1151.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1152
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1152: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1153: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1154: Dma_PatchSrc (.L__pc.1154.LD), (.L__movme_tmp.1), (.L__pc.1154.LD)
	.p2align 4
	.L__pc.1154.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1155
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1155: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1156
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1156: Dma_PatchSrc (.L__pc.1156.LD), (.L__movme_cp.1), (.L__pc.1156.LD)
	.p2align 4
	.L__pc.1156.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1157
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1157: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1158
	
	.L__pc.1158: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1159
	
	.p2align 4
	.L__pc.1159: Dma_PatchDst (.L__pc.1159.ST), ((.L__movme.reg.eax+0)), (.L__pc.1159.ST)
	.L__pc.1159.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1160
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.1160: Dma_PatchSrc (.L__pc.1160.LD), (.L__movme_cp.8), (.L__pc.1160.LD)
	.p2align 4
	.L__pc.1160.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1161
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1161: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1162
	
	.L__pc.1162: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1163
	
	.p2align 4
	.L__pc.1163: Dma_PatchDst (.L__pc.1163.ST), (.L__movme_cp.1), (.L__pc.1163.ST)
	.L__pc.1163.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1164
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1164: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1165
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1165: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1166
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1166: Dma_PatchSrc (.L__pc.1166.LD), (.L__movme_cp.3), (.L__pc.1166.LD)
	.p2align 4
	.L__pc.1166.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1167
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1167: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1168
	
	.L__pc.1168: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1169
	
	.p2align 4
	.L__pc.1169: Dma_PatchDst (.L__pc.1169.ST), (.L__movme_cp.4), (.L__pc.1169.ST)
	.L__pc.1169.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1170
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1170: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1171: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1172: Dma_PatchSrc (.L__pc.1172.LD), (.L__movme_tmp.1), (.L__pc.1172.LD)
	.p2align 4
	.L__pc.1172.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1173
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1173: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1174
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1174: Dma_PatchSrc (.L__pc.1174.LD), (.L__movme_cp.2), (.L__pc.1174.LD)
	.p2align 4
	.L__pc.1174.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1175
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1175: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1176
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1176: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1177: Dma_PatchSrc (.L__pc.1177.LD), (.L__movme_tmp.1), (.L__pc.1177.LD)
	.p2align 4
	.L__pc.1177.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1178
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1178: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1179
	
	.L__pc.1179: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1180
	
	.p2align 4
	.L__pc.1180: Dma_PatchDst (.L__pc.1180.ST), ((.L__movme.reg.eax+0)), (.L__pc.1180.ST)
	.L__pc.1180.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1181
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1181: Dma_PatchSrc (.L__pc.1181.LD), (.L__movme_cp.2), (.L__pc.1181.LD)
	.p2align 4
	.L__pc.1181.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1182
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1182: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1183
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1183: Dma_PatchSrc (.L__pc.1183.LD), (.L__movme_cp.3), (.L__pc.1183.LD)
	.p2align 4
	.L__pc.1183.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1184
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1184: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1185
	
	.L__pc.1185: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1186
	
	.p2align 4
	.L__pc.1186: Dma_PatchDst (.L__pc.1186.ST), (.L__movme_cp.4), (.L__pc.1186.ST)
	.L__pc.1186.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1187
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1187: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1188: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1189: Dma_PatchSrc (.L__pc.1189.LD), (.L__movme_tmp.1), (.L__pc.1189.LD)
	.p2align 4
	.L__pc.1189.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1190
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1190: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1191
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1191: Dma_PatchSrc (.L__pc.1191.LD), (.L__movme_cp.1), (.L__pc.1191.LD)
	.p2align 4
	.L__pc.1191.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1192
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1192: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1193
	
	.L__pc.1193: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1194
	
	.p2align 4
	.L__pc.1194: Dma_PatchDst (.L__pc.1194.ST), ((.L__movme.reg.eax+0)), (.L__pc.1194.ST)
	.L__pc.1194.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1195
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.1195: Dma_PatchSrc (.L__pc.1195.LD), (.L__movme_cp.9), (.L__pc.1195.LD)
	.p2align 4
	.L__pc.1195.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1196
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1196: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1197
	
	.L__pc.1197: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1198
	
	.p2align 4
	.L__pc.1198: Dma_PatchDst (.L__pc.1198.ST), (.L__movme_cp.1), (.L__pc.1198.ST)
	.L__pc.1198.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1199
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1199: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1200
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1200: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1201
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1201: Dma_PatchSrc (.L__pc.1201.LD), (.L__movme_cp.3), (.L__pc.1201.LD)
	.p2align 4
	.L__pc.1201.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1202
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1202: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1203
	
	.L__pc.1203: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1204
	
	.p2align 4
	.L__pc.1204: Dma_PatchDst (.L__pc.1204.ST), (.L__movme_cp.4), (.L__pc.1204.ST)
	.L__pc.1204.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1205
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1205: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1206: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1207: Dma_PatchSrc (.L__pc.1207.LD), (.L__movme_tmp.1), (.L__pc.1207.LD)
	.p2align 4
	.L__pc.1207.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1208
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1208: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1209
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1209: Dma_PatchSrc (.L__pc.1209.LD), (.L__movme_cp.2), (.L__pc.1209.LD)
	.p2align 4
	.L__pc.1209.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1210
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1210: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1211
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1211: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1212: Dma_PatchSrc (.L__pc.1212.LD), (.L__movme_tmp.1), (.L__pc.1212.LD)
	.p2align 4
	.L__pc.1212.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1213
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1213: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1214
	
	.L__pc.1214: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1215
	
	.p2align 4
	.L__pc.1215: Dma_PatchDst (.L__pc.1215.ST), ((.L__movme.reg.eax+0)), (.L__pc.1215.ST)
	.L__pc.1215.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1216
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1216: Dma_PatchSrc (.L__pc.1216.LD), (.L__movme_cp.2), (.L__pc.1216.LD)
	.p2align 4
	.L__pc.1216.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1217
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1217: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1218
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1218: Dma_PatchSrc (.L__pc.1218.LD), (.L__movme_cp.3), (.L__pc.1218.LD)
	.p2align 4
	.L__pc.1218.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1219
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1219: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1220
	
	.L__pc.1220: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1221
	
	.p2align 4
	.L__pc.1221: Dma_PatchDst (.L__pc.1221.ST), (.L__movme_cp.4), (.L__pc.1221.ST)
	.L__pc.1221.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1222
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1222: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1223: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1224: Dma_PatchSrc (.L__pc.1224.LD), (.L__movme_tmp.1), (.L__pc.1224.LD)
	.p2align 4
	.L__pc.1224.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1225
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1225: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1226
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1226: Dma_PatchSrc (.L__pc.1226.LD), (.L__movme_cp.1), (.L__pc.1226.LD)
	.p2align 4
	.L__pc.1226.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1227
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1227: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1228
	
	.L__pc.1228: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1229
	
	.p2align 4
	.L__pc.1229: Dma_PatchDst (.L__pc.1229.ST), ((.L__movme.reg.eax+0)), (.L__pc.1229.ST)
	.L__pc.1229.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1230
	
	// CG.LOAD4 [.L__movme_cp.10} => .L__movme_tmp.0
	.L__pc.1230: Dma_PatchSrc (.L__pc.1230.LD), (.L__movme_cp.10), (.L__pc.1230.LD)
	.p2align 4
	.L__pc.1230.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1231
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1231: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1232
	
	.L__pc.1232: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1233
	
	.p2align 4
	.L__pc.1233: Dma_PatchDst (.L__pc.1233.ST), (.L__movme_cp.1), (.L__pc.1233.ST)
	.L__pc.1233.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1234
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1234: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1235
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1235: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1236
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1236: Dma_PatchSrc (.L__pc.1236.LD), (.L__movme_cp.3), (.L__pc.1236.LD)
	.p2align 4
	.L__pc.1236.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1237
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1237: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1238
	
	.L__pc.1238: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1239
	
	.p2align 4
	.L__pc.1239: Dma_PatchDst (.L__pc.1239.ST), (.L__movme_cp.4), (.L__pc.1239.ST)
	.L__pc.1239.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1240
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1240: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1241: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1242: Dma_PatchSrc (.L__pc.1242.LD), (.L__movme_tmp.1), (.L__pc.1242.LD)
	.p2align 4
	.L__pc.1242.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1243
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1243: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1244
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1244: Dma_PatchSrc (.L__pc.1244.LD), (.L__movme_cp.2), (.L__pc.1244.LD)
	.p2align 4
	.L__pc.1244.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1245
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1245: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1246
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1246: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1247: Dma_PatchSrc (.L__pc.1247.LD), (.L__movme_tmp.1), (.L__pc.1247.LD)
	.p2align 4
	.L__pc.1247.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1248
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1248: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1249
	
	.L__pc.1249: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1250
	
	.p2align 4
	.L__pc.1250: Dma_PatchDst (.L__pc.1250.ST), ((.L__movme.reg.eax+0)), (.L__pc.1250.ST)
	.L__pc.1250.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1251
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1251: Dma_PatchSrc (.L__pc.1251.LD), (.L__movme_cp.2), (.L__pc.1251.LD)
	.p2align 4
	.L__pc.1251.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1252
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1252: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1253
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1253: Dma_PatchSrc (.L__pc.1253.LD), (.L__movme_cp.3), (.L__pc.1253.LD)
	.p2align 4
	.L__pc.1253.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1254
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1254: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1255
	
	.L__pc.1255: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1256
	
	.p2align 4
	.L__pc.1256: Dma_PatchDst (.L__pc.1256.ST), (.L__movme_cp.4), (.L__pc.1256.ST)
	.L__pc.1256.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1257
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1257: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1258: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1259: Dma_PatchSrc (.L__pc.1259.LD), (.L__movme_tmp.1), (.L__pc.1259.LD)
	.p2align 4
	.L__pc.1259.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1260
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1260: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1261
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1261: Dma_PatchSrc (.L__pc.1261.LD), (.L__movme_cp.1), (.L__pc.1261.LD)
	.p2align 4
	.L__pc.1261.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1262
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1262: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1263
	
	.L__pc.1263: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1264
	
	.p2align 4
	.L__pc.1264: Dma_PatchDst (.L__pc.1264.ST), ((.L__movme.reg.eax+0)), (.L__pc.1264.ST)
	.L__pc.1264.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1265
	
	// CG.LOAD4 [.L__movme_cp.11} => .L__movme_tmp.0
	.L__pc.1265: Dma_PatchSrc (.L__pc.1265.LD), (.L__movme_cp.11), (.L__pc.1265.LD)
	.p2align 4
	.L__pc.1265.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1266
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1266: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1267
	
	.L__pc.1267: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1268
	
	.p2align 4
	.L__pc.1268: Dma_PatchDst (.L__pc.1268.ST), (.L__movme_cp.1), (.L__pc.1268.ST)
	.L__pc.1268.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1269
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1269: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1270
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1270: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1271
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1271: Dma_PatchSrc (.L__pc.1271.LD), (.L__movme_cp.3), (.L__pc.1271.LD)
	.p2align 4
	.L__pc.1271.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1272
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1272: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1273
	
	.L__pc.1273: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1274
	
	.p2align 4
	.L__pc.1274: Dma_PatchDst (.L__pc.1274.ST), (.L__movme_cp.4), (.L__pc.1274.ST)
	.L__pc.1274.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1275
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1275: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1276: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1277: Dma_PatchSrc (.L__pc.1277.LD), (.L__movme_tmp.1), (.L__pc.1277.LD)
	.p2align 4
	.L__pc.1277.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1278
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1278: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1279
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1279: Dma_PatchSrc (.L__pc.1279.LD), (.L__movme_cp.2), (.L__pc.1279.LD)
	.p2align 4
	.L__pc.1279.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1280
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1280: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1281
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1281: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1282: Dma_PatchSrc (.L__pc.1282.LD), (.L__movme_tmp.1), (.L__pc.1282.LD)
	.p2align 4
	.L__pc.1282.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1283
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1283: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1284
	
	.L__pc.1284: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1285
	
	.p2align 4
	.L__pc.1285: Dma_PatchDst (.L__pc.1285.ST), ((.L__movme.reg.eax+0)), (.L__pc.1285.ST)
	.L__pc.1285.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1286
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1286: Dma_PatchSrc (.L__pc.1286.LD), (.L__movme_cp.2), (.L__pc.1286.LD)
	.p2align 4
	.L__pc.1286.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1287
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1287: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1288
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1288: Dma_PatchSrc (.L__pc.1288.LD), (.L__movme_cp.3), (.L__pc.1288.LD)
	.p2align 4
	.L__pc.1288.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1289
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1289: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1290
	
	.L__pc.1290: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1291
	
	.p2align 4
	.L__pc.1291: Dma_PatchDst (.L__pc.1291.ST), (.L__movme_cp.4), (.L__pc.1291.ST)
	.L__pc.1291.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1292
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1292: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1293: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1294: Dma_PatchSrc (.L__pc.1294.LD), (.L__movme_tmp.1), (.L__pc.1294.LD)
	.p2align 4
	.L__pc.1294.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1295
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1295: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1296
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1296: Dma_PatchSrc (.L__pc.1296.LD), (.L__movme_cp.1), (.L__pc.1296.LD)
	.p2align 4
	.L__pc.1296.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1297
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1297: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1298
	
	.L__pc.1298: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1299
	
	.p2align 4
	.L__pc.1299: Dma_PatchDst (.L__pc.1299.ST), ((.L__movme.reg.eax+0)), (.L__pc.1299.ST)
	.L__pc.1299.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1300
	
	// CG.LOAD4 [.L__movme_cp.12} => .L__movme_tmp.0
	.L__pc.1300: Dma_PatchSrc (.L__pc.1300.LD), (.L__movme_cp.12), (.L__pc.1300.LD)
	.p2align 4
	.L__pc.1300.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1301
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1301: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1302
	
	.L__pc.1302: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1303
	
	.p2align 4
	.L__pc.1303: Dma_PatchDst (.L__pc.1303.ST), (.L__movme_cp.1), (.L__pc.1303.ST)
	.L__pc.1303.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1304
	
	// CG.LOAD4 [.L__movme_cp.13} => .L__movme_tmp.0
	.L__pc.1304: Dma_PatchSrc (.L__pc.1304.LD), (.L__movme_cp.13), (.L__pc.1304.LD)
	.p2align 4
	.L__pc.1304.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1305
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1305: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1306
	
	.L__pc.1306: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1307
	
	.p2align 4
	.L__pc.1307: Dma_PatchDst (.L__pc.1307.ST), (.L__movme_cp.14), (.L__pc.1307.ST)
	.L__pc.1307.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1308
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1308: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1309
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1309: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1310
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1310: Dma_PatchSrc (.L__pc.1310.LD), (.L__movme_cp.3), (.L__pc.1310.LD)
	.p2align 4
	.L__pc.1310.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1311
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1311: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1312
	
	.L__pc.1312: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1313
	
	.p2align 4
	.L__pc.1313: Dma_PatchDst (.L__pc.1313.ST), (.L__movme_cp.4), (.L__pc.1313.ST)
	.L__pc.1313.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1314
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1314: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1315: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1316: Dma_PatchSrc (.L__pc.1316.LD), (.L__movme_tmp.1), (.L__pc.1316.LD)
	.p2align 4
	.L__pc.1316.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1317
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1317: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1318
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1318: Dma_PatchSrc (.L__pc.1318.LD), (.L__movme_cp.2), (.L__pc.1318.LD)
	.p2align 4
	.L__pc.1318.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1319
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1319: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1320
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1320: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1321: Dma_PatchSrc (.L__pc.1321.LD), (.L__movme_tmp.1), (.L__pc.1321.LD)
	.p2align 4
	.L__pc.1321.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1322
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1322: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1323
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1323: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1324: Dma_PatchSrc (.L__pc.1324.LD), (.L__movme_tmp.1), (.L__pc.1324.LD)
	.p2align 4
	.L__pc.1324.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1325
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1325: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1326
	
	.L__pc.1326: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1327
	
	.p2align 4
	.L__pc.1327: Dma_PatchDst (.L__pc.1327.ST), ((.L__movme.reg.eax+0)), (.L__pc.1327.ST)
	.L__pc.1327.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1328
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1328: Dma_PatchSrc (.L__pc.1328.LD), (.L__movme_cp.2), (.L__pc.1328.LD)
	.p2align 4
	.L__pc.1328.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1329
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1329: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1330
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1330: Dma_PatchSrc (.L__pc.1330.LD), (.L__movme_cp.3), (.L__pc.1330.LD)
	.p2align 4
	.L__pc.1330.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1331
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1331: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1332
	
	.L__pc.1332: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1333
	
	.p2align 4
	.L__pc.1333: Dma_PatchDst (.L__pc.1333.ST), (.L__movme_cp.4), (.L__pc.1333.ST)
	.L__pc.1333.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1334
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1334: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1335: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1336: Dma_PatchSrc (.L__pc.1336.LD), (.L__movme_tmp.1), (.L__pc.1336.LD)
	.p2align 4
	.L__pc.1336.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1337
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1337: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1338
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1338: Dma_PatchSrc (.L__pc.1338.LD), (.L__movme_cp.1), (.L__pc.1338.LD)
	.p2align 4
	.L__pc.1338.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1339
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1339: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1340
	
	.L__pc.1340: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1341
	
	.p2align 4
	.L__pc.1341: Dma_PatchDst (.L__pc.1341.ST), ((.L__movme.reg.eax+0)), (.L__pc.1341.ST)
	.L__pc.1341.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1342
	
	// CG.LOAD4 [.L__movme_cp.14} => .L__movme_tmp.0
	.L__pc.1342: Dma_PatchSrc (.L__pc.1342.LD), (.L__movme_cp.14), (.L__pc.1342.LD)
	.p2align 4
	.L__pc.1342.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1343
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1343: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1344
	
	.L__pc.1344: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1345
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.1345: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	.p2align 4
	.L__pc.1346: Dma_PatchDst (.L__pc.1346.ST), (.L__movme_tmp.1), (.L__pc.1346.ST)
	.L__pc.1346.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1347
	
	// CG.LOAD4 [.L__movme_cp.16} => .L__movme_tmp.0
	.L__pc.1347: Dma_PatchSrc (.L__pc.1347.LD), (.L__movme_cp.16), (.L__pc.1347.LD)
	.p2align 4
	.L__pc.1347.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1348
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1348: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1349
	
	.L__pc.1349: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1350
	
	.p2align 4
	.L__pc.1350: Dma_PatchDst (.L__pc.1350.ST), (.L__movme_cp.1), (.L__pc.1350.ST)
	.L__pc.1350.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1351
	
	// CG.LOAD4 [.L__movme_cp.17} => .L__movme_tmp.0
	.L__pc.1351: Dma_PatchSrc (.L__pc.1351.LD), (.L__movme_cp.17), (.L__pc.1351.LD)
	.p2align 4
	.L__pc.1351.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1352
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1352: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1353
	
	.L__pc.1353: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1354
	
	.p2align 4
	.L__pc.1354: Dma_PatchDst (.L__pc.1354.ST), (.L__movme_cp.14), (.L__pc.1354.ST)
	.L__pc.1354.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1355
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1355: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1356
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1356: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1357
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1357: Dma_PatchSrc (.L__pc.1357.LD), (.L__movme_cp.3), (.L__pc.1357.LD)
	.p2align 4
	.L__pc.1357.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1358
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1358: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1359
	
	.L__pc.1359: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1360
	
	.p2align 4
	.L__pc.1360: Dma_PatchDst (.L__pc.1360.ST), (.L__movme_cp.4), (.L__pc.1360.ST)
	.L__pc.1360.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1361
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1361: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1362: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1363: Dma_PatchSrc (.L__pc.1363.LD), (.L__movme_tmp.1), (.L__pc.1363.LD)
	.p2align 4
	.L__pc.1363.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1364
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1364: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1365
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1365: Dma_PatchSrc (.L__pc.1365.LD), (.L__movme_cp.2), (.L__pc.1365.LD)
	.p2align 4
	.L__pc.1365.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1366
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1366: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1367
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1367: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1368: Dma_PatchSrc (.L__pc.1368.LD), (.L__movme_tmp.1), (.L__pc.1368.LD)
	.p2align 4
	.L__pc.1368.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1369
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1369: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1370
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1370: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1371: Dma_PatchSrc (.L__pc.1371.LD), (.L__movme_tmp.1), (.L__pc.1371.LD)
	.p2align 4
	.L__pc.1371.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1372
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1372: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1373
	
	.L__pc.1373: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1374
	
	.p2align 4
	.L__pc.1374: Dma_PatchDst (.L__pc.1374.ST), ((.L__movme.reg.eax+0)), (.L__pc.1374.ST)
	.L__pc.1374.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1375
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1375: Dma_PatchSrc (.L__pc.1375.LD), (.L__movme_cp.2), (.L__pc.1375.LD)
	.p2align 4
	.L__pc.1375.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1376
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1376: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1377
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1377: Dma_PatchSrc (.L__pc.1377.LD), (.L__movme_cp.3), (.L__pc.1377.LD)
	.p2align 4
	.L__pc.1377.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1378
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1378: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1379
	
	.L__pc.1379: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1380
	
	.p2align 4
	.L__pc.1380: Dma_PatchDst (.L__pc.1380.ST), (.L__movme_cp.4), (.L__pc.1380.ST)
	.L__pc.1380.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1381
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1381: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1382: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1383: Dma_PatchSrc (.L__pc.1383.LD), (.L__movme_tmp.1), (.L__pc.1383.LD)
	.p2align 4
	.L__pc.1383.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1384
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1384: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1385
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1385: Dma_PatchSrc (.L__pc.1385.LD), (.L__movme_cp.1), (.L__pc.1385.LD)
	.p2align 4
	.L__pc.1385.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1386
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1386: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1387
	
	.L__pc.1387: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1388
	
	.p2align 4
	.L__pc.1388: Dma_PatchDst (.L__pc.1388.ST), ((.L__movme.reg.eax+0)), (.L__pc.1388.ST)
	.L__pc.1388.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1389
	
	// CG.LOAD4 [.L__movme_cp.14} => .L__movme_tmp.0
	.L__pc.1389: Dma_PatchSrc (.L__pc.1389.LD), (.L__movme_cp.14), (.L__pc.1389.LD)
	.p2align 4
	.L__pc.1389.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1390
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1390: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1391
	
	.L__pc.1391: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1392
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.1392: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	.p2align 4
	.L__pc.1393: Dma_PatchDst (.L__pc.1393.ST), (.L__movme_tmp.1), (.L__pc.1393.ST)
	.L__pc.1393.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1394
	
	// CG.COPY4 .L__movme_cp.0 => .L__movme_tmp.0
	.L__pc.1394: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.0), 4, .L__pc.1395
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1395: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1396
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1396: Dma_PatchSrc (.L__pc.1396.LD), (.L__movme_cp.3), (.L__pc.1396.LD)
	.p2align 4
	.L__pc.1396.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1397
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1397: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1398
	
	.L__pc.1398: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1399
	
	.p2align 4
	.L__pc.1399: Dma_PatchDst (.L__pc.1399.ST), (.L__movme_cp.4), (.L__pc.1399.ST)
	.L__pc.1399.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1400
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1400: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1401: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1402: Dma_PatchSrc (.L__pc.1402.LD), (.L__movme_tmp.1), (.L__pc.1402.LD)
	.p2align 4
	.L__pc.1402.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1403
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1403: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1404
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1404: Dma_PatchSrc (.L__pc.1404.LD), (.L__movme_cp.2), (.L__pc.1404.LD)
	.p2align 4
	.L__pc.1404.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1405
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1405: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1406
	
	.L__pc.1406: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1407
	
	.p2align 4
	.L__pc.1407: Dma_PatchDst (.L__pc.1407.ST), ((.L__movme.reg.eax+0)), (.L__pc.1407.ST)
	.L__pc.1407.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1408
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1408: Dma_PatchSrc (.L__pc.1408.LD), (.L__movme_cp.2), (.L__pc.1408.LD)
	.p2align 4
	.L__pc.1408.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1409
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1409: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1410
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.1410: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1411: Dma_PatchSrc (.L__pc.1411.LD), (.L__movme_tmp.1), (.L__pc.1411.LD)
	.p2align 4
	.L__pc.1411.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1412
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1412: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1413
	
	.L__pc.1413: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1414
	
	.p2align 4
	.L__pc.1414: Dma_PatchDst (.L__pc.1414.ST), (.L__movme_cp.1), (.L__pc.1414.ST)
	.L__pc.1414.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1415
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1415: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1416
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1416: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1417
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1417: Dma_PatchSrc (.L__pc.1417.LD), (.L__movme_cp.3), (.L__pc.1417.LD)
	.p2align 4
	.L__pc.1417.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1418
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1418: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1419
	
	.L__pc.1419: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1420
	
	.p2align 4
	.L__pc.1420: Dma_PatchDst (.L__pc.1420.ST), (.L__movme_cp.4), (.L__pc.1420.ST)
	.L__pc.1420.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1421
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1421: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1422: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1423: Dma_PatchSrc (.L__pc.1423.LD), (.L__movme_tmp.1), (.L__pc.1423.LD)
	.p2align 4
	.L__pc.1423.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1424
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1424: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1425
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1425: Dma_PatchSrc (.L__pc.1425.LD), (.L__movme_cp.1), (.L__pc.1425.LD)
	.p2align 4
	.L__pc.1425.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1426
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1426: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1427
	
	.L__pc.1427: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1428
	
	.p2align 4
	.L__pc.1428: Dma_PatchDst (.L__pc.1428.ST), ((.L__movme.reg.eax+0)), (.L__pc.1428.ST)
	.L__pc.1428.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1429
	
	// CG.COPY4 .L__movme_cp.45 => .L__movme_tmp.0
	.L__pc.1429: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.45), 4, .L__pc.1430
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1430: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1431
	
	.L__pc.1431: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1432
	
	.p2align 4
	.L__pc.1432: Dma_PatchDst (.L__pc.1432.ST), (.L__movme_cp.9), (.L__pc.1432.ST)
	.L__pc.1432.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1433
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.1433: Dma_PatchSrc (.L__pc.1433.LD), (.L__movme_cp.9), (.L__pc.1433.LD)
	.p2align 4
	.L__pc.1433.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1434
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1434: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1435
	
	.L__pc.1435: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1436
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1436: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1437
	
	.L__pc.1437: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1438
	
	.p2align 4
	.L__pc.1438: Dma_PatchDst (.L__pc.1438.ST), (.L__movme_cp.1), (.L__pc.1438.ST)
	.L__pc.1438.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1439
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1439: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1440
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1440: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1441
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1441: Dma_PatchSrc (.L__pc.1441.LD), (.L__movme_cp.3), (.L__pc.1441.LD)
	.p2align 4
	.L__pc.1441.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1442
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1442: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1443
	
	.L__pc.1443: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1444
	
	.p2align 4
	.L__pc.1444: Dma_PatchDst (.L__pc.1444.ST), (.L__movme_cp.4), (.L__pc.1444.ST)
	.L__pc.1444.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1445
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1445: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1446: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1447: Dma_PatchSrc (.L__pc.1447.LD), (.L__movme_tmp.1), (.L__pc.1447.LD)
	.p2align 4
	.L__pc.1447.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1448
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1448: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1449
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1449: Dma_PatchSrc (.L__pc.1449.LD), (.L__movme_cp.2), (.L__pc.1449.LD)
	.p2align 4
	.L__pc.1449.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1450
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1450: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1451
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1451: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1452: Dma_PatchSrc (.L__pc.1452.LD), (.L__movme_tmp.1), (.L__pc.1452.LD)
	.p2align 4
	.L__pc.1452.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1453
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1453: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1454
	
	.L__pc.1454: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1455
	
	.p2align 4
	.L__pc.1455: Dma_PatchDst (.L__pc.1455.ST), ((.L__movme.reg.eax+0)), (.L__pc.1455.ST)
	.L__pc.1455.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1456
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1456: Dma_PatchSrc (.L__pc.1456.LD), (.L__movme_cp.2), (.L__pc.1456.LD)
	.p2align 4
	.L__pc.1456.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1457
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1457: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1458
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1458: Dma_PatchSrc (.L__pc.1458.LD), (.L__movme_cp.3), (.L__pc.1458.LD)
	.p2align 4
	.L__pc.1458.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1459
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1459: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1460
	
	.L__pc.1460: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1461
	
	.p2align 4
	.L__pc.1461: Dma_PatchDst (.L__pc.1461.ST), (.L__movme_cp.4), (.L__pc.1461.ST)
	.L__pc.1461.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1462
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1462: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1463: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1464: Dma_PatchSrc (.L__pc.1464.LD), (.L__movme_tmp.1), (.L__pc.1464.LD)
	.p2align 4
	.L__pc.1464.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1465
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1465: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1466
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1466: Dma_PatchSrc (.L__pc.1466.LD), (.L__movme_cp.1), (.L__pc.1466.LD)
	.p2align 4
	.L__pc.1466.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1467
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1467: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1468
	
	.L__pc.1468: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1469
	
	.p2align 4
	.L__pc.1469: Dma_PatchDst (.L__pc.1469.ST), ((.L__movme.reg.eax+0)), (.L__pc.1469.ST)
	.L__pc.1469.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1470
	
	// CG.COPY4 .L__movme_cp.46 => .L__movme_tmp.0
	.L__pc.1470: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.46), 4, .L__pc.1471
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1471: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1472
	
	.L__pc.1472: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1473
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1473: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1474
	
	.L__pc.1474: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1475
	
	.p2align 4
	.L__pc.1475: Dma_PatchDst (.L__pc.1475.ST), (.L__movme_cp.1), (.L__pc.1475.ST)
	.L__pc.1475.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1476
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1476: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1477
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1477: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1478
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1478: Dma_PatchSrc (.L__pc.1478.LD), (.L__movme_cp.3), (.L__pc.1478.LD)
	.p2align 4
	.L__pc.1478.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1479
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1479: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1480
	
	.L__pc.1480: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1481
	
	.p2align 4
	.L__pc.1481: Dma_PatchDst (.L__pc.1481.ST), (.L__movme_cp.4), (.L__pc.1481.ST)
	.L__pc.1481.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1482
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1482: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1483: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1484: Dma_PatchSrc (.L__pc.1484.LD), (.L__movme_tmp.1), (.L__pc.1484.LD)
	.p2align 4
	.L__pc.1484.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1485
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1485: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1486
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1486: Dma_PatchSrc (.L__pc.1486.LD), (.L__movme_cp.2), (.L__pc.1486.LD)
	.p2align 4
	.L__pc.1486.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1487
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1487: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1488
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1488: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1489: Dma_PatchSrc (.L__pc.1489.LD), (.L__movme_tmp.1), (.L__pc.1489.LD)
	.p2align 4
	.L__pc.1489.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1490
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1490: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1491
	
	.L__pc.1491: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1492
	
	.p2align 4
	.L__pc.1492: Dma_PatchDst (.L__pc.1492.ST), ((.L__movme.reg.eax+0)), (.L__pc.1492.ST)
	.L__pc.1492.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1493
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1493: Dma_PatchSrc (.L__pc.1493.LD), (.L__movme_cp.2), (.L__pc.1493.LD)
	.p2align 4
	.L__pc.1493.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1494
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1494: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1495
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1495: Dma_PatchSrc (.L__pc.1495.LD), (.L__movme_cp.3), (.L__pc.1495.LD)
	.p2align 4
	.L__pc.1495.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1496
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1496: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1497
	
	.L__pc.1497: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1498
	
	.p2align 4
	.L__pc.1498: Dma_PatchDst (.L__pc.1498.ST), (.L__movme_cp.4), (.L__pc.1498.ST)
	.L__pc.1498.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1499
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1499: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1500: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1501: Dma_PatchSrc (.L__pc.1501.LD), (.L__movme_tmp.1), (.L__pc.1501.LD)
	.p2align 4
	.L__pc.1501.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1502
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1502: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1503
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1503: Dma_PatchSrc (.L__pc.1503.LD), (.L__movme_cp.1), (.L__pc.1503.LD)
	.p2align 4
	.L__pc.1503.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1504
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1504: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1505
	
	.L__pc.1505: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1506
	
	.p2align 4
	.L__pc.1506: Dma_PatchDst (.L__pc.1506.ST), ((.L__movme.reg.eax+0)), (.L__pc.1506.ST)
	.L__pc.1506.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1507
	
	// JMP imm.4(print)
	.L__pc.1507: Dma_PatchLink (.L__pc.1507.J), (.L__movme_cp.47), (.L__pc.1507.J)
	.p2align 4
	.L__pc.1507.J: Dma_ByteCopy  (.L__movme_tmp.0), (.L__movme_tmp.0), 1, .L__pc.1508
	
	// LABEL .LCI18
	.LCI18:
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.1508: Dma_PatchSrc (.L__pc.1508.LD), (.L__movme_cp.2), (.L__pc.1508.LD)
	.p2align 4
	.L__pc.1508.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1509
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1509: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1510
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.1510: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1511: Dma_PatchSrc (.L__pc.1511.LD), (.L__movme_tmp.1), (.L__pc.1511.LD)
	.p2align 4
	.L__pc.1511.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1512
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1512: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1513
	
	.L__pc.1513: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1514
	
	.p2align 4
	.L__pc.1514: Dma_PatchDst (.L__pc.1514.ST), (.L__movme_cp.1), (.L__pc.1514.ST)
	.L__pc.1514.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1515
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.1515: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.1516
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1516: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1517
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1517: Dma_PatchSrc (.L__pc.1517.LD), (.L__movme_cp.3), (.L__pc.1517.LD)
	.p2align 4
	.L__pc.1517.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1518
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1518: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1519
	
	.L__pc.1519: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1520
	
	.p2align 4
	.L__pc.1520: Dma_PatchDst (.L__pc.1520.ST), (.L__movme_cp.4), (.L__pc.1520.ST)
	.L__pc.1520.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1521
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1521: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1522: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1523: Dma_PatchSrc (.L__pc.1523.LD), (.L__movme_tmp.1), (.L__pc.1523.LD)
	.p2align 4
	.L__pc.1523.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1524
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1524: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1525
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.1525: Dma_PatchSrc (.L__pc.1525.LD), (.L__movme_cp.1), (.L__pc.1525.LD)
	.p2align 4
	.L__pc.1525.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1526
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1526: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1527
	
	.L__pc.1527: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1528
	
	.p2align 4
	.L__pc.1528: Dma_PatchDst (.L__pc.1528.ST), ((.L__movme.reg.eax+0)), (.L__pc.1528.ST)
	.L__pc.1528.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1529
	
	// JMP imm.4(.LCI10)
	.L__pc.1529: Dma_PatchLink (.L__pc.1529.J), (.L__movme_cp.48), (.L__pc.1529.J)
	.p2align 4
	.L__pc.1529.J: Dma_ByteCopy  (.L__movme_tmp.0), (.L__movme_tmp.0), 1, .L__pc.1530
	
	// LABEL .LCI9
	.LCI9:
	
	// CG.COPY4 .L__movme_cp.49 => .L__movme_tmp.0
	.L__pc.1530: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.49), 4, .L__pc.1531
	
	.p2align 4
	.L__pc.1531: Dma_PatchDst (.L__pc.1531.ST), (.L__movme_cp.9), (.L__pc.1531.ST)
	.L__pc.1531.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1532
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.1532: Dma_PatchSrc (.L__pc.1532.LD), (.L__movme_cp.9), (.L__pc.1532.LD)
	.p2align 4
	.L__pc.1532.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1533
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1533: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1534
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1534: Dma_PatchSrc (.L__pc.1534.LD), (.L__movme_cp.3), (.L__pc.1534.LD)
	.p2align 4
	.L__pc.1534.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1535
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1535: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1536
	
	.L__pc.1536: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1537
	
	.p2align 4
	.L__pc.1537: Dma_PatchDst (.L__pc.1537.ST), (.L__movme_cp.4), (.L__pc.1537.ST)
	.L__pc.1537.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1538
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1538: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1539: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1540: Dma_PatchSrc (.L__pc.1540.LD), (.L__movme_tmp.1), (.L__pc.1540.LD)
	.p2align 4
	.L__pc.1540.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1541
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1541: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1542
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.1542: Dma_PatchSrc (.L__pc.1542.LD), ((.L__movme.reg.eax+0)), (.L__pc.1542.LD)
	.p2align 4
	.L__pc.1542.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1543
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1543: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1544
	
	.L__pc.1544: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1545
	
	.p2align 4
	.L__pc.1545: Dma_PatchDst (.L__pc.1545.ST), (.L__movme_cp.9), (.L__pc.1545.ST)
	.L__pc.1545.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1546
	
	// CG.COPY4 .L__movme_cp.37 => .L__movme_tmp.0
	.L__pc.1546: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.37), 4, .L__pc.1547
	
	.p2align 4
	.L__pc.1547: Dma_PatchDst (.L__pc.1547.ST), (.L__movme_cp.8), (.L__pc.1547.ST)
	.L__pc.1547.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1548
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.1548: Dma_PatchSrc (.L__pc.1548.LD), (.L__movme_cp.9), (.L__pc.1548.LD)
	.p2align 4
	.L__pc.1548.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1549
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1549: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1550
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.1550: Dma_PatchSrc (.L__pc.1550.LD), (.L__movme_cp.8), (.L__pc.1550.LD)
	.p2align 4
	.L__pc.1550.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1551
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1551: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1552
	
	.L__pc.1552: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1553
	
	.p2align 4
	.L__pc.1553: Dma_PatchDst (.L__pc.1553.ST), (.L__movme_cp.21), (.L__pc.1553.ST)
	.L__pc.1553.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1554
	
	.L__pc.1554: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1555
	
	.p2align 4
	.L__pc.1555: Dma_PatchDst (.L__pc.1555.ST), (.L__movme_cp.22), (.L__pc.1555.ST)
	.L__pc.1555.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1556
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1556: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1557
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1557: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1558
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1558: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1559
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1559: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1560
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.1560: Dma_PatchSrc (.L__pc.1560.LD), (.L__movme_cp.25), (.L__pc.1560.LD)
	.p2align 4
	.L__pc.1560.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1561
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1561: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.1562
	.L__pc.1562: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.1563
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.1563: Dma_PatchSrc (.L__pc.1563.LD), (.L__movme_cp.26), (.L__pc.1563.LD)
	.p2align 4
	.L__pc.1563.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1564
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1564: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.1565
	.L__pc.1565: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.1566
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.1566: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.38 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1567: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1568: Dma_PatchSrc (.L__pc.1568.LD), (.L__movme_tmp.1), (.L__pc.1568.LD)
	.p2align 4
	.L__pc.1568.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1569
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1569: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1570
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.eax+0) + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1570: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1571: Dma_PatchSrc (.L__pc.1571.LD), (.L__movme_tmp.1), (.L__pc.1571.LD)
	.p2align 4
	.L__pc.1571.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1572
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1572: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.1573
	.L__pc.1573: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.1574
	
	.L__pc.1574: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.1575
	
	.p2align 4
	.L__pc.1575: Dma_PatchDst (.L__pc.1575.ST), (.L__movme_cp.29), (.L__pc.1575.ST)
	.L__pc.1575.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1576
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1576: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1577
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1577: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1578
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1578: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1579
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1579: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1580
	
	// CG.LOAD4 [.L__movme_cp.39} => .L__movme_tmp.0
	.L__pc.1580: Dma_PatchSrc (.L__pc.1580.LD), (.L__movme_cp.39), (.L__pc.1580.LD)
	.p2align 4
	.L__pc.1580.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1581
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1581: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.1582
	.L__pc.1582: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.1583
	
	// CG.LOAD4 [.L__movme_cp.40} => .L__movme_tmp.0
	.L__pc.1583: Dma_PatchSrc (.L__pc.1583.LD), (.L__movme_cp.40), (.L__pc.1583.LD)
	.p2align 4
	.L__pc.1583.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1584
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1584: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.1585
	.L__pc.1585: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.1586
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.1586: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.38 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1587: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1588: Dma_PatchSrc (.L__pc.1588.LD), (.L__movme_tmp.1), (.L__pc.1588.LD)
	.p2align 4
	.L__pc.1588.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1589
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1589: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1590
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.eax+0) + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1590: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1591: Dma_PatchSrc (.L__pc.1591.LD), (.L__movme_tmp.1), (.L__pc.1591.LD)
	.p2align 4
	.L__pc.1591.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1592
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1592: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.1593
	.L__pc.1593: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.1594
	
	.L__pc.1594: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.1595
	
	.p2align 4
	.L__pc.1595: Dma_PatchDst (.L__pc.1595.ST), (.L__movme_cp.41), (.L__pc.1595.ST)
	.L__pc.1595.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1596
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1596: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1597
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1597: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1598
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1598: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1599
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1599: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1600
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.1600: Dma_PatchSrc (.L__pc.1600.LD), (.L__movme_cp.30), (.L__pc.1600.LD)
	.p2align 4
	.L__pc.1600.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1601
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1601: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.1602
	.L__pc.1602: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.1603
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.1603: Dma_PatchSrc (.L__pc.1603.LD), (.L__movme_cp.31), (.L__pc.1603.LD)
	.p2align 4
	.L__pc.1603.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1604
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1604: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.1605
	.L__pc.1605: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.1606
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.1606: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.38 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1607: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1608: Dma_PatchSrc (.L__pc.1608.LD), (.L__movme_tmp.1), (.L__pc.1608.LD)
	.p2align 4
	.L__pc.1608.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1609
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1609: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1610
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.eax+0) + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1610: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1611: Dma_PatchSrc (.L__pc.1611.LD), (.L__movme_tmp.1), (.L__pc.1611.LD)
	.p2align 4
	.L__pc.1611.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1612
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1612: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.1613
	.L__pc.1613: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.1614
	
	.L__pc.1614: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.1615
	
	.p2align 4
	.L__pc.1615: Dma_PatchDst (.L__pc.1615.ST), (.L__movme_cp.32), (.L__pc.1615.ST)
	.L__pc.1615.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1616
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1616: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1617
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1617: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1618
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1618: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1619
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1619: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1620
	
	// CG.LOAD4 [.L__movme_cp.42} => .L__movme_tmp.0
	.L__pc.1620: Dma_PatchSrc (.L__pc.1620.LD), (.L__movme_cp.42), (.L__pc.1620.LD)
	.p2align 4
	.L__pc.1620.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1621
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1621: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.1622
	.L__pc.1622: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.1623
	
	// CG.LOAD4 [.L__movme_cp.43} => .L__movme_tmp.0
	.L__pc.1623: Dma_PatchSrc (.L__pc.1623.LD), (.L__movme_cp.43), (.L__pc.1623.LD)
	.p2align 4
	.L__pc.1623.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1624
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1624: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.1625
	.L__pc.1625: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.1626
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.1626: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.38 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1627: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1628: Dma_PatchSrc (.L__pc.1628.LD), (.L__movme_tmp.1), (.L__pc.1628.LD)
	.p2align 4
	.L__pc.1628.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1629
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1629: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1630
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.eax+0) + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.1630: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1631: Dma_PatchSrc (.L__pc.1631.LD), (.L__movme_tmp.1), (.L__pc.1631.LD)
	.p2align 4
	.L__pc.1631.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1632
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1632: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.1633
	.L__pc.1633: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.1634
	
	.L__pc.1634: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.1635
	
	.p2align 4
	.L__pc.1635: Dma_PatchDst (.L__pc.1635.ST), (.L__movme_cp.44), (.L__pc.1635.ST)
	.L__pc.1635.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1636
	
	// CG.LOAD4 [.L__movme_cp.33} => .L__movme_tmp.0
	.L__pc.1636: Dma_PatchSrc (.L__pc.1636.LD), (.L__movme_cp.33), (.L__pc.1636.LD)
	.p2align 4
	.L__pc.1636.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1637
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1637: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1638
	
	.L__pc.1638: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1639
	
	.p2align 4
	.L__pc.1639: Dma_PatchDst (.L__pc.1639.ST), (.L__movme_cp.9), (.L__pc.1639.ST)
	.L__pc.1639.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1640
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.1640: Dma_PatchSrc (.L__pc.1640.LD), (.L__movme_cp.0), (.L__pc.1640.LD)
	.p2align 4
	.L__pc.1640.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1641
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1641: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1642
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.1642: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1643: Dma_PatchSrc (.L__pc.1643.LD), (.L__movme_tmp.1), (.L__pc.1643.LD)
	.p2align 4
	.L__pc.1643.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1644
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1644: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1645
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1645: Dma_PatchSrc (.L__pc.1645.LD), (.L__movme_cp.3), (.L__pc.1645.LD)
	.p2align 4
	.L__pc.1645.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1646
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1646: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1647
	
	.L__pc.1647: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1648
	
	.p2align 4
	.L__pc.1648: Dma_PatchDst (.L__pc.1648.ST), (.L__movme_cp.4), (.L__pc.1648.ST)
	.L__pc.1648.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1649
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1649: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1650: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1651: Dma_PatchSrc (.L__pc.1651.LD), (.L__movme_tmp.1), (.L__pc.1651.LD)
	.p2align 4
	.L__pc.1651.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1652
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1652: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1653
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.1653: Dma_PatchSrc (.L__pc.1653.LD), (.L__movme_cp.9), (.L__pc.1653.LD)
	.p2align 4
	.L__pc.1653.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1654
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1654: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1655
	
	.L__pc.1655: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1656
	
	.p2align 4
	.L__pc.1656: Dma_PatchDst (.L__pc.1656.ST), ((.L__movme.reg.eax+0)), (.L__pc.1656.ST)
	.L__pc.1656.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1657
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.1657: Dma_PatchSrc (.L__pc.1657.LD), (.L__movme_cp.0), (.L__pc.1657.LD)
	.p2align 4
	.L__pc.1657.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1658
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1658: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1659
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.1659: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1660: Dma_PatchSrc (.L__pc.1660.LD), (.L__movme_tmp.1), (.L__pc.1660.LD)
	.p2align 4
	.L__pc.1660.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1661
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1661: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1662
	
	.L__pc.1662: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1663
	
	.p2align 4
	.L__pc.1663: Dma_PatchDst (.L__pc.1663.ST), (.L__movme_cp.9), (.L__pc.1663.ST)
	.L__pc.1663.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1664
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.1664: Dma_PatchSrc (.L__pc.1664.LD), (.L__movme_cp.9), (.L__pc.1664.LD)
	.p2align 4
	.L__pc.1664.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1665
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1665: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1666
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1666: Dma_PatchSrc (.L__pc.1666.LD), (.L__movme_cp.3), (.L__pc.1666.LD)
	.p2align 4
	.L__pc.1666.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1667
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1667: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1668
	
	.L__pc.1668: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1669
	
	.p2align 4
	.L__pc.1669: Dma_PatchDst (.L__pc.1669.ST), (.L__movme_cp.4), (.L__pc.1669.ST)
	.L__pc.1669.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1670
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1670: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1671: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1672: Dma_PatchSrc (.L__pc.1672.LD), (.L__movme_tmp.1), (.L__pc.1672.LD)
	.p2align 4
	.L__pc.1672.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1673
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1673: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1674
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.1674: Dma_PatchSrc (.L__pc.1674.LD), ((.L__movme.reg.eax+0)), (.L__pc.1674.LD)
	.p2align 4
	.L__pc.1674.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1675
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1675: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1676
	
	.L__pc.1676: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1677
	
	.p2align 4
	.L__pc.1677: Dma_PatchDst (.L__pc.1677.ST), (.L__movme_cp.9), (.L__pc.1677.ST)
	.L__pc.1677.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1678
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1678: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1679
	
	.p2align 4
	.L__pc.1679: Dma_PatchDst (.L__pc.1679.ST), (.L__movme_cp.8), (.L__pc.1679.ST)
	.L__pc.1679.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1680
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.1680: Dma_PatchSrc (.L__pc.1680.LD), (.L__movme_cp.9), (.L__pc.1680.LD)
	.p2align 4
	.L__pc.1680.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1681
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1681: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1682
	
	// CG.UNIMPLEMENTED: CMP.4 mem.4(imm.4(R2)) ?= reg.4(eax)
	.L__pc.1682: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: COND JMP je TO imm.4(.LCI12)
	.L__pc.1683: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.1684: Dma_PatchSrc (.L__pc.1684.LD), (.L__movme_cp.0), (.L__pc.1684.LD)
	.p2align 4
	.L__pc.1684.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1685
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1685: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1686
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.1686: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1687: Dma_PatchSrc (.L__pc.1687.LD), (.L__movme_tmp.1), (.L__pc.1687.LD)
	.p2align 4
	.L__pc.1687.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1688
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1688: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1689
	
	.L__pc.1689: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1690
	
	.p2align 4
	.L__pc.1690: Dma_PatchDst (.L__pc.1690.ST), (.L__movme_cp.9), (.L__pc.1690.ST)
	.L__pc.1690.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1691
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.1691: Dma_PatchSrc (.L__pc.1691.LD), (.L__movme_cp.9), (.L__pc.1691.LD)
	.p2align 4
	.L__pc.1691.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1692
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1692: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1693
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1693: Dma_PatchSrc (.L__pc.1693.LD), (.L__movme_cp.3), (.L__pc.1693.LD)
	.p2align 4
	.L__pc.1693.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1694
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1694: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1695
	
	.L__pc.1695: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1696
	
	.p2align 4
	.L__pc.1696: Dma_PatchDst (.L__pc.1696.ST), (.L__movme_cp.4), (.L__pc.1696.ST)
	.L__pc.1696.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1697
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1697: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1698: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1699: Dma_PatchSrc (.L__pc.1699.LD), (.L__movme_tmp.1), (.L__pc.1699.LD)
	.p2align 4
	.L__pc.1699.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1700
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1700: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1701
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.1701: Dma_PatchSrc (.L__pc.1701.LD), ((.L__movme.reg.eax+0)), (.L__pc.1701.LD)
	.p2align 4
	.L__pc.1701.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1702
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1702: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1703
	
	.L__pc.1703: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1704
	
	.p2align 4
	.L__pc.1704: Dma_PatchDst (.L__pc.1704.ST), (.L__movme_cp.9), (.L__pc.1704.ST)
	.L__pc.1704.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1705
	
	// CG.COPY4 .L__movme_cp.50 => .L__movme_tmp.0
	.L__pc.1705: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.50), 4, .L__pc.1706
	
	.p2align 4
	.L__pc.1706: Dma_PatchDst (.L__pc.1706.ST), (.L__movme_cp.8), (.L__pc.1706.ST)
	.L__pc.1706.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1707
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.1707: Dma_PatchSrc (.L__pc.1707.LD), (.L__movme_cp.9), (.L__pc.1707.LD)
	.p2align 4
	.L__pc.1707.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1708
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1708: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1709
	
	// CG.UNIMPLEMENTED: CMP.4 mem.4(imm.4(R2)) ?= reg.4(eax)
	.L__pc.1709: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: COND JMP jb TO imm.4(.LCI14)
	.L__pc.1710: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.COPY4 .L__movme_cp.51 => .L__movme_tmp.0
	.L__pc.1711: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.51), 4, .L__pc.1712
	
	.p2align 4
	.L__pc.1712: Dma_PatchDst (.L__pc.1712.ST), (.L__movme_cp.8), (.L__pc.1712.ST)
	.L__pc.1712.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1713
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.1713: Dma_PatchSrc (.L__pc.1713.LD), (.L__movme_cp.9), (.L__pc.1713.LD)
	.p2align 4
	.L__pc.1713.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1714
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1714: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1715
	
	// CG.UNIMPLEMENTED: CMP.4 mem.4(imm.4(R2)) ?= reg.4(eax)
	.L__pc.1715: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: COND JMP ja TO imm.4(.LCI14)
	.L__pc.1716: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.COPY4 .L__movme_cp.50 => .L__movme_tmp.0
	.L__pc.1717: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.50), 4, .L__pc.1718
	
	.p2align 4
	.L__pc.1718: Dma_PatchDst (.L__pc.1718.ST), (.L__movme_cp.9), (.L__pc.1718.ST)
	.L__pc.1718.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1719
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.1719: Dma_PatchSrc (.L__pc.1719.LD), (.L__movme_cp.0), (.L__pc.1719.LD)
	.p2align 4
	.L__pc.1719.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1720
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1720: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1721
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.1721: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1722: Dma_PatchSrc (.L__pc.1722.LD), (.L__movme_tmp.1), (.L__pc.1722.LD)
	.p2align 4
	.L__pc.1722.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1723
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1723: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1724
	
	.L__pc.1724: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1725
	
	.p2align 4
	.L__pc.1725: Dma_PatchDst (.L__pc.1725.ST), (.L__movme_cp.8), (.L__pc.1725.ST)
	.L__pc.1725.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1726
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.1726: Dma_PatchSrc (.L__pc.1726.LD), (.L__movme_cp.8), (.L__pc.1726.LD)
	.p2align 4
	.L__pc.1726.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1727
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1727: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1728
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.1728: Dma_PatchSrc (.L__pc.1728.LD), (.L__movme_cp.3), (.L__pc.1728.LD)
	.p2align 4
	.L__pc.1728.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1729
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1729: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1730
	
	.L__pc.1730: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1731
	
	.p2align 4
	.L__pc.1731: Dma_PatchDst (.L__pc.1731.ST), (.L__movme_cp.4), (.L__pc.1731.ST)
	.L__pc.1731.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1732
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1732: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1733: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1734: Dma_PatchSrc (.L__pc.1734.LD), (.L__movme_tmp.1), (.L__pc.1734.LD)
	.p2align 4
	.L__pc.1734.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1735
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1735: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1736
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.1736: Dma_PatchSrc (.L__pc.1736.LD), ((.L__movme.reg.eax+0)), (.L__pc.1736.LD)
	.p2align 4
	.L__pc.1736.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1737
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1737: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1738
	
	.L__pc.1738: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1739
	
	.p2align 4
	.L__pc.1739: Dma_PatchDst (.L__pc.1739.ST), (.L__movme_cp.8), (.L__pc.1739.ST)
	.L__pc.1739.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1740
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.1740: Dma_PatchSrc (.L__pc.1740.LD), (.L__movme_cp.8), (.L__pc.1740.LD)
	.p2align 4
	.L__pc.1740.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1741
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1741: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1742
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.1742: Dma_PatchSrc (.L__pc.1742.LD), (.L__movme_cp.9), (.L__pc.1742.LD)
	.p2align 4
	.L__pc.1742.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1743
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1743: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1744
	
	.L__pc.1744: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1745
	
	.p2align 4
	.L__pc.1745: Dma_PatchDst (.L__pc.1745.ST), (.L__movme_cp.21), (.L__pc.1745.ST)
	.L__pc.1745.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1746
	
	.L__pc.1746: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1747
	
	.p2align 4
	.L__pc.1747: Dma_PatchDst (.L__pc.1747.ST), (.L__movme_cp.22), (.L__pc.1747.ST)
	.L__pc.1747.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1748
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1748: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1749
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1749: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1750
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1750: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1751
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1751: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.1752
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.1752: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.1753
	
	.p2align 4
	.L__pc.1753: Dma_PatchDst (.L__pc.1753.ST), (.L__movme_cp.24), (.L__pc.1753.ST)
	.L__pc.1753.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1754
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.1754: Dma_PatchSrc (.L__pc.1754.LD), (.L__movme_cp.25), (.L__pc.1754.LD)
	.p2align 4
	.L__pc.1754.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1755
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1755: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.1756
	.L__pc.1756: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.1757
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.1757: Dma_PatchSrc (.L__pc.1757.LD), (.L__movme_cp.26), (.L__pc.1757.LD)
	.p2align 4
	.L__pc.1757.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1758
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1758: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.1759
	.L__pc.1759: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.1760
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.1760: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1761: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1762: Dma_PatchSrc (.L__pc.1762.LD), (.L__movme_tmp.1), (.L__pc.1762.LD)
	.p2align 4
	.L__pc.1762.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1763
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1763: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.1764
	.L__pc.1764: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.1765
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.1765: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1766: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1767: Dma_PatchSrc (.L__pc.1767.LD), (.L__movme_tmp.1), (.L__pc.1767.LD)
	.p2align 4
	.L__pc.1767.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1768
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1768: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1769
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.1769: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1770: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1771: Dma_PatchSrc (.L__pc.1771.LD), (.L__movme_tmp.1), (.L__pc.1771.LD)
	.p2align 4
	.L__pc.1771.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1772
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1772: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1773
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1773: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1774: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1775: Dma_PatchSrc (.L__pc.1775.LD), (.L__movme_tmp.1), (.L__pc.1775.LD)
	.p2align 4
	.L__pc.1775.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1776
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1776: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1777
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.1777: Dma_PatchSrc (.L__pc.1777.LD), (.L__movme_cp.24), (.L__pc.1777.LD)
	.p2align 4
	.L__pc.1777.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1778
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1778: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.1779
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.1779: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1780: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1781: Dma_PatchSrc (.L__pc.1781.LD), (.L__movme_tmp.1), (.L__pc.1781.LD)
	.p2align 4
	.L__pc.1781.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1782
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1782: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1783
	
	.L__pc.1783: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.1784
	
	.p2align 4
	.L__pc.1784: Dma_PatchDst (.L__pc.1784.ST), (.L__movme_cp.29), (.L__pc.1784.ST)
	.L__pc.1784.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1785
	
	.L__pc.1785: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1786
	
	.p2align 4
	.L__pc.1786: Dma_PatchDst (.L__pc.1786.ST), (.L__movme_cp.54), (.L__pc.1786.ST)
	.L__pc.1786.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1787
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.1787: Dma_PatchSrc (.L__pc.1787.LD), (.L__movme_cp.30), (.L__pc.1787.LD)
	.p2align 4
	.L__pc.1787.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1788
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1788: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.1789
	.L__pc.1789: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.1790
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.1790: Dma_PatchSrc (.L__pc.1790.LD), (.L__movme_cp.31), (.L__pc.1790.LD)
	.p2align 4
	.L__pc.1790.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1791
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1791: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.1792
	.L__pc.1792: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.1793
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.1793: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1794: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1795: Dma_PatchSrc (.L__pc.1795.LD), (.L__movme_tmp.1), (.L__pc.1795.LD)
	.p2align 4
	.L__pc.1795.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1796
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1796: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.1797
	.L__pc.1797: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.1798
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.1798: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1799: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1800: Dma_PatchSrc (.L__pc.1800.LD), (.L__movme_tmp.1), (.L__pc.1800.LD)
	.p2align 4
	.L__pc.1800.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1801
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1801: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1802
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.1802: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1803: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1804: Dma_PatchSrc (.L__pc.1804.LD), (.L__movme_tmp.1), (.L__pc.1804.LD)
	.p2align 4
	.L__pc.1804.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1805
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1805: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1806
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1806: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1807: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1808: Dma_PatchSrc (.L__pc.1808.LD), (.L__movme_tmp.1), (.L__pc.1808.LD)
	.p2align 4
	.L__pc.1808.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1809
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1809: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1810
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.1810: Dma_PatchSrc (.L__pc.1810.LD), (.L__movme_cp.24), (.L__pc.1810.LD)
	.p2align 4
	.L__pc.1810.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1811
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1811: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.1812
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.1812: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1813: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1814: Dma_PatchSrc (.L__pc.1814.LD), (.L__movme_tmp.1), (.L__pc.1814.LD)
	.p2align 4
	.L__pc.1814.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1815
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1815: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1816
	
	.L__pc.1816: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.1817
	
	.p2align 4
	.L__pc.1817: Dma_PatchDst (.L__pc.1817.ST), (.L__movme_cp.32), (.L__pc.1817.ST)
	.L__pc.1817.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1818
	
	.L__pc.1818: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1819
	
	.p2align 4
	.L__pc.1819: Dma_PatchDst (.L__pc.1819.ST), (.L__movme_cp.54), (.L__pc.1819.ST)
	.L__pc.1819.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1820
	
	// CG.LOAD4 [.L__movme_cp.33} => .L__movme_tmp.0
	.L__pc.1820: Dma_PatchSrc (.L__pc.1820.LD), (.L__movme_cp.33), (.L__pc.1820.LD)
	.p2align 4
	.L__pc.1820.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1821
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1821: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1822
	
	.L__pc.1822: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1823
	
	.p2align 4
	.L__pc.1823: Dma_PatchDst (.L__pc.1823.ST), (.L__movme_cp.8), (.L__pc.1823.ST)
	.L__pc.1823.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1824
	
	// CG.COPY4 .L__movme_cp.55 => .L__movme_tmp.0
	.L__pc.1824: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.55), 4, .L__pc.1825
	
	.p2align 4
	.L__pc.1825: Dma_PatchDst (.L__pc.1825.ST), (.L__movme_cp.7), (.L__pc.1825.ST)
	.L__pc.1825.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1826
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.1826: Dma_PatchSrc (.L__pc.1826.LD), (.L__movme_cp.8), (.L__pc.1826.LD)
	.p2align 4
	.L__pc.1826.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1827
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1827: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1828
	
	// CG.LOAD4 [.L__movme_cp.7} => .L__movme_tmp.0
	.L__pc.1828: Dma_PatchSrc (.L__pc.1828.LD), (.L__movme_cp.7), (.L__pc.1828.LD)
	.p2align 4
	.L__pc.1828.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1829
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1829: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1830
	
	.L__pc.1830: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1831
	
	.p2align 4
	.L__pc.1831: Dma_PatchDst (.L__pc.1831.ST), (.L__movme_cp.21), (.L__pc.1831.ST)
	.L__pc.1831.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1832
	
	.L__pc.1832: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1833
	
	.p2align 4
	.L__pc.1833: Dma_PatchDst (.L__pc.1833.ST), (.L__movme_cp.22), (.L__pc.1833.ST)
	.L__pc.1833.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1834
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1834: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1835
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1835: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1836
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1836: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1837
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1837: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.1838
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1838: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1839
	
	.p2align 4
	.L__pc.1839: Dma_PatchDst (.L__pc.1839.ST), (.L__movme_cp.24), (.L__pc.1839.ST)
	.L__pc.1839.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1840
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.1840: Dma_PatchSrc (.L__pc.1840.LD), (.L__movme_cp.25), (.L__pc.1840.LD)
	.p2align 4
	.L__pc.1840.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1841
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1841: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.1842
	.L__pc.1842: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.1843
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.1843: Dma_PatchSrc (.L__pc.1843.LD), (.L__movme_cp.26), (.L__pc.1843.LD)
	.p2align 4
	.L__pc.1843.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1844
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1844: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.1845
	.L__pc.1845: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.1846
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.1846: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1847: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1848: Dma_PatchSrc (.L__pc.1848.LD), (.L__movme_tmp.1), (.L__pc.1848.LD)
	.p2align 4
	.L__pc.1848.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1849
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1849: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1850
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.1850: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1851: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1852: Dma_PatchSrc (.L__pc.1852.LD), (.L__movme_tmp.1), (.L__pc.1852.LD)
	.p2align 4
	.L__pc.1852.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1853
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1853: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1854
	
	// CG.LOAD4 [.L__movme_cp.28} => .L__movme_tmp.0
	.L__pc.1854: Dma_PatchSrc (.L__pc.1854.LD), (.L__movme_cp.28), (.L__pc.1854.LD)
	.p2align 4
	.L__pc.1854.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1855
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1855: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.1856
	.L__pc.1856: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.1857
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1857: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1858: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1859: Dma_PatchSrc (.L__pc.1859.LD), (.L__movme_tmp.1), (.L__pc.1859.LD)
	.p2align 4
	.L__pc.1859.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1860
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1860: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1861
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.1861: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1862: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1863: Dma_PatchSrc (.L__pc.1863.LD), (.L__movme_tmp.1), (.L__pc.1863.LD)
	.p2align 4
	.L__pc.1863.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1864
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1864: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1865
	
	.L__pc.1865: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.1866
	
	.p2align 4
	.L__pc.1866: Dma_PatchDst (.L__pc.1866.ST), (.L__movme_cp.29), (.L__pc.1866.ST)
	.L__pc.1866.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1867
	
	.L__pc.1867: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1868
	
	.p2align 4
	.L__pc.1868: Dma_PatchDst (.L__pc.1868.ST), (.L__movme_cp.24), (.L__pc.1868.ST)
	.L__pc.1868.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1869
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.1869: Dma_PatchSrc (.L__pc.1869.LD), (.L__movme_cp.30), (.L__pc.1869.LD)
	.p2align 4
	.L__pc.1869.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1870
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1870: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.1871
	.L__pc.1871: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.1872
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.1872: Dma_PatchSrc (.L__pc.1872.LD), (.L__movme_cp.31), (.L__pc.1872.LD)
	.p2align 4
	.L__pc.1872.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1873
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1873: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.1874
	.L__pc.1874: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.1875
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.1875: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1876: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1877: Dma_PatchSrc (.L__pc.1877.LD), (.L__movme_tmp.1), (.L__pc.1877.LD)
	.p2align 4
	.L__pc.1877.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1878
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1878: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1879
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.1879: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1880: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1881: Dma_PatchSrc (.L__pc.1881.LD), (.L__movme_tmp.1), (.L__pc.1881.LD)
	.p2align 4
	.L__pc.1881.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1882
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1882: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1883
	
	// CG.LOAD4 [.L__movme_cp.28} => .L__movme_tmp.0
	.L__pc.1883: Dma_PatchSrc (.L__pc.1883.LD), (.L__movme_cp.28), (.L__pc.1883.LD)
	.p2align 4
	.L__pc.1883.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1884
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.1884: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.1885
	.L__pc.1885: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.1886
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1886: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1887: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1888: Dma_PatchSrc (.L__pc.1888.LD), (.L__movme_tmp.1), (.L__pc.1888.LD)
	.p2align 4
	.L__pc.1888.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1889
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1889: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1890
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.1890: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1891: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1892: Dma_PatchSrc (.L__pc.1892.LD), (.L__movme_tmp.1), (.L__pc.1892.LD)
	.p2align 4
	.L__pc.1892.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1893
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1893: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1894
	
	.L__pc.1894: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.1895
	
	.p2align 4
	.L__pc.1895: Dma_PatchDst (.L__pc.1895.ST), (.L__movme_cp.32), (.L__pc.1895.ST)
	.L__pc.1895.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1896
	
	.L__pc.1896: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1897
	
	.p2align 4
	.L__pc.1897: Dma_PatchDst (.L__pc.1897.ST), (.L__movme_cp.24), (.L__pc.1897.ST)
	.L__pc.1897.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1898
	
	// CG.LOAD4 [.L__movme_cp.33} => .L__movme_tmp.0
	.L__pc.1898: Dma_PatchSrc (.L__pc.1898.LD), (.L__movme_cp.33), (.L__pc.1898.LD)
	.p2align 4
	.L__pc.1898.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1899
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1899: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1900
	
	.L__pc.1900: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1901
	
	.p2align 4
	.L__pc.1901: Dma_PatchDst (.L__pc.1901.ST), (.L__movme_cp.8), (.L__pc.1901.ST)
	.L__pc.1901.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1902
	
	// CG.COPY4 .L__movme_cp.56 => .L__movme_tmp.0
	.L__pc.1902: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.56), 4, .L__pc.1903
	
	.p2align 4
	.L__pc.1903: Dma_PatchDst (.L__pc.1903.ST), (.L__movme_cp.7), (.L__pc.1903.ST)
	.L__pc.1903.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1904
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.1904: Dma_PatchSrc (.L__pc.1904.LD), (.L__movme_cp.8), (.L__pc.1904.LD)
	.p2align 4
	.L__pc.1904.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1905
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1905: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1906
	
	// CG.LOAD4 [.L__movme_cp.7} => .L__movme_tmp.0
	.L__pc.1906: Dma_PatchSrc (.L__pc.1906.LD), (.L__movme_cp.7), (.L__pc.1906.LD)
	.p2align 4
	.L__pc.1906.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1907
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1907: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1908
	
	.L__pc.1908: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1909
	
	.p2align 4
	.L__pc.1909: Dma_PatchDst (.L__pc.1909.ST), (.L__movme_cp.57), (.L__pc.1909.ST)
	.L__pc.1909.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1910
	
	.L__pc.1910: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.1911
	
	.p2align 4
	.L__pc.1911: Dma_PatchDst (.L__pc.1911.ST), (.L__movme_cp.58), (.L__pc.1911.ST)
	.L__pc.1911.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1912
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1912: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1913
	
	.p2align 4
	.L__pc.1913: Dma_PatchDst (.L__pc.1913.ST), (.L__movme_cp.59), (.L__pc.1913.ST)
	.L__pc.1913.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1914
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1914: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1915
	
	.p2align 4
	.L__pc.1915: Dma_PatchDst (.L__pc.1915.ST), (.L__movme_cp.60), (.L__pc.1915.ST)
	.L__pc.1915.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1916
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1916: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1917
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1917: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1918
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.1918: Dma_PatchSrc (.L__pc.1918.LD), (.L__movme_cp.61), (.L__pc.1918.LD)
	.p2align 4
	.L__pc.1918.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1919
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1919: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.1920
	.L__pc.1920: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.1921
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.1921: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.62 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1922: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1923: Dma_PatchSrc (.L__pc.1923.LD), (.L__movme_tmp.1), (.L__pc.1923.LD)
	.p2align 4
	.L__pc.1923.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1924
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1924: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1925
	
	.L__pc.1925: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.1926
	
	.p2align 4
	.L__pc.1926: Dma_PatchDst (.L__pc.1926.ST), (.L__movme_cp.24), (.L__pc.1926.ST)
	.L__pc.1926.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1927
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1927: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1928
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1928: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1929
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1929: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1930
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1930: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1931
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.1931: Dma_PatchSrc (.L__pc.1931.LD), (.L__movme_cp.63), (.L__pc.1931.LD)
	.p2align 4
	.L__pc.1931.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1932
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1932: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.1933
	.L__pc.1933: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.1934
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.1934: Dma_PatchSrc (.L__pc.1934.LD), (.L__movme_cp.24), (.L__pc.1934.LD)
	.p2align 4
	.L__pc.1934.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1935
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1935: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.1936
	.L__pc.1936: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.1937
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.1937: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1938: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1939: Dma_PatchSrc (.L__pc.1939.LD), (.L__movme_tmp.1), (.L__pc.1939.LD)
	.p2align 4
	.L__pc.1939.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1940
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1940: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1941
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.1941: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.1942: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.1943: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1944: Dma_PatchSrc (.L__pc.1944.LD), (.L__movme_tmp.1), (.L__pc.1944.LD)
	.p2align 4
	.L__pc.1944.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1945
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1945: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1946
	
	.L__pc.1946: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.1947
	
	.p2align 4
	.L__pc.1947: Dma_PatchDst (.L__pc.1947.ST), (.L__movme_cp.63), (.L__pc.1947.ST)
	.L__pc.1947.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1948
	
	.L__pc.1948: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.1949
	
	.p2align 4
	.L__pc.1949: Dma_PatchDst (.L__pc.1949.ST), (.L__movme_cp.24), (.L__pc.1949.ST)
	.L__pc.1949.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1950
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1950: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1951
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1951: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1952
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1952: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1953
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1953: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1954
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.1954: Dma_PatchSrc (.L__pc.1954.LD), (.L__movme_cp.66), (.L__pc.1954.LD)
	.p2align 4
	.L__pc.1954.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1955
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1955: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.1956
	.L__pc.1956: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.1957
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.1957: Dma_PatchSrc (.L__pc.1957.LD), (.L__movme_cp.24), (.L__pc.1957.LD)
	.p2align 4
	.L__pc.1957.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1958
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1958: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.1959
	.L__pc.1959: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.1960
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.1960: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1961: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1962: Dma_PatchSrc (.L__pc.1962.LD), (.L__movme_tmp.1), (.L__pc.1962.LD)
	.p2align 4
	.L__pc.1962.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1963
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1963: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1964
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.1964: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.1965: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.1966: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1967: Dma_PatchSrc (.L__pc.1967.LD), (.L__movme_tmp.1), (.L__pc.1967.LD)
	.p2align 4
	.L__pc.1967.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1968
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1968: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1969
	
	.L__pc.1969: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.1970
	
	.p2align 4
	.L__pc.1970: Dma_PatchDst (.L__pc.1970.ST), (.L__movme_cp.66), (.L__pc.1970.ST)
	.L__pc.1970.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1971
	
	.L__pc.1971: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.1972
	
	.p2align 4
	.L__pc.1972: Dma_PatchDst (.L__pc.1972.ST), (.L__movme_cp.24), (.L__pc.1972.ST)
	.L__pc.1972.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1973
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1973: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1974
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1974: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1975
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1975: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1976
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1976: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.1977
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.1977: Dma_PatchSrc (.L__pc.1977.LD), (.L__movme_cp.67), (.L__pc.1977.LD)
	.p2align 4
	.L__pc.1977.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1978
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1978: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.1979
	.L__pc.1979: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.1980
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.1980: Dma_PatchSrc (.L__pc.1980.LD), (.L__movme_cp.24), (.L__pc.1980.LD)
	.p2align 4
	.L__pc.1980.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1981
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1981: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.1982
	.L__pc.1982: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.1983
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.1983: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.1984: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1985: Dma_PatchSrc (.L__pc.1985.LD), (.L__movme_tmp.1), (.L__pc.1985.LD)
	.p2align 4
	.L__pc.1985.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1986
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1986: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1987
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.1987: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.1988: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.1989: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.1990: Dma_PatchSrc (.L__pc.1990.LD), (.L__movme_tmp.1), (.L__pc.1990.LD)
	.p2align 4
	.L__pc.1990.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.1991
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1991: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1992
	
	.L__pc.1992: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.1993
	
	.p2align 4
	.L__pc.1993: Dma_PatchDst (.L__pc.1993.ST), (.L__movme_cp.67), (.L__pc.1993.ST)
	.L__pc.1993.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1994
	
	.L__pc.1994: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.1995
	
	.p2align 4
	.L__pc.1995: Dma_PatchDst (.L__pc.1995.ST), (.L__movme_cp.24), (.L__pc.1995.ST)
	.L__pc.1995.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.1996
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1996: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1997
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.1997: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.1998
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.1998: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.1999
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.1999: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2000
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.2000: Dma_PatchSrc (.L__pc.2000.LD), (.L__movme_cp.68), (.L__pc.2000.LD)
	.p2align 4
	.L__pc.2000.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2001
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2001: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2002
	.L__pc.2002: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2003
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2003: Dma_PatchSrc (.L__pc.2003.LD), (.L__movme_cp.24), (.L__pc.2003.LD)
	.p2align 4
	.L__pc.2003.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2004
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2004: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2005
	.L__pc.2005: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2006
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2006: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2007: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2008: Dma_PatchSrc (.L__pc.2008.LD), (.L__movme_tmp.1), (.L__pc.2008.LD)
	.p2align 4
	.L__pc.2008.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2009
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2009: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2010
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2010: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2011: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2012: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2013: Dma_PatchSrc (.L__pc.2013.LD), (.L__movme_tmp.1), (.L__pc.2013.LD)
	.p2align 4
	.L__pc.2013.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2014
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2014: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2015
	
	.L__pc.2015: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2016
	
	.p2align 4
	.L__pc.2016: Dma_PatchDst (.L__pc.2016.ST), (.L__movme_cp.68), (.L__pc.2016.ST)
	.L__pc.2016.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2017
	
	.L__pc.2017: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2018
	
	.p2align 4
	.L__pc.2018: Dma_PatchDst (.L__pc.2018.ST), (.L__movme_cp.24), (.L__pc.2018.ST)
	.L__pc.2018.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2019
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2019: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2020
	
	.p2align 4
	.L__pc.2020: Dma_PatchDst (.L__pc.2020.ST), (.L__movme_cp.24), (.L__pc.2020.ST)
	.L__pc.2020.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2021
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.2021: Dma_PatchSrc (.L__pc.2021.LD), (.L__movme_cp.60), (.L__pc.2021.LD)
	.p2align 4
	.L__pc.2021.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2022
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2022: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2023
	
	.L__pc.2023: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2024
	
	.p2align 4
	.L__pc.2024: Dma_PatchDst (.L__pc.2024.ST), (.L__movme_cp.21), (.L__pc.2024.ST)
	.L__pc.2024.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2025
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.2025: Dma_PatchSrc (.L__pc.2025.LD), (.L__movme_cp.58), (.L__pc.2025.LD)
	.p2align 4
	.L__pc.2025.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2026
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2026: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2027
	
	.L__pc.2027: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2028
	
	.p2align 4
	.L__pc.2028: Dma_PatchDst (.L__pc.2028.ST), (.L__movme_cp.22), (.L__pc.2028.ST)
	.L__pc.2028.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2029
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2029: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2030
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2030: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2031
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2031: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2032
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2032: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2033
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.2033: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.2034
	
	.p2align 4
	.L__pc.2034: Dma_PatchDst (.L__pc.2034.ST), (.L__movme_cp.24), (.L__pc.2034.ST)
	.L__pc.2034.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2035
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.2035: Dma_PatchSrc (.L__pc.2035.LD), (.L__movme_cp.25), (.L__pc.2035.LD)
	.p2align 4
	.L__pc.2035.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2036
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2036: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2037
	.L__pc.2037: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2038
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.2038: Dma_PatchSrc (.L__pc.2038.LD), (.L__movme_cp.26), (.L__pc.2038.LD)
	.p2align 4
	.L__pc.2038.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2039
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2039: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2040
	.L__pc.2040: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2041
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2041: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2042: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2043: Dma_PatchSrc (.L__pc.2043.LD), (.L__movme_tmp.1), (.L__pc.2043.LD)
	.p2align 4
	.L__pc.2043.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2044
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2044: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2045
	.L__pc.2045: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2046
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2046: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2047: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2048: Dma_PatchSrc (.L__pc.2048.LD), (.L__movme_tmp.1), (.L__pc.2048.LD)
	.p2align 4
	.L__pc.2048.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2049
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2049: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2050
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2050: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2051: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2052: Dma_PatchSrc (.L__pc.2052.LD), (.L__movme_tmp.1), (.L__pc.2052.LD)
	.p2align 4
	.L__pc.2052.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2053
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2053: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2054
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2054: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2055: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2056: Dma_PatchSrc (.L__pc.2056.LD), (.L__movme_tmp.1), (.L__pc.2056.LD)
	.p2align 4
	.L__pc.2056.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2057
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2057: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2058
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2058: Dma_PatchSrc (.L__pc.2058.LD), (.L__movme_cp.24), (.L__pc.2058.LD)
	.p2align 4
	.L__pc.2058.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2059
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2059: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2060
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2060: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2061: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2062: Dma_PatchSrc (.L__pc.2062.LD), (.L__movme_tmp.1), (.L__pc.2062.LD)
	.p2align 4
	.L__pc.2062.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2063
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2063: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2064
	
	.L__pc.2064: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2065
	
	.p2align 4
	.L__pc.2065: Dma_PatchDst (.L__pc.2065.ST), (.L__movme_cp.69), (.L__pc.2065.ST)
	.L__pc.2065.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2066
	
	.L__pc.2066: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2067
	
	.p2align 4
	.L__pc.2067: Dma_PatchDst (.L__pc.2067.ST), (.L__movme_cp.54), (.L__pc.2067.ST)
	.L__pc.2067.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2068
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.2068: Dma_PatchSrc (.L__pc.2068.LD), (.L__movme_cp.30), (.L__pc.2068.LD)
	.p2align 4
	.L__pc.2068.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2069
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2069: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2070
	.L__pc.2070: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2071
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.2071: Dma_PatchSrc (.L__pc.2071.LD), (.L__movme_cp.31), (.L__pc.2071.LD)
	.p2align 4
	.L__pc.2071.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2072
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2072: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2073
	.L__pc.2073: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2074
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2074: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2075: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2076: Dma_PatchSrc (.L__pc.2076.LD), (.L__movme_tmp.1), (.L__pc.2076.LD)
	.p2align 4
	.L__pc.2076.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2077
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2077: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2078
	.L__pc.2078: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2079
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2079: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2080: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2081: Dma_PatchSrc (.L__pc.2081.LD), (.L__movme_tmp.1), (.L__pc.2081.LD)
	.p2align 4
	.L__pc.2081.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2082
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2082: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2083
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2083: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2084: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2085: Dma_PatchSrc (.L__pc.2085.LD), (.L__movme_tmp.1), (.L__pc.2085.LD)
	.p2align 4
	.L__pc.2085.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2086
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2086: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2087
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2087: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2088: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2089: Dma_PatchSrc (.L__pc.2089.LD), (.L__movme_tmp.1), (.L__pc.2089.LD)
	.p2align 4
	.L__pc.2089.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2090
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2090: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2091
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2091: Dma_PatchSrc (.L__pc.2091.LD), (.L__movme_cp.24), (.L__pc.2091.LD)
	.p2align 4
	.L__pc.2091.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2092
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2092: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2093
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2093: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2094: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2095: Dma_PatchSrc (.L__pc.2095.LD), (.L__movme_tmp.1), (.L__pc.2095.LD)
	.p2align 4
	.L__pc.2095.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2096
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2096: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2097
	
	.L__pc.2097: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2098
	
	.p2align 4
	.L__pc.2098: Dma_PatchDst (.L__pc.2098.ST), (.L__movme_cp.70), (.L__pc.2098.ST)
	.L__pc.2098.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2099
	
	.L__pc.2099: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2100
	
	.p2align 4
	.L__pc.2100: Dma_PatchDst (.L__pc.2100.ST), (.L__movme_cp.54), (.L__pc.2100.ST)
	.L__pc.2100.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2101
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2101: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2102
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2102: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2103
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2103: Dma_PatchSrc (.L__pc.2103.LD), (.L__movme_cp.24), (.L__pc.2103.LD)
	.p2align 4
	.L__pc.2103.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2104
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2104: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2105
	.L__pc.2105: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2106
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.2106: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2107: Dma_PatchSrc (.L__pc.2107.LD), (.L__movme_tmp.1), (.L__pc.2107.LD)
	.p2align 4
	.L__pc.2107.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2108
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2108: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2109
	.L__pc.2109: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2110
	
	.L__pc.2110: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2111
	
	.p2align 4
	.L__pc.2111: Dma_PatchDst (.L__pc.2111.ST), (.L__movme_cp.72), (.L__pc.2111.ST)
	.L__pc.2111.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2112
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.2112: Dma_PatchSrc (.L__pc.2112.LD), (.L__movme_cp.72), (.L__pc.2112.LD)
	.p2align 4
	.L__pc.2112.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2113
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2113: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2114
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2114: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2115: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2116: Dma_PatchSrc (.L__pc.2116.LD), (.L__movme_tmp.1), (.L__pc.2116.LD)
	.p2align 4
	.L__pc.2116.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2117
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2117: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2118
	
	.L__pc.2118: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2119
	
	.p2align 4
	.L__pc.2119: Dma_PatchDst (.L__pc.2119.ST), (.L__movme_cp.74), (.L__pc.2119.ST)
	.L__pc.2119.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2120
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2120: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2121: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2122: Dma_PatchSrc (.L__pc.2122.LD), (.L__movme_tmp.1), (.L__pc.2122.LD)
	.p2align 4
	.L__pc.2122.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2123
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2123: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2124
	
	.L__pc.2124: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2125
	
	.p2align 4
	.L__pc.2125: Dma_PatchDst (.L__pc.2125.ST), (.L__movme_cp.76), (.L__pc.2125.ST)
	.L__pc.2125.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2126
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.2126: Dma_PatchSrc (.L__pc.2126.LD), (.L__movme_cp.74), (.L__pc.2126.LD)
	.p2align 4
	.L__pc.2126.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2127
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2127: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2128
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.2128: Dma_PatchSrc (.L__pc.2128.LD), ((.L__movme.reg.eax+0)), (.L__pc.2128.LD)
	.p2align 4
	.L__pc.2128.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2129
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2129: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2130
	
	.L__pc.2130: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2131
	
	.p2align 4
	.L__pc.2131: Dma_PatchDst (.L__pc.2131.ST), (.L__movme_cp.77), (.L__pc.2131.ST)
	.L__pc.2131.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2132
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.2132: Dma_PatchSrc (.L__pc.2132.LD), (.L__movme_cp.77), (.L__pc.2132.LD)
	.p2align 4
	.L__pc.2132.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2133
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2133: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2134
	
	.L__pc.2134: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2135
	
	.p2align 4
	.L__pc.2135: Dma_PatchDst (.L__pc.2135.ST), (.L__movme_cp.21), (.L__pc.2135.ST)
	.L__pc.2135.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2136
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.2136: Dma_PatchSrc (.L__pc.2136.LD), (.L__movme_cp.58), (.L__pc.2136.LD)
	.p2align 4
	.L__pc.2136.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2137
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2137: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2138
	
	.L__pc.2138: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2139
	
	.p2align 4
	.L__pc.2139: Dma_PatchDst (.L__pc.2139.ST), (.L__movme_cp.22), (.L__pc.2139.ST)
	.L__pc.2139.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2140
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2140: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2141
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2141: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2142
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2142: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2143
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2143: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2144
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.2144: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.2145
	
	.p2align 4
	.L__pc.2145: Dma_PatchDst (.L__pc.2145.ST), (.L__movme_cp.24), (.L__pc.2145.ST)
	.L__pc.2145.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2146
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.2146: Dma_PatchSrc (.L__pc.2146.LD), (.L__movme_cp.25), (.L__pc.2146.LD)
	.p2align 4
	.L__pc.2146.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2147
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2147: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2148
	.L__pc.2148: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2149
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.2149: Dma_PatchSrc (.L__pc.2149.LD), (.L__movme_cp.26), (.L__pc.2149.LD)
	.p2align 4
	.L__pc.2149.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2150
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2150: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2151
	.L__pc.2151: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2152
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2152: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2153: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2154: Dma_PatchSrc (.L__pc.2154.LD), (.L__movme_tmp.1), (.L__pc.2154.LD)
	.p2align 4
	.L__pc.2154.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2155
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2155: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2156
	.L__pc.2156: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2157
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2157: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2158: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2159: Dma_PatchSrc (.L__pc.2159.LD), (.L__movme_tmp.1), (.L__pc.2159.LD)
	.p2align 4
	.L__pc.2159.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2160
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2160: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2161
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2161: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2162: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2163: Dma_PatchSrc (.L__pc.2163.LD), (.L__movme_tmp.1), (.L__pc.2163.LD)
	.p2align 4
	.L__pc.2163.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2164
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2164: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2165
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2165: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2166: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2167: Dma_PatchSrc (.L__pc.2167.LD), (.L__movme_tmp.1), (.L__pc.2167.LD)
	.p2align 4
	.L__pc.2167.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2168
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2168: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2169
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2169: Dma_PatchSrc (.L__pc.2169.LD), (.L__movme_cp.24), (.L__pc.2169.LD)
	.p2align 4
	.L__pc.2169.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2170
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2170: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2171
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2171: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2172: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2173: Dma_PatchSrc (.L__pc.2173.LD), (.L__movme_tmp.1), (.L__pc.2173.LD)
	.p2align 4
	.L__pc.2173.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2174
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2174: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2175
	
	.L__pc.2175: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2176
	
	.p2align 4
	.L__pc.2176: Dma_PatchDst (.L__pc.2176.ST), (.L__movme_cp.78), (.L__pc.2176.ST)
	.L__pc.2176.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2177
	
	.L__pc.2177: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2178
	
	.p2align 4
	.L__pc.2178: Dma_PatchDst (.L__pc.2178.ST), (.L__movme_cp.54), (.L__pc.2178.ST)
	.L__pc.2178.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2179
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.2179: Dma_PatchSrc (.L__pc.2179.LD), (.L__movme_cp.30), (.L__pc.2179.LD)
	.p2align 4
	.L__pc.2179.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2180
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2180: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2181
	.L__pc.2181: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2182
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.2182: Dma_PatchSrc (.L__pc.2182.LD), (.L__movme_cp.31), (.L__pc.2182.LD)
	.p2align 4
	.L__pc.2182.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2183
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2183: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2184
	.L__pc.2184: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2185
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2185: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2186: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2187: Dma_PatchSrc (.L__pc.2187.LD), (.L__movme_tmp.1), (.L__pc.2187.LD)
	.p2align 4
	.L__pc.2187.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2188
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2188: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2189
	.L__pc.2189: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2190
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2190: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2191: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2192: Dma_PatchSrc (.L__pc.2192.LD), (.L__movme_tmp.1), (.L__pc.2192.LD)
	.p2align 4
	.L__pc.2192.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2193
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2193: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2194
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2194: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2195: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2196: Dma_PatchSrc (.L__pc.2196.LD), (.L__movme_tmp.1), (.L__pc.2196.LD)
	.p2align 4
	.L__pc.2196.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2197
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2197: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2198
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2198: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2199: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2200: Dma_PatchSrc (.L__pc.2200.LD), (.L__movme_tmp.1), (.L__pc.2200.LD)
	.p2align 4
	.L__pc.2200.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2201
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2201: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2202
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2202: Dma_PatchSrc (.L__pc.2202.LD), (.L__movme_cp.24), (.L__pc.2202.LD)
	.p2align 4
	.L__pc.2202.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2203
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2203: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2204
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2204: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2205: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2206: Dma_PatchSrc (.L__pc.2206.LD), (.L__movme_tmp.1), (.L__pc.2206.LD)
	.p2align 4
	.L__pc.2206.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2207
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2207: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2208
	
	.L__pc.2208: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2209
	
	.p2align 4
	.L__pc.2209: Dma_PatchDst (.L__pc.2209.ST), (.L__movme_cp.79), (.L__pc.2209.ST)
	.L__pc.2209.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2210
	
	.L__pc.2210: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2211
	
	.p2align 4
	.L__pc.2211: Dma_PatchDst (.L__pc.2211.ST), (.L__movme_cp.54), (.L__pc.2211.ST)
	.L__pc.2211.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2212
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.2212: Dma_PatchSrc (.L__pc.2212.LD), (.L__movme_cp.74), (.L__pc.2212.LD)
	.p2align 4
	.L__pc.2212.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2213
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2213: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2214
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.2214: Dma_PatchSrc (.L__pc.2214.LD), (.L__movme_cp.77), (.L__pc.2214.LD)
	.p2align 4
	.L__pc.2214.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2215
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2215: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2216
	
	.L__pc.2216: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2217
	
	.p2align 4
	.L__pc.2217: Dma_PatchDst (.L__pc.2217.ST), ((.L__movme.reg.eax+0)), (.L__pc.2217.ST)
	.L__pc.2217.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2218
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.2218: Dma_PatchSrc (.L__pc.2218.LD), (.L__movme_cp.76), (.L__pc.2218.LD)
	.p2align 4
	.L__pc.2218.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2219
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2219: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2220
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.2220: Dma_PatchSrc (.L__pc.2220.LD), ((.L__movme.reg.eax+0)), (.L__pc.2220.LD)
	.p2align 4
	.L__pc.2220.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2221
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2221: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2222
	
	.L__pc.2222: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2223
	
	.p2align 4
	.L__pc.2223: Dma_PatchDst (.L__pc.2223.ST), (.L__movme_cp.80), (.L__pc.2223.ST)
	.L__pc.2223.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2224
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2224: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2225
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2225: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2226
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.2226: Dma_PatchSrc (.L__pc.2226.LD), (.L__movme_cp.81), (.L__pc.2226.LD)
	.p2align 4
	.L__pc.2226.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2227
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2227: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2228
	.L__pc.2228: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2229
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.82 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.2229: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2230: Dma_PatchSrc (.L__pc.2230.LD), (.L__movme_tmp.1), (.L__pc.2230.LD)
	.p2align 4
	.L__pc.2230.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2231
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2231: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2232
	.L__pc.2232: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2233
	
	.L__pc.2233: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2234
	
	.p2align 4
	.L__pc.2234: Dma_PatchDst (.L__pc.2234.ST), (.L__movme_cp.81), (.L__pc.2234.ST)
	.L__pc.2234.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2235
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.2235: Dma_PatchSrc (.L__pc.2235.LD), (.L__movme_cp.76), (.L__pc.2235.LD)
	.p2align 4
	.L__pc.2235.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2236
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2236: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2237
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.2237: Dma_PatchSrc (.L__pc.2237.LD), (.L__movme_cp.80), (.L__pc.2237.LD)
	.p2align 4
	.L__pc.2237.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2238
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2238: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2239
	
	.L__pc.2239: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2240
	
	.p2align 4
	.L__pc.2240: Dma_PatchDst (.L__pc.2240.ST), ((.L__movme.reg.eax+0)), (.L__pc.2240.ST)
	.L__pc.2240.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2241
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2241: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2242
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2242: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2243
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.2243: Dma_PatchSrc (.L__pc.2243.LD), (.L__movme_cp.61), (.L__pc.2243.LD)
	.p2align 4
	.L__pc.2243.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2244
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2244: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2245
	.L__pc.2245: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2246
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2246: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.83 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2247: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2248: Dma_PatchSrc (.L__pc.2248.LD), (.L__movme_tmp.1), (.L__pc.2248.LD)
	.p2align 4
	.L__pc.2248.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2249
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2249: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2250
	
	.L__pc.2250: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2251
	
	.p2align 4
	.L__pc.2251: Dma_PatchDst (.L__pc.2251.ST), (.L__movme_cp.24), (.L__pc.2251.ST)
	.L__pc.2251.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2252
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2252: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2253
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2253: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2254
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2254: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2255
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2255: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2256
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.2256: Dma_PatchSrc (.L__pc.2256.LD), (.L__movme_cp.63), (.L__pc.2256.LD)
	.p2align 4
	.L__pc.2256.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2257
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2257: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2258
	.L__pc.2258: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2259
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2259: Dma_PatchSrc (.L__pc.2259.LD), (.L__movme_cp.24), (.L__pc.2259.LD)
	.p2align 4
	.L__pc.2259.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2260
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2260: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2261
	.L__pc.2261: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2262
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2262: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2263: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2264: Dma_PatchSrc (.L__pc.2264.LD), (.L__movme_tmp.1), (.L__pc.2264.LD)
	.p2align 4
	.L__pc.2264.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2265
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2265: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2266
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2266: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2267: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2268: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2269: Dma_PatchSrc (.L__pc.2269.LD), (.L__movme_tmp.1), (.L__pc.2269.LD)
	.p2align 4
	.L__pc.2269.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2270
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2270: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2271
	
	.L__pc.2271: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2272
	
	.p2align 4
	.L__pc.2272: Dma_PatchDst (.L__pc.2272.ST), (.L__movme_cp.63), (.L__pc.2272.ST)
	.L__pc.2272.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2273
	
	.L__pc.2273: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2274
	
	.p2align 4
	.L__pc.2274: Dma_PatchDst (.L__pc.2274.ST), (.L__movme_cp.24), (.L__pc.2274.ST)
	.L__pc.2274.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2275
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2275: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2276
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2276: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2277
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2277: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2278
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2278: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2279
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.2279: Dma_PatchSrc (.L__pc.2279.LD), (.L__movme_cp.66), (.L__pc.2279.LD)
	.p2align 4
	.L__pc.2279.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2280
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2280: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2281
	.L__pc.2281: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2282
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2282: Dma_PatchSrc (.L__pc.2282.LD), (.L__movme_cp.24), (.L__pc.2282.LD)
	.p2align 4
	.L__pc.2282.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2283
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2283: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2284
	.L__pc.2284: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2285
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2285: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2286: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2287: Dma_PatchSrc (.L__pc.2287.LD), (.L__movme_tmp.1), (.L__pc.2287.LD)
	.p2align 4
	.L__pc.2287.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2288
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2288: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2289
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2289: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2290: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2291: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2292: Dma_PatchSrc (.L__pc.2292.LD), (.L__movme_tmp.1), (.L__pc.2292.LD)
	.p2align 4
	.L__pc.2292.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2293
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2293: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2294
	
	.L__pc.2294: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2295
	
	.p2align 4
	.L__pc.2295: Dma_PatchDst (.L__pc.2295.ST), (.L__movme_cp.66), (.L__pc.2295.ST)
	.L__pc.2295.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2296
	
	.L__pc.2296: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2297
	
	.p2align 4
	.L__pc.2297: Dma_PatchDst (.L__pc.2297.ST), (.L__movme_cp.24), (.L__pc.2297.ST)
	.L__pc.2297.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2298
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2298: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2299
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2299: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2300
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2300: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2301
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2301: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2302
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.2302: Dma_PatchSrc (.L__pc.2302.LD), (.L__movme_cp.67), (.L__pc.2302.LD)
	.p2align 4
	.L__pc.2302.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2303
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2303: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2304
	.L__pc.2304: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2305
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2305: Dma_PatchSrc (.L__pc.2305.LD), (.L__movme_cp.24), (.L__pc.2305.LD)
	.p2align 4
	.L__pc.2305.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2306
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2306: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2307
	.L__pc.2307: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2308
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2308: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2309: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2310: Dma_PatchSrc (.L__pc.2310.LD), (.L__movme_tmp.1), (.L__pc.2310.LD)
	.p2align 4
	.L__pc.2310.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2311
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2311: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2312
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2312: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2313: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2314: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2315: Dma_PatchSrc (.L__pc.2315.LD), (.L__movme_tmp.1), (.L__pc.2315.LD)
	.p2align 4
	.L__pc.2315.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2316
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2316: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2317
	
	.L__pc.2317: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2318
	
	.p2align 4
	.L__pc.2318: Dma_PatchDst (.L__pc.2318.ST), (.L__movme_cp.67), (.L__pc.2318.ST)
	.L__pc.2318.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2319
	
	.L__pc.2319: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2320
	
	.p2align 4
	.L__pc.2320: Dma_PatchDst (.L__pc.2320.ST), (.L__movme_cp.24), (.L__pc.2320.ST)
	.L__pc.2320.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2321
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2321: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2322
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2322: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2323
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2323: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2324
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2324: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2325
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.2325: Dma_PatchSrc (.L__pc.2325.LD), (.L__movme_cp.68), (.L__pc.2325.LD)
	.p2align 4
	.L__pc.2325.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2326
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2326: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2327
	.L__pc.2327: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2328
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2328: Dma_PatchSrc (.L__pc.2328.LD), (.L__movme_cp.24), (.L__pc.2328.LD)
	.p2align 4
	.L__pc.2328.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2329
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2329: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2330
	.L__pc.2330: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2331
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2331: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2332: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2333: Dma_PatchSrc (.L__pc.2333.LD), (.L__movme_tmp.1), (.L__pc.2333.LD)
	.p2align 4
	.L__pc.2333.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2334
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2334: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2335
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2335: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2336: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2337: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2338: Dma_PatchSrc (.L__pc.2338.LD), (.L__movme_tmp.1), (.L__pc.2338.LD)
	.p2align 4
	.L__pc.2338.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2339
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2339: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2340
	
	.L__pc.2340: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2341
	
	.p2align 4
	.L__pc.2341: Dma_PatchDst (.L__pc.2341.ST), (.L__movme_cp.68), (.L__pc.2341.ST)
	.L__pc.2341.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2342
	
	.L__pc.2342: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2343
	
	.p2align 4
	.L__pc.2343: Dma_PatchDst (.L__pc.2343.ST), (.L__movme_cp.24), (.L__pc.2343.ST)
	.L__pc.2343.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2344
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2344: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2345
	
	.p2align 4
	.L__pc.2345: Dma_PatchDst (.L__pc.2345.ST), (.L__movme_cp.24), (.L__pc.2345.ST)
	.L__pc.2345.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2346
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.2346: Dma_PatchSrc (.L__pc.2346.LD), (.L__movme_cp.60), (.L__pc.2346.LD)
	.p2align 4
	.L__pc.2346.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2347
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2347: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2348
	
	.L__pc.2348: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2349
	
	.p2align 4
	.L__pc.2349: Dma_PatchDst (.L__pc.2349.ST), (.L__movme_cp.21), (.L__pc.2349.ST)
	.L__pc.2349.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2350
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.2350: Dma_PatchSrc (.L__pc.2350.LD), (.L__movme_cp.58), (.L__pc.2350.LD)
	.p2align 4
	.L__pc.2350.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2351
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2351: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2352
	
	.L__pc.2352: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2353
	
	.p2align 4
	.L__pc.2353: Dma_PatchDst (.L__pc.2353.ST), (.L__movme_cp.22), (.L__pc.2353.ST)
	.L__pc.2353.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2354
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2354: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2355
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2355: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2356
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2356: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2357
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2357: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2358
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.2358: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.2359
	
	.p2align 4
	.L__pc.2359: Dma_PatchDst (.L__pc.2359.ST), (.L__movme_cp.24), (.L__pc.2359.ST)
	.L__pc.2359.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2360
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.2360: Dma_PatchSrc (.L__pc.2360.LD), (.L__movme_cp.25), (.L__pc.2360.LD)
	.p2align 4
	.L__pc.2360.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2361
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2361: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2362
	.L__pc.2362: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2363
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.2363: Dma_PatchSrc (.L__pc.2363.LD), (.L__movme_cp.26), (.L__pc.2363.LD)
	.p2align 4
	.L__pc.2363.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2364
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2364: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2365
	.L__pc.2365: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2366
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2366: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2367: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2368: Dma_PatchSrc (.L__pc.2368.LD), (.L__movme_tmp.1), (.L__pc.2368.LD)
	.p2align 4
	.L__pc.2368.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2369
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2369: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2370
	.L__pc.2370: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2371
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2371: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2372: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2373: Dma_PatchSrc (.L__pc.2373.LD), (.L__movme_tmp.1), (.L__pc.2373.LD)
	.p2align 4
	.L__pc.2373.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2374
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2374: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2375
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2375: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2376: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2377: Dma_PatchSrc (.L__pc.2377.LD), (.L__movme_tmp.1), (.L__pc.2377.LD)
	.p2align 4
	.L__pc.2377.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2378
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2378: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2379
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2379: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2380: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2381: Dma_PatchSrc (.L__pc.2381.LD), (.L__movme_tmp.1), (.L__pc.2381.LD)
	.p2align 4
	.L__pc.2381.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2382
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2382: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2383
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2383: Dma_PatchSrc (.L__pc.2383.LD), (.L__movme_cp.24), (.L__pc.2383.LD)
	.p2align 4
	.L__pc.2383.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2384
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2384: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2385
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2385: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2386: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2387: Dma_PatchSrc (.L__pc.2387.LD), (.L__movme_tmp.1), (.L__pc.2387.LD)
	.p2align 4
	.L__pc.2387.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2388
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2388: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2389
	
	.L__pc.2389: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2390
	
	.p2align 4
	.L__pc.2390: Dma_PatchDst (.L__pc.2390.ST), (.L__movme_cp.69), (.L__pc.2390.ST)
	.L__pc.2390.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2391
	
	.L__pc.2391: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2392
	
	.p2align 4
	.L__pc.2392: Dma_PatchDst (.L__pc.2392.ST), (.L__movme_cp.54), (.L__pc.2392.ST)
	.L__pc.2392.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2393
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.2393: Dma_PatchSrc (.L__pc.2393.LD), (.L__movme_cp.30), (.L__pc.2393.LD)
	.p2align 4
	.L__pc.2393.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2394
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2394: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2395
	.L__pc.2395: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2396
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.2396: Dma_PatchSrc (.L__pc.2396.LD), (.L__movme_cp.31), (.L__pc.2396.LD)
	.p2align 4
	.L__pc.2396.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2397
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2397: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2398
	.L__pc.2398: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2399
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2399: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2400: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2401: Dma_PatchSrc (.L__pc.2401.LD), (.L__movme_tmp.1), (.L__pc.2401.LD)
	.p2align 4
	.L__pc.2401.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2402
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2402: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2403
	.L__pc.2403: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2404
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2404: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2405: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2406: Dma_PatchSrc (.L__pc.2406.LD), (.L__movme_tmp.1), (.L__pc.2406.LD)
	.p2align 4
	.L__pc.2406.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2407
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2407: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2408
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2408: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2409: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2410: Dma_PatchSrc (.L__pc.2410.LD), (.L__movme_tmp.1), (.L__pc.2410.LD)
	.p2align 4
	.L__pc.2410.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2411
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2411: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2412
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2412: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2413: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2414: Dma_PatchSrc (.L__pc.2414.LD), (.L__movme_tmp.1), (.L__pc.2414.LD)
	.p2align 4
	.L__pc.2414.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2415
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2415: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2416
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2416: Dma_PatchSrc (.L__pc.2416.LD), (.L__movme_cp.24), (.L__pc.2416.LD)
	.p2align 4
	.L__pc.2416.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2417
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2417: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2418
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2418: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2419: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2420: Dma_PatchSrc (.L__pc.2420.LD), (.L__movme_tmp.1), (.L__pc.2420.LD)
	.p2align 4
	.L__pc.2420.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2421
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2421: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2422
	
	.L__pc.2422: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2423
	
	.p2align 4
	.L__pc.2423: Dma_PatchDst (.L__pc.2423.ST), (.L__movme_cp.70), (.L__pc.2423.ST)
	.L__pc.2423.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2424
	
	.L__pc.2424: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2425
	
	.p2align 4
	.L__pc.2425: Dma_PatchDst (.L__pc.2425.ST), (.L__movme_cp.54), (.L__pc.2425.ST)
	.L__pc.2425.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2426
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2426: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2427
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2427: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2428
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2428: Dma_PatchSrc (.L__pc.2428.LD), (.L__movme_cp.24), (.L__pc.2428.LD)
	.p2align 4
	.L__pc.2428.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2429
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2429: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2430
	.L__pc.2430: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2431
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.2431: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2432: Dma_PatchSrc (.L__pc.2432.LD), (.L__movme_tmp.1), (.L__pc.2432.LD)
	.p2align 4
	.L__pc.2432.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2433
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2433: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2434
	.L__pc.2434: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2435
	
	.L__pc.2435: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2436
	
	.p2align 4
	.L__pc.2436: Dma_PatchDst (.L__pc.2436.ST), (.L__movme_cp.72), (.L__pc.2436.ST)
	.L__pc.2436.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2437
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.2437: Dma_PatchSrc (.L__pc.2437.LD), (.L__movme_cp.72), (.L__pc.2437.LD)
	.p2align 4
	.L__pc.2437.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2438
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2438: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2439
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2439: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2440: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2441: Dma_PatchSrc (.L__pc.2441.LD), (.L__movme_tmp.1), (.L__pc.2441.LD)
	.p2align 4
	.L__pc.2441.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2442
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2442: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2443
	
	.L__pc.2443: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2444
	
	.p2align 4
	.L__pc.2444: Dma_PatchDst (.L__pc.2444.ST), (.L__movme_cp.74), (.L__pc.2444.ST)
	.L__pc.2444.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2445
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2445: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2446: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2447: Dma_PatchSrc (.L__pc.2447.LD), (.L__movme_tmp.1), (.L__pc.2447.LD)
	.p2align 4
	.L__pc.2447.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2448
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2448: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2449
	
	.L__pc.2449: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2450
	
	.p2align 4
	.L__pc.2450: Dma_PatchDst (.L__pc.2450.ST), (.L__movme_cp.76), (.L__pc.2450.ST)
	.L__pc.2450.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2451
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.2451: Dma_PatchSrc (.L__pc.2451.LD), (.L__movme_cp.74), (.L__pc.2451.LD)
	.p2align 4
	.L__pc.2451.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2452
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2452: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2453
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.2453: Dma_PatchSrc (.L__pc.2453.LD), ((.L__movme.reg.eax+0)), (.L__pc.2453.LD)
	.p2align 4
	.L__pc.2453.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2454
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2454: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2455
	
	.L__pc.2455: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2456
	
	.p2align 4
	.L__pc.2456: Dma_PatchDst (.L__pc.2456.ST), (.L__movme_cp.77), (.L__pc.2456.ST)
	.L__pc.2456.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2457
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.2457: Dma_PatchSrc (.L__pc.2457.LD), (.L__movme_cp.77), (.L__pc.2457.LD)
	.p2align 4
	.L__pc.2457.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2458
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2458: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2459
	
	.L__pc.2459: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2460
	
	.p2align 4
	.L__pc.2460: Dma_PatchDst (.L__pc.2460.ST), (.L__movme_cp.21), (.L__pc.2460.ST)
	.L__pc.2460.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2461
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.2461: Dma_PatchSrc (.L__pc.2461.LD), (.L__movme_cp.58), (.L__pc.2461.LD)
	.p2align 4
	.L__pc.2461.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2462
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2462: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2463
	
	.L__pc.2463: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2464
	
	.p2align 4
	.L__pc.2464: Dma_PatchDst (.L__pc.2464.ST), (.L__movme_cp.22), (.L__pc.2464.ST)
	.L__pc.2464.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2465
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2465: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2466
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2466: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2467
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2467: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2468
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2468: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2469
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.2469: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.2470
	
	.p2align 4
	.L__pc.2470: Dma_PatchDst (.L__pc.2470.ST), (.L__movme_cp.24), (.L__pc.2470.ST)
	.L__pc.2470.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2471
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.2471: Dma_PatchSrc (.L__pc.2471.LD), (.L__movme_cp.25), (.L__pc.2471.LD)
	.p2align 4
	.L__pc.2471.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2472
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2472: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2473
	.L__pc.2473: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2474
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.2474: Dma_PatchSrc (.L__pc.2474.LD), (.L__movme_cp.26), (.L__pc.2474.LD)
	.p2align 4
	.L__pc.2474.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2475
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2475: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2476
	.L__pc.2476: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2477
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2477: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2478: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2479: Dma_PatchSrc (.L__pc.2479.LD), (.L__movme_tmp.1), (.L__pc.2479.LD)
	.p2align 4
	.L__pc.2479.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2480
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2480: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2481
	.L__pc.2481: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2482
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2482: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2483: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2484: Dma_PatchSrc (.L__pc.2484.LD), (.L__movme_tmp.1), (.L__pc.2484.LD)
	.p2align 4
	.L__pc.2484.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2485
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2485: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2486
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2486: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2487: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2488: Dma_PatchSrc (.L__pc.2488.LD), (.L__movme_tmp.1), (.L__pc.2488.LD)
	.p2align 4
	.L__pc.2488.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2489
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2489: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2490
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2490: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2491: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2492: Dma_PatchSrc (.L__pc.2492.LD), (.L__movme_tmp.1), (.L__pc.2492.LD)
	.p2align 4
	.L__pc.2492.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2493
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2493: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2494
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2494: Dma_PatchSrc (.L__pc.2494.LD), (.L__movme_cp.24), (.L__pc.2494.LD)
	.p2align 4
	.L__pc.2494.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2495
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2495: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2496
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2496: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2497: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2498: Dma_PatchSrc (.L__pc.2498.LD), (.L__movme_tmp.1), (.L__pc.2498.LD)
	.p2align 4
	.L__pc.2498.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2499
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2499: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2500
	
	.L__pc.2500: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2501
	
	.p2align 4
	.L__pc.2501: Dma_PatchDst (.L__pc.2501.ST), (.L__movme_cp.78), (.L__pc.2501.ST)
	.L__pc.2501.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2502
	
	.L__pc.2502: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2503
	
	.p2align 4
	.L__pc.2503: Dma_PatchDst (.L__pc.2503.ST), (.L__movme_cp.54), (.L__pc.2503.ST)
	.L__pc.2503.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2504
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.2504: Dma_PatchSrc (.L__pc.2504.LD), (.L__movme_cp.30), (.L__pc.2504.LD)
	.p2align 4
	.L__pc.2504.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2505
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2505: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2506
	.L__pc.2506: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2507
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.2507: Dma_PatchSrc (.L__pc.2507.LD), (.L__movme_cp.31), (.L__pc.2507.LD)
	.p2align 4
	.L__pc.2507.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2508
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2508: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2509
	.L__pc.2509: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2510
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2510: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2511: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2512: Dma_PatchSrc (.L__pc.2512.LD), (.L__movme_tmp.1), (.L__pc.2512.LD)
	.p2align 4
	.L__pc.2512.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2513
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2513: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2514
	.L__pc.2514: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2515
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2515: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2516: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2517: Dma_PatchSrc (.L__pc.2517.LD), (.L__movme_tmp.1), (.L__pc.2517.LD)
	.p2align 4
	.L__pc.2517.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2518
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2518: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2519
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2519: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2520: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2521: Dma_PatchSrc (.L__pc.2521.LD), (.L__movme_tmp.1), (.L__pc.2521.LD)
	.p2align 4
	.L__pc.2521.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2522
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2522: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2523
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2523: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2524: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2525: Dma_PatchSrc (.L__pc.2525.LD), (.L__movme_tmp.1), (.L__pc.2525.LD)
	.p2align 4
	.L__pc.2525.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2526
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2526: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2527
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2527: Dma_PatchSrc (.L__pc.2527.LD), (.L__movme_cp.24), (.L__pc.2527.LD)
	.p2align 4
	.L__pc.2527.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2528
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2528: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2529
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2529: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2530: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2531: Dma_PatchSrc (.L__pc.2531.LD), (.L__movme_tmp.1), (.L__pc.2531.LD)
	.p2align 4
	.L__pc.2531.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2532
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2532: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2533
	
	.L__pc.2533: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2534
	
	.p2align 4
	.L__pc.2534: Dma_PatchDst (.L__pc.2534.ST), (.L__movme_cp.79), (.L__pc.2534.ST)
	.L__pc.2534.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2535
	
	.L__pc.2535: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2536
	
	.p2align 4
	.L__pc.2536: Dma_PatchDst (.L__pc.2536.ST), (.L__movme_cp.54), (.L__pc.2536.ST)
	.L__pc.2536.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2537
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.2537: Dma_PatchSrc (.L__pc.2537.LD), (.L__movme_cp.74), (.L__pc.2537.LD)
	.p2align 4
	.L__pc.2537.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2538
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2538: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2539
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.2539: Dma_PatchSrc (.L__pc.2539.LD), (.L__movme_cp.77), (.L__pc.2539.LD)
	.p2align 4
	.L__pc.2539.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2540
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2540: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2541
	
	.L__pc.2541: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2542
	
	.p2align 4
	.L__pc.2542: Dma_PatchDst (.L__pc.2542.ST), ((.L__movme.reg.eax+0)), (.L__pc.2542.ST)
	.L__pc.2542.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2543
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.2543: Dma_PatchSrc (.L__pc.2543.LD), (.L__movme_cp.76), (.L__pc.2543.LD)
	.p2align 4
	.L__pc.2543.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2544
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2544: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2545
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.2545: Dma_PatchSrc (.L__pc.2545.LD), ((.L__movme.reg.eax+0)), (.L__pc.2545.LD)
	.p2align 4
	.L__pc.2545.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2546
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2546: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2547
	
	.L__pc.2547: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2548
	
	.p2align 4
	.L__pc.2548: Dma_PatchDst (.L__pc.2548.ST), (.L__movme_cp.80), (.L__pc.2548.ST)
	.L__pc.2548.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2549
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2549: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2550
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2550: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2551
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.2551: Dma_PatchSrc (.L__pc.2551.LD), (.L__movme_cp.81), (.L__pc.2551.LD)
	.p2align 4
	.L__pc.2551.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2552
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2552: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2553
	.L__pc.2553: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2554
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.84 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.2554: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2555: Dma_PatchSrc (.L__pc.2555.LD), (.L__movme_tmp.1), (.L__pc.2555.LD)
	.p2align 4
	.L__pc.2555.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2556
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2556: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2557
	.L__pc.2557: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2558
	
	.L__pc.2558: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2559
	
	.p2align 4
	.L__pc.2559: Dma_PatchDst (.L__pc.2559.ST), (.L__movme_cp.81), (.L__pc.2559.ST)
	.L__pc.2559.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2560
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.2560: Dma_PatchSrc (.L__pc.2560.LD), (.L__movme_cp.76), (.L__pc.2560.LD)
	.p2align 4
	.L__pc.2560.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2561
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2561: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2562
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.2562: Dma_PatchSrc (.L__pc.2562.LD), (.L__movme_cp.80), (.L__pc.2562.LD)
	.p2align 4
	.L__pc.2562.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2563
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2563: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2564
	
	.L__pc.2564: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2565
	
	.p2align 4
	.L__pc.2565: Dma_PatchDst (.L__pc.2565.ST), ((.L__movme.reg.eax+0)), (.L__pc.2565.ST)
	.L__pc.2565.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2566
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2566: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2567
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2567: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2568
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.2568: Dma_PatchSrc (.L__pc.2568.LD), (.L__movme_cp.61), (.L__pc.2568.LD)
	.p2align 4
	.L__pc.2568.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2569
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2569: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2570
	.L__pc.2570: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2571
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2571: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.85 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2572: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2573: Dma_PatchSrc (.L__pc.2573.LD), (.L__movme_tmp.1), (.L__pc.2573.LD)
	.p2align 4
	.L__pc.2573.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2574
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2574: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2575
	
	.L__pc.2575: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2576
	
	.p2align 4
	.L__pc.2576: Dma_PatchDst (.L__pc.2576.ST), (.L__movme_cp.24), (.L__pc.2576.ST)
	.L__pc.2576.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2577
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2577: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2578
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2578: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2579
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2579: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2580
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2580: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2581
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.2581: Dma_PatchSrc (.L__pc.2581.LD), (.L__movme_cp.63), (.L__pc.2581.LD)
	.p2align 4
	.L__pc.2581.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2582
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2582: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2583
	.L__pc.2583: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2584
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2584: Dma_PatchSrc (.L__pc.2584.LD), (.L__movme_cp.24), (.L__pc.2584.LD)
	.p2align 4
	.L__pc.2584.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2585
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2585: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2586
	.L__pc.2586: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2587
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2587: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2588: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2589: Dma_PatchSrc (.L__pc.2589.LD), (.L__movme_tmp.1), (.L__pc.2589.LD)
	.p2align 4
	.L__pc.2589.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2590
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2590: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2591
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2591: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2592: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2593: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2594: Dma_PatchSrc (.L__pc.2594.LD), (.L__movme_tmp.1), (.L__pc.2594.LD)
	.p2align 4
	.L__pc.2594.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2595
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2595: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2596
	
	.L__pc.2596: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2597
	
	.p2align 4
	.L__pc.2597: Dma_PatchDst (.L__pc.2597.ST), (.L__movme_cp.63), (.L__pc.2597.ST)
	.L__pc.2597.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2598
	
	.L__pc.2598: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2599
	
	.p2align 4
	.L__pc.2599: Dma_PatchDst (.L__pc.2599.ST), (.L__movme_cp.24), (.L__pc.2599.ST)
	.L__pc.2599.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2600
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2600: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2601
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2601: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2602
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2602: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2603
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2603: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2604
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.2604: Dma_PatchSrc (.L__pc.2604.LD), (.L__movme_cp.66), (.L__pc.2604.LD)
	.p2align 4
	.L__pc.2604.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2605
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2605: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2606
	.L__pc.2606: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2607
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2607: Dma_PatchSrc (.L__pc.2607.LD), (.L__movme_cp.24), (.L__pc.2607.LD)
	.p2align 4
	.L__pc.2607.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2608
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2608: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2609
	.L__pc.2609: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2610
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2610: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2611: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2612: Dma_PatchSrc (.L__pc.2612.LD), (.L__movme_tmp.1), (.L__pc.2612.LD)
	.p2align 4
	.L__pc.2612.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2613
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2613: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2614
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2614: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2615: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2616: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2617: Dma_PatchSrc (.L__pc.2617.LD), (.L__movme_tmp.1), (.L__pc.2617.LD)
	.p2align 4
	.L__pc.2617.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2618
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2618: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2619
	
	.L__pc.2619: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2620
	
	.p2align 4
	.L__pc.2620: Dma_PatchDst (.L__pc.2620.ST), (.L__movme_cp.66), (.L__pc.2620.ST)
	.L__pc.2620.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2621
	
	.L__pc.2621: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2622
	
	.p2align 4
	.L__pc.2622: Dma_PatchDst (.L__pc.2622.ST), (.L__movme_cp.24), (.L__pc.2622.ST)
	.L__pc.2622.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2623
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2623: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2624
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2624: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2625
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2625: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2626
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2626: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2627
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.2627: Dma_PatchSrc (.L__pc.2627.LD), (.L__movme_cp.67), (.L__pc.2627.LD)
	.p2align 4
	.L__pc.2627.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2628
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2628: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2629
	.L__pc.2629: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2630
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2630: Dma_PatchSrc (.L__pc.2630.LD), (.L__movme_cp.24), (.L__pc.2630.LD)
	.p2align 4
	.L__pc.2630.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2631
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2631: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2632
	.L__pc.2632: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2633
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2633: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2634: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2635: Dma_PatchSrc (.L__pc.2635.LD), (.L__movme_tmp.1), (.L__pc.2635.LD)
	.p2align 4
	.L__pc.2635.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2636
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2636: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2637
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2637: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2638: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2639: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2640: Dma_PatchSrc (.L__pc.2640.LD), (.L__movme_tmp.1), (.L__pc.2640.LD)
	.p2align 4
	.L__pc.2640.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2641
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2641: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2642
	
	.L__pc.2642: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2643
	
	.p2align 4
	.L__pc.2643: Dma_PatchDst (.L__pc.2643.ST), (.L__movme_cp.67), (.L__pc.2643.ST)
	.L__pc.2643.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2644
	
	.L__pc.2644: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2645
	
	.p2align 4
	.L__pc.2645: Dma_PatchDst (.L__pc.2645.ST), (.L__movme_cp.24), (.L__pc.2645.ST)
	.L__pc.2645.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2646
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2646: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2647
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2647: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2648
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2648: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2649
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2649: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2650
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.2650: Dma_PatchSrc (.L__pc.2650.LD), (.L__movme_cp.68), (.L__pc.2650.LD)
	.p2align 4
	.L__pc.2650.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2651
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2651: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2652
	.L__pc.2652: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2653
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2653: Dma_PatchSrc (.L__pc.2653.LD), (.L__movme_cp.24), (.L__pc.2653.LD)
	.p2align 4
	.L__pc.2653.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2654
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2654: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2655
	.L__pc.2655: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2656
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2656: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2657: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2658: Dma_PatchSrc (.L__pc.2658.LD), (.L__movme_tmp.1), (.L__pc.2658.LD)
	.p2align 4
	.L__pc.2658.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2659
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2659: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2660
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2660: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2661: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2662: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2663: Dma_PatchSrc (.L__pc.2663.LD), (.L__movme_tmp.1), (.L__pc.2663.LD)
	.p2align 4
	.L__pc.2663.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2664
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2664: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2665
	
	.L__pc.2665: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2666
	
	.p2align 4
	.L__pc.2666: Dma_PatchDst (.L__pc.2666.ST), (.L__movme_cp.68), (.L__pc.2666.ST)
	.L__pc.2666.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2667
	
	.L__pc.2667: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2668
	
	.p2align 4
	.L__pc.2668: Dma_PatchDst (.L__pc.2668.ST), (.L__movme_cp.24), (.L__pc.2668.ST)
	.L__pc.2668.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2669
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2669: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2670
	
	.p2align 4
	.L__pc.2670: Dma_PatchDst (.L__pc.2670.ST), (.L__movme_cp.24), (.L__pc.2670.ST)
	.L__pc.2670.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2671
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.2671: Dma_PatchSrc (.L__pc.2671.LD), (.L__movme_cp.60), (.L__pc.2671.LD)
	.p2align 4
	.L__pc.2671.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2672
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2672: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2673
	
	.L__pc.2673: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2674
	
	.p2align 4
	.L__pc.2674: Dma_PatchDst (.L__pc.2674.ST), (.L__movme_cp.21), (.L__pc.2674.ST)
	.L__pc.2674.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2675
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.2675: Dma_PatchSrc (.L__pc.2675.LD), (.L__movme_cp.58), (.L__pc.2675.LD)
	.p2align 4
	.L__pc.2675.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2676
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2676: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2677
	
	.L__pc.2677: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2678
	
	.p2align 4
	.L__pc.2678: Dma_PatchDst (.L__pc.2678.ST), (.L__movme_cp.22), (.L__pc.2678.ST)
	.L__pc.2678.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2679
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2679: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2680
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2680: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2681
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2681: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2682
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2682: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2683
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.2683: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.2684
	
	.p2align 4
	.L__pc.2684: Dma_PatchDst (.L__pc.2684.ST), (.L__movme_cp.24), (.L__pc.2684.ST)
	.L__pc.2684.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2685
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.2685: Dma_PatchSrc (.L__pc.2685.LD), (.L__movme_cp.25), (.L__pc.2685.LD)
	.p2align 4
	.L__pc.2685.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2686
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2686: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2687
	.L__pc.2687: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2688
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.2688: Dma_PatchSrc (.L__pc.2688.LD), (.L__movme_cp.26), (.L__pc.2688.LD)
	.p2align 4
	.L__pc.2688.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2689
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2689: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2690
	.L__pc.2690: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2691
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2691: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2692: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2693: Dma_PatchSrc (.L__pc.2693.LD), (.L__movme_tmp.1), (.L__pc.2693.LD)
	.p2align 4
	.L__pc.2693.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2694
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2694: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2695
	.L__pc.2695: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2696
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2696: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2697: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2698: Dma_PatchSrc (.L__pc.2698.LD), (.L__movme_tmp.1), (.L__pc.2698.LD)
	.p2align 4
	.L__pc.2698.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2699
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2699: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2700
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2700: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2701: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2702: Dma_PatchSrc (.L__pc.2702.LD), (.L__movme_tmp.1), (.L__pc.2702.LD)
	.p2align 4
	.L__pc.2702.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2703
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2703: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2704
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2704: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2705: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2706: Dma_PatchSrc (.L__pc.2706.LD), (.L__movme_tmp.1), (.L__pc.2706.LD)
	.p2align 4
	.L__pc.2706.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2707
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2707: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2708
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2708: Dma_PatchSrc (.L__pc.2708.LD), (.L__movme_cp.24), (.L__pc.2708.LD)
	.p2align 4
	.L__pc.2708.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2709
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2709: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2710
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2710: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2711: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2712: Dma_PatchSrc (.L__pc.2712.LD), (.L__movme_tmp.1), (.L__pc.2712.LD)
	.p2align 4
	.L__pc.2712.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2713
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2713: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2714
	
	.L__pc.2714: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2715
	
	.p2align 4
	.L__pc.2715: Dma_PatchDst (.L__pc.2715.ST), (.L__movme_cp.69), (.L__pc.2715.ST)
	.L__pc.2715.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2716
	
	.L__pc.2716: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2717
	
	.p2align 4
	.L__pc.2717: Dma_PatchDst (.L__pc.2717.ST), (.L__movme_cp.54), (.L__pc.2717.ST)
	.L__pc.2717.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2718
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.2718: Dma_PatchSrc (.L__pc.2718.LD), (.L__movme_cp.30), (.L__pc.2718.LD)
	.p2align 4
	.L__pc.2718.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2719
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2719: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2720
	.L__pc.2720: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2721
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.2721: Dma_PatchSrc (.L__pc.2721.LD), (.L__movme_cp.31), (.L__pc.2721.LD)
	.p2align 4
	.L__pc.2721.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2722
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2722: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2723
	.L__pc.2723: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2724
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2724: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2725: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2726: Dma_PatchSrc (.L__pc.2726.LD), (.L__movme_tmp.1), (.L__pc.2726.LD)
	.p2align 4
	.L__pc.2726.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2727
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2727: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2728
	.L__pc.2728: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2729
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2729: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2730: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2731: Dma_PatchSrc (.L__pc.2731.LD), (.L__movme_tmp.1), (.L__pc.2731.LD)
	.p2align 4
	.L__pc.2731.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2732
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2732: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2733
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2733: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2734: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2735: Dma_PatchSrc (.L__pc.2735.LD), (.L__movme_tmp.1), (.L__pc.2735.LD)
	.p2align 4
	.L__pc.2735.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2736
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2736: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2737
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2737: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2738: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2739: Dma_PatchSrc (.L__pc.2739.LD), (.L__movme_tmp.1), (.L__pc.2739.LD)
	.p2align 4
	.L__pc.2739.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2740
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2740: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2741
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2741: Dma_PatchSrc (.L__pc.2741.LD), (.L__movme_cp.24), (.L__pc.2741.LD)
	.p2align 4
	.L__pc.2741.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2742
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2742: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2743
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2743: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2744: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2745: Dma_PatchSrc (.L__pc.2745.LD), (.L__movme_tmp.1), (.L__pc.2745.LD)
	.p2align 4
	.L__pc.2745.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2746
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2746: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2747
	
	.L__pc.2747: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2748
	
	.p2align 4
	.L__pc.2748: Dma_PatchDst (.L__pc.2748.ST), (.L__movme_cp.70), (.L__pc.2748.ST)
	.L__pc.2748.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2749
	
	.L__pc.2749: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2750
	
	.p2align 4
	.L__pc.2750: Dma_PatchDst (.L__pc.2750.ST), (.L__movme_cp.54), (.L__pc.2750.ST)
	.L__pc.2750.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2751
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2751: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2752
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2752: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2753
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2753: Dma_PatchSrc (.L__pc.2753.LD), (.L__movme_cp.24), (.L__pc.2753.LD)
	.p2align 4
	.L__pc.2753.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2754
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2754: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2755
	.L__pc.2755: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2756
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.2756: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2757: Dma_PatchSrc (.L__pc.2757.LD), (.L__movme_tmp.1), (.L__pc.2757.LD)
	.p2align 4
	.L__pc.2757.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2758
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2758: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2759
	.L__pc.2759: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2760
	
	.L__pc.2760: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2761
	
	.p2align 4
	.L__pc.2761: Dma_PatchDst (.L__pc.2761.ST), (.L__movme_cp.72), (.L__pc.2761.ST)
	.L__pc.2761.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2762
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.2762: Dma_PatchSrc (.L__pc.2762.LD), (.L__movme_cp.72), (.L__pc.2762.LD)
	.p2align 4
	.L__pc.2762.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2763
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2763: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2764
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2764: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2765: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2766: Dma_PatchSrc (.L__pc.2766.LD), (.L__movme_tmp.1), (.L__pc.2766.LD)
	.p2align 4
	.L__pc.2766.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2767
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2767: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2768
	
	.L__pc.2768: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2769
	
	.p2align 4
	.L__pc.2769: Dma_PatchDst (.L__pc.2769.ST), (.L__movme_cp.74), (.L__pc.2769.ST)
	.L__pc.2769.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2770
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2770: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2771: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2772: Dma_PatchSrc (.L__pc.2772.LD), (.L__movme_tmp.1), (.L__pc.2772.LD)
	.p2align 4
	.L__pc.2772.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2773
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2773: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2774
	
	.L__pc.2774: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2775
	
	.p2align 4
	.L__pc.2775: Dma_PatchDst (.L__pc.2775.ST), (.L__movme_cp.76), (.L__pc.2775.ST)
	.L__pc.2775.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2776
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.2776: Dma_PatchSrc (.L__pc.2776.LD), (.L__movme_cp.74), (.L__pc.2776.LD)
	.p2align 4
	.L__pc.2776.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2777
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2777: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2778
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.2778: Dma_PatchSrc (.L__pc.2778.LD), ((.L__movme.reg.eax+0)), (.L__pc.2778.LD)
	.p2align 4
	.L__pc.2778.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2779
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2779: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2780
	
	.L__pc.2780: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2781
	
	.p2align 4
	.L__pc.2781: Dma_PatchDst (.L__pc.2781.ST), (.L__movme_cp.77), (.L__pc.2781.ST)
	.L__pc.2781.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2782
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.2782: Dma_PatchSrc (.L__pc.2782.LD), (.L__movme_cp.77), (.L__pc.2782.LD)
	.p2align 4
	.L__pc.2782.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2783
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2783: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2784
	
	.L__pc.2784: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2785
	
	.p2align 4
	.L__pc.2785: Dma_PatchDst (.L__pc.2785.ST), (.L__movme_cp.21), (.L__pc.2785.ST)
	.L__pc.2785.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2786
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.2786: Dma_PatchSrc (.L__pc.2786.LD), (.L__movme_cp.58), (.L__pc.2786.LD)
	.p2align 4
	.L__pc.2786.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2787
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2787: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2788
	
	.L__pc.2788: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2789
	
	.p2align 4
	.L__pc.2789: Dma_PatchDst (.L__pc.2789.ST), (.L__movme_cp.22), (.L__pc.2789.ST)
	.L__pc.2789.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2790
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2790: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2791
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2791: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2792
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2792: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2793
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2793: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2794
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.2794: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.2795
	
	.p2align 4
	.L__pc.2795: Dma_PatchDst (.L__pc.2795.ST), (.L__movme_cp.24), (.L__pc.2795.ST)
	.L__pc.2795.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2796
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.2796: Dma_PatchSrc (.L__pc.2796.LD), (.L__movme_cp.25), (.L__pc.2796.LD)
	.p2align 4
	.L__pc.2796.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2797
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2797: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2798
	.L__pc.2798: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2799
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.2799: Dma_PatchSrc (.L__pc.2799.LD), (.L__movme_cp.26), (.L__pc.2799.LD)
	.p2align 4
	.L__pc.2799.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2800
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2800: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2801
	.L__pc.2801: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2802
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2802: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2803: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2804: Dma_PatchSrc (.L__pc.2804.LD), (.L__movme_tmp.1), (.L__pc.2804.LD)
	.p2align 4
	.L__pc.2804.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2805
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2805: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2806
	.L__pc.2806: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2807
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2807: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2808: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2809: Dma_PatchSrc (.L__pc.2809.LD), (.L__movme_tmp.1), (.L__pc.2809.LD)
	.p2align 4
	.L__pc.2809.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2810
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2810: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2811
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2811: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2812: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2813: Dma_PatchSrc (.L__pc.2813.LD), (.L__movme_tmp.1), (.L__pc.2813.LD)
	.p2align 4
	.L__pc.2813.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2814
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2814: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2815
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2815: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2816: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2817: Dma_PatchSrc (.L__pc.2817.LD), (.L__movme_tmp.1), (.L__pc.2817.LD)
	.p2align 4
	.L__pc.2817.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2818
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2818: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2819
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2819: Dma_PatchSrc (.L__pc.2819.LD), (.L__movme_cp.24), (.L__pc.2819.LD)
	.p2align 4
	.L__pc.2819.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2820
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2820: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2821
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2821: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2822: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2823: Dma_PatchSrc (.L__pc.2823.LD), (.L__movme_tmp.1), (.L__pc.2823.LD)
	.p2align 4
	.L__pc.2823.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2824
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2824: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2825
	
	.L__pc.2825: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2826
	
	.p2align 4
	.L__pc.2826: Dma_PatchDst (.L__pc.2826.ST), (.L__movme_cp.78), (.L__pc.2826.ST)
	.L__pc.2826.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2827
	
	.L__pc.2827: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2828
	
	.p2align 4
	.L__pc.2828: Dma_PatchDst (.L__pc.2828.ST), (.L__movme_cp.54), (.L__pc.2828.ST)
	.L__pc.2828.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2829
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.2829: Dma_PatchSrc (.L__pc.2829.LD), (.L__movme_cp.30), (.L__pc.2829.LD)
	.p2align 4
	.L__pc.2829.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2830
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2830: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.2831
	.L__pc.2831: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.2832
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.2832: Dma_PatchSrc (.L__pc.2832.LD), (.L__movme_cp.31), (.L__pc.2832.LD)
	.p2align 4
	.L__pc.2832.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2833
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2833: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2834
	.L__pc.2834: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2835
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.2835: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2836: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2837: Dma_PatchSrc (.L__pc.2837.LD), (.L__movme_tmp.1), (.L__pc.2837.LD)
	.p2align 4
	.L__pc.2837.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2838
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2838: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.2839
	.L__pc.2839: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.2840
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2840: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2841: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2842: Dma_PatchSrc (.L__pc.2842.LD), (.L__movme_tmp.1), (.L__pc.2842.LD)
	.p2align 4
	.L__pc.2842.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2843
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2843: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2844
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2844: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2845: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2846: Dma_PatchSrc (.L__pc.2846.LD), (.L__movme_tmp.1), (.L__pc.2846.LD)
	.p2align 4
	.L__pc.2846.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2847
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2847: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2848
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2848: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2849: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2850: Dma_PatchSrc (.L__pc.2850.LD), (.L__movme_tmp.1), (.L__pc.2850.LD)
	.p2align 4
	.L__pc.2850.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2851
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2851: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2852
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2852: Dma_PatchSrc (.L__pc.2852.LD), (.L__movme_cp.24), (.L__pc.2852.LD)
	.p2align 4
	.L__pc.2852.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2853
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.2853: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.2854
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.2854: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2855: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2856: Dma_PatchSrc (.L__pc.2856.LD), (.L__movme_tmp.1), (.L__pc.2856.LD)
	.p2align 4
	.L__pc.2856.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2857
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2857: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2858
	
	.L__pc.2858: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.2859
	
	.p2align 4
	.L__pc.2859: Dma_PatchDst (.L__pc.2859.ST), (.L__movme_cp.79), (.L__pc.2859.ST)
	.L__pc.2859.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2860
	
	.L__pc.2860: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2861
	
	.p2align 4
	.L__pc.2861: Dma_PatchDst (.L__pc.2861.ST), (.L__movme_cp.54), (.L__pc.2861.ST)
	.L__pc.2861.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2862
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.2862: Dma_PatchSrc (.L__pc.2862.LD), (.L__movme_cp.74), (.L__pc.2862.LD)
	.p2align 4
	.L__pc.2862.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2863
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2863: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2864
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.2864: Dma_PatchSrc (.L__pc.2864.LD), (.L__movme_cp.77), (.L__pc.2864.LD)
	.p2align 4
	.L__pc.2864.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2865
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2865: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2866
	
	.L__pc.2866: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2867
	
	.p2align 4
	.L__pc.2867: Dma_PatchDst (.L__pc.2867.ST), ((.L__movme.reg.eax+0)), (.L__pc.2867.ST)
	.L__pc.2867.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2868
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.2868: Dma_PatchSrc (.L__pc.2868.LD), (.L__movme_cp.76), (.L__pc.2868.LD)
	.p2align 4
	.L__pc.2868.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2869
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2869: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2870
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.2870: Dma_PatchSrc (.L__pc.2870.LD), ((.L__movme.reg.eax+0)), (.L__pc.2870.LD)
	.p2align 4
	.L__pc.2870.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2871
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2871: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2872
	
	.L__pc.2872: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2873
	
	.p2align 4
	.L__pc.2873: Dma_PatchDst (.L__pc.2873.ST), (.L__movme_cp.80), (.L__pc.2873.ST)
	.L__pc.2873.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2874
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2874: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2875
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2875: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2876
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.2876: Dma_PatchSrc (.L__pc.2876.LD), (.L__movme_cp.81), (.L__pc.2876.LD)
	.p2align 4
	.L__pc.2876.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2877
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2877: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2878
	.L__pc.2878: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2879
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.86 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.2879: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2880: Dma_PatchSrc (.L__pc.2880.LD), (.L__movme_tmp.1), (.L__pc.2880.LD)
	.p2align 4
	.L__pc.2880.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2881
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2881: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2882
	.L__pc.2882: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2883
	
	.L__pc.2883: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2884
	
	.p2align 4
	.L__pc.2884: Dma_PatchDst (.L__pc.2884.ST), (.L__movme_cp.81), (.L__pc.2884.ST)
	.L__pc.2884.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2885
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.2885: Dma_PatchSrc (.L__pc.2885.LD), (.L__movme_cp.76), (.L__pc.2885.LD)
	.p2align 4
	.L__pc.2885.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2886
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2886: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2887
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.2887: Dma_PatchSrc (.L__pc.2887.LD), (.L__movme_cp.80), (.L__pc.2887.LD)
	.p2align 4
	.L__pc.2887.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2888
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2888: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2889
	
	.L__pc.2889: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.2890
	
	.p2align 4
	.L__pc.2890: Dma_PatchDst (.L__pc.2890.ST), ((.L__movme.reg.eax+0)), (.L__pc.2890.ST)
	.L__pc.2890.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2891
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2891: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2892
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2892: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2893
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.2893: Dma_PatchSrc (.L__pc.2893.LD), (.L__movme_cp.61), (.L__pc.2893.LD)
	.p2align 4
	.L__pc.2893.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2894
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2894: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2895
	.L__pc.2895: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2896
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.2896: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.87 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2897: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2898: Dma_PatchSrc (.L__pc.2898.LD), (.L__movme_tmp.1), (.L__pc.2898.LD)
	.p2align 4
	.L__pc.2898.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2899
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2899: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2900
	
	.L__pc.2900: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2901
	
	.p2align 4
	.L__pc.2901: Dma_PatchDst (.L__pc.2901.ST), (.L__movme_cp.24), (.L__pc.2901.ST)
	.L__pc.2901.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2902
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2902: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2903
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2903: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2904
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2904: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2905
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2905: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2906
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.2906: Dma_PatchSrc (.L__pc.2906.LD), (.L__movme_cp.63), (.L__pc.2906.LD)
	.p2align 4
	.L__pc.2906.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2907
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2907: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2908
	.L__pc.2908: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2909
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2909: Dma_PatchSrc (.L__pc.2909.LD), (.L__movme_cp.24), (.L__pc.2909.LD)
	.p2align 4
	.L__pc.2909.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2910
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2910: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2911
	.L__pc.2911: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2912
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2912: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2913: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2914: Dma_PatchSrc (.L__pc.2914.LD), (.L__movme_tmp.1), (.L__pc.2914.LD)
	.p2align 4
	.L__pc.2914.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2915
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2915: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2916
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2916: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2917: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2918: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2919: Dma_PatchSrc (.L__pc.2919.LD), (.L__movme_tmp.1), (.L__pc.2919.LD)
	.p2align 4
	.L__pc.2919.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2920
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2920: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2921
	
	.L__pc.2921: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2922
	
	.p2align 4
	.L__pc.2922: Dma_PatchDst (.L__pc.2922.ST), (.L__movme_cp.63), (.L__pc.2922.ST)
	.L__pc.2922.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2923
	
	.L__pc.2923: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2924
	
	.p2align 4
	.L__pc.2924: Dma_PatchDst (.L__pc.2924.ST), (.L__movme_cp.24), (.L__pc.2924.ST)
	.L__pc.2924.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2925
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2925: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2926
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2926: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2927
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2927: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2928
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2928: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2929
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.2929: Dma_PatchSrc (.L__pc.2929.LD), (.L__movme_cp.66), (.L__pc.2929.LD)
	.p2align 4
	.L__pc.2929.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2930
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2930: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2931
	.L__pc.2931: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2932
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2932: Dma_PatchSrc (.L__pc.2932.LD), (.L__movme_cp.24), (.L__pc.2932.LD)
	.p2align 4
	.L__pc.2932.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2933
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2933: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2934
	.L__pc.2934: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2935
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2935: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2936: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2937: Dma_PatchSrc (.L__pc.2937.LD), (.L__movme_tmp.1), (.L__pc.2937.LD)
	.p2align 4
	.L__pc.2937.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2938
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2938: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2939
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2939: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2940: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2941: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2942: Dma_PatchSrc (.L__pc.2942.LD), (.L__movme_tmp.1), (.L__pc.2942.LD)
	.p2align 4
	.L__pc.2942.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2943
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2943: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2944
	
	.L__pc.2944: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2945
	
	.p2align 4
	.L__pc.2945: Dma_PatchDst (.L__pc.2945.ST), (.L__movme_cp.66), (.L__pc.2945.ST)
	.L__pc.2945.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2946
	
	.L__pc.2946: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2947
	
	.p2align 4
	.L__pc.2947: Dma_PatchDst (.L__pc.2947.ST), (.L__movme_cp.24), (.L__pc.2947.ST)
	.L__pc.2947.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2948
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2948: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2949
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2949: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2950
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2950: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2951
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2951: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2952
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.2952: Dma_PatchSrc (.L__pc.2952.LD), (.L__movme_cp.67), (.L__pc.2952.LD)
	.p2align 4
	.L__pc.2952.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2953
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2953: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2954
	.L__pc.2954: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2955
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2955: Dma_PatchSrc (.L__pc.2955.LD), (.L__movme_cp.24), (.L__pc.2955.LD)
	.p2align 4
	.L__pc.2955.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2956
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2956: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2957
	.L__pc.2957: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2958
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2958: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2959: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2960: Dma_PatchSrc (.L__pc.2960.LD), (.L__movme_tmp.1), (.L__pc.2960.LD)
	.p2align 4
	.L__pc.2960.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2961
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2961: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2962
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2962: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2963: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2964: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2965: Dma_PatchSrc (.L__pc.2965.LD), (.L__movme_tmp.1), (.L__pc.2965.LD)
	.p2align 4
	.L__pc.2965.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2966
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2966: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2967
	
	.L__pc.2967: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2968
	
	.p2align 4
	.L__pc.2968: Dma_PatchDst (.L__pc.2968.ST), (.L__movme_cp.67), (.L__pc.2968.ST)
	.L__pc.2968.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2969
	
	.L__pc.2969: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2970
	
	.p2align 4
	.L__pc.2970: Dma_PatchDst (.L__pc.2970.ST), (.L__movme_cp.24), (.L__pc.2970.ST)
	.L__pc.2970.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2971
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2971: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2972
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2972: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2973
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2973: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2974
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2974: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.2975
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.2975: Dma_PatchSrc (.L__pc.2975.LD), (.L__movme_cp.68), (.L__pc.2975.LD)
	.p2align 4
	.L__pc.2975.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2976
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2976: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.2977
	.L__pc.2977: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.2978
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.2978: Dma_PatchSrc (.L__pc.2978.LD), (.L__movme_cp.24), (.L__pc.2978.LD)
	.p2align 4
	.L__pc.2978.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2979
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.2979: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.2980
	.L__pc.2980: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.2981
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.2981: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.2982: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2983: Dma_PatchSrc (.L__pc.2983.LD), (.L__movme_tmp.1), (.L__pc.2983.LD)
	.p2align 4
	.L__pc.2983.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2984
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2984: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2985
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.2985: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.2986: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.2987: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.2988: Dma_PatchSrc (.L__pc.2988.LD), (.L__movme_tmp.1), (.L__pc.2988.LD)
	.p2align 4
	.L__pc.2988.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2989
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2989: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2990
	
	.L__pc.2990: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.2991
	
	.p2align 4
	.L__pc.2991: Dma_PatchDst (.L__pc.2991.ST), (.L__movme_cp.68), (.L__pc.2991.ST)
	.L__pc.2991.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2992
	
	.L__pc.2992: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.2993
	
	.p2align 4
	.L__pc.2993: Dma_PatchDst (.L__pc.2993.ST), (.L__movme_cp.24), (.L__pc.2993.ST)
	.L__pc.2993.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2994
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.2994: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.2995
	
	.p2align 4
	.L__pc.2995: Dma_PatchDst (.L__pc.2995.ST), (.L__movme_cp.24), (.L__pc.2995.ST)
	.L__pc.2995.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.2996
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.2996: Dma_PatchSrc (.L__pc.2996.LD), (.L__movme_cp.60), (.L__pc.2996.LD)
	.p2align 4
	.L__pc.2996.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.2997
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.2997: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.2998
	
	.L__pc.2998: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.2999
	
	.p2align 4
	.L__pc.2999: Dma_PatchDst (.L__pc.2999.ST), (.L__movme_cp.21), (.L__pc.2999.ST)
	.L__pc.2999.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3000
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.3000: Dma_PatchSrc (.L__pc.3000.LD), (.L__movme_cp.58), (.L__pc.3000.LD)
	.p2align 4
	.L__pc.3000.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3001
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3001: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3002
	
	.L__pc.3002: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3003
	
	.p2align 4
	.L__pc.3003: Dma_PatchDst (.L__pc.3003.ST), (.L__movme_cp.22), (.L__pc.3003.ST)
	.L__pc.3003.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3004
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3004: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3005
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3005: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3006
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3006: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3007
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3007: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3008
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.3008: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.3009
	
	.p2align 4
	.L__pc.3009: Dma_PatchDst (.L__pc.3009.ST), (.L__movme_cp.24), (.L__pc.3009.ST)
	.L__pc.3009.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3010
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.3010: Dma_PatchSrc (.L__pc.3010.LD), (.L__movme_cp.25), (.L__pc.3010.LD)
	.p2align 4
	.L__pc.3010.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3011
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3011: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3012
	.L__pc.3012: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3013
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.3013: Dma_PatchSrc (.L__pc.3013.LD), (.L__movme_cp.26), (.L__pc.3013.LD)
	.p2align 4
	.L__pc.3013.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3014
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3014: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3015
	.L__pc.3015: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3016
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3016: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3017: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3018: Dma_PatchSrc (.L__pc.3018.LD), (.L__movme_tmp.1), (.L__pc.3018.LD)
	.p2align 4
	.L__pc.3018.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3019
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3019: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3020
	.L__pc.3020: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3021
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3021: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3022: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3023: Dma_PatchSrc (.L__pc.3023.LD), (.L__movme_tmp.1), (.L__pc.3023.LD)
	.p2align 4
	.L__pc.3023.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3024
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3024: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3025
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3025: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3026: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3027: Dma_PatchSrc (.L__pc.3027.LD), (.L__movme_tmp.1), (.L__pc.3027.LD)
	.p2align 4
	.L__pc.3027.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3028
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3028: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3029
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3029: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3030: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3031: Dma_PatchSrc (.L__pc.3031.LD), (.L__movme_tmp.1), (.L__pc.3031.LD)
	.p2align 4
	.L__pc.3031.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3032
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3032: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3033
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3033: Dma_PatchSrc (.L__pc.3033.LD), (.L__movme_cp.24), (.L__pc.3033.LD)
	.p2align 4
	.L__pc.3033.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3034
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3034: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3035
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3035: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3036: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3037: Dma_PatchSrc (.L__pc.3037.LD), (.L__movme_tmp.1), (.L__pc.3037.LD)
	.p2align 4
	.L__pc.3037.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3038
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3038: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3039
	
	.L__pc.3039: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3040
	
	.p2align 4
	.L__pc.3040: Dma_PatchDst (.L__pc.3040.ST), (.L__movme_cp.69), (.L__pc.3040.ST)
	.L__pc.3040.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3041
	
	.L__pc.3041: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3042
	
	.p2align 4
	.L__pc.3042: Dma_PatchDst (.L__pc.3042.ST), (.L__movme_cp.54), (.L__pc.3042.ST)
	.L__pc.3042.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3043
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.3043: Dma_PatchSrc (.L__pc.3043.LD), (.L__movme_cp.30), (.L__pc.3043.LD)
	.p2align 4
	.L__pc.3043.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3044
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3044: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3045
	.L__pc.3045: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3046
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.3046: Dma_PatchSrc (.L__pc.3046.LD), (.L__movme_cp.31), (.L__pc.3046.LD)
	.p2align 4
	.L__pc.3046.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3047
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3047: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3048
	.L__pc.3048: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3049
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3049: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3050: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3051: Dma_PatchSrc (.L__pc.3051.LD), (.L__movme_tmp.1), (.L__pc.3051.LD)
	.p2align 4
	.L__pc.3051.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3052
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3052: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3053
	.L__pc.3053: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3054
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3054: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3055: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3056: Dma_PatchSrc (.L__pc.3056.LD), (.L__movme_tmp.1), (.L__pc.3056.LD)
	.p2align 4
	.L__pc.3056.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3057
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3057: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3058
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3058: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3059: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3060: Dma_PatchSrc (.L__pc.3060.LD), (.L__movme_tmp.1), (.L__pc.3060.LD)
	.p2align 4
	.L__pc.3060.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3061
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3061: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3062
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3062: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3063: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3064: Dma_PatchSrc (.L__pc.3064.LD), (.L__movme_tmp.1), (.L__pc.3064.LD)
	.p2align 4
	.L__pc.3064.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3065
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3065: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3066
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3066: Dma_PatchSrc (.L__pc.3066.LD), (.L__movme_cp.24), (.L__pc.3066.LD)
	.p2align 4
	.L__pc.3066.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3067
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3067: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3068
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3068: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3069: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3070: Dma_PatchSrc (.L__pc.3070.LD), (.L__movme_tmp.1), (.L__pc.3070.LD)
	.p2align 4
	.L__pc.3070.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3071
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3071: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3072
	
	.L__pc.3072: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3073
	
	.p2align 4
	.L__pc.3073: Dma_PatchDst (.L__pc.3073.ST), (.L__movme_cp.70), (.L__pc.3073.ST)
	.L__pc.3073.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3074
	
	.L__pc.3074: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3075
	
	.p2align 4
	.L__pc.3075: Dma_PatchDst (.L__pc.3075.ST), (.L__movme_cp.54), (.L__pc.3075.ST)
	.L__pc.3075.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3076
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3076: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3077
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3077: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3078
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3078: Dma_PatchSrc (.L__pc.3078.LD), (.L__movme_cp.24), (.L__pc.3078.LD)
	.p2align 4
	.L__pc.3078.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3079
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3079: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3080
	.L__pc.3080: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3081
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.3081: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3082: Dma_PatchSrc (.L__pc.3082.LD), (.L__movme_tmp.1), (.L__pc.3082.LD)
	.p2align 4
	.L__pc.3082.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3083
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3083: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3084
	.L__pc.3084: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3085
	
	.L__pc.3085: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3086
	
	.p2align 4
	.L__pc.3086: Dma_PatchDst (.L__pc.3086.ST), (.L__movme_cp.72), (.L__pc.3086.ST)
	.L__pc.3086.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3087
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.3087: Dma_PatchSrc (.L__pc.3087.LD), (.L__movme_cp.72), (.L__pc.3087.LD)
	.p2align 4
	.L__pc.3087.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3088
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3088: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3089
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3089: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3090: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3091: Dma_PatchSrc (.L__pc.3091.LD), (.L__movme_tmp.1), (.L__pc.3091.LD)
	.p2align 4
	.L__pc.3091.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3092
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3092: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3093
	
	.L__pc.3093: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3094
	
	.p2align 4
	.L__pc.3094: Dma_PatchDst (.L__pc.3094.ST), (.L__movme_cp.74), (.L__pc.3094.ST)
	.L__pc.3094.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3095
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3095: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3096: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3097: Dma_PatchSrc (.L__pc.3097.LD), (.L__movme_tmp.1), (.L__pc.3097.LD)
	.p2align 4
	.L__pc.3097.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3098
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3098: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3099
	
	.L__pc.3099: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3100
	
	.p2align 4
	.L__pc.3100: Dma_PatchDst (.L__pc.3100.ST), (.L__movme_cp.76), (.L__pc.3100.ST)
	.L__pc.3100.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3101
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.3101: Dma_PatchSrc (.L__pc.3101.LD), (.L__movme_cp.74), (.L__pc.3101.LD)
	.p2align 4
	.L__pc.3101.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3102
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3102: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3103
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.3103: Dma_PatchSrc (.L__pc.3103.LD), ((.L__movme.reg.eax+0)), (.L__pc.3103.LD)
	.p2align 4
	.L__pc.3103.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3104
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3104: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3105
	
	.L__pc.3105: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3106
	
	.p2align 4
	.L__pc.3106: Dma_PatchDst (.L__pc.3106.ST), (.L__movme_cp.77), (.L__pc.3106.ST)
	.L__pc.3106.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3107
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.3107: Dma_PatchSrc (.L__pc.3107.LD), (.L__movme_cp.77), (.L__pc.3107.LD)
	.p2align 4
	.L__pc.3107.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3108
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3108: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3109
	
	.L__pc.3109: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3110
	
	.p2align 4
	.L__pc.3110: Dma_PatchDst (.L__pc.3110.ST), (.L__movme_cp.21), (.L__pc.3110.ST)
	.L__pc.3110.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3111
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.3111: Dma_PatchSrc (.L__pc.3111.LD), (.L__movme_cp.58), (.L__pc.3111.LD)
	.p2align 4
	.L__pc.3111.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3112
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3112: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3113
	
	.L__pc.3113: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3114
	
	.p2align 4
	.L__pc.3114: Dma_PatchDst (.L__pc.3114.ST), (.L__movme_cp.22), (.L__pc.3114.ST)
	.L__pc.3114.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3115
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3115: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3116
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3116: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3117
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3117: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3118
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3118: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3119
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.3119: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.3120
	
	.p2align 4
	.L__pc.3120: Dma_PatchDst (.L__pc.3120.ST), (.L__movme_cp.24), (.L__pc.3120.ST)
	.L__pc.3120.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3121
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.3121: Dma_PatchSrc (.L__pc.3121.LD), (.L__movme_cp.25), (.L__pc.3121.LD)
	.p2align 4
	.L__pc.3121.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3122
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3122: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3123
	.L__pc.3123: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3124
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.3124: Dma_PatchSrc (.L__pc.3124.LD), (.L__movme_cp.26), (.L__pc.3124.LD)
	.p2align 4
	.L__pc.3124.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3125
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3125: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3126
	.L__pc.3126: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3127
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3127: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3128: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3129: Dma_PatchSrc (.L__pc.3129.LD), (.L__movme_tmp.1), (.L__pc.3129.LD)
	.p2align 4
	.L__pc.3129.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3130
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3130: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3131
	.L__pc.3131: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3132
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3132: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3133: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3134: Dma_PatchSrc (.L__pc.3134.LD), (.L__movme_tmp.1), (.L__pc.3134.LD)
	.p2align 4
	.L__pc.3134.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3135
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3135: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3136
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3136: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3137: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3138: Dma_PatchSrc (.L__pc.3138.LD), (.L__movme_tmp.1), (.L__pc.3138.LD)
	.p2align 4
	.L__pc.3138.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3139
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3139: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3140
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3140: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3141: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3142: Dma_PatchSrc (.L__pc.3142.LD), (.L__movme_tmp.1), (.L__pc.3142.LD)
	.p2align 4
	.L__pc.3142.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3143
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3143: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3144
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3144: Dma_PatchSrc (.L__pc.3144.LD), (.L__movme_cp.24), (.L__pc.3144.LD)
	.p2align 4
	.L__pc.3144.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3145
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3145: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3146
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3146: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3147: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3148: Dma_PatchSrc (.L__pc.3148.LD), (.L__movme_tmp.1), (.L__pc.3148.LD)
	.p2align 4
	.L__pc.3148.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3149
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3149: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3150
	
	.L__pc.3150: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3151
	
	.p2align 4
	.L__pc.3151: Dma_PatchDst (.L__pc.3151.ST), (.L__movme_cp.78), (.L__pc.3151.ST)
	.L__pc.3151.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3152
	
	.L__pc.3152: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3153
	
	.p2align 4
	.L__pc.3153: Dma_PatchDst (.L__pc.3153.ST), (.L__movme_cp.54), (.L__pc.3153.ST)
	.L__pc.3153.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3154
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.3154: Dma_PatchSrc (.L__pc.3154.LD), (.L__movme_cp.30), (.L__pc.3154.LD)
	.p2align 4
	.L__pc.3154.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3155
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3155: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3156
	.L__pc.3156: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3157
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.3157: Dma_PatchSrc (.L__pc.3157.LD), (.L__movme_cp.31), (.L__pc.3157.LD)
	.p2align 4
	.L__pc.3157.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3158
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3158: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3159
	.L__pc.3159: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3160
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3160: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3161: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3162: Dma_PatchSrc (.L__pc.3162.LD), (.L__movme_tmp.1), (.L__pc.3162.LD)
	.p2align 4
	.L__pc.3162.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3163
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3163: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3164
	.L__pc.3164: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3165
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3165: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3166: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3167: Dma_PatchSrc (.L__pc.3167.LD), (.L__movme_tmp.1), (.L__pc.3167.LD)
	.p2align 4
	.L__pc.3167.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3168
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3168: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3169
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3169: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3170: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3171: Dma_PatchSrc (.L__pc.3171.LD), (.L__movme_tmp.1), (.L__pc.3171.LD)
	.p2align 4
	.L__pc.3171.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3172
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3172: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3173
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3173: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3174: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3175: Dma_PatchSrc (.L__pc.3175.LD), (.L__movme_tmp.1), (.L__pc.3175.LD)
	.p2align 4
	.L__pc.3175.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3176
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3176: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3177
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3177: Dma_PatchSrc (.L__pc.3177.LD), (.L__movme_cp.24), (.L__pc.3177.LD)
	.p2align 4
	.L__pc.3177.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3178
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3178: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3179
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3179: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3180: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3181: Dma_PatchSrc (.L__pc.3181.LD), (.L__movme_tmp.1), (.L__pc.3181.LD)
	.p2align 4
	.L__pc.3181.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3182
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3182: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3183
	
	.L__pc.3183: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3184
	
	.p2align 4
	.L__pc.3184: Dma_PatchDst (.L__pc.3184.ST), (.L__movme_cp.79), (.L__pc.3184.ST)
	.L__pc.3184.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3185
	
	.L__pc.3185: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3186
	
	.p2align 4
	.L__pc.3186: Dma_PatchDst (.L__pc.3186.ST), (.L__movme_cp.54), (.L__pc.3186.ST)
	.L__pc.3186.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3187
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.3187: Dma_PatchSrc (.L__pc.3187.LD), (.L__movme_cp.74), (.L__pc.3187.LD)
	.p2align 4
	.L__pc.3187.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3188
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3188: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3189
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.3189: Dma_PatchSrc (.L__pc.3189.LD), (.L__movme_cp.77), (.L__pc.3189.LD)
	.p2align 4
	.L__pc.3189.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3190
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3190: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3191
	
	.L__pc.3191: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3192
	
	.p2align 4
	.L__pc.3192: Dma_PatchDst (.L__pc.3192.ST), ((.L__movme.reg.eax+0)), (.L__pc.3192.ST)
	.L__pc.3192.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3193
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.3193: Dma_PatchSrc (.L__pc.3193.LD), (.L__movme_cp.76), (.L__pc.3193.LD)
	.p2align 4
	.L__pc.3193.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3194
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3194: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3195
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.3195: Dma_PatchSrc (.L__pc.3195.LD), ((.L__movme.reg.eax+0)), (.L__pc.3195.LD)
	.p2align 4
	.L__pc.3195.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3196
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3196: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3197
	
	.L__pc.3197: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3198
	
	.p2align 4
	.L__pc.3198: Dma_PatchDst (.L__pc.3198.ST), (.L__movme_cp.80), (.L__pc.3198.ST)
	.L__pc.3198.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3199
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3199: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3200
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3200: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3201
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.3201: Dma_PatchSrc (.L__pc.3201.LD), (.L__movme_cp.81), (.L__pc.3201.LD)
	.p2align 4
	.L__pc.3201.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3202
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3202: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3203
	.L__pc.3203: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3204
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.88 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.3204: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3205: Dma_PatchSrc (.L__pc.3205.LD), (.L__movme_tmp.1), (.L__pc.3205.LD)
	.p2align 4
	.L__pc.3205.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3206
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3206: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3207
	.L__pc.3207: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3208
	
	.L__pc.3208: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3209
	
	.p2align 4
	.L__pc.3209: Dma_PatchDst (.L__pc.3209.ST), (.L__movme_cp.81), (.L__pc.3209.ST)
	.L__pc.3209.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3210
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.3210: Dma_PatchSrc (.L__pc.3210.LD), (.L__movme_cp.76), (.L__pc.3210.LD)
	.p2align 4
	.L__pc.3210.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3211
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3211: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3212
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.3212: Dma_PatchSrc (.L__pc.3212.LD), (.L__movme_cp.80), (.L__pc.3212.LD)
	.p2align 4
	.L__pc.3212.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3213
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3213: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3214
	
	.L__pc.3214: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3215
	
	.p2align 4
	.L__pc.3215: Dma_PatchDst (.L__pc.3215.ST), ((.L__movme.reg.eax+0)), (.L__pc.3215.ST)
	.L__pc.3215.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3216
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3216: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3217
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3217: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3218
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.3218: Dma_PatchSrc (.L__pc.3218.LD), (.L__movme_cp.61), (.L__pc.3218.LD)
	.p2align 4
	.L__pc.3218.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3219
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3219: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3220
	.L__pc.3220: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3221
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3221: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.89 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3222: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3223: Dma_PatchSrc (.L__pc.3223.LD), (.L__movme_tmp.1), (.L__pc.3223.LD)
	.p2align 4
	.L__pc.3223.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3224
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3224: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3225
	
	.L__pc.3225: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3226
	
	.p2align 4
	.L__pc.3226: Dma_PatchDst (.L__pc.3226.ST), (.L__movme_cp.24), (.L__pc.3226.ST)
	.L__pc.3226.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3227
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3227: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3228
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3228: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3229
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3229: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3230
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3230: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3231
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.3231: Dma_PatchSrc (.L__pc.3231.LD), (.L__movme_cp.63), (.L__pc.3231.LD)
	.p2align 4
	.L__pc.3231.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3232
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3232: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3233
	.L__pc.3233: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3234
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3234: Dma_PatchSrc (.L__pc.3234.LD), (.L__movme_cp.24), (.L__pc.3234.LD)
	.p2align 4
	.L__pc.3234.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3235
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3235: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3236
	.L__pc.3236: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3237
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3237: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3238: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3239: Dma_PatchSrc (.L__pc.3239.LD), (.L__movme_tmp.1), (.L__pc.3239.LD)
	.p2align 4
	.L__pc.3239.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3240
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3240: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3241
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3241: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3242: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3243: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3244: Dma_PatchSrc (.L__pc.3244.LD), (.L__movme_tmp.1), (.L__pc.3244.LD)
	.p2align 4
	.L__pc.3244.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3245
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3245: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3246
	
	.L__pc.3246: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3247
	
	.p2align 4
	.L__pc.3247: Dma_PatchDst (.L__pc.3247.ST), (.L__movme_cp.63), (.L__pc.3247.ST)
	.L__pc.3247.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3248
	
	.L__pc.3248: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3249
	
	.p2align 4
	.L__pc.3249: Dma_PatchDst (.L__pc.3249.ST), (.L__movme_cp.24), (.L__pc.3249.ST)
	.L__pc.3249.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3250
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3250: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3251
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3251: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3252
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3252: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3253
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3253: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3254
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.3254: Dma_PatchSrc (.L__pc.3254.LD), (.L__movme_cp.66), (.L__pc.3254.LD)
	.p2align 4
	.L__pc.3254.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3255
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3255: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3256
	.L__pc.3256: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3257
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3257: Dma_PatchSrc (.L__pc.3257.LD), (.L__movme_cp.24), (.L__pc.3257.LD)
	.p2align 4
	.L__pc.3257.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3258
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3258: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3259
	.L__pc.3259: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3260
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3260: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3261: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3262: Dma_PatchSrc (.L__pc.3262.LD), (.L__movme_tmp.1), (.L__pc.3262.LD)
	.p2align 4
	.L__pc.3262.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3263
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3263: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3264
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3264: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3265: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3266: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3267: Dma_PatchSrc (.L__pc.3267.LD), (.L__movme_tmp.1), (.L__pc.3267.LD)
	.p2align 4
	.L__pc.3267.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3268
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3268: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3269
	
	.L__pc.3269: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3270
	
	.p2align 4
	.L__pc.3270: Dma_PatchDst (.L__pc.3270.ST), (.L__movme_cp.66), (.L__pc.3270.ST)
	.L__pc.3270.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3271
	
	.L__pc.3271: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3272
	
	.p2align 4
	.L__pc.3272: Dma_PatchDst (.L__pc.3272.ST), (.L__movme_cp.24), (.L__pc.3272.ST)
	.L__pc.3272.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3273
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3273: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3274
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3274: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3275
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3275: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3276
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3276: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3277
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.3277: Dma_PatchSrc (.L__pc.3277.LD), (.L__movme_cp.67), (.L__pc.3277.LD)
	.p2align 4
	.L__pc.3277.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3278
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3278: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3279
	.L__pc.3279: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3280
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3280: Dma_PatchSrc (.L__pc.3280.LD), (.L__movme_cp.24), (.L__pc.3280.LD)
	.p2align 4
	.L__pc.3280.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3281
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3281: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3282
	.L__pc.3282: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3283
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3283: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3284: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3285: Dma_PatchSrc (.L__pc.3285.LD), (.L__movme_tmp.1), (.L__pc.3285.LD)
	.p2align 4
	.L__pc.3285.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3286
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3286: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3287
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3287: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3288: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3289: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3290: Dma_PatchSrc (.L__pc.3290.LD), (.L__movme_tmp.1), (.L__pc.3290.LD)
	.p2align 4
	.L__pc.3290.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3291
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3291: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3292
	
	.L__pc.3292: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3293
	
	.p2align 4
	.L__pc.3293: Dma_PatchDst (.L__pc.3293.ST), (.L__movme_cp.67), (.L__pc.3293.ST)
	.L__pc.3293.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3294
	
	.L__pc.3294: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3295
	
	.p2align 4
	.L__pc.3295: Dma_PatchDst (.L__pc.3295.ST), (.L__movme_cp.24), (.L__pc.3295.ST)
	.L__pc.3295.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3296
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3296: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3297
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3297: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3298
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3298: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3299
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3299: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3300
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.3300: Dma_PatchSrc (.L__pc.3300.LD), (.L__movme_cp.68), (.L__pc.3300.LD)
	.p2align 4
	.L__pc.3300.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3301
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3301: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3302
	.L__pc.3302: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3303
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3303: Dma_PatchSrc (.L__pc.3303.LD), (.L__movme_cp.24), (.L__pc.3303.LD)
	.p2align 4
	.L__pc.3303.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3304
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3304: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3305
	.L__pc.3305: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3306
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3306: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3307: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3308: Dma_PatchSrc (.L__pc.3308.LD), (.L__movme_tmp.1), (.L__pc.3308.LD)
	.p2align 4
	.L__pc.3308.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3309
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3309: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3310
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3310: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3311: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3312: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3313: Dma_PatchSrc (.L__pc.3313.LD), (.L__movme_tmp.1), (.L__pc.3313.LD)
	.p2align 4
	.L__pc.3313.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3314
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3314: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3315
	
	.L__pc.3315: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3316
	
	.p2align 4
	.L__pc.3316: Dma_PatchDst (.L__pc.3316.ST), (.L__movme_cp.68), (.L__pc.3316.ST)
	.L__pc.3316.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3317
	
	.L__pc.3317: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3318
	
	.p2align 4
	.L__pc.3318: Dma_PatchDst (.L__pc.3318.ST), (.L__movme_cp.24), (.L__pc.3318.ST)
	.L__pc.3318.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3319
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3319: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3320
	
	.p2align 4
	.L__pc.3320: Dma_PatchDst (.L__pc.3320.ST), (.L__movme_cp.24), (.L__pc.3320.ST)
	.L__pc.3320.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3321
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.3321: Dma_PatchSrc (.L__pc.3321.LD), (.L__movme_cp.60), (.L__pc.3321.LD)
	.p2align 4
	.L__pc.3321.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3322
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3322: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3323
	
	.L__pc.3323: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3324
	
	.p2align 4
	.L__pc.3324: Dma_PatchDst (.L__pc.3324.ST), (.L__movme_cp.21), (.L__pc.3324.ST)
	.L__pc.3324.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3325
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.3325: Dma_PatchSrc (.L__pc.3325.LD), (.L__movme_cp.58), (.L__pc.3325.LD)
	.p2align 4
	.L__pc.3325.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3326
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3326: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3327
	
	.L__pc.3327: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3328
	
	.p2align 4
	.L__pc.3328: Dma_PatchDst (.L__pc.3328.ST), (.L__movme_cp.22), (.L__pc.3328.ST)
	.L__pc.3328.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3329
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3329: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3330
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3330: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3331
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3331: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3332
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3332: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3333
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.3333: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.3334
	
	.p2align 4
	.L__pc.3334: Dma_PatchDst (.L__pc.3334.ST), (.L__movme_cp.24), (.L__pc.3334.ST)
	.L__pc.3334.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3335
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.3335: Dma_PatchSrc (.L__pc.3335.LD), (.L__movme_cp.25), (.L__pc.3335.LD)
	.p2align 4
	.L__pc.3335.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3336
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3336: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3337
	.L__pc.3337: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3338
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.3338: Dma_PatchSrc (.L__pc.3338.LD), (.L__movme_cp.26), (.L__pc.3338.LD)
	.p2align 4
	.L__pc.3338.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3339
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3339: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3340
	.L__pc.3340: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3341
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3341: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3342: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3343: Dma_PatchSrc (.L__pc.3343.LD), (.L__movme_tmp.1), (.L__pc.3343.LD)
	.p2align 4
	.L__pc.3343.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3344
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3344: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3345
	.L__pc.3345: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3346
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3346: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3347: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3348: Dma_PatchSrc (.L__pc.3348.LD), (.L__movme_tmp.1), (.L__pc.3348.LD)
	.p2align 4
	.L__pc.3348.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3349
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3349: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3350
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3350: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3351: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3352: Dma_PatchSrc (.L__pc.3352.LD), (.L__movme_tmp.1), (.L__pc.3352.LD)
	.p2align 4
	.L__pc.3352.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3353
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3353: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3354
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3354: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3355: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3356: Dma_PatchSrc (.L__pc.3356.LD), (.L__movme_tmp.1), (.L__pc.3356.LD)
	.p2align 4
	.L__pc.3356.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3357
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3357: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3358
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3358: Dma_PatchSrc (.L__pc.3358.LD), (.L__movme_cp.24), (.L__pc.3358.LD)
	.p2align 4
	.L__pc.3358.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3359
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3359: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3360
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3360: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3361: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3362: Dma_PatchSrc (.L__pc.3362.LD), (.L__movme_tmp.1), (.L__pc.3362.LD)
	.p2align 4
	.L__pc.3362.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3363
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3363: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3364
	
	.L__pc.3364: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3365
	
	.p2align 4
	.L__pc.3365: Dma_PatchDst (.L__pc.3365.ST), (.L__movme_cp.69), (.L__pc.3365.ST)
	.L__pc.3365.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3366
	
	.L__pc.3366: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3367
	
	.p2align 4
	.L__pc.3367: Dma_PatchDst (.L__pc.3367.ST), (.L__movme_cp.54), (.L__pc.3367.ST)
	.L__pc.3367.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3368
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.3368: Dma_PatchSrc (.L__pc.3368.LD), (.L__movme_cp.30), (.L__pc.3368.LD)
	.p2align 4
	.L__pc.3368.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3369
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3369: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3370
	.L__pc.3370: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3371
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.3371: Dma_PatchSrc (.L__pc.3371.LD), (.L__movme_cp.31), (.L__pc.3371.LD)
	.p2align 4
	.L__pc.3371.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3372
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3372: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3373
	.L__pc.3373: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3374
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3374: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3375: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3376: Dma_PatchSrc (.L__pc.3376.LD), (.L__movme_tmp.1), (.L__pc.3376.LD)
	.p2align 4
	.L__pc.3376.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3377
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3377: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3378
	.L__pc.3378: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3379
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3379: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3380: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3381: Dma_PatchSrc (.L__pc.3381.LD), (.L__movme_tmp.1), (.L__pc.3381.LD)
	.p2align 4
	.L__pc.3381.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3382
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3382: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3383
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3383: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3384: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3385: Dma_PatchSrc (.L__pc.3385.LD), (.L__movme_tmp.1), (.L__pc.3385.LD)
	.p2align 4
	.L__pc.3385.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3386
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3386: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3387
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3387: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3388: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3389: Dma_PatchSrc (.L__pc.3389.LD), (.L__movme_tmp.1), (.L__pc.3389.LD)
	.p2align 4
	.L__pc.3389.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3390
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3390: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3391
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3391: Dma_PatchSrc (.L__pc.3391.LD), (.L__movme_cp.24), (.L__pc.3391.LD)
	.p2align 4
	.L__pc.3391.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3392
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3392: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3393
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3393: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3394: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3395: Dma_PatchSrc (.L__pc.3395.LD), (.L__movme_tmp.1), (.L__pc.3395.LD)
	.p2align 4
	.L__pc.3395.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3396
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3396: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3397
	
	.L__pc.3397: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3398
	
	.p2align 4
	.L__pc.3398: Dma_PatchDst (.L__pc.3398.ST), (.L__movme_cp.70), (.L__pc.3398.ST)
	.L__pc.3398.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3399
	
	.L__pc.3399: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3400
	
	.p2align 4
	.L__pc.3400: Dma_PatchDst (.L__pc.3400.ST), (.L__movme_cp.54), (.L__pc.3400.ST)
	.L__pc.3400.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3401
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3401: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3402
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3402: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3403
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3403: Dma_PatchSrc (.L__pc.3403.LD), (.L__movme_cp.24), (.L__pc.3403.LD)
	.p2align 4
	.L__pc.3403.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3404
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3404: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3405
	.L__pc.3405: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3406
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.3406: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3407: Dma_PatchSrc (.L__pc.3407.LD), (.L__movme_tmp.1), (.L__pc.3407.LD)
	.p2align 4
	.L__pc.3407.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3408
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3408: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3409
	.L__pc.3409: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3410
	
	.L__pc.3410: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3411
	
	.p2align 4
	.L__pc.3411: Dma_PatchDst (.L__pc.3411.ST), (.L__movme_cp.72), (.L__pc.3411.ST)
	.L__pc.3411.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3412
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.3412: Dma_PatchSrc (.L__pc.3412.LD), (.L__movme_cp.72), (.L__pc.3412.LD)
	.p2align 4
	.L__pc.3412.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3413
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3413: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3414
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3414: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3415: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3416: Dma_PatchSrc (.L__pc.3416.LD), (.L__movme_tmp.1), (.L__pc.3416.LD)
	.p2align 4
	.L__pc.3416.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3417
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3417: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3418
	
	.L__pc.3418: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3419
	
	.p2align 4
	.L__pc.3419: Dma_PatchDst (.L__pc.3419.ST), (.L__movme_cp.74), (.L__pc.3419.ST)
	.L__pc.3419.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3420
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3420: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3421: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3422: Dma_PatchSrc (.L__pc.3422.LD), (.L__movme_tmp.1), (.L__pc.3422.LD)
	.p2align 4
	.L__pc.3422.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3423
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3423: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3424
	
	.L__pc.3424: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3425
	
	.p2align 4
	.L__pc.3425: Dma_PatchDst (.L__pc.3425.ST), (.L__movme_cp.76), (.L__pc.3425.ST)
	.L__pc.3425.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3426
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.3426: Dma_PatchSrc (.L__pc.3426.LD), (.L__movme_cp.74), (.L__pc.3426.LD)
	.p2align 4
	.L__pc.3426.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3427
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3427: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3428
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.3428: Dma_PatchSrc (.L__pc.3428.LD), ((.L__movme.reg.eax+0)), (.L__pc.3428.LD)
	.p2align 4
	.L__pc.3428.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3429
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3429: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3430
	
	.L__pc.3430: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3431
	
	.p2align 4
	.L__pc.3431: Dma_PatchDst (.L__pc.3431.ST), (.L__movme_cp.77), (.L__pc.3431.ST)
	.L__pc.3431.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3432
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.3432: Dma_PatchSrc (.L__pc.3432.LD), (.L__movme_cp.77), (.L__pc.3432.LD)
	.p2align 4
	.L__pc.3432.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3433
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3433: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3434
	
	.L__pc.3434: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3435
	
	.p2align 4
	.L__pc.3435: Dma_PatchDst (.L__pc.3435.ST), (.L__movme_cp.21), (.L__pc.3435.ST)
	.L__pc.3435.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3436
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.3436: Dma_PatchSrc (.L__pc.3436.LD), (.L__movme_cp.58), (.L__pc.3436.LD)
	.p2align 4
	.L__pc.3436.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3437
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3437: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3438
	
	.L__pc.3438: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3439
	
	.p2align 4
	.L__pc.3439: Dma_PatchDst (.L__pc.3439.ST), (.L__movme_cp.22), (.L__pc.3439.ST)
	.L__pc.3439.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3440
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3440: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3441
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3441: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3442
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3442: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3443
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3443: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3444
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.3444: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.3445
	
	.p2align 4
	.L__pc.3445: Dma_PatchDst (.L__pc.3445.ST), (.L__movme_cp.24), (.L__pc.3445.ST)
	.L__pc.3445.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3446
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.3446: Dma_PatchSrc (.L__pc.3446.LD), (.L__movme_cp.25), (.L__pc.3446.LD)
	.p2align 4
	.L__pc.3446.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3447
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3447: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3448
	.L__pc.3448: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3449
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.3449: Dma_PatchSrc (.L__pc.3449.LD), (.L__movme_cp.26), (.L__pc.3449.LD)
	.p2align 4
	.L__pc.3449.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3450
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3450: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3451
	.L__pc.3451: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3452
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3452: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3453: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3454: Dma_PatchSrc (.L__pc.3454.LD), (.L__movme_tmp.1), (.L__pc.3454.LD)
	.p2align 4
	.L__pc.3454.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3455
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3455: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3456
	.L__pc.3456: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3457
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3457: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3458: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3459: Dma_PatchSrc (.L__pc.3459.LD), (.L__movme_tmp.1), (.L__pc.3459.LD)
	.p2align 4
	.L__pc.3459.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3460
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3460: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3461
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3461: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3462: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3463: Dma_PatchSrc (.L__pc.3463.LD), (.L__movme_tmp.1), (.L__pc.3463.LD)
	.p2align 4
	.L__pc.3463.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3464
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3464: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3465
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3465: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3466: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3467: Dma_PatchSrc (.L__pc.3467.LD), (.L__movme_tmp.1), (.L__pc.3467.LD)
	.p2align 4
	.L__pc.3467.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3468
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3468: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3469
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3469: Dma_PatchSrc (.L__pc.3469.LD), (.L__movme_cp.24), (.L__pc.3469.LD)
	.p2align 4
	.L__pc.3469.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3470
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3470: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3471
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3471: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3472: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3473: Dma_PatchSrc (.L__pc.3473.LD), (.L__movme_tmp.1), (.L__pc.3473.LD)
	.p2align 4
	.L__pc.3473.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3474
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3474: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3475
	
	.L__pc.3475: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3476
	
	.p2align 4
	.L__pc.3476: Dma_PatchDst (.L__pc.3476.ST), (.L__movme_cp.78), (.L__pc.3476.ST)
	.L__pc.3476.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3477
	
	.L__pc.3477: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3478
	
	.p2align 4
	.L__pc.3478: Dma_PatchDst (.L__pc.3478.ST), (.L__movme_cp.54), (.L__pc.3478.ST)
	.L__pc.3478.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3479
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.3479: Dma_PatchSrc (.L__pc.3479.LD), (.L__movme_cp.30), (.L__pc.3479.LD)
	.p2align 4
	.L__pc.3479.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3480
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3480: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3481
	.L__pc.3481: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3482
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.3482: Dma_PatchSrc (.L__pc.3482.LD), (.L__movme_cp.31), (.L__pc.3482.LD)
	.p2align 4
	.L__pc.3482.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3483
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3483: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3484
	.L__pc.3484: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3485
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3485: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3486: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3487: Dma_PatchSrc (.L__pc.3487.LD), (.L__movme_tmp.1), (.L__pc.3487.LD)
	.p2align 4
	.L__pc.3487.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3488
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3488: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3489
	.L__pc.3489: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3490
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3490: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3491: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3492: Dma_PatchSrc (.L__pc.3492.LD), (.L__movme_tmp.1), (.L__pc.3492.LD)
	.p2align 4
	.L__pc.3492.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3493
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3493: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3494
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3494: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3495: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3496: Dma_PatchSrc (.L__pc.3496.LD), (.L__movme_tmp.1), (.L__pc.3496.LD)
	.p2align 4
	.L__pc.3496.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3497
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3497: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3498
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3498: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3499: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3500: Dma_PatchSrc (.L__pc.3500.LD), (.L__movme_tmp.1), (.L__pc.3500.LD)
	.p2align 4
	.L__pc.3500.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3501
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3501: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3502
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3502: Dma_PatchSrc (.L__pc.3502.LD), (.L__movme_cp.24), (.L__pc.3502.LD)
	.p2align 4
	.L__pc.3502.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3503
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3503: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3504
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3504: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3505: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3506: Dma_PatchSrc (.L__pc.3506.LD), (.L__movme_tmp.1), (.L__pc.3506.LD)
	.p2align 4
	.L__pc.3506.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3507
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3507: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3508
	
	.L__pc.3508: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3509
	
	.p2align 4
	.L__pc.3509: Dma_PatchDst (.L__pc.3509.ST), (.L__movme_cp.79), (.L__pc.3509.ST)
	.L__pc.3509.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3510
	
	.L__pc.3510: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3511
	
	.p2align 4
	.L__pc.3511: Dma_PatchDst (.L__pc.3511.ST), (.L__movme_cp.54), (.L__pc.3511.ST)
	.L__pc.3511.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3512
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.3512: Dma_PatchSrc (.L__pc.3512.LD), (.L__movme_cp.74), (.L__pc.3512.LD)
	.p2align 4
	.L__pc.3512.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3513
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3513: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3514
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.3514: Dma_PatchSrc (.L__pc.3514.LD), (.L__movme_cp.77), (.L__pc.3514.LD)
	.p2align 4
	.L__pc.3514.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3515
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3515: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3516
	
	.L__pc.3516: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3517
	
	.p2align 4
	.L__pc.3517: Dma_PatchDst (.L__pc.3517.ST), ((.L__movme.reg.eax+0)), (.L__pc.3517.ST)
	.L__pc.3517.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3518
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.3518: Dma_PatchSrc (.L__pc.3518.LD), (.L__movme_cp.76), (.L__pc.3518.LD)
	.p2align 4
	.L__pc.3518.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3519
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3519: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3520
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.3520: Dma_PatchSrc (.L__pc.3520.LD), ((.L__movme.reg.eax+0)), (.L__pc.3520.LD)
	.p2align 4
	.L__pc.3520.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3521
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3521: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3522
	
	.L__pc.3522: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3523
	
	.p2align 4
	.L__pc.3523: Dma_PatchDst (.L__pc.3523.ST), (.L__movme_cp.80), (.L__pc.3523.ST)
	.L__pc.3523.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3524
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3524: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3525
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3525: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3526
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.3526: Dma_PatchSrc (.L__pc.3526.LD), (.L__movme_cp.81), (.L__pc.3526.LD)
	.p2align 4
	.L__pc.3526.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3527
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3527: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3528
	.L__pc.3528: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3529
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.90 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.3529: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3530: Dma_PatchSrc (.L__pc.3530.LD), (.L__movme_tmp.1), (.L__pc.3530.LD)
	.p2align 4
	.L__pc.3530.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3531
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3531: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3532
	.L__pc.3532: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3533
	
	.L__pc.3533: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3534
	
	.p2align 4
	.L__pc.3534: Dma_PatchDst (.L__pc.3534.ST), (.L__movme_cp.81), (.L__pc.3534.ST)
	.L__pc.3534.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3535
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.3535: Dma_PatchSrc (.L__pc.3535.LD), (.L__movme_cp.76), (.L__pc.3535.LD)
	.p2align 4
	.L__pc.3535.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3536
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3536: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3537
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.3537: Dma_PatchSrc (.L__pc.3537.LD), (.L__movme_cp.80), (.L__pc.3537.LD)
	.p2align 4
	.L__pc.3537.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3538
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3538: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3539
	
	.L__pc.3539: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3540
	
	.p2align 4
	.L__pc.3540: Dma_PatchDst (.L__pc.3540.ST), ((.L__movme.reg.eax+0)), (.L__pc.3540.ST)
	.L__pc.3540.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3541
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3541: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3542
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3542: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3543
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.3543: Dma_PatchSrc (.L__pc.3543.LD), (.L__movme_cp.61), (.L__pc.3543.LD)
	.p2align 4
	.L__pc.3543.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3544
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3544: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3545
	.L__pc.3545: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3546
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3546: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.91 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3547: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3548: Dma_PatchSrc (.L__pc.3548.LD), (.L__movme_tmp.1), (.L__pc.3548.LD)
	.p2align 4
	.L__pc.3548.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3549
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3549: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3550
	
	.L__pc.3550: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3551
	
	.p2align 4
	.L__pc.3551: Dma_PatchDst (.L__pc.3551.ST), (.L__movme_cp.24), (.L__pc.3551.ST)
	.L__pc.3551.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3552
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3552: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3553
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3553: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3554
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3554: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3555
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3555: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3556
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.3556: Dma_PatchSrc (.L__pc.3556.LD), (.L__movme_cp.63), (.L__pc.3556.LD)
	.p2align 4
	.L__pc.3556.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3557
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3557: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3558
	.L__pc.3558: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3559
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3559: Dma_PatchSrc (.L__pc.3559.LD), (.L__movme_cp.24), (.L__pc.3559.LD)
	.p2align 4
	.L__pc.3559.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3560
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3560: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3561
	.L__pc.3561: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3562
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3562: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3563: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3564: Dma_PatchSrc (.L__pc.3564.LD), (.L__movme_tmp.1), (.L__pc.3564.LD)
	.p2align 4
	.L__pc.3564.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3565
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3565: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3566
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3566: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3567: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3568: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3569: Dma_PatchSrc (.L__pc.3569.LD), (.L__movme_tmp.1), (.L__pc.3569.LD)
	.p2align 4
	.L__pc.3569.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3570
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3570: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3571
	
	.L__pc.3571: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3572
	
	.p2align 4
	.L__pc.3572: Dma_PatchDst (.L__pc.3572.ST), (.L__movme_cp.63), (.L__pc.3572.ST)
	.L__pc.3572.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3573
	
	.L__pc.3573: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3574
	
	.p2align 4
	.L__pc.3574: Dma_PatchDst (.L__pc.3574.ST), (.L__movme_cp.24), (.L__pc.3574.ST)
	.L__pc.3574.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3575
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3575: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3576
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3576: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3577
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3577: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3578
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3578: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3579
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.3579: Dma_PatchSrc (.L__pc.3579.LD), (.L__movme_cp.66), (.L__pc.3579.LD)
	.p2align 4
	.L__pc.3579.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3580
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3580: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3581
	.L__pc.3581: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3582
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3582: Dma_PatchSrc (.L__pc.3582.LD), (.L__movme_cp.24), (.L__pc.3582.LD)
	.p2align 4
	.L__pc.3582.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3583
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3583: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3584
	.L__pc.3584: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3585
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3585: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3586: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3587: Dma_PatchSrc (.L__pc.3587.LD), (.L__movme_tmp.1), (.L__pc.3587.LD)
	.p2align 4
	.L__pc.3587.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3588
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3588: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3589
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3589: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3590: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3591: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3592: Dma_PatchSrc (.L__pc.3592.LD), (.L__movme_tmp.1), (.L__pc.3592.LD)
	.p2align 4
	.L__pc.3592.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3593
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3593: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3594
	
	.L__pc.3594: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3595
	
	.p2align 4
	.L__pc.3595: Dma_PatchDst (.L__pc.3595.ST), (.L__movme_cp.66), (.L__pc.3595.ST)
	.L__pc.3595.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3596
	
	.L__pc.3596: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3597
	
	.p2align 4
	.L__pc.3597: Dma_PatchDst (.L__pc.3597.ST), (.L__movme_cp.24), (.L__pc.3597.ST)
	.L__pc.3597.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3598
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3598: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3599
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3599: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3600
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3600: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3601
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3601: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3602
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.3602: Dma_PatchSrc (.L__pc.3602.LD), (.L__movme_cp.67), (.L__pc.3602.LD)
	.p2align 4
	.L__pc.3602.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3603
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3603: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3604
	.L__pc.3604: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3605
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3605: Dma_PatchSrc (.L__pc.3605.LD), (.L__movme_cp.24), (.L__pc.3605.LD)
	.p2align 4
	.L__pc.3605.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3606
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3606: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3607
	.L__pc.3607: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3608
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3608: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3609: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3610: Dma_PatchSrc (.L__pc.3610.LD), (.L__movme_tmp.1), (.L__pc.3610.LD)
	.p2align 4
	.L__pc.3610.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3611
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3611: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3612
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3612: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3613: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3614: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3615: Dma_PatchSrc (.L__pc.3615.LD), (.L__movme_tmp.1), (.L__pc.3615.LD)
	.p2align 4
	.L__pc.3615.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3616
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3616: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3617
	
	.L__pc.3617: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3618
	
	.p2align 4
	.L__pc.3618: Dma_PatchDst (.L__pc.3618.ST), (.L__movme_cp.67), (.L__pc.3618.ST)
	.L__pc.3618.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3619
	
	.L__pc.3619: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3620
	
	.p2align 4
	.L__pc.3620: Dma_PatchDst (.L__pc.3620.ST), (.L__movme_cp.24), (.L__pc.3620.ST)
	.L__pc.3620.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3621
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3621: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3622
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3622: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3623
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3623: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3624
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3624: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3625
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.3625: Dma_PatchSrc (.L__pc.3625.LD), (.L__movme_cp.68), (.L__pc.3625.LD)
	.p2align 4
	.L__pc.3625.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3626
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3626: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3627
	.L__pc.3627: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3628
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3628: Dma_PatchSrc (.L__pc.3628.LD), (.L__movme_cp.24), (.L__pc.3628.LD)
	.p2align 4
	.L__pc.3628.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3629
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3629: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3630
	.L__pc.3630: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3631
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3631: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3632: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3633: Dma_PatchSrc (.L__pc.3633.LD), (.L__movme_tmp.1), (.L__pc.3633.LD)
	.p2align 4
	.L__pc.3633.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3634
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3634: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3635
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3635: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3636: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3637: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3638: Dma_PatchSrc (.L__pc.3638.LD), (.L__movme_tmp.1), (.L__pc.3638.LD)
	.p2align 4
	.L__pc.3638.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3639
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3639: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3640
	
	.L__pc.3640: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3641
	
	.p2align 4
	.L__pc.3641: Dma_PatchDst (.L__pc.3641.ST), (.L__movme_cp.68), (.L__pc.3641.ST)
	.L__pc.3641.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3642
	
	.L__pc.3642: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3643
	
	.p2align 4
	.L__pc.3643: Dma_PatchDst (.L__pc.3643.ST), (.L__movme_cp.24), (.L__pc.3643.ST)
	.L__pc.3643.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3644
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3644: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3645
	
	.p2align 4
	.L__pc.3645: Dma_PatchDst (.L__pc.3645.ST), (.L__movme_cp.24), (.L__pc.3645.ST)
	.L__pc.3645.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3646
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.3646: Dma_PatchSrc (.L__pc.3646.LD), (.L__movme_cp.60), (.L__pc.3646.LD)
	.p2align 4
	.L__pc.3646.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3647
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3647: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3648
	
	.L__pc.3648: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3649
	
	.p2align 4
	.L__pc.3649: Dma_PatchDst (.L__pc.3649.ST), (.L__movme_cp.21), (.L__pc.3649.ST)
	.L__pc.3649.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3650
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.3650: Dma_PatchSrc (.L__pc.3650.LD), (.L__movme_cp.58), (.L__pc.3650.LD)
	.p2align 4
	.L__pc.3650.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3651
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3651: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3652
	
	.L__pc.3652: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3653
	
	.p2align 4
	.L__pc.3653: Dma_PatchDst (.L__pc.3653.ST), (.L__movme_cp.22), (.L__pc.3653.ST)
	.L__pc.3653.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3654
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3654: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3655
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3655: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3656
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3656: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3657
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3657: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3658
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.3658: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.3659
	
	.p2align 4
	.L__pc.3659: Dma_PatchDst (.L__pc.3659.ST), (.L__movme_cp.24), (.L__pc.3659.ST)
	.L__pc.3659.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3660
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.3660: Dma_PatchSrc (.L__pc.3660.LD), (.L__movme_cp.25), (.L__pc.3660.LD)
	.p2align 4
	.L__pc.3660.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3661
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3661: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3662
	.L__pc.3662: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3663
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.3663: Dma_PatchSrc (.L__pc.3663.LD), (.L__movme_cp.26), (.L__pc.3663.LD)
	.p2align 4
	.L__pc.3663.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3664
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3664: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3665
	.L__pc.3665: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3666
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3666: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3667: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3668: Dma_PatchSrc (.L__pc.3668.LD), (.L__movme_tmp.1), (.L__pc.3668.LD)
	.p2align 4
	.L__pc.3668.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3669
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3669: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3670
	.L__pc.3670: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3671
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3671: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3672: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3673: Dma_PatchSrc (.L__pc.3673.LD), (.L__movme_tmp.1), (.L__pc.3673.LD)
	.p2align 4
	.L__pc.3673.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3674
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3674: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3675
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3675: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3676: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3677: Dma_PatchSrc (.L__pc.3677.LD), (.L__movme_tmp.1), (.L__pc.3677.LD)
	.p2align 4
	.L__pc.3677.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3678
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3678: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3679
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3679: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3680: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3681: Dma_PatchSrc (.L__pc.3681.LD), (.L__movme_tmp.1), (.L__pc.3681.LD)
	.p2align 4
	.L__pc.3681.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3682
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3682: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3683
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3683: Dma_PatchSrc (.L__pc.3683.LD), (.L__movme_cp.24), (.L__pc.3683.LD)
	.p2align 4
	.L__pc.3683.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3684
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3684: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3685
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3685: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3686: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3687: Dma_PatchSrc (.L__pc.3687.LD), (.L__movme_tmp.1), (.L__pc.3687.LD)
	.p2align 4
	.L__pc.3687.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3688
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3688: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3689
	
	.L__pc.3689: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3690
	
	.p2align 4
	.L__pc.3690: Dma_PatchDst (.L__pc.3690.ST), (.L__movme_cp.69), (.L__pc.3690.ST)
	.L__pc.3690.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3691
	
	.L__pc.3691: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3692
	
	.p2align 4
	.L__pc.3692: Dma_PatchDst (.L__pc.3692.ST), (.L__movme_cp.54), (.L__pc.3692.ST)
	.L__pc.3692.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3693
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.3693: Dma_PatchSrc (.L__pc.3693.LD), (.L__movme_cp.30), (.L__pc.3693.LD)
	.p2align 4
	.L__pc.3693.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3694
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3694: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3695
	.L__pc.3695: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3696
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.3696: Dma_PatchSrc (.L__pc.3696.LD), (.L__movme_cp.31), (.L__pc.3696.LD)
	.p2align 4
	.L__pc.3696.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3697
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3697: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3698
	.L__pc.3698: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3699
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3699: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3700: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3701: Dma_PatchSrc (.L__pc.3701.LD), (.L__movme_tmp.1), (.L__pc.3701.LD)
	.p2align 4
	.L__pc.3701.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3702
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3702: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3703
	.L__pc.3703: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3704
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3704: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3705: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3706: Dma_PatchSrc (.L__pc.3706.LD), (.L__movme_tmp.1), (.L__pc.3706.LD)
	.p2align 4
	.L__pc.3706.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3707
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3707: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3708
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3708: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3709: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3710: Dma_PatchSrc (.L__pc.3710.LD), (.L__movme_tmp.1), (.L__pc.3710.LD)
	.p2align 4
	.L__pc.3710.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3711
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3711: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3712
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3712: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3713: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3714: Dma_PatchSrc (.L__pc.3714.LD), (.L__movme_tmp.1), (.L__pc.3714.LD)
	.p2align 4
	.L__pc.3714.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3715
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3715: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3716
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3716: Dma_PatchSrc (.L__pc.3716.LD), (.L__movme_cp.24), (.L__pc.3716.LD)
	.p2align 4
	.L__pc.3716.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3717
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3717: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3718
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3718: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3719: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3720: Dma_PatchSrc (.L__pc.3720.LD), (.L__movme_tmp.1), (.L__pc.3720.LD)
	.p2align 4
	.L__pc.3720.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3721
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3721: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3722
	
	.L__pc.3722: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3723
	
	.p2align 4
	.L__pc.3723: Dma_PatchDst (.L__pc.3723.ST), (.L__movme_cp.70), (.L__pc.3723.ST)
	.L__pc.3723.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3724
	
	.L__pc.3724: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3725
	
	.p2align 4
	.L__pc.3725: Dma_PatchDst (.L__pc.3725.ST), (.L__movme_cp.54), (.L__pc.3725.ST)
	.L__pc.3725.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3726
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3726: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3727
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3727: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3728
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3728: Dma_PatchSrc (.L__pc.3728.LD), (.L__movme_cp.24), (.L__pc.3728.LD)
	.p2align 4
	.L__pc.3728.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3729
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3729: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3730
	.L__pc.3730: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3731
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.3731: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3732: Dma_PatchSrc (.L__pc.3732.LD), (.L__movme_tmp.1), (.L__pc.3732.LD)
	.p2align 4
	.L__pc.3732.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3733
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3733: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3734
	.L__pc.3734: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3735
	
	.L__pc.3735: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3736
	
	.p2align 4
	.L__pc.3736: Dma_PatchDst (.L__pc.3736.ST), (.L__movme_cp.72), (.L__pc.3736.ST)
	.L__pc.3736.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3737
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.3737: Dma_PatchSrc (.L__pc.3737.LD), (.L__movme_cp.72), (.L__pc.3737.LD)
	.p2align 4
	.L__pc.3737.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3738
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3738: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3739
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3739: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3740: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3741: Dma_PatchSrc (.L__pc.3741.LD), (.L__movme_tmp.1), (.L__pc.3741.LD)
	.p2align 4
	.L__pc.3741.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3742
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3742: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3743
	
	.L__pc.3743: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3744
	
	.p2align 4
	.L__pc.3744: Dma_PatchDst (.L__pc.3744.ST), (.L__movme_cp.74), (.L__pc.3744.ST)
	.L__pc.3744.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3745
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3745: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3746: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3747: Dma_PatchSrc (.L__pc.3747.LD), (.L__movme_tmp.1), (.L__pc.3747.LD)
	.p2align 4
	.L__pc.3747.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3748
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3748: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3749
	
	.L__pc.3749: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3750
	
	.p2align 4
	.L__pc.3750: Dma_PatchDst (.L__pc.3750.ST), (.L__movme_cp.76), (.L__pc.3750.ST)
	.L__pc.3750.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3751
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.3751: Dma_PatchSrc (.L__pc.3751.LD), (.L__movme_cp.74), (.L__pc.3751.LD)
	.p2align 4
	.L__pc.3751.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3752
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3752: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3753
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.3753: Dma_PatchSrc (.L__pc.3753.LD), ((.L__movme.reg.eax+0)), (.L__pc.3753.LD)
	.p2align 4
	.L__pc.3753.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3754
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3754: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3755
	
	.L__pc.3755: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3756
	
	.p2align 4
	.L__pc.3756: Dma_PatchDst (.L__pc.3756.ST), (.L__movme_cp.77), (.L__pc.3756.ST)
	.L__pc.3756.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3757
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.3757: Dma_PatchSrc (.L__pc.3757.LD), (.L__movme_cp.77), (.L__pc.3757.LD)
	.p2align 4
	.L__pc.3757.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3758
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3758: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3759
	
	.L__pc.3759: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3760
	
	.p2align 4
	.L__pc.3760: Dma_PatchDst (.L__pc.3760.ST), (.L__movme_cp.21), (.L__pc.3760.ST)
	.L__pc.3760.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3761
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.3761: Dma_PatchSrc (.L__pc.3761.LD), (.L__movme_cp.58), (.L__pc.3761.LD)
	.p2align 4
	.L__pc.3761.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3762
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3762: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3763
	
	.L__pc.3763: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3764
	
	.p2align 4
	.L__pc.3764: Dma_PatchDst (.L__pc.3764.ST), (.L__movme_cp.22), (.L__pc.3764.ST)
	.L__pc.3764.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3765
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3765: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3766
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3766: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3767
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3767: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3768
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3768: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3769
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.3769: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.3770
	
	.p2align 4
	.L__pc.3770: Dma_PatchDst (.L__pc.3770.ST), (.L__movme_cp.24), (.L__pc.3770.ST)
	.L__pc.3770.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3771
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.3771: Dma_PatchSrc (.L__pc.3771.LD), (.L__movme_cp.25), (.L__pc.3771.LD)
	.p2align 4
	.L__pc.3771.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3772
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3772: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3773
	.L__pc.3773: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3774
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.3774: Dma_PatchSrc (.L__pc.3774.LD), (.L__movme_cp.26), (.L__pc.3774.LD)
	.p2align 4
	.L__pc.3774.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3775
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3775: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3776
	.L__pc.3776: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3777
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3777: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3778: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3779: Dma_PatchSrc (.L__pc.3779.LD), (.L__movme_tmp.1), (.L__pc.3779.LD)
	.p2align 4
	.L__pc.3779.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3780
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3780: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3781
	.L__pc.3781: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3782
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3782: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3783: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3784: Dma_PatchSrc (.L__pc.3784.LD), (.L__movme_tmp.1), (.L__pc.3784.LD)
	.p2align 4
	.L__pc.3784.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3785
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3785: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3786
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3786: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3787: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3788: Dma_PatchSrc (.L__pc.3788.LD), (.L__movme_tmp.1), (.L__pc.3788.LD)
	.p2align 4
	.L__pc.3788.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3789
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3789: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3790
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3790: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3791: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3792: Dma_PatchSrc (.L__pc.3792.LD), (.L__movme_tmp.1), (.L__pc.3792.LD)
	.p2align 4
	.L__pc.3792.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3793
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3793: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3794
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3794: Dma_PatchSrc (.L__pc.3794.LD), (.L__movme_cp.24), (.L__pc.3794.LD)
	.p2align 4
	.L__pc.3794.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3795
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3795: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3796
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3796: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3797: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3798: Dma_PatchSrc (.L__pc.3798.LD), (.L__movme_tmp.1), (.L__pc.3798.LD)
	.p2align 4
	.L__pc.3798.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3799
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3799: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3800
	
	.L__pc.3800: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3801
	
	.p2align 4
	.L__pc.3801: Dma_PatchDst (.L__pc.3801.ST), (.L__movme_cp.78), (.L__pc.3801.ST)
	.L__pc.3801.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3802
	
	.L__pc.3802: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3803
	
	.p2align 4
	.L__pc.3803: Dma_PatchDst (.L__pc.3803.ST), (.L__movme_cp.54), (.L__pc.3803.ST)
	.L__pc.3803.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3804
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.3804: Dma_PatchSrc (.L__pc.3804.LD), (.L__movme_cp.30), (.L__pc.3804.LD)
	.p2align 4
	.L__pc.3804.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3805
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3805: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3806
	.L__pc.3806: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3807
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.3807: Dma_PatchSrc (.L__pc.3807.LD), (.L__movme_cp.31), (.L__pc.3807.LD)
	.p2align 4
	.L__pc.3807.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3808
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3808: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3809
	.L__pc.3809: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3810
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3810: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3811: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3812: Dma_PatchSrc (.L__pc.3812.LD), (.L__movme_tmp.1), (.L__pc.3812.LD)
	.p2align 4
	.L__pc.3812.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3813
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3813: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3814
	.L__pc.3814: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3815
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3815: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3816: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3817: Dma_PatchSrc (.L__pc.3817.LD), (.L__movme_tmp.1), (.L__pc.3817.LD)
	.p2align 4
	.L__pc.3817.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3818
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3818: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3819
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3819: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3820: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3821: Dma_PatchSrc (.L__pc.3821.LD), (.L__movme_tmp.1), (.L__pc.3821.LD)
	.p2align 4
	.L__pc.3821.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3822
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3822: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3823
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3823: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3824: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3825: Dma_PatchSrc (.L__pc.3825.LD), (.L__movme_tmp.1), (.L__pc.3825.LD)
	.p2align 4
	.L__pc.3825.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3826
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3826: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3827
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3827: Dma_PatchSrc (.L__pc.3827.LD), (.L__movme_cp.24), (.L__pc.3827.LD)
	.p2align 4
	.L__pc.3827.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3828
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3828: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3829
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.3829: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3830: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3831: Dma_PatchSrc (.L__pc.3831.LD), (.L__movme_tmp.1), (.L__pc.3831.LD)
	.p2align 4
	.L__pc.3831.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3832
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3832: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3833
	
	.L__pc.3833: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.3834
	
	.p2align 4
	.L__pc.3834: Dma_PatchDst (.L__pc.3834.ST), (.L__movme_cp.79), (.L__pc.3834.ST)
	.L__pc.3834.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3835
	
	.L__pc.3835: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3836
	
	.p2align 4
	.L__pc.3836: Dma_PatchDst (.L__pc.3836.ST), (.L__movme_cp.54), (.L__pc.3836.ST)
	.L__pc.3836.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3837
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.3837: Dma_PatchSrc (.L__pc.3837.LD), (.L__movme_cp.74), (.L__pc.3837.LD)
	.p2align 4
	.L__pc.3837.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3838
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3838: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3839
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.3839: Dma_PatchSrc (.L__pc.3839.LD), (.L__movme_cp.77), (.L__pc.3839.LD)
	.p2align 4
	.L__pc.3839.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3840
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3840: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3841
	
	.L__pc.3841: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3842
	
	.p2align 4
	.L__pc.3842: Dma_PatchDst (.L__pc.3842.ST), ((.L__movme.reg.eax+0)), (.L__pc.3842.ST)
	.L__pc.3842.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3843
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.3843: Dma_PatchSrc (.L__pc.3843.LD), (.L__movme_cp.76), (.L__pc.3843.LD)
	.p2align 4
	.L__pc.3843.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3844
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3844: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3845
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.3845: Dma_PatchSrc (.L__pc.3845.LD), ((.L__movme.reg.eax+0)), (.L__pc.3845.LD)
	.p2align 4
	.L__pc.3845.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3846
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3846: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3847
	
	.L__pc.3847: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3848
	
	.p2align 4
	.L__pc.3848: Dma_PatchDst (.L__pc.3848.ST), (.L__movme_cp.80), (.L__pc.3848.ST)
	.L__pc.3848.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3849
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3849: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3850
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3850: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3851
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.3851: Dma_PatchSrc (.L__pc.3851.LD), (.L__movme_cp.81), (.L__pc.3851.LD)
	.p2align 4
	.L__pc.3851.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3852
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3852: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3853
	.L__pc.3853: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3854
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.92 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.3854: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3855: Dma_PatchSrc (.L__pc.3855.LD), (.L__movme_tmp.1), (.L__pc.3855.LD)
	.p2align 4
	.L__pc.3855.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3856
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3856: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3857
	.L__pc.3857: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3858
	
	.L__pc.3858: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3859
	
	.p2align 4
	.L__pc.3859: Dma_PatchDst (.L__pc.3859.ST), (.L__movme_cp.81), (.L__pc.3859.ST)
	.L__pc.3859.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3860
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.3860: Dma_PatchSrc (.L__pc.3860.LD), (.L__movme_cp.76), (.L__pc.3860.LD)
	.p2align 4
	.L__pc.3860.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3861
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3861: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3862
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.3862: Dma_PatchSrc (.L__pc.3862.LD), (.L__movme_cp.80), (.L__pc.3862.LD)
	.p2align 4
	.L__pc.3862.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3863
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3863: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3864
	
	.L__pc.3864: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.3865
	
	.p2align 4
	.L__pc.3865: Dma_PatchDst (.L__pc.3865.ST), ((.L__movme.reg.eax+0)), (.L__pc.3865.ST)
	.L__pc.3865.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3866
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3866: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3867
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3867: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3868
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.3868: Dma_PatchSrc (.L__pc.3868.LD), (.L__movme_cp.61), (.L__pc.3868.LD)
	.p2align 4
	.L__pc.3868.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3869
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3869: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3870
	.L__pc.3870: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3871
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.3871: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.93 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3872: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3873: Dma_PatchSrc (.L__pc.3873.LD), (.L__movme_tmp.1), (.L__pc.3873.LD)
	.p2align 4
	.L__pc.3873.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3874
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3874: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3875
	
	.L__pc.3875: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3876
	
	.p2align 4
	.L__pc.3876: Dma_PatchDst (.L__pc.3876.ST), (.L__movme_cp.24), (.L__pc.3876.ST)
	.L__pc.3876.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3877
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3877: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3878
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3878: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3879
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3879: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3880
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3880: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3881
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.3881: Dma_PatchSrc (.L__pc.3881.LD), (.L__movme_cp.63), (.L__pc.3881.LD)
	.p2align 4
	.L__pc.3881.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3882
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3882: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3883
	.L__pc.3883: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3884
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3884: Dma_PatchSrc (.L__pc.3884.LD), (.L__movme_cp.24), (.L__pc.3884.LD)
	.p2align 4
	.L__pc.3884.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3885
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3885: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3886
	.L__pc.3886: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3887
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3887: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3888: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3889: Dma_PatchSrc (.L__pc.3889.LD), (.L__movme_tmp.1), (.L__pc.3889.LD)
	.p2align 4
	.L__pc.3889.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3890
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3890: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3891
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3891: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3892: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3893: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3894: Dma_PatchSrc (.L__pc.3894.LD), (.L__movme_tmp.1), (.L__pc.3894.LD)
	.p2align 4
	.L__pc.3894.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3895
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3895: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3896
	
	.L__pc.3896: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3897
	
	.p2align 4
	.L__pc.3897: Dma_PatchDst (.L__pc.3897.ST), (.L__movme_cp.63), (.L__pc.3897.ST)
	.L__pc.3897.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3898
	
	.L__pc.3898: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3899
	
	.p2align 4
	.L__pc.3899: Dma_PatchDst (.L__pc.3899.ST), (.L__movme_cp.24), (.L__pc.3899.ST)
	.L__pc.3899.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3900
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3900: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3901
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3901: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3902
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3902: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3903
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3903: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3904
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.3904: Dma_PatchSrc (.L__pc.3904.LD), (.L__movme_cp.66), (.L__pc.3904.LD)
	.p2align 4
	.L__pc.3904.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3905
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3905: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3906
	.L__pc.3906: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3907
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3907: Dma_PatchSrc (.L__pc.3907.LD), (.L__movme_cp.24), (.L__pc.3907.LD)
	.p2align 4
	.L__pc.3907.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3908
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3908: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3909
	.L__pc.3909: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3910
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3910: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3911: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3912: Dma_PatchSrc (.L__pc.3912.LD), (.L__movme_tmp.1), (.L__pc.3912.LD)
	.p2align 4
	.L__pc.3912.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3913
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3913: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3914
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3914: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3915: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3916: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3917: Dma_PatchSrc (.L__pc.3917.LD), (.L__movme_tmp.1), (.L__pc.3917.LD)
	.p2align 4
	.L__pc.3917.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3918
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3918: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3919
	
	.L__pc.3919: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3920
	
	.p2align 4
	.L__pc.3920: Dma_PatchDst (.L__pc.3920.ST), (.L__movme_cp.66), (.L__pc.3920.ST)
	.L__pc.3920.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3921
	
	.L__pc.3921: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3922
	
	.p2align 4
	.L__pc.3922: Dma_PatchDst (.L__pc.3922.ST), (.L__movme_cp.24), (.L__pc.3922.ST)
	.L__pc.3922.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3923
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3923: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3924
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3924: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3925
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3925: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3926
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3926: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3927
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.3927: Dma_PatchSrc (.L__pc.3927.LD), (.L__movme_cp.67), (.L__pc.3927.LD)
	.p2align 4
	.L__pc.3927.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3928
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3928: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3929
	.L__pc.3929: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3930
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3930: Dma_PatchSrc (.L__pc.3930.LD), (.L__movme_cp.24), (.L__pc.3930.LD)
	.p2align 4
	.L__pc.3930.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3931
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3931: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3932
	.L__pc.3932: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3933
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3933: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3934: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3935: Dma_PatchSrc (.L__pc.3935.LD), (.L__movme_tmp.1), (.L__pc.3935.LD)
	.p2align 4
	.L__pc.3935.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3936
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3936: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3937
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3937: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3938: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3939: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3940: Dma_PatchSrc (.L__pc.3940.LD), (.L__movme_tmp.1), (.L__pc.3940.LD)
	.p2align 4
	.L__pc.3940.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3941
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3941: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3942
	
	.L__pc.3942: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3943
	
	.p2align 4
	.L__pc.3943: Dma_PatchDst (.L__pc.3943.ST), (.L__movme_cp.67), (.L__pc.3943.ST)
	.L__pc.3943.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3944
	
	.L__pc.3944: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3945
	
	.p2align 4
	.L__pc.3945: Dma_PatchDst (.L__pc.3945.ST), (.L__movme_cp.24), (.L__pc.3945.ST)
	.L__pc.3945.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3946
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3946: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3947
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3947: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3948
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3948: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3949
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3949: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.3950
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.3950: Dma_PatchSrc (.L__pc.3950.LD), (.L__movme_cp.68), (.L__pc.3950.LD)
	.p2align 4
	.L__pc.3950.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3951
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3951: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.3952
	.L__pc.3952: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.3953
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.3953: Dma_PatchSrc (.L__pc.3953.LD), (.L__movme_cp.24), (.L__pc.3953.LD)
	.p2align 4
	.L__pc.3953.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3954
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3954: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.3955
	.L__pc.3955: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.3956
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3956: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3957: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3958: Dma_PatchSrc (.L__pc.3958.LD), (.L__movme_tmp.1), (.L__pc.3958.LD)
	.p2align 4
	.L__pc.3958.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3959
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3959: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3960
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.3960: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.3961: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.3962: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3963: Dma_PatchSrc (.L__pc.3963.LD), (.L__movme_tmp.1), (.L__pc.3963.LD)
	.p2align 4
	.L__pc.3963.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3964
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3964: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3965
	
	.L__pc.3965: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.3966
	
	.p2align 4
	.L__pc.3966: Dma_PatchDst (.L__pc.3966.ST), (.L__movme_cp.68), (.L__pc.3966.ST)
	.L__pc.3966.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3967
	
	.L__pc.3967: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.3968
	
	.p2align 4
	.L__pc.3968: Dma_PatchDst (.L__pc.3968.ST), (.L__movme_cp.24), (.L__pc.3968.ST)
	.L__pc.3968.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3969
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3969: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3970
	
	.p2align 4
	.L__pc.3970: Dma_PatchDst (.L__pc.3970.ST), (.L__movme_cp.24), (.L__pc.3970.ST)
	.L__pc.3970.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3971
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.3971: Dma_PatchSrc (.L__pc.3971.LD), (.L__movme_cp.60), (.L__pc.3971.LD)
	.p2align 4
	.L__pc.3971.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3972
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3972: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3973
	
	.L__pc.3973: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3974
	
	.p2align 4
	.L__pc.3974: Dma_PatchDst (.L__pc.3974.ST), (.L__movme_cp.21), (.L__pc.3974.ST)
	.L__pc.3974.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3975
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.3975: Dma_PatchSrc (.L__pc.3975.LD), (.L__movme_cp.58), (.L__pc.3975.LD)
	.p2align 4
	.L__pc.3975.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3976
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3976: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3977
	
	.L__pc.3977: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.3978
	
	.p2align 4
	.L__pc.3978: Dma_PatchDst (.L__pc.3978.ST), (.L__movme_cp.22), (.L__pc.3978.ST)
	.L__pc.3978.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3979
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3979: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3980
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3980: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.3981
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.3981: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.3982
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3982: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.3983
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.3983: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.3984
	
	.p2align 4
	.L__pc.3984: Dma_PatchDst (.L__pc.3984.ST), (.L__movme_cp.24), (.L__pc.3984.ST)
	.L__pc.3984.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.3985
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.3985: Dma_PatchSrc (.L__pc.3985.LD), (.L__movme_cp.25), (.L__pc.3985.LD)
	.p2align 4
	.L__pc.3985.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3986
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.3986: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.3987
	.L__pc.3987: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.3988
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.3988: Dma_PatchSrc (.L__pc.3988.LD), (.L__movme_cp.26), (.L__pc.3988.LD)
	.p2align 4
	.L__pc.3988.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3989
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3989: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3990
	.L__pc.3990: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3991
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.3991: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3992: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3993: Dma_PatchSrc (.L__pc.3993.LD), (.L__movme_tmp.1), (.L__pc.3993.LD)
	.p2align 4
	.L__pc.3993.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3994
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.3994: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.3995
	.L__pc.3995: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.3996
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.3996: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.3997: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.3998: Dma_PatchSrc (.L__pc.3998.LD), (.L__movme_tmp.1), (.L__pc.3998.LD)
	.p2align 4
	.L__pc.3998.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.3999
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.3999: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4000
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4000: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4001: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4002: Dma_PatchSrc (.L__pc.4002.LD), (.L__movme_tmp.1), (.L__pc.4002.LD)
	.p2align 4
	.L__pc.4002.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4003
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4003: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4004
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4004: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4005: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4006: Dma_PatchSrc (.L__pc.4006.LD), (.L__movme_tmp.1), (.L__pc.4006.LD)
	.p2align 4
	.L__pc.4006.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4007
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4007: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4008
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4008: Dma_PatchSrc (.L__pc.4008.LD), (.L__movme_cp.24), (.L__pc.4008.LD)
	.p2align 4
	.L__pc.4008.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4009
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4009: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4010
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4010: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4011: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4012: Dma_PatchSrc (.L__pc.4012.LD), (.L__movme_tmp.1), (.L__pc.4012.LD)
	.p2align 4
	.L__pc.4012.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4013
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4013: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4014
	
	.L__pc.4014: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4015
	
	.p2align 4
	.L__pc.4015: Dma_PatchDst (.L__pc.4015.ST), (.L__movme_cp.69), (.L__pc.4015.ST)
	.L__pc.4015.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4016
	
	.L__pc.4016: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4017
	
	.p2align 4
	.L__pc.4017: Dma_PatchDst (.L__pc.4017.ST), (.L__movme_cp.54), (.L__pc.4017.ST)
	.L__pc.4017.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4018
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.4018: Dma_PatchSrc (.L__pc.4018.LD), (.L__movme_cp.30), (.L__pc.4018.LD)
	.p2align 4
	.L__pc.4018.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4019
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4019: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4020
	.L__pc.4020: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4021
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.4021: Dma_PatchSrc (.L__pc.4021.LD), (.L__movme_cp.31), (.L__pc.4021.LD)
	.p2align 4
	.L__pc.4021.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4022
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4022: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4023
	.L__pc.4023: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4024
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4024: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4025: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4026: Dma_PatchSrc (.L__pc.4026.LD), (.L__movme_tmp.1), (.L__pc.4026.LD)
	.p2align 4
	.L__pc.4026.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4027
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4027: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4028
	.L__pc.4028: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4029
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4029: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4030: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4031: Dma_PatchSrc (.L__pc.4031.LD), (.L__movme_tmp.1), (.L__pc.4031.LD)
	.p2align 4
	.L__pc.4031.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4032
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4032: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4033
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4033: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4034: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4035: Dma_PatchSrc (.L__pc.4035.LD), (.L__movme_tmp.1), (.L__pc.4035.LD)
	.p2align 4
	.L__pc.4035.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4036
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4036: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4037
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4037: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4038: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4039: Dma_PatchSrc (.L__pc.4039.LD), (.L__movme_tmp.1), (.L__pc.4039.LD)
	.p2align 4
	.L__pc.4039.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4040
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4040: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4041
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4041: Dma_PatchSrc (.L__pc.4041.LD), (.L__movme_cp.24), (.L__pc.4041.LD)
	.p2align 4
	.L__pc.4041.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4042
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4042: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4043
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4043: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4044: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4045: Dma_PatchSrc (.L__pc.4045.LD), (.L__movme_tmp.1), (.L__pc.4045.LD)
	.p2align 4
	.L__pc.4045.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4046
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4046: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4047
	
	.L__pc.4047: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4048
	
	.p2align 4
	.L__pc.4048: Dma_PatchDst (.L__pc.4048.ST), (.L__movme_cp.70), (.L__pc.4048.ST)
	.L__pc.4048.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4049
	
	.L__pc.4049: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4050
	
	.p2align 4
	.L__pc.4050: Dma_PatchDst (.L__pc.4050.ST), (.L__movme_cp.54), (.L__pc.4050.ST)
	.L__pc.4050.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4051
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4051: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4052
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4052: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4053
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4053: Dma_PatchSrc (.L__pc.4053.LD), (.L__movme_cp.24), (.L__pc.4053.LD)
	.p2align 4
	.L__pc.4053.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4054
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4054: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4055
	.L__pc.4055: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4056
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.4056: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4057: Dma_PatchSrc (.L__pc.4057.LD), (.L__movme_tmp.1), (.L__pc.4057.LD)
	.p2align 4
	.L__pc.4057.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4058
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4058: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4059
	.L__pc.4059: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4060
	
	.L__pc.4060: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4061
	
	.p2align 4
	.L__pc.4061: Dma_PatchDst (.L__pc.4061.ST), (.L__movme_cp.72), (.L__pc.4061.ST)
	.L__pc.4061.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4062
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.4062: Dma_PatchSrc (.L__pc.4062.LD), (.L__movme_cp.72), (.L__pc.4062.LD)
	.p2align 4
	.L__pc.4062.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4063
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4063: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4064
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4064: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4065: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4066: Dma_PatchSrc (.L__pc.4066.LD), (.L__movme_tmp.1), (.L__pc.4066.LD)
	.p2align 4
	.L__pc.4066.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4067
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4067: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4068
	
	.L__pc.4068: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4069
	
	.p2align 4
	.L__pc.4069: Dma_PatchDst (.L__pc.4069.ST), (.L__movme_cp.74), (.L__pc.4069.ST)
	.L__pc.4069.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4070
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4070: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4071: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4072: Dma_PatchSrc (.L__pc.4072.LD), (.L__movme_tmp.1), (.L__pc.4072.LD)
	.p2align 4
	.L__pc.4072.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4073
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4073: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4074
	
	.L__pc.4074: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4075
	
	.p2align 4
	.L__pc.4075: Dma_PatchDst (.L__pc.4075.ST), (.L__movme_cp.76), (.L__pc.4075.ST)
	.L__pc.4075.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4076
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.4076: Dma_PatchSrc (.L__pc.4076.LD), (.L__movme_cp.74), (.L__pc.4076.LD)
	.p2align 4
	.L__pc.4076.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4077
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4077: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4078
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.4078: Dma_PatchSrc (.L__pc.4078.LD), ((.L__movme.reg.eax+0)), (.L__pc.4078.LD)
	.p2align 4
	.L__pc.4078.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4079
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4079: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4080
	
	.L__pc.4080: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4081
	
	.p2align 4
	.L__pc.4081: Dma_PatchDst (.L__pc.4081.ST), (.L__movme_cp.77), (.L__pc.4081.ST)
	.L__pc.4081.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4082
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.4082: Dma_PatchSrc (.L__pc.4082.LD), (.L__movme_cp.77), (.L__pc.4082.LD)
	.p2align 4
	.L__pc.4082.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4083
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4083: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4084
	
	.L__pc.4084: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4085
	
	.p2align 4
	.L__pc.4085: Dma_PatchDst (.L__pc.4085.ST), (.L__movme_cp.21), (.L__pc.4085.ST)
	.L__pc.4085.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4086
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.4086: Dma_PatchSrc (.L__pc.4086.LD), (.L__movme_cp.58), (.L__pc.4086.LD)
	.p2align 4
	.L__pc.4086.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4087
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4087: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4088
	
	.L__pc.4088: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4089
	
	.p2align 4
	.L__pc.4089: Dma_PatchDst (.L__pc.4089.ST), (.L__movme_cp.22), (.L__pc.4089.ST)
	.L__pc.4089.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4090
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4090: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4091
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4091: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4092
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4092: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4093
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4093: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4094
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.4094: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.4095
	
	.p2align 4
	.L__pc.4095: Dma_PatchDst (.L__pc.4095.ST), (.L__movme_cp.24), (.L__pc.4095.ST)
	.L__pc.4095.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4096
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.4096: Dma_PatchSrc (.L__pc.4096.LD), (.L__movme_cp.25), (.L__pc.4096.LD)
	.p2align 4
	.L__pc.4096.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4097
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4097: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4098
	.L__pc.4098: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4099
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.4099: Dma_PatchSrc (.L__pc.4099.LD), (.L__movme_cp.26), (.L__pc.4099.LD)
	.p2align 4
	.L__pc.4099.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4100
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4100: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4101
	.L__pc.4101: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4102
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4102: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4103: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4104: Dma_PatchSrc (.L__pc.4104.LD), (.L__movme_tmp.1), (.L__pc.4104.LD)
	.p2align 4
	.L__pc.4104.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4105
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4105: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4106
	.L__pc.4106: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4107
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4107: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4108: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4109: Dma_PatchSrc (.L__pc.4109.LD), (.L__movme_tmp.1), (.L__pc.4109.LD)
	.p2align 4
	.L__pc.4109.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4110
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4110: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4111
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4111: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4112: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4113: Dma_PatchSrc (.L__pc.4113.LD), (.L__movme_tmp.1), (.L__pc.4113.LD)
	.p2align 4
	.L__pc.4113.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4114
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4114: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4115
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4115: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4116: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4117: Dma_PatchSrc (.L__pc.4117.LD), (.L__movme_tmp.1), (.L__pc.4117.LD)
	.p2align 4
	.L__pc.4117.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4118
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4118: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4119
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4119: Dma_PatchSrc (.L__pc.4119.LD), (.L__movme_cp.24), (.L__pc.4119.LD)
	.p2align 4
	.L__pc.4119.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4120
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4120: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4121
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4121: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4122: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4123: Dma_PatchSrc (.L__pc.4123.LD), (.L__movme_tmp.1), (.L__pc.4123.LD)
	.p2align 4
	.L__pc.4123.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4124
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4124: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4125
	
	.L__pc.4125: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4126
	
	.p2align 4
	.L__pc.4126: Dma_PatchDst (.L__pc.4126.ST), (.L__movme_cp.78), (.L__pc.4126.ST)
	.L__pc.4126.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4127
	
	.L__pc.4127: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4128
	
	.p2align 4
	.L__pc.4128: Dma_PatchDst (.L__pc.4128.ST), (.L__movme_cp.54), (.L__pc.4128.ST)
	.L__pc.4128.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4129
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.4129: Dma_PatchSrc (.L__pc.4129.LD), (.L__movme_cp.30), (.L__pc.4129.LD)
	.p2align 4
	.L__pc.4129.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4130
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4130: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4131
	.L__pc.4131: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4132
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.4132: Dma_PatchSrc (.L__pc.4132.LD), (.L__movme_cp.31), (.L__pc.4132.LD)
	.p2align 4
	.L__pc.4132.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4133
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4133: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4134
	.L__pc.4134: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4135
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4135: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4136: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4137: Dma_PatchSrc (.L__pc.4137.LD), (.L__movme_tmp.1), (.L__pc.4137.LD)
	.p2align 4
	.L__pc.4137.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4138
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4138: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4139
	.L__pc.4139: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4140
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4140: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4141: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4142: Dma_PatchSrc (.L__pc.4142.LD), (.L__movme_tmp.1), (.L__pc.4142.LD)
	.p2align 4
	.L__pc.4142.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4143
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4143: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4144
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4144: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4145: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4146: Dma_PatchSrc (.L__pc.4146.LD), (.L__movme_tmp.1), (.L__pc.4146.LD)
	.p2align 4
	.L__pc.4146.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4147
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4147: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4148
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4148: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4149: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4150: Dma_PatchSrc (.L__pc.4150.LD), (.L__movme_tmp.1), (.L__pc.4150.LD)
	.p2align 4
	.L__pc.4150.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4151
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4151: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4152
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4152: Dma_PatchSrc (.L__pc.4152.LD), (.L__movme_cp.24), (.L__pc.4152.LD)
	.p2align 4
	.L__pc.4152.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4153
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4153: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4154
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4154: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4155: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4156: Dma_PatchSrc (.L__pc.4156.LD), (.L__movme_tmp.1), (.L__pc.4156.LD)
	.p2align 4
	.L__pc.4156.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4157
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4157: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4158
	
	.L__pc.4158: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4159
	
	.p2align 4
	.L__pc.4159: Dma_PatchDst (.L__pc.4159.ST), (.L__movme_cp.79), (.L__pc.4159.ST)
	.L__pc.4159.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4160
	
	.L__pc.4160: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4161
	
	.p2align 4
	.L__pc.4161: Dma_PatchDst (.L__pc.4161.ST), (.L__movme_cp.54), (.L__pc.4161.ST)
	.L__pc.4161.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4162
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.4162: Dma_PatchSrc (.L__pc.4162.LD), (.L__movme_cp.74), (.L__pc.4162.LD)
	.p2align 4
	.L__pc.4162.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4163
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4163: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4164
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.4164: Dma_PatchSrc (.L__pc.4164.LD), (.L__movme_cp.77), (.L__pc.4164.LD)
	.p2align 4
	.L__pc.4164.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4165
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4165: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4166
	
	.L__pc.4166: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4167
	
	.p2align 4
	.L__pc.4167: Dma_PatchDst (.L__pc.4167.ST), ((.L__movme.reg.eax+0)), (.L__pc.4167.ST)
	.L__pc.4167.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4168
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.4168: Dma_PatchSrc (.L__pc.4168.LD), (.L__movme_cp.76), (.L__pc.4168.LD)
	.p2align 4
	.L__pc.4168.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4169
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4169: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4170
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.4170: Dma_PatchSrc (.L__pc.4170.LD), ((.L__movme.reg.eax+0)), (.L__pc.4170.LD)
	.p2align 4
	.L__pc.4170.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4171
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4171: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4172
	
	.L__pc.4172: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4173
	
	.p2align 4
	.L__pc.4173: Dma_PatchDst (.L__pc.4173.ST), (.L__movme_cp.80), (.L__pc.4173.ST)
	.L__pc.4173.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4174
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4174: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4175
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4175: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4176
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.4176: Dma_PatchSrc (.L__pc.4176.LD), (.L__movme_cp.81), (.L__pc.4176.LD)
	.p2align 4
	.L__pc.4176.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4177
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4177: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4178
	.L__pc.4178: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4179
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.94 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.4179: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4180: Dma_PatchSrc (.L__pc.4180.LD), (.L__movme_tmp.1), (.L__pc.4180.LD)
	.p2align 4
	.L__pc.4180.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4181
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4181: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4182
	.L__pc.4182: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4183
	
	.L__pc.4183: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4184
	
	.p2align 4
	.L__pc.4184: Dma_PatchDst (.L__pc.4184.ST), (.L__movme_cp.81), (.L__pc.4184.ST)
	.L__pc.4184.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4185
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.4185: Dma_PatchSrc (.L__pc.4185.LD), (.L__movme_cp.76), (.L__pc.4185.LD)
	.p2align 4
	.L__pc.4185.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4186
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4186: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4187
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.4187: Dma_PatchSrc (.L__pc.4187.LD), (.L__movme_cp.80), (.L__pc.4187.LD)
	.p2align 4
	.L__pc.4187.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4188
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4188: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4189
	
	.L__pc.4189: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4190
	
	.p2align 4
	.L__pc.4190: Dma_PatchDst (.L__pc.4190.ST), ((.L__movme.reg.eax+0)), (.L__pc.4190.ST)
	.L__pc.4190.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4191
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4191: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4192
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4192: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4193
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.4193: Dma_PatchSrc (.L__pc.4193.LD), (.L__movme_cp.61), (.L__pc.4193.LD)
	.p2align 4
	.L__pc.4193.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4194
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4194: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4195
	.L__pc.4195: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4196
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4196: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.95 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4197: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4198: Dma_PatchSrc (.L__pc.4198.LD), (.L__movme_tmp.1), (.L__pc.4198.LD)
	.p2align 4
	.L__pc.4198.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4199
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4199: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4200
	
	.L__pc.4200: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4201
	
	.p2align 4
	.L__pc.4201: Dma_PatchDst (.L__pc.4201.ST), (.L__movme_cp.24), (.L__pc.4201.ST)
	.L__pc.4201.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4202
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4202: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4203
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4203: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4204
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4204: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4205
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4205: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4206
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.4206: Dma_PatchSrc (.L__pc.4206.LD), (.L__movme_cp.63), (.L__pc.4206.LD)
	.p2align 4
	.L__pc.4206.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4207
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4207: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4208
	.L__pc.4208: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4209
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4209: Dma_PatchSrc (.L__pc.4209.LD), (.L__movme_cp.24), (.L__pc.4209.LD)
	.p2align 4
	.L__pc.4209.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4210
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4210: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4211
	.L__pc.4211: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4212
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4212: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4213: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4214: Dma_PatchSrc (.L__pc.4214.LD), (.L__movme_tmp.1), (.L__pc.4214.LD)
	.p2align 4
	.L__pc.4214.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4215
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4215: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4216
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4216: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4217: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4218: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4219: Dma_PatchSrc (.L__pc.4219.LD), (.L__movme_tmp.1), (.L__pc.4219.LD)
	.p2align 4
	.L__pc.4219.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4220
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4220: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4221
	
	.L__pc.4221: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4222
	
	.p2align 4
	.L__pc.4222: Dma_PatchDst (.L__pc.4222.ST), (.L__movme_cp.63), (.L__pc.4222.ST)
	.L__pc.4222.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4223
	
	.L__pc.4223: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4224
	
	.p2align 4
	.L__pc.4224: Dma_PatchDst (.L__pc.4224.ST), (.L__movme_cp.24), (.L__pc.4224.ST)
	.L__pc.4224.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4225
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4225: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4226
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4226: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4227
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4227: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4228
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4228: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4229
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.4229: Dma_PatchSrc (.L__pc.4229.LD), (.L__movme_cp.66), (.L__pc.4229.LD)
	.p2align 4
	.L__pc.4229.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4230
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4230: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4231
	.L__pc.4231: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4232
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4232: Dma_PatchSrc (.L__pc.4232.LD), (.L__movme_cp.24), (.L__pc.4232.LD)
	.p2align 4
	.L__pc.4232.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4233
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4233: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4234
	.L__pc.4234: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4235
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4235: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4236: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4237: Dma_PatchSrc (.L__pc.4237.LD), (.L__movme_tmp.1), (.L__pc.4237.LD)
	.p2align 4
	.L__pc.4237.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4238
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4238: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4239
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4239: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4240: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4241: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4242: Dma_PatchSrc (.L__pc.4242.LD), (.L__movme_tmp.1), (.L__pc.4242.LD)
	.p2align 4
	.L__pc.4242.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4243
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4243: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4244
	
	.L__pc.4244: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4245
	
	.p2align 4
	.L__pc.4245: Dma_PatchDst (.L__pc.4245.ST), (.L__movme_cp.66), (.L__pc.4245.ST)
	.L__pc.4245.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4246
	
	.L__pc.4246: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4247
	
	.p2align 4
	.L__pc.4247: Dma_PatchDst (.L__pc.4247.ST), (.L__movme_cp.24), (.L__pc.4247.ST)
	.L__pc.4247.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4248
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4248: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4249
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4249: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4250
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4250: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4251
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4251: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4252
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.4252: Dma_PatchSrc (.L__pc.4252.LD), (.L__movme_cp.67), (.L__pc.4252.LD)
	.p2align 4
	.L__pc.4252.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4253
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4253: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4254
	.L__pc.4254: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4255
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4255: Dma_PatchSrc (.L__pc.4255.LD), (.L__movme_cp.24), (.L__pc.4255.LD)
	.p2align 4
	.L__pc.4255.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4256
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4256: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4257
	.L__pc.4257: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4258
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4258: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4259: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4260: Dma_PatchSrc (.L__pc.4260.LD), (.L__movme_tmp.1), (.L__pc.4260.LD)
	.p2align 4
	.L__pc.4260.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4261
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4261: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4262
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4262: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4263: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4264: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4265: Dma_PatchSrc (.L__pc.4265.LD), (.L__movme_tmp.1), (.L__pc.4265.LD)
	.p2align 4
	.L__pc.4265.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4266
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4266: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4267
	
	.L__pc.4267: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4268
	
	.p2align 4
	.L__pc.4268: Dma_PatchDst (.L__pc.4268.ST), (.L__movme_cp.67), (.L__pc.4268.ST)
	.L__pc.4268.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4269
	
	.L__pc.4269: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4270
	
	.p2align 4
	.L__pc.4270: Dma_PatchDst (.L__pc.4270.ST), (.L__movme_cp.24), (.L__pc.4270.ST)
	.L__pc.4270.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4271
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4271: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4272
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4272: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4273
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4273: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4274
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4274: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4275
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.4275: Dma_PatchSrc (.L__pc.4275.LD), (.L__movme_cp.68), (.L__pc.4275.LD)
	.p2align 4
	.L__pc.4275.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4276
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4276: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4277
	.L__pc.4277: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4278
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4278: Dma_PatchSrc (.L__pc.4278.LD), (.L__movme_cp.24), (.L__pc.4278.LD)
	.p2align 4
	.L__pc.4278.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4279
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4279: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4280
	.L__pc.4280: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4281
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4281: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4282: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4283: Dma_PatchSrc (.L__pc.4283.LD), (.L__movme_tmp.1), (.L__pc.4283.LD)
	.p2align 4
	.L__pc.4283.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4284
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4284: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4285
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4285: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4286: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4287: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4288: Dma_PatchSrc (.L__pc.4288.LD), (.L__movme_tmp.1), (.L__pc.4288.LD)
	.p2align 4
	.L__pc.4288.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4289
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4289: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4290
	
	.L__pc.4290: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4291
	
	.p2align 4
	.L__pc.4291: Dma_PatchDst (.L__pc.4291.ST), (.L__movme_cp.68), (.L__pc.4291.ST)
	.L__pc.4291.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4292
	
	.L__pc.4292: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4293
	
	.p2align 4
	.L__pc.4293: Dma_PatchDst (.L__pc.4293.ST), (.L__movme_cp.24), (.L__pc.4293.ST)
	.L__pc.4293.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4294
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4294: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4295
	
	.p2align 4
	.L__pc.4295: Dma_PatchDst (.L__pc.4295.ST), (.L__movme_cp.24), (.L__pc.4295.ST)
	.L__pc.4295.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4296
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.4296: Dma_PatchSrc (.L__pc.4296.LD), (.L__movme_cp.60), (.L__pc.4296.LD)
	.p2align 4
	.L__pc.4296.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4297
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4297: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4298
	
	.L__pc.4298: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4299
	
	.p2align 4
	.L__pc.4299: Dma_PatchDst (.L__pc.4299.ST), (.L__movme_cp.21), (.L__pc.4299.ST)
	.L__pc.4299.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4300
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.4300: Dma_PatchSrc (.L__pc.4300.LD), (.L__movme_cp.58), (.L__pc.4300.LD)
	.p2align 4
	.L__pc.4300.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4301
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4301: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4302
	
	.L__pc.4302: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4303
	
	.p2align 4
	.L__pc.4303: Dma_PatchDst (.L__pc.4303.ST), (.L__movme_cp.22), (.L__pc.4303.ST)
	.L__pc.4303.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4304
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4304: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4305
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4305: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4306
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4306: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4307
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4307: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4308
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.4308: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.4309
	
	.p2align 4
	.L__pc.4309: Dma_PatchDst (.L__pc.4309.ST), (.L__movme_cp.24), (.L__pc.4309.ST)
	.L__pc.4309.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4310
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.4310: Dma_PatchSrc (.L__pc.4310.LD), (.L__movme_cp.25), (.L__pc.4310.LD)
	.p2align 4
	.L__pc.4310.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4311
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4311: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4312
	.L__pc.4312: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4313
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.4313: Dma_PatchSrc (.L__pc.4313.LD), (.L__movme_cp.26), (.L__pc.4313.LD)
	.p2align 4
	.L__pc.4313.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4314
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4314: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4315
	.L__pc.4315: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4316
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4316: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4317: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4318: Dma_PatchSrc (.L__pc.4318.LD), (.L__movme_tmp.1), (.L__pc.4318.LD)
	.p2align 4
	.L__pc.4318.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4319
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4319: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4320
	.L__pc.4320: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4321
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4321: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4322: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4323: Dma_PatchSrc (.L__pc.4323.LD), (.L__movme_tmp.1), (.L__pc.4323.LD)
	.p2align 4
	.L__pc.4323.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4324
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4324: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4325
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4325: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4326: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4327: Dma_PatchSrc (.L__pc.4327.LD), (.L__movme_tmp.1), (.L__pc.4327.LD)
	.p2align 4
	.L__pc.4327.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4328
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4328: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4329
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4329: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4330: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4331: Dma_PatchSrc (.L__pc.4331.LD), (.L__movme_tmp.1), (.L__pc.4331.LD)
	.p2align 4
	.L__pc.4331.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4332
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4332: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4333
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4333: Dma_PatchSrc (.L__pc.4333.LD), (.L__movme_cp.24), (.L__pc.4333.LD)
	.p2align 4
	.L__pc.4333.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4334
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4334: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4335
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4335: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4336: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4337: Dma_PatchSrc (.L__pc.4337.LD), (.L__movme_tmp.1), (.L__pc.4337.LD)
	.p2align 4
	.L__pc.4337.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4338
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4338: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4339
	
	.L__pc.4339: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4340
	
	.p2align 4
	.L__pc.4340: Dma_PatchDst (.L__pc.4340.ST), (.L__movme_cp.69), (.L__pc.4340.ST)
	.L__pc.4340.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4341
	
	.L__pc.4341: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4342
	
	.p2align 4
	.L__pc.4342: Dma_PatchDst (.L__pc.4342.ST), (.L__movme_cp.54), (.L__pc.4342.ST)
	.L__pc.4342.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4343
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.4343: Dma_PatchSrc (.L__pc.4343.LD), (.L__movme_cp.30), (.L__pc.4343.LD)
	.p2align 4
	.L__pc.4343.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4344
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4344: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4345
	.L__pc.4345: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4346
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.4346: Dma_PatchSrc (.L__pc.4346.LD), (.L__movme_cp.31), (.L__pc.4346.LD)
	.p2align 4
	.L__pc.4346.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4347
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4347: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4348
	.L__pc.4348: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4349
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4349: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4350: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4351: Dma_PatchSrc (.L__pc.4351.LD), (.L__movme_tmp.1), (.L__pc.4351.LD)
	.p2align 4
	.L__pc.4351.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4352
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4352: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4353
	.L__pc.4353: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4354
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4354: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4355: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4356: Dma_PatchSrc (.L__pc.4356.LD), (.L__movme_tmp.1), (.L__pc.4356.LD)
	.p2align 4
	.L__pc.4356.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4357
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4357: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4358
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4358: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4359: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4360: Dma_PatchSrc (.L__pc.4360.LD), (.L__movme_tmp.1), (.L__pc.4360.LD)
	.p2align 4
	.L__pc.4360.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4361
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4361: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4362
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4362: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4363: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4364: Dma_PatchSrc (.L__pc.4364.LD), (.L__movme_tmp.1), (.L__pc.4364.LD)
	.p2align 4
	.L__pc.4364.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4365
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4365: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4366
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4366: Dma_PatchSrc (.L__pc.4366.LD), (.L__movme_cp.24), (.L__pc.4366.LD)
	.p2align 4
	.L__pc.4366.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4367
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4367: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4368
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4368: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4369: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4370: Dma_PatchSrc (.L__pc.4370.LD), (.L__movme_tmp.1), (.L__pc.4370.LD)
	.p2align 4
	.L__pc.4370.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4371
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4371: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4372
	
	.L__pc.4372: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4373
	
	.p2align 4
	.L__pc.4373: Dma_PatchDst (.L__pc.4373.ST), (.L__movme_cp.70), (.L__pc.4373.ST)
	.L__pc.4373.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4374
	
	.L__pc.4374: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4375
	
	.p2align 4
	.L__pc.4375: Dma_PatchDst (.L__pc.4375.ST), (.L__movme_cp.54), (.L__pc.4375.ST)
	.L__pc.4375.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4376
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4376: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4377
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4377: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4378
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4378: Dma_PatchSrc (.L__pc.4378.LD), (.L__movme_cp.24), (.L__pc.4378.LD)
	.p2align 4
	.L__pc.4378.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4379
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4379: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4380
	.L__pc.4380: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4381
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.4381: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4382: Dma_PatchSrc (.L__pc.4382.LD), (.L__movme_tmp.1), (.L__pc.4382.LD)
	.p2align 4
	.L__pc.4382.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4383
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4383: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4384
	.L__pc.4384: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4385
	
	.L__pc.4385: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4386
	
	.p2align 4
	.L__pc.4386: Dma_PatchDst (.L__pc.4386.ST), (.L__movme_cp.72), (.L__pc.4386.ST)
	.L__pc.4386.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4387
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.4387: Dma_PatchSrc (.L__pc.4387.LD), (.L__movme_cp.72), (.L__pc.4387.LD)
	.p2align 4
	.L__pc.4387.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4388
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4388: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4389
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4389: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4390: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4391: Dma_PatchSrc (.L__pc.4391.LD), (.L__movme_tmp.1), (.L__pc.4391.LD)
	.p2align 4
	.L__pc.4391.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4392
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4392: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4393
	
	.L__pc.4393: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4394
	
	.p2align 4
	.L__pc.4394: Dma_PatchDst (.L__pc.4394.ST), (.L__movme_cp.74), (.L__pc.4394.ST)
	.L__pc.4394.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4395
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4395: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4396: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4397: Dma_PatchSrc (.L__pc.4397.LD), (.L__movme_tmp.1), (.L__pc.4397.LD)
	.p2align 4
	.L__pc.4397.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4398
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4398: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4399
	
	.L__pc.4399: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4400
	
	.p2align 4
	.L__pc.4400: Dma_PatchDst (.L__pc.4400.ST), (.L__movme_cp.76), (.L__pc.4400.ST)
	.L__pc.4400.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4401
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.4401: Dma_PatchSrc (.L__pc.4401.LD), (.L__movme_cp.74), (.L__pc.4401.LD)
	.p2align 4
	.L__pc.4401.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4402
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4402: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4403
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.4403: Dma_PatchSrc (.L__pc.4403.LD), ((.L__movme.reg.eax+0)), (.L__pc.4403.LD)
	.p2align 4
	.L__pc.4403.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4404
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4404: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4405
	
	.L__pc.4405: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4406
	
	.p2align 4
	.L__pc.4406: Dma_PatchDst (.L__pc.4406.ST), (.L__movme_cp.77), (.L__pc.4406.ST)
	.L__pc.4406.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4407
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.4407: Dma_PatchSrc (.L__pc.4407.LD), (.L__movme_cp.77), (.L__pc.4407.LD)
	.p2align 4
	.L__pc.4407.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4408
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4408: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4409
	
	.L__pc.4409: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4410
	
	.p2align 4
	.L__pc.4410: Dma_PatchDst (.L__pc.4410.ST), (.L__movme_cp.21), (.L__pc.4410.ST)
	.L__pc.4410.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4411
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.4411: Dma_PatchSrc (.L__pc.4411.LD), (.L__movme_cp.58), (.L__pc.4411.LD)
	.p2align 4
	.L__pc.4411.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4412
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4412: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4413
	
	.L__pc.4413: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4414
	
	.p2align 4
	.L__pc.4414: Dma_PatchDst (.L__pc.4414.ST), (.L__movme_cp.22), (.L__pc.4414.ST)
	.L__pc.4414.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4415
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4415: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4416
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4416: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4417
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4417: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4418
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4418: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4419
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.4419: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.4420
	
	.p2align 4
	.L__pc.4420: Dma_PatchDst (.L__pc.4420.ST), (.L__movme_cp.24), (.L__pc.4420.ST)
	.L__pc.4420.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4421
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.4421: Dma_PatchSrc (.L__pc.4421.LD), (.L__movme_cp.25), (.L__pc.4421.LD)
	.p2align 4
	.L__pc.4421.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4422
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4422: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4423
	.L__pc.4423: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4424
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.4424: Dma_PatchSrc (.L__pc.4424.LD), (.L__movme_cp.26), (.L__pc.4424.LD)
	.p2align 4
	.L__pc.4424.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4425
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4425: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4426
	.L__pc.4426: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4427
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4427: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4428: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4429: Dma_PatchSrc (.L__pc.4429.LD), (.L__movme_tmp.1), (.L__pc.4429.LD)
	.p2align 4
	.L__pc.4429.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4430
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4430: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4431
	.L__pc.4431: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4432
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4432: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4433: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4434: Dma_PatchSrc (.L__pc.4434.LD), (.L__movme_tmp.1), (.L__pc.4434.LD)
	.p2align 4
	.L__pc.4434.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4435
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4435: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4436
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4436: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4437: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4438: Dma_PatchSrc (.L__pc.4438.LD), (.L__movme_tmp.1), (.L__pc.4438.LD)
	.p2align 4
	.L__pc.4438.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4439
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4439: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4440
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4440: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4441: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4442: Dma_PatchSrc (.L__pc.4442.LD), (.L__movme_tmp.1), (.L__pc.4442.LD)
	.p2align 4
	.L__pc.4442.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4443
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4443: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4444
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4444: Dma_PatchSrc (.L__pc.4444.LD), (.L__movme_cp.24), (.L__pc.4444.LD)
	.p2align 4
	.L__pc.4444.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4445
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4445: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4446
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4446: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4447: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4448: Dma_PatchSrc (.L__pc.4448.LD), (.L__movme_tmp.1), (.L__pc.4448.LD)
	.p2align 4
	.L__pc.4448.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4449
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4449: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4450
	
	.L__pc.4450: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4451
	
	.p2align 4
	.L__pc.4451: Dma_PatchDst (.L__pc.4451.ST), (.L__movme_cp.78), (.L__pc.4451.ST)
	.L__pc.4451.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4452
	
	.L__pc.4452: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4453
	
	.p2align 4
	.L__pc.4453: Dma_PatchDst (.L__pc.4453.ST), (.L__movme_cp.54), (.L__pc.4453.ST)
	.L__pc.4453.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4454
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.4454: Dma_PatchSrc (.L__pc.4454.LD), (.L__movme_cp.30), (.L__pc.4454.LD)
	.p2align 4
	.L__pc.4454.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4455
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4455: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4456
	.L__pc.4456: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4457
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.4457: Dma_PatchSrc (.L__pc.4457.LD), (.L__movme_cp.31), (.L__pc.4457.LD)
	.p2align 4
	.L__pc.4457.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4458
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4458: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4459
	.L__pc.4459: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4460
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4460: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4461: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4462: Dma_PatchSrc (.L__pc.4462.LD), (.L__movme_tmp.1), (.L__pc.4462.LD)
	.p2align 4
	.L__pc.4462.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4463
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4463: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4464
	.L__pc.4464: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4465
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4465: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4466: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4467: Dma_PatchSrc (.L__pc.4467.LD), (.L__movme_tmp.1), (.L__pc.4467.LD)
	.p2align 4
	.L__pc.4467.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4468
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4468: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4469
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4469: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4470: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4471: Dma_PatchSrc (.L__pc.4471.LD), (.L__movme_tmp.1), (.L__pc.4471.LD)
	.p2align 4
	.L__pc.4471.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4472
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4472: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4473
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4473: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4474: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4475: Dma_PatchSrc (.L__pc.4475.LD), (.L__movme_tmp.1), (.L__pc.4475.LD)
	.p2align 4
	.L__pc.4475.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4476
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4476: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4477
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4477: Dma_PatchSrc (.L__pc.4477.LD), (.L__movme_cp.24), (.L__pc.4477.LD)
	.p2align 4
	.L__pc.4477.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4478
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4478: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4479
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4479: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4480: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4481: Dma_PatchSrc (.L__pc.4481.LD), (.L__movme_tmp.1), (.L__pc.4481.LD)
	.p2align 4
	.L__pc.4481.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4482
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4482: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4483
	
	.L__pc.4483: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4484
	
	.p2align 4
	.L__pc.4484: Dma_PatchDst (.L__pc.4484.ST), (.L__movme_cp.79), (.L__pc.4484.ST)
	.L__pc.4484.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4485
	
	.L__pc.4485: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4486
	
	.p2align 4
	.L__pc.4486: Dma_PatchDst (.L__pc.4486.ST), (.L__movme_cp.54), (.L__pc.4486.ST)
	.L__pc.4486.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4487
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.4487: Dma_PatchSrc (.L__pc.4487.LD), (.L__movme_cp.74), (.L__pc.4487.LD)
	.p2align 4
	.L__pc.4487.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4488
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4488: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4489
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.4489: Dma_PatchSrc (.L__pc.4489.LD), (.L__movme_cp.77), (.L__pc.4489.LD)
	.p2align 4
	.L__pc.4489.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4490
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4490: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4491
	
	.L__pc.4491: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4492
	
	.p2align 4
	.L__pc.4492: Dma_PatchDst (.L__pc.4492.ST), ((.L__movme.reg.eax+0)), (.L__pc.4492.ST)
	.L__pc.4492.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4493
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.4493: Dma_PatchSrc (.L__pc.4493.LD), (.L__movme_cp.76), (.L__pc.4493.LD)
	.p2align 4
	.L__pc.4493.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4494
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4494: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4495
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.4495: Dma_PatchSrc (.L__pc.4495.LD), ((.L__movme.reg.eax+0)), (.L__pc.4495.LD)
	.p2align 4
	.L__pc.4495.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4496
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4496: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4497
	
	.L__pc.4497: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4498
	
	.p2align 4
	.L__pc.4498: Dma_PatchDst (.L__pc.4498.ST), (.L__movme_cp.80), (.L__pc.4498.ST)
	.L__pc.4498.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4499
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4499: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4500
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4500: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4501
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.4501: Dma_PatchSrc (.L__pc.4501.LD), (.L__movme_cp.81), (.L__pc.4501.LD)
	.p2align 4
	.L__pc.4501.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4502
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4502: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4503
	.L__pc.4503: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4504
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.96 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.4504: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4505: Dma_PatchSrc (.L__pc.4505.LD), (.L__movme_tmp.1), (.L__pc.4505.LD)
	.p2align 4
	.L__pc.4505.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4506
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4506: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4507
	.L__pc.4507: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4508
	
	.L__pc.4508: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4509
	
	.p2align 4
	.L__pc.4509: Dma_PatchDst (.L__pc.4509.ST), (.L__movme_cp.81), (.L__pc.4509.ST)
	.L__pc.4509.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4510
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.4510: Dma_PatchSrc (.L__pc.4510.LD), (.L__movme_cp.76), (.L__pc.4510.LD)
	.p2align 4
	.L__pc.4510.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4511
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4511: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4512
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.4512: Dma_PatchSrc (.L__pc.4512.LD), (.L__movme_cp.80), (.L__pc.4512.LD)
	.p2align 4
	.L__pc.4512.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4513
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4513: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4514
	
	.L__pc.4514: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4515
	
	.p2align 4
	.L__pc.4515: Dma_PatchDst (.L__pc.4515.ST), ((.L__movme.reg.eax+0)), (.L__pc.4515.ST)
	.L__pc.4515.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4516
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4516: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4517
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4517: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4518
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.4518: Dma_PatchSrc (.L__pc.4518.LD), (.L__movme_cp.97), (.L__pc.4518.LD)
	.p2align 4
	.L__pc.4518.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4519
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4519: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4520
	.L__pc.4520: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4521
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4521: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.62 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4522: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4523: Dma_PatchSrc (.L__pc.4523.LD), (.L__movme_tmp.1), (.L__pc.4523.LD)
	.p2align 4
	.L__pc.4523.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4524
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4524: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4525
	
	.L__pc.4525: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4526
	
	.p2align 4
	.L__pc.4526: Dma_PatchDst (.L__pc.4526.ST), (.L__movme_cp.24), (.L__pc.4526.ST)
	.L__pc.4526.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4527
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4527: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4528
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4528: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4529
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4529: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4530
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4530: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4531
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.4531: Dma_PatchSrc (.L__pc.4531.LD), (.L__movme_cp.63), (.L__pc.4531.LD)
	.p2align 4
	.L__pc.4531.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4532
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4532: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4533
	.L__pc.4533: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4534
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4534: Dma_PatchSrc (.L__pc.4534.LD), (.L__movme_cp.24), (.L__pc.4534.LD)
	.p2align 4
	.L__pc.4534.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4535
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4535: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4536
	.L__pc.4536: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4537
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4537: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4538: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4539: Dma_PatchSrc (.L__pc.4539.LD), (.L__movme_tmp.1), (.L__pc.4539.LD)
	.p2align 4
	.L__pc.4539.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4540
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4540: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4541
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4541: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4542: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4543: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4544: Dma_PatchSrc (.L__pc.4544.LD), (.L__movme_tmp.1), (.L__pc.4544.LD)
	.p2align 4
	.L__pc.4544.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4545
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4545: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4546
	
	.L__pc.4546: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4547
	
	.p2align 4
	.L__pc.4547: Dma_PatchDst (.L__pc.4547.ST), (.L__movme_cp.63), (.L__pc.4547.ST)
	.L__pc.4547.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4548
	
	.L__pc.4548: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4549
	
	.p2align 4
	.L__pc.4549: Dma_PatchDst (.L__pc.4549.ST), (.L__movme_cp.24), (.L__pc.4549.ST)
	.L__pc.4549.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4550
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4550: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4551
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4551: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4552
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4552: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4553
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4553: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4554
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.4554: Dma_PatchSrc (.L__pc.4554.LD), (.L__movme_cp.66), (.L__pc.4554.LD)
	.p2align 4
	.L__pc.4554.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4555
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4555: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4556
	.L__pc.4556: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4557
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4557: Dma_PatchSrc (.L__pc.4557.LD), (.L__movme_cp.24), (.L__pc.4557.LD)
	.p2align 4
	.L__pc.4557.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4558
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4558: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4559
	.L__pc.4559: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4560
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4560: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4561: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4562: Dma_PatchSrc (.L__pc.4562.LD), (.L__movme_tmp.1), (.L__pc.4562.LD)
	.p2align 4
	.L__pc.4562.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4563
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4563: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4564
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4564: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4565: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4566: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4567: Dma_PatchSrc (.L__pc.4567.LD), (.L__movme_tmp.1), (.L__pc.4567.LD)
	.p2align 4
	.L__pc.4567.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4568
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4568: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4569
	
	.L__pc.4569: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4570
	
	.p2align 4
	.L__pc.4570: Dma_PatchDst (.L__pc.4570.ST), (.L__movme_cp.66), (.L__pc.4570.ST)
	.L__pc.4570.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4571
	
	.L__pc.4571: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4572
	
	.p2align 4
	.L__pc.4572: Dma_PatchDst (.L__pc.4572.ST), (.L__movme_cp.24), (.L__pc.4572.ST)
	.L__pc.4572.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4573
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4573: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4574
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4574: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4575
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4575: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4576
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4576: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4577
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.4577: Dma_PatchSrc (.L__pc.4577.LD), (.L__movme_cp.67), (.L__pc.4577.LD)
	.p2align 4
	.L__pc.4577.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4578
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4578: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4579
	.L__pc.4579: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4580
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4580: Dma_PatchSrc (.L__pc.4580.LD), (.L__movme_cp.24), (.L__pc.4580.LD)
	.p2align 4
	.L__pc.4580.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4581
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4581: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4582
	.L__pc.4582: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4583
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4583: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4584: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4585: Dma_PatchSrc (.L__pc.4585.LD), (.L__movme_tmp.1), (.L__pc.4585.LD)
	.p2align 4
	.L__pc.4585.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4586
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4586: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4587
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4587: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4588: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4589: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4590: Dma_PatchSrc (.L__pc.4590.LD), (.L__movme_tmp.1), (.L__pc.4590.LD)
	.p2align 4
	.L__pc.4590.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4591
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4591: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4592
	
	.L__pc.4592: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4593
	
	.p2align 4
	.L__pc.4593: Dma_PatchDst (.L__pc.4593.ST), (.L__movme_cp.67), (.L__pc.4593.ST)
	.L__pc.4593.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4594
	
	.L__pc.4594: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4595
	
	.p2align 4
	.L__pc.4595: Dma_PatchDst (.L__pc.4595.ST), (.L__movme_cp.24), (.L__pc.4595.ST)
	.L__pc.4595.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4596
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4596: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4597
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4597: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4598
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4598: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4599
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4599: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4600
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.4600: Dma_PatchSrc (.L__pc.4600.LD), (.L__movme_cp.68), (.L__pc.4600.LD)
	.p2align 4
	.L__pc.4600.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4601
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4601: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4602
	.L__pc.4602: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4603
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4603: Dma_PatchSrc (.L__pc.4603.LD), (.L__movme_cp.24), (.L__pc.4603.LD)
	.p2align 4
	.L__pc.4603.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4604
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4604: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4605
	.L__pc.4605: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4606
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4606: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4607: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4608: Dma_PatchSrc (.L__pc.4608.LD), (.L__movme_tmp.1), (.L__pc.4608.LD)
	.p2align 4
	.L__pc.4608.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4609
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4609: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4610
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4610: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4611: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4612: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4613: Dma_PatchSrc (.L__pc.4613.LD), (.L__movme_tmp.1), (.L__pc.4613.LD)
	.p2align 4
	.L__pc.4613.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4614
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4614: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4615
	
	.L__pc.4615: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4616
	
	.p2align 4
	.L__pc.4616: Dma_PatchDst (.L__pc.4616.ST), (.L__movme_cp.68), (.L__pc.4616.ST)
	.L__pc.4616.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4617
	
	.L__pc.4617: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4618
	
	.p2align 4
	.L__pc.4618: Dma_PatchDst (.L__pc.4618.ST), (.L__movme_cp.24), (.L__pc.4618.ST)
	.L__pc.4618.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4619
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4619: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4620
	
	.p2align 4
	.L__pc.4620: Dma_PatchDst (.L__pc.4620.ST), (.L__movme_cp.24), (.L__pc.4620.ST)
	.L__pc.4620.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4621
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.4621: Dma_PatchSrc (.L__pc.4621.LD), (.L__movme_cp.60), (.L__pc.4621.LD)
	.p2align 4
	.L__pc.4621.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4622
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4622: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4623
	
	.L__pc.4623: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4624
	
	.p2align 4
	.L__pc.4624: Dma_PatchDst (.L__pc.4624.ST), (.L__movme_cp.21), (.L__pc.4624.ST)
	.L__pc.4624.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4625
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.4625: Dma_PatchSrc (.L__pc.4625.LD), (.L__movme_cp.58), (.L__pc.4625.LD)
	.p2align 4
	.L__pc.4625.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4626
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4626: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4627
	
	.L__pc.4627: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4628
	
	.p2align 4
	.L__pc.4628: Dma_PatchDst (.L__pc.4628.ST), (.L__movme_cp.22), (.L__pc.4628.ST)
	.L__pc.4628.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4629
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4629: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4630
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4630: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4631
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4631: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4632
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4632: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4633
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.4633: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.4634
	
	.p2align 4
	.L__pc.4634: Dma_PatchDst (.L__pc.4634.ST), (.L__movme_cp.24), (.L__pc.4634.ST)
	.L__pc.4634.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4635
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.4635: Dma_PatchSrc (.L__pc.4635.LD), (.L__movme_cp.25), (.L__pc.4635.LD)
	.p2align 4
	.L__pc.4635.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4636
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4636: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4637
	.L__pc.4637: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4638
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.4638: Dma_PatchSrc (.L__pc.4638.LD), (.L__movme_cp.26), (.L__pc.4638.LD)
	.p2align 4
	.L__pc.4638.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4639
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4639: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4640
	.L__pc.4640: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4641
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4641: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4642: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4643: Dma_PatchSrc (.L__pc.4643.LD), (.L__movme_tmp.1), (.L__pc.4643.LD)
	.p2align 4
	.L__pc.4643.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4644
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4644: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4645
	.L__pc.4645: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4646
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4646: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4647: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4648: Dma_PatchSrc (.L__pc.4648.LD), (.L__movme_tmp.1), (.L__pc.4648.LD)
	.p2align 4
	.L__pc.4648.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4649
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4649: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4650
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4650: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4651: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4652: Dma_PatchSrc (.L__pc.4652.LD), (.L__movme_tmp.1), (.L__pc.4652.LD)
	.p2align 4
	.L__pc.4652.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4653
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4653: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4654
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4654: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4655: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4656: Dma_PatchSrc (.L__pc.4656.LD), (.L__movme_tmp.1), (.L__pc.4656.LD)
	.p2align 4
	.L__pc.4656.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4657
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4657: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4658
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4658: Dma_PatchSrc (.L__pc.4658.LD), (.L__movme_cp.24), (.L__pc.4658.LD)
	.p2align 4
	.L__pc.4658.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4659
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4659: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4660
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4660: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4661: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4662: Dma_PatchSrc (.L__pc.4662.LD), (.L__movme_tmp.1), (.L__pc.4662.LD)
	.p2align 4
	.L__pc.4662.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4663
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4663: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4664
	
	.L__pc.4664: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4665
	
	.p2align 4
	.L__pc.4665: Dma_PatchDst (.L__pc.4665.ST), (.L__movme_cp.69), (.L__pc.4665.ST)
	.L__pc.4665.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4666
	
	.L__pc.4666: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4667
	
	.p2align 4
	.L__pc.4667: Dma_PatchDst (.L__pc.4667.ST), (.L__movme_cp.54), (.L__pc.4667.ST)
	.L__pc.4667.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4668
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.4668: Dma_PatchSrc (.L__pc.4668.LD), (.L__movme_cp.30), (.L__pc.4668.LD)
	.p2align 4
	.L__pc.4668.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4669
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4669: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4670
	.L__pc.4670: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4671
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.4671: Dma_PatchSrc (.L__pc.4671.LD), (.L__movme_cp.31), (.L__pc.4671.LD)
	.p2align 4
	.L__pc.4671.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4672
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4672: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4673
	.L__pc.4673: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4674
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4674: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4675: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4676: Dma_PatchSrc (.L__pc.4676.LD), (.L__movme_tmp.1), (.L__pc.4676.LD)
	.p2align 4
	.L__pc.4676.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4677
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4677: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4678
	.L__pc.4678: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4679
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4679: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4680: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4681: Dma_PatchSrc (.L__pc.4681.LD), (.L__movme_tmp.1), (.L__pc.4681.LD)
	.p2align 4
	.L__pc.4681.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4682
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4682: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4683
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4683: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4684: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4685: Dma_PatchSrc (.L__pc.4685.LD), (.L__movme_tmp.1), (.L__pc.4685.LD)
	.p2align 4
	.L__pc.4685.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4686
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4686: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4687
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4687: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4688: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4689: Dma_PatchSrc (.L__pc.4689.LD), (.L__movme_tmp.1), (.L__pc.4689.LD)
	.p2align 4
	.L__pc.4689.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4690
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4690: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4691
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4691: Dma_PatchSrc (.L__pc.4691.LD), (.L__movme_cp.24), (.L__pc.4691.LD)
	.p2align 4
	.L__pc.4691.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4692
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4692: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4693
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4693: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4694: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4695: Dma_PatchSrc (.L__pc.4695.LD), (.L__movme_tmp.1), (.L__pc.4695.LD)
	.p2align 4
	.L__pc.4695.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4696
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4696: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4697
	
	.L__pc.4697: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4698
	
	.p2align 4
	.L__pc.4698: Dma_PatchDst (.L__pc.4698.ST), (.L__movme_cp.70), (.L__pc.4698.ST)
	.L__pc.4698.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4699
	
	.L__pc.4699: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4700
	
	.p2align 4
	.L__pc.4700: Dma_PatchDst (.L__pc.4700.ST), (.L__movme_cp.54), (.L__pc.4700.ST)
	.L__pc.4700.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4701
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4701: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4702
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4702: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4703
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4703: Dma_PatchSrc (.L__pc.4703.LD), (.L__movme_cp.24), (.L__pc.4703.LD)
	.p2align 4
	.L__pc.4703.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4704
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4704: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4705
	.L__pc.4705: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4706
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.4706: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4707: Dma_PatchSrc (.L__pc.4707.LD), (.L__movme_tmp.1), (.L__pc.4707.LD)
	.p2align 4
	.L__pc.4707.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4708
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4708: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4709
	.L__pc.4709: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4710
	
	.L__pc.4710: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4711
	
	.p2align 4
	.L__pc.4711: Dma_PatchDst (.L__pc.4711.ST), (.L__movme_cp.72), (.L__pc.4711.ST)
	.L__pc.4711.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4712
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.4712: Dma_PatchSrc (.L__pc.4712.LD), (.L__movme_cp.72), (.L__pc.4712.LD)
	.p2align 4
	.L__pc.4712.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4713
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4713: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4714
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4714: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4715: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4716: Dma_PatchSrc (.L__pc.4716.LD), (.L__movme_tmp.1), (.L__pc.4716.LD)
	.p2align 4
	.L__pc.4716.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4717
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4717: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4718
	
	.L__pc.4718: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4719
	
	.p2align 4
	.L__pc.4719: Dma_PatchDst (.L__pc.4719.ST), (.L__movme_cp.74), (.L__pc.4719.ST)
	.L__pc.4719.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4720
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4720: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4721: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4722: Dma_PatchSrc (.L__pc.4722.LD), (.L__movme_tmp.1), (.L__pc.4722.LD)
	.p2align 4
	.L__pc.4722.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4723
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4723: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4724
	
	.L__pc.4724: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4725
	
	.p2align 4
	.L__pc.4725: Dma_PatchDst (.L__pc.4725.ST), (.L__movme_cp.76), (.L__pc.4725.ST)
	.L__pc.4725.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4726
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.4726: Dma_PatchSrc (.L__pc.4726.LD), (.L__movme_cp.74), (.L__pc.4726.LD)
	.p2align 4
	.L__pc.4726.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4727
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4727: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4728
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.4728: Dma_PatchSrc (.L__pc.4728.LD), ((.L__movme.reg.eax+0)), (.L__pc.4728.LD)
	.p2align 4
	.L__pc.4728.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4729
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4729: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4730
	
	.L__pc.4730: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4731
	
	.p2align 4
	.L__pc.4731: Dma_PatchDst (.L__pc.4731.ST), (.L__movme_cp.77), (.L__pc.4731.ST)
	.L__pc.4731.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4732
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.4732: Dma_PatchSrc (.L__pc.4732.LD), (.L__movme_cp.77), (.L__pc.4732.LD)
	.p2align 4
	.L__pc.4732.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4733
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4733: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4734
	
	.L__pc.4734: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4735
	
	.p2align 4
	.L__pc.4735: Dma_PatchDst (.L__pc.4735.ST), (.L__movme_cp.21), (.L__pc.4735.ST)
	.L__pc.4735.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4736
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.4736: Dma_PatchSrc (.L__pc.4736.LD), (.L__movme_cp.58), (.L__pc.4736.LD)
	.p2align 4
	.L__pc.4736.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4737
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4737: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4738
	
	.L__pc.4738: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4739
	
	.p2align 4
	.L__pc.4739: Dma_PatchDst (.L__pc.4739.ST), (.L__movme_cp.22), (.L__pc.4739.ST)
	.L__pc.4739.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4740
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4740: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4741
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4741: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4742
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4742: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4743
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4743: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4744
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.4744: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.4745
	
	.p2align 4
	.L__pc.4745: Dma_PatchDst (.L__pc.4745.ST), (.L__movme_cp.24), (.L__pc.4745.ST)
	.L__pc.4745.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4746
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.4746: Dma_PatchSrc (.L__pc.4746.LD), (.L__movme_cp.25), (.L__pc.4746.LD)
	.p2align 4
	.L__pc.4746.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4747
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4747: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4748
	.L__pc.4748: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4749
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.4749: Dma_PatchSrc (.L__pc.4749.LD), (.L__movme_cp.26), (.L__pc.4749.LD)
	.p2align 4
	.L__pc.4749.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4750
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4750: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4751
	.L__pc.4751: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4752
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4752: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4753: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4754: Dma_PatchSrc (.L__pc.4754.LD), (.L__movme_tmp.1), (.L__pc.4754.LD)
	.p2align 4
	.L__pc.4754.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4755
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4755: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4756
	.L__pc.4756: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4757
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4757: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4758: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4759: Dma_PatchSrc (.L__pc.4759.LD), (.L__movme_tmp.1), (.L__pc.4759.LD)
	.p2align 4
	.L__pc.4759.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4760
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4760: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4761
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4761: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4762: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4763: Dma_PatchSrc (.L__pc.4763.LD), (.L__movme_tmp.1), (.L__pc.4763.LD)
	.p2align 4
	.L__pc.4763.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4764
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4764: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4765
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4765: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4766: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4767: Dma_PatchSrc (.L__pc.4767.LD), (.L__movme_tmp.1), (.L__pc.4767.LD)
	.p2align 4
	.L__pc.4767.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4768
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4768: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4769
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4769: Dma_PatchSrc (.L__pc.4769.LD), (.L__movme_cp.24), (.L__pc.4769.LD)
	.p2align 4
	.L__pc.4769.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4770
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4770: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4771
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4771: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4772: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4773: Dma_PatchSrc (.L__pc.4773.LD), (.L__movme_tmp.1), (.L__pc.4773.LD)
	.p2align 4
	.L__pc.4773.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4774
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4774: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4775
	
	.L__pc.4775: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4776
	
	.p2align 4
	.L__pc.4776: Dma_PatchDst (.L__pc.4776.ST), (.L__movme_cp.78), (.L__pc.4776.ST)
	.L__pc.4776.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4777
	
	.L__pc.4777: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4778
	
	.p2align 4
	.L__pc.4778: Dma_PatchDst (.L__pc.4778.ST), (.L__movme_cp.54), (.L__pc.4778.ST)
	.L__pc.4778.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4779
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.4779: Dma_PatchSrc (.L__pc.4779.LD), (.L__movme_cp.30), (.L__pc.4779.LD)
	.p2align 4
	.L__pc.4779.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4780
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4780: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4781
	.L__pc.4781: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4782
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.4782: Dma_PatchSrc (.L__pc.4782.LD), (.L__movme_cp.31), (.L__pc.4782.LD)
	.p2align 4
	.L__pc.4782.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4783
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4783: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4784
	.L__pc.4784: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4785
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4785: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4786: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4787: Dma_PatchSrc (.L__pc.4787.LD), (.L__movme_tmp.1), (.L__pc.4787.LD)
	.p2align 4
	.L__pc.4787.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4788
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4788: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4789
	.L__pc.4789: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4790
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4790: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4791: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4792: Dma_PatchSrc (.L__pc.4792.LD), (.L__movme_tmp.1), (.L__pc.4792.LD)
	.p2align 4
	.L__pc.4792.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4793
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4793: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4794
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4794: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4795: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4796: Dma_PatchSrc (.L__pc.4796.LD), (.L__movme_tmp.1), (.L__pc.4796.LD)
	.p2align 4
	.L__pc.4796.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4797
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4797: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4798
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4798: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4799: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4800: Dma_PatchSrc (.L__pc.4800.LD), (.L__movme_tmp.1), (.L__pc.4800.LD)
	.p2align 4
	.L__pc.4800.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4801
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4801: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4802
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4802: Dma_PatchSrc (.L__pc.4802.LD), (.L__movme_cp.24), (.L__pc.4802.LD)
	.p2align 4
	.L__pc.4802.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4803
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4803: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4804
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4804: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4805: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4806: Dma_PatchSrc (.L__pc.4806.LD), (.L__movme_tmp.1), (.L__pc.4806.LD)
	.p2align 4
	.L__pc.4806.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4807
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4807: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4808
	
	.L__pc.4808: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4809
	
	.p2align 4
	.L__pc.4809: Dma_PatchDst (.L__pc.4809.ST), (.L__movme_cp.79), (.L__pc.4809.ST)
	.L__pc.4809.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4810
	
	.L__pc.4810: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4811
	
	.p2align 4
	.L__pc.4811: Dma_PatchDst (.L__pc.4811.ST), (.L__movme_cp.54), (.L__pc.4811.ST)
	.L__pc.4811.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4812
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.4812: Dma_PatchSrc (.L__pc.4812.LD), (.L__movme_cp.74), (.L__pc.4812.LD)
	.p2align 4
	.L__pc.4812.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4813
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4813: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4814
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.4814: Dma_PatchSrc (.L__pc.4814.LD), (.L__movme_cp.77), (.L__pc.4814.LD)
	.p2align 4
	.L__pc.4814.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4815
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4815: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4816
	
	.L__pc.4816: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4817
	
	.p2align 4
	.L__pc.4817: Dma_PatchDst (.L__pc.4817.ST), ((.L__movme.reg.eax+0)), (.L__pc.4817.ST)
	.L__pc.4817.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4818
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.4818: Dma_PatchSrc (.L__pc.4818.LD), (.L__movme_cp.76), (.L__pc.4818.LD)
	.p2align 4
	.L__pc.4818.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4819
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4819: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4820
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.4820: Dma_PatchSrc (.L__pc.4820.LD), ((.L__movme.reg.eax+0)), (.L__pc.4820.LD)
	.p2align 4
	.L__pc.4820.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4821
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4821: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4822
	
	.L__pc.4822: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4823
	
	.p2align 4
	.L__pc.4823: Dma_PatchDst (.L__pc.4823.ST), (.L__movme_cp.80), (.L__pc.4823.ST)
	.L__pc.4823.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4824
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4824: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4825
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4825: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4826
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.4826: Dma_PatchSrc (.L__pc.4826.LD), (.L__movme_cp.98), (.L__pc.4826.LD)
	.p2align 4
	.L__pc.4826.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4827
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4827: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4828
	.L__pc.4828: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4829
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.82 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.4829: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4830: Dma_PatchSrc (.L__pc.4830.LD), (.L__movme_tmp.1), (.L__pc.4830.LD)
	.p2align 4
	.L__pc.4830.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4831
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4831: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4832
	.L__pc.4832: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4833
	
	.L__pc.4833: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4834
	
	.p2align 4
	.L__pc.4834: Dma_PatchDst (.L__pc.4834.ST), (.L__movme_cp.98), (.L__pc.4834.ST)
	.L__pc.4834.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4835
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.4835: Dma_PatchSrc (.L__pc.4835.LD), (.L__movme_cp.76), (.L__pc.4835.LD)
	.p2align 4
	.L__pc.4835.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4836
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4836: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4837
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.4837: Dma_PatchSrc (.L__pc.4837.LD), (.L__movme_cp.80), (.L__pc.4837.LD)
	.p2align 4
	.L__pc.4837.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4838
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4838: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4839
	
	.L__pc.4839: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4840
	
	.p2align 4
	.L__pc.4840: Dma_PatchDst (.L__pc.4840.ST), ((.L__movme.reg.eax+0)), (.L__pc.4840.ST)
	.L__pc.4840.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4841
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4841: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4842
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4842: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4843
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.4843: Dma_PatchSrc (.L__pc.4843.LD), (.L__movme_cp.97), (.L__pc.4843.LD)
	.p2align 4
	.L__pc.4843.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4844
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4844: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4845
	.L__pc.4845: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4846
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4846: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.83 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4847: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4848: Dma_PatchSrc (.L__pc.4848.LD), (.L__movme_tmp.1), (.L__pc.4848.LD)
	.p2align 4
	.L__pc.4848.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4849
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4849: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4850
	
	.L__pc.4850: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4851
	
	.p2align 4
	.L__pc.4851: Dma_PatchDst (.L__pc.4851.ST), (.L__movme_cp.24), (.L__pc.4851.ST)
	.L__pc.4851.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4852
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4852: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4853
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4853: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4854
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4854: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4855
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4855: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4856
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.4856: Dma_PatchSrc (.L__pc.4856.LD), (.L__movme_cp.63), (.L__pc.4856.LD)
	.p2align 4
	.L__pc.4856.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4857
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4857: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4858
	.L__pc.4858: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4859
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4859: Dma_PatchSrc (.L__pc.4859.LD), (.L__movme_cp.24), (.L__pc.4859.LD)
	.p2align 4
	.L__pc.4859.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4860
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4860: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4861
	.L__pc.4861: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4862
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4862: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4863: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4864: Dma_PatchSrc (.L__pc.4864.LD), (.L__movme_tmp.1), (.L__pc.4864.LD)
	.p2align 4
	.L__pc.4864.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4865
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4865: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4866
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4866: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4867: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4868: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4869: Dma_PatchSrc (.L__pc.4869.LD), (.L__movme_tmp.1), (.L__pc.4869.LD)
	.p2align 4
	.L__pc.4869.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4870
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4870: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4871
	
	.L__pc.4871: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4872
	
	.p2align 4
	.L__pc.4872: Dma_PatchDst (.L__pc.4872.ST), (.L__movme_cp.63), (.L__pc.4872.ST)
	.L__pc.4872.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4873
	
	.L__pc.4873: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4874
	
	.p2align 4
	.L__pc.4874: Dma_PatchDst (.L__pc.4874.ST), (.L__movme_cp.24), (.L__pc.4874.ST)
	.L__pc.4874.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4875
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4875: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4876
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4876: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4877
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4877: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4878
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4878: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4879
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.4879: Dma_PatchSrc (.L__pc.4879.LD), (.L__movme_cp.66), (.L__pc.4879.LD)
	.p2align 4
	.L__pc.4879.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4880
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4880: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4881
	.L__pc.4881: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4882
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4882: Dma_PatchSrc (.L__pc.4882.LD), (.L__movme_cp.24), (.L__pc.4882.LD)
	.p2align 4
	.L__pc.4882.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4883
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4883: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4884
	.L__pc.4884: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4885
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4885: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4886: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4887: Dma_PatchSrc (.L__pc.4887.LD), (.L__movme_tmp.1), (.L__pc.4887.LD)
	.p2align 4
	.L__pc.4887.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4888
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4888: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4889
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4889: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4890: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4891: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4892: Dma_PatchSrc (.L__pc.4892.LD), (.L__movme_tmp.1), (.L__pc.4892.LD)
	.p2align 4
	.L__pc.4892.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4893
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4893: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4894
	
	.L__pc.4894: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4895
	
	.p2align 4
	.L__pc.4895: Dma_PatchDst (.L__pc.4895.ST), (.L__movme_cp.66), (.L__pc.4895.ST)
	.L__pc.4895.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4896
	
	.L__pc.4896: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4897
	
	.p2align 4
	.L__pc.4897: Dma_PatchDst (.L__pc.4897.ST), (.L__movme_cp.24), (.L__pc.4897.ST)
	.L__pc.4897.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4898
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4898: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4899
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4899: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4900
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4900: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4901
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4901: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4902
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.4902: Dma_PatchSrc (.L__pc.4902.LD), (.L__movme_cp.67), (.L__pc.4902.LD)
	.p2align 4
	.L__pc.4902.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4903
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4903: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4904
	.L__pc.4904: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4905
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4905: Dma_PatchSrc (.L__pc.4905.LD), (.L__movme_cp.24), (.L__pc.4905.LD)
	.p2align 4
	.L__pc.4905.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4906
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4906: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4907
	.L__pc.4907: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4908
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4908: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4909: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4910: Dma_PatchSrc (.L__pc.4910.LD), (.L__movme_tmp.1), (.L__pc.4910.LD)
	.p2align 4
	.L__pc.4910.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4911
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4911: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4912
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4912: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4913: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4914: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4915: Dma_PatchSrc (.L__pc.4915.LD), (.L__movme_tmp.1), (.L__pc.4915.LD)
	.p2align 4
	.L__pc.4915.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4916
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4916: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4917
	
	.L__pc.4917: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4918
	
	.p2align 4
	.L__pc.4918: Dma_PatchDst (.L__pc.4918.ST), (.L__movme_cp.67), (.L__pc.4918.ST)
	.L__pc.4918.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4919
	
	.L__pc.4919: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4920
	
	.p2align 4
	.L__pc.4920: Dma_PatchDst (.L__pc.4920.ST), (.L__movme_cp.24), (.L__pc.4920.ST)
	.L__pc.4920.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4921
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4921: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4922
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4922: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4923
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4923: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4924
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4924: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4925
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.4925: Dma_PatchSrc (.L__pc.4925.LD), (.L__movme_cp.68), (.L__pc.4925.LD)
	.p2align 4
	.L__pc.4925.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4926
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4926: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.4927
	.L__pc.4927: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.4928
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4928: Dma_PatchSrc (.L__pc.4928.LD), (.L__movme_cp.24), (.L__pc.4928.LD)
	.p2align 4
	.L__pc.4928.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4929
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4929: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.4930
	.L__pc.4930: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.4931
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4931: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4932: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4933: Dma_PatchSrc (.L__pc.4933.LD), (.L__movme_tmp.1), (.L__pc.4933.LD)
	.p2align 4
	.L__pc.4933.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4934
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4934: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4935
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.4935: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.4936: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.4937: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4938: Dma_PatchSrc (.L__pc.4938.LD), (.L__movme_tmp.1), (.L__pc.4938.LD)
	.p2align 4
	.L__pc.4938.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4939
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4939: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4940
	
	.L__pc.4940: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.4941
	
	.p2align 4
	.L__pc.4941: Dma_PatchDst (.L__pc.4941.ST), (.L__movme_cp.68), (.L__pc.4941.ST)
	.L__pc.4941.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4942
	
	.L__pc.4942: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.4943
	
	.p2align 4
	.L__pc.4943: Dma_PatchDst (.L__pc.4943.ST), (.L__movme_cp.24), (.L__pc.4943.ST)
	.L__pc.4943.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4944
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4944: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4945
	
	.p2align 4
	.L__pc.4945: Dma_PatchDst (.L__pc.4945.ST), (.L__movme_cp.24), (.L__pc.4945.ST)
	.L__pc.4945.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4946
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.4946: Dma_PatchSrc (.L__pc.4946.LD), (.L__movme_cp.60), (.L__pc.4946.LD)
	.p2align 4
	.L__pc.4946.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4947
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4947: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4948
	
	.L__pc.4948: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4949
	
	.p2align 4
	.L__pc.4949: Dma_PatchDst (.L__pc.4949.ST), (.L__movme_cp.21), (.L__pc.4949.ST)
	.L__pc.4949.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4950
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.4950: Dma_PatchSrc (.L__pc.4950.LD), (.L__movme_cp.58), (.L__pc.4950.LD)
	.p2align 4
	.L__pc.4950.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4951
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4951: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4952
	
	.L__pc.4952: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.4953
	
	.p2align 4
	.L__pc.4953: Dma_PatchDst (.L__pc.4953.ST), (.L__movme_cp.22), (.L__pc.4953.ST)
	.L__pc.4953.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4954
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4954: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4955
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4955: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.4956
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.4956: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.4957
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4957: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4958
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.4958: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.4959
	
	.p2align 4
	.L__pc.4959: Dma_PatchDst (.L__pc.4959.ST), (.L__movme_cp.24), (.L__pc.4959.ST)
	.L__pc.4959.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4960
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.4960: Dma_PatchSrc (.L__pc.4960.LD), (.L__movme_cp.25), (.L__pc.4960.LD)
	.p2align 4
	.L__pc.4960.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4961
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4961: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4962
	.L__pc.4962: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4963
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.4963: Dma_PatchSrc (.L__pc.4963.LD), (.L__movme_cp.26), (.L__pc.4963.LD)
	.p2align 4
	.L__pc.4963.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4964
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4964: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4965
	.L__pc.4965: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4966
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4966: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4967: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4968: Dma_PatchSrc (.L__pc.4968.LD), (.L__movme_tmp.1), (.L__pc.4968.LD)
	.p2align 4
	.L__pc.4968.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4969
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4969: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4970
	.L__pc.4970: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4971
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.4971: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4972: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4973: Dma_PatchSrc (.L__pc.4973.LD), (.L__movme_tmp.1), (.L__pc.4973.LD)
	.p2align 4
	.L__pc.4973.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4974
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4974: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4975
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4975: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4976: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4977: Dma_PatchSrc (.L__pc.4977.LD), (.L__movme_tmp.1), (.L__pc.4977.LD)
	.p2align 4
	.L__pc.4977.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4978
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4978: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4979
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.4979: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4980: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4981: Dma_PatchSrc (.L__pc.4981.LD), (.L__movme_tmp.1), (.L__pc.4981.LD)
	.p2align 4
	.L__pc.4981.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4982
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4982: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4983
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.4983: Dma_PatchSrc (.L__pc.4983.LD), (.L__movme_cp.24), (.L__pc.4983.LD)
	.p2align 4
	.L__pc.4983.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4984
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4984: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.4985
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.4985: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.4986: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.4987: Dma_PatchSrc (.L__pc.4987.LD), (.L__movme_tmp.1), (.L__pc.4987.LD)
	.p2align 4
	.L__pc.4987.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4988
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.4988: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.4989
	
	.L__pc.4989: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.4990
	
	.p2align 4
	.L__pc.4990: Dma_PatchDst (.L__pc.4990.ST), (.L__movme_cp.69), (.L__pc.4990.ST)
	.L__pc.4990.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4991
	
	.L__pc.4991: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.4992
	
	.p2align 4
	.L__pc.4992: Dma_PatchDst (.L__pc.4992.ST), (.L__movme_cp.54), (.L__pc.4992.ST)
	.L__pc.4992.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.4993
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.4993: Dma_PatchSrc (.L__pc.4993.LD), (.L__movme_cp.30), (.L__pc.4993.LD)
	.p2align 4
	.L__pc.4993.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4994
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.4994: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.4995
	.L__pc.4995: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.4996
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.4996: Dma_PatchSrc (.L__pc.4996.LD), (.L__movme_cp.31), (.L__pc.4996.LD)
	.p2align 4
	.L__pc.4996.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.4997
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.4997: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.4998
	.L__pc.4998: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.4999
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.4999: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5000: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5001: Dma_PatchSrc (.L__pc.5001.LD), (.L__movme_tmp.1), (.L__pc.5001.LD)
	.p2align 4
	.L__pc.5001.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5002
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5002: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5003
	.L__pc.5003: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5004
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5004: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5005: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5006: Dma_PatchSrc (.L__pc.5006.LD), (.L__movme_tmp.1), (.L__pc.5006.LD)
	.p2align 4
	.L__pc.5006.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5007
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5007: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5008
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5008: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5009: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5010: Dma_PatchSrc (.L__pc.5010.LD), (.L__movme_tmp.1), (.L__pc.5010.LD)
	.p2align 4
	.L__pc.5010.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5011
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5011: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5012
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5012: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5013: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5014: Dma_PatchSrc (.L__pc.5014.LD), (.L__movme_tmp.1), (.L__pc.5014.LD)
	.p2align 4
	.L__pc.5014.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5015
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5015: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5016
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5016: Dma_PatchSrc (.L__pc.5016.LD), (.L__movme_cp.24), (.L__pc.5016.LD)
	.p2align 4
	.L__pc.5016.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5017
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5017: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5018
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5018: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5019: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5020: Dma_PatchSrc (.L__pc.5020.LD), (.L__movme_tmp.1), (.L__pc.5020.LD)
	.p2align 4
	.L__pc.5020.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5021
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5021: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5022
	
	.L__pc.5022: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5023
	
	.p2align 4
	.L__pc.5023: Dma_PatchDst (.L__pc.5023.ST), (.L__movme_cp.70), (.L__pc.5023.ST)
	.L__pc.5023.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5024
	
	.L__pc.5024: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5025
	
	.p2align 4
	.L__pc.5025: Dma_PatchDst (.L__pc.5025.ST), (.L__movme_cp.54), (.L__pc.5025.ST)
	.L__pc.5025.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5026
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5026: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5027
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5027: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5028
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5028: Dma_PatchSrc (.L__pc.5028.LD), (.L__movme_cp.24), (.L__pc.5028.LD)
	.p2align 4
	.L__pc.5028.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5029
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5029: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5030
	.L__pc.5030: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5031
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.5031: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5032: Dma_PatchSrc (.L__pc.5032.LD), (.L__movme_tmp.1), (.L__pc.5032.LD)
	.p2align 4
	.L__pc.5032.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5033
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5033: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5034
	.L__pc.5034: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5035
	
	.L__pc.5035: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5036
	
	.p2align 4
	.L__pc.5036: Dma_PatchDst (.L__pc.5036.ST), (.L__movme_cp.72), (.L__pc.5036.ST)
	.L__pc.5036.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5037
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.5037: Dma_PatchSrc (.L__pc.5037.LD), (.L__movme_cp.72), (.L__pc.5037.LD)
	.p2align 4
	.L__pc.5037.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5038
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5038: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5039
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5039: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5040: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5041: Dma_PatchSrc (.L__pc.5041.LD), (.L__movme_tmp.1), (.L__pc.5041.LD)
	.p2align 4
	.L__pc.5041.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5042
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5042: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5043
	
	.L__pc.5043: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5044
	
	.p2align 4
	.L__pc.5044: Dma_PatchDst (.L__pc.5044.ST), (.L__movme_cp.74), (.L__pc.5044.ST)
	.L__pc.5044.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5045
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5045: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5046: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5047: Dma_PatchSrc (.L__pc.5047.LD), (.L__movme_tmp.1), (.L__pc.5047.LD)
	.p2align 4
	.L__pc.5047.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5048
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5048: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5049
	
	.L__pc.5049: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5050
	
	.p2align 4
	.L__pc.5050: Dma_PatchDst (.L__pc.5050.ST), (.L__movme_cp.76), (.L__pc.5050.ST)
	.L__pc.5050.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5051
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.5051: Dma_PatchSrc (.L__pc.5051.LD), (.L__movme_cp.74), (.L__pc.5051.LD)
	.p2align 4
	.L__pc.5051.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5052
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5052: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5053
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.5053: Dma_PatchSrc (.L__pc.5053.LD), ((.L__movme.reg.eax+0)), (.L__pc.5053.LD)
	.p2align 4
	.L__pc.5053.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5054
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5054: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5055
	
	.L__pc.5055: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5056
	
	.p2align 4
	.L__pc.5056: Dma_PatchDst (.L__pc.5056.ST), (.L__movme_cp.77), (.L__pc.5056.ST)
	.L__pc.5056.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5057
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.5057: Dma_PatchSrc (.L__pc.5057.LD), (.L__movme_cp.77), (.L__pc.5057.LD)
	.p2align 4
	.L__pc.5057.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5058
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5058: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5059
	
	.L__pc.5059: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5060
	
	.p2align 4
	.L__pc.5060: Dma_PatchDst (.L__pc.5060.ST), (.L__movme_cp.21), (.L__pc.5060.ST)
	.L__pc.5060.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5061
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.5061: Dma_PatchSrc (.L__pc.5061.LD), (.L__movme_cp.58), (.L__pc.5061.LD)
	.p2align 4
	.L__pc.5061.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5062
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5062: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5063
	
	.L__pc.5063: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5064
	
	.p2align 4
	.L__pc.5064: Dma_PatchDst (.L__pc.5064.ST), (.L__movme_cp.22), (.L__pc.5064.ST)
	.L__pc.5064.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5065
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5065: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5066
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5066: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5067
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5067: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5068
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5068: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5069
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.5069: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.5070
	
	.p2align 4
	.L__pc.5070: Dma_PatchDst (.L__pc.5070.ST), (.L__movme_cp.24), (.L__pc.5070.ST)
	.L__pc.5070.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5071
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.5071: Dma_PatchSrc (.L__pc.5071.LD), (.L__movme_cp.25), (.L__pc.5071.LD)
	.p2align 4
	.L__pc.5071.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5072
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5072: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5073
	.L__pc.5073: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5074
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.5074: Dma_PatchSrc (.L__pc.5074.LD), (.L__movme_cp.26), (.L__pc.5074.LD)
	.p2align 4
	.L__pc.5074.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5075
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5075: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5076
	.L__pc.5076: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5077
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5077: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5078: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5079: Dma_PatchSrc (.L__pc.5079.LD), (.L__movme_tmp.1), (.L__pc.5079.LD)
	.p2align 4
	.L__pc.5079.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5080
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5080: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5081
	.L__pc.5081: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5082
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5082: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5083: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5084: Dma_PatchSrc (.L__pc.5084.LD), (.L__movme_tmp.1), (.L__pc.5084.LD)
	.p2align 4
	.L__pc.5084.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5085
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5085: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5086
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5086: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5087: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5088: Dma_PatchSrc (.L__pc.5088.LD), (.L__movme_tmp.1), (.L__pc.5088.LD)
	.p2align 4
	.L__pc.5088.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5089
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5089: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5090
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5090: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5091: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5092: Dma_PatchSrc (.L__pc.5092.LD), (.L__movme_tmp.1), (.L__pc.5092.LD)
	.p2align 4
	.L__pc.5092.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5093
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5093: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5094
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5094: Dma_PatchSrc (.L__pc.5094.LD), (.L__movme_cp.24), (.L__pc.5094.LD)
	.p2align 4
	.L__pc.5094.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5095
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5095: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5096
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5096: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5097: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5098: Dma_PatchSrc (.L__pc.5098.LD), (.L__movme_tmp.1), (.L__pc.5098.LD)
	.p2align 4
	.L__pc.5098.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5099
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5099: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5100
	
	.L__pc.5100: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5101
	
	.p2align 4
	.L__pc.5101: Dma_PatchDst (.L__pc.5101.ST), (.L__movme_cp.78), (.L__pc.5101.ST)
	.L__pc.5101.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5102
	
	.L__pc.5102: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5103
	
	.p2align 4
	.L__pc.5103: Dma_PatchDst (.L__pc.5103.ST), (.L__movme_cp.54), (.L__pc.5103.ST)
	.L__pc.5103.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5104
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.5104: Dma_PatchSrc (.L__pc.5104.LD), (.L__movme_cp.30), (.L__pc.5104.LD)
	.p2align 4
	.L__pc.5104.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5105
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5105: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5106
	.L__pc.5106: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5107
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.5107: Dma_PatchSrc (.L__pc.5107.LD), (.L__movme_cp.31), (.L__pc.5107.LD)
	.p2align 4
	.L__pc.5107.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5108
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5108: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5109
	.L__pc.5109: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5110
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5110: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5111: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5112: Dma_PatchSrc (.L__pc.5112.LD), (.L__movme_tmp.1), (.L__pc.5112.LD)
	.p2align 4
	.L__pc.5112.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5113
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5113: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5114
	.L__pc.5114: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5115
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5115: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5116: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5117: Dma_PatchSrc (.L__pc.5117.LD), (.L__movme_tmp.1), (.L__pc.5117.LD)
	.p2align 4
	.L__pc.5117.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5118
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5118: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5119
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5119: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5120: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5121: Dma_PatchSrc (.L__pc.5121.LD), (.L__movme_tmp.1), (.L__pc.5121.LD)
	.p2align 4
	.L__pc.5121.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5122
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5122: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5123
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5123: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5124: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5125: Dma_PatchSrc (.L__pc.5125.LD), (.L__movme_tmp.1), (.L__pc.5125.LD)
	.p2align 4
	.L__pc.5125.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5126
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5126: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5127
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5127: Dma_PatchSrc (.L__pc.5127.LD), (.L__movme_cp.24), (.L__pc.5127.LD)
	.p2align 4
	.L__pc.5127.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5128
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5128: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5129
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5129: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5130: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5131: Dma_PatchSrc (.L__pc.5131.LD), (.L__movme_tmp.1), (.L__pc.5131.LD)
	.p2align 4
	.L__pc.5131.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5132
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5132: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5133
	
	.L__pc.5133: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5134
	
	.p2align 4
	.L__pc.5134: Dma_PatchDst (.L__pc.5134.ST), (.L__movme_cp.79), (.L__pc.5134.ST)
	.L__pc.5134.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5135
	
	.L__pc.5135: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5136
	
	.p2align 4
	.L__pc.5136: Dma_PatchDst (.L__pc.5136.ST), (.L__movme_cp.54), (.L__pc.5136.ST)
	.L__pc.5136.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5137
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.5137: Dma_PatchSrc (.L__pc.5137.LD), (.L__movme_cp.74), (.L__pc.5137.LD)
	.p2align 4
	.L__pc.5137.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5138
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5138: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5139
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.5139: Dma_PatchSrc (.L__pc.5139.LD), (.L__movme_cp.77), (.L__pc.5139.LD)
	.p2align 4
	.L__pc.5139.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5140
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5140: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5141
	
	.L__pc.5141: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5142
	
	.p2align 4
	.L__pc.5142: Dma_PatchDst (.L__pc.5142.ST), ((.L__movme.reg.eax+0)), (.L__pc.5142.ST)
	.L__pc.5142.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5143
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.5143: Dma_PatchSrc (.L__pc.5143.LD), (.L__movme_cp.76), (.L__pc.5143.LD)
	.p2align 4
	.L__pc.5143.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5144
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5144: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5145
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.5145: Dma_PatchSrc (.L__pc.5145.LD), ((.L__movme.reg.eax+0)), (.L__pc.5145.LD)
	.p2align 4
	.L__pc.5145.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5146
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5146: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5147
	
	.L__pc.5147: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5148
	
	.p2align 4
	.L__pc.5148: Dma_PatchDst (.L__pc.5148.ST), (.L__movme_cp.80), (.L__pc.5148.ST)
	.L__pc.5148.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5149
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5149: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5150
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5150: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5151
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.5151: Dma_PatchSrc (.L__pc.5151.LD), (.L__movme_cp.98), (.L__pc.5151.LD)
	.p2align 4
	.L__pc.5151.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5152
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5152: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5153
	.L__pc.5153: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5154
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.84 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.5154: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5155: Dma_PatchSrc (.L__pc.5155.LD), (.L__movme_tmp.1), (.L__pc.5155.LD)
	.p2align 4
	.L__pc.5155.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5156
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5156: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5157
	.L__pc.5157: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5158
	
	.L__pc.5158: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5159
	
	.p2align 4
	.L__pc.5159: Dma_PatchDst (.L__pc.5159.ST), (.L__movme_cp.98), (.L__pc.5159.ST)
	.L__pc.5159.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5160
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.5160: Dma_PatchSrc (.L__pc.5160.LD), (.L__movme_cp.76), (.L__pc.5160.LD)
	.p2align 4
	.L__pc.5160.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5161
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5161: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5162
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.5162: Dma_PatchSrc (.L__pc.5162.LD), (.L__movme_cp.80), (.L__pc.5162.LD)
	.p2align 4
	.L__pc.5162.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5163
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5163: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5164
	
	.L__pc.5164: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5165
	
	.p2align 4
	.L__pc.5165: Dma_PatchDst (.L__pc.5165.ST), ((.L__movme.reg.eax+0)), (.L__pc.5165.ST)
	.L__pc.5165.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5166
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5166: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5167
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5167: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5168
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.5168: Dma_PatchSrc (.L__pc.5168.LD), (.L__movme_cp.97), (.L__pc.5168.LD)
	.p2align 4
	.L__pc.5168.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5169
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5169: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5170
	.L__pc.5170: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5171
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5171: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.85 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5172: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5173: Dma_PatchSrc (.L__pc.5173.LD), (.L__movme_tmp.1), (.L__pc.5173.LD)
	.p2align 4
	.L__pc.5173.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5174
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5174: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5175
	
	.L__pc.5175: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5176
	
	.p2align 4
	.L__pc.5176: Dma_PatchDst (.L__pc.5176.ST), (.L__movme_cp.24), (.L__pc.5176.ST)
	.L__pc.5176.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5177
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5177: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5178
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5178: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5179
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5179: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5180
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5180: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5181
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.5181: Dma_PatchSrc (.L__pc.5181.LD), (.L__movme_cp.63), (.L__pc.5181.LD)
	.p2align 4
	.L__pc.5181.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5182
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5182: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5183
	.L__pc.5183: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5184
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5184: Dma_PatchSrc (.L__pc.5184.LD), (.L__movme_cp.24), (.L__pc.5184.LD)
	.p2align 4
	.L__pc.5184.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5185
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5185: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5186
	.L__pc.5186: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5187
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5187: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5188: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5189: Dma_PatchSrc (.L__pc.5189.LD), (.L__movme_tmp.1), (.L__pc.5189.LD)
	.p2align 4
	.L__pc.5189.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5190
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5190: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5191
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5191: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5192: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5193: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5194: Dma_PatchSrc (.L__pc.5194.LD), (.L__movme_tmp.1), (.L__pc.5194.LD)
	.p2align 4
	.L__pc.5194.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5195
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5195: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5196
	
	.L__pc.5196: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5197
	
	.p2align 4
	.L__pc.5197: Dma_PatchDst (.L__pc.5197.ST), (.L__movme_cp.63), (.L__pc.5197.ST)
	.L__pc.5197.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5198
	
	.L__pc.5198: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5199
	
	.p2align 4
	.L__pc.5199: Dma_PatchDst (.L__pc.5199.ST), (.L__movme_cp.24), (.L__pc.5199.ST)
	.L__pc.5199.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5200
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5200: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5201
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5201: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5202
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5202: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5203
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5203: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5204
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.5204: Dma_PatchSrc (.L__pc.5204.LD), (.L__movme_cp.66), (.L__pc.5204.LD)
	.p2align 4
	.L__pc.5204.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5205
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5205: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5206
	.L__pc.5206: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5207
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5207: Dma_PatchSrc (.L__pc.5207.LD), (.L__movme_cp.24), (.L__pc.5207.LD)
	.p2align 4
	.L__pc.5207.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5208
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5208: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5209
	.L__pc.5209: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5210
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5210: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5211: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5212: Dma_PatchSrc (.L__pc.5212.LD), (.L__movme_tmp.1), (.L__pc.5212.LD)
	.p2align 4
	.L__pc.5212.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5213
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5213: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5214
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5214: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5215: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5216: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5217: Dma_PatchSrc (.L__pc.5217.LD), (.L__movme_tmp.1), (.L__pc.5217.LD)
	.p2align 4
	.L__pc.5217.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5218
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5218: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5219
	
	.L__pc.5219: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5220
	
	.p2align 4
	.L__pc.5220: Dma_PatchDst (.L__pc.5220.ST), (.L__movme_cp.66), (.L__pc.5220.ST)
	.L__pc.5220.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5221
	
	.L__pc.5221: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5222
	
	.p2align 4
	.L__pc.5222: Dma_PatchDst (.L__pc.5222.ST), (.L__movme_cp.24), (.L__pc.5222.ST)
	.L__pc.5222.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5223
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5223: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5224
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5224: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5225
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5225: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5226
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5226: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5227
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.5227: Dma_PatchSrc (.L__pc.5227.LD), (.L__movme_cp.67), (.L__pc.5227.LD)
	.p2align 4
	.L__pc.5227.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5228
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5228: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5229
	.L__pc.5229: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5230
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5230: Dma_PatchSrc (.L__pc.5230.LD), (.L__movme_cp.24), (.L__pc.5230.LD)
	.p2align 4
	.L__pc.5230.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5231
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5231: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5232
	.L__pc.5232: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5233
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5233: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5234: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5235: Dma_PatchSrc (.L__pc.5235.LD), (.L__movme_tmp.1), (.L__pc.5235.LD)
	.p2align 4
	.L__pc.5235.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5236
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5236: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5237
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5237: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5238: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5239: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5240: Dma_PatchSrc (.L__pc.5240.LD), (.L__movme_tmp.1), (.L__pc.5240.LD)
	.p2align 4
	.L__pc.5240.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5241
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5241: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5242
	
	.L__pc.5242: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5243
	
	.p2align 4
	.L__pc.5243: Dma_PatchDst (.L__pc.5243.ST), (.L__movme_cp.67), (.L__pc.5243.ST)
	.L__pc.5243.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5244
	
	.L__pc.5244: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5245
	
	.p2align 4
	.L__pc.5245: Dma_PatchDst (.L__pc.5245.ST), (.L__movme_cp.24), (.L__pc.5245.ST)
	.L__pc.5245.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5246
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5246: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5247
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5247: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5248
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5248: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5249
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5249: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5250
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.5250: Dma_PatchSrc (.L__pc.5250.LD), (.L__movme_cp.68), (.L__pc.5250.LD)
	.p2align 4
	.L__pc.5250.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5251
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5251: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5252
	.L__pc.5252: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5253
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5253: Dma_PatchSrc (.L__pc.5253.LD), (.L__movme_cp.24), (.L__pc.5253.LD)
	.p2align 4
	.L__pc.5253.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5254
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5254: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5255
	.L__pc.5255: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5256
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5256: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5257: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5258: Dma_PatchSrc (.L__pc.5258.LD), (.L__movme_tmp.1), (.L__pc.5258.LD)
	.p2align 4
	.L__pc.5258.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5259
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5259: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5260
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5260: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5261: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5262: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5263: Dma_PatchSrc (.L__pc.5263.LD), (.L__movme_tmp.1), (.L__pc.5263.LD)
	.p2align 4
	.L__pc.5263.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5264
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5264: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5265
	
	.L__pc.5265: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5266
	
	.p2align 4
	.L__pc.5266: Dma_PatchDst (.L__pc.5266.ST), (.L__movme_cp.68), (.L__pc.5266.ST)
	.L__pc.5266.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5267
	
	.L__pc.5267: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5268
	
	.p2align 4
	.L__pc.5268: Dma_PatchDst (.L__pc.5268.ST), (.L__movme_cp.24), (.L__pc.5268.ST)
	.L__pc.5268.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5269
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5269: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5270
	
	.p2align 4
	.L__pc.5270: Dma_PatchDst (.L__pc.5270.ST), (.L__movme_cp.24), (.L__pc.5270.ST)
	.L__pc.5270.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5271
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.5271: Dma_PatchSrc (.L__pc.5271.LD), (.L__movme_cp.60), (.L__pc.5271.LD)
	.p2align 4
	.L__pc.5271.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5272
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5272: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5273
	
	.L__pc.5273: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5274
	
	.p2align 4
	.L__pc.5274: Dma_PatchDst (.L__pc.5274.ST), (.L__movme_cp.21), (.L__pc.5274.ST)
	.L__pc.5274.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5275
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.5275: Dma_PatchSrc (.L__pc.5275.LD), (.L__movme_cp.58), (.L__pc.5275.LD)
	.p2align 4
	.L__pc.5275.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5276
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5276: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5277
	
	.L__pc.5277: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5278
	
	.p2align 4
	.L__pc.5278: Dma_PatchDst (.L__pc.5278.ST), (.L__movme_cp.22), (.L__pc.5278.ST)
	.L__pc.5278.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5279
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5279: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5280
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5280: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5281
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5281: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5282
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5282: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5283
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.5283: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.5284
	
	.p2align 4
	.L__pc.5284: Dma_PatchDst (.L__pc.5284.ST), (.L__movme_cp.24), (.L__pc.5284.ST)
	.L__pc.5284.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5285
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.5285: Dma_PatchSrc (.L__pc.5285.LD), (.L__movme_cp.25), (.L__pc.5285.LD)
	.p2align 4
	.L__pc.5285.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5286
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5286: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5287
	.L__pc.5287: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5288
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.5288: Dma_PatchSrc (.L__pc.5288.LD), (.L__movme_cp.26), (.L__pc.5288.LD)
	.p2align 4
	.L__pc.5288.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5289
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5289: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5290
	.L__pc.5290: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5291
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5291: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5292: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5293: Dma_PatchSrc (.L__pc.5293.LD), (.L__movme_tmp.1), (.L__pc.5293.LD)
	.p2align 4
	.L__pc.5293.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5294
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5294: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5295
	.L__pc.5295: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5296
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5296: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5297: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5298: Dma_PatchSrc (.L__pc.5298.LD), (.L__movme_tmp.1), (.L__pc.5298.LD)
	.p2align 4
	.L__pc.5298.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5299
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5299: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5300
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5300: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5301: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5302: Dma_PatchSrc (.L__pc.5302.LD), (.L__movme_tmp.1), (.L__pc.5302.LD)
	.p2align 4
	.L__pc.5302.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5303
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5303: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5304
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5304: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5305: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5306: Dma_PatchSrc (.L__pc.5306.LD), (.L__movme_tmp.1), (.L__pc.5306.LD)
	.p2align 4
	.L__pc.5306.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5307
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5307: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5308
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5308: Dma_PatchSrc (.L__pc.5308.LD), (.L__movme_cp.24), (.L__pc.5308.LD)
	.p2align 4
	.L__pc.5308.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5309
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5309: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5310
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5310: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5311: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5312: Dma_PatchSrc (.L__pc.5312.LD), (.L__movme_tmp.1), (.L__pc.5312.LD)
	.p2align 4
	.L__pc.5312.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5313
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5313: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5314
	
	.L__pc.5314: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5315
	
	.p2align 4
	.L__pc.5315: Dma_PatchDst (.L__pc.5315.ST), (.L__movme_cp.69), (.L__pc.5315.ST)
	.L__pc.5315.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5316
	
	.L__pc.5316: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5317
	
	.p2align 4
	.L__pc.5317: Dma_PatchDst (.L__pc.5317.ST), (.L__movme_cp.54), (.L__pc.5317.ST)
	.L__pc.5317.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5318
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.5318: Dma_PatchSrc (.L__pc.5318.LD), (.L__movme_cp.30), (.L__pc.5318.LD)
	.p2align 4
	.L__pc.5318.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5319
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5319: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5320
	.L__pc.5320: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5321
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.5321: Dma_PatchSrc (.L__pc.5321.LD), (.L__movme_cp.31), (.L__pc.5321.LD)
	.p2align 4
	.L__pc.5321.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5322
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5322: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5323
	.L__pc.5323: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5324
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5324: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5325: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5326: Dma_PatchSrc (.L__pc.5326.LD), (.L__movme_tmp.1), (.L__pc.5326.LD)
	.p2align 4
	.L__pc.5326.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5327
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5327: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5328
	.L__pc.5328: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5329
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5329: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5330: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5331: Dma_PatchSrc (.L__pc.5331.LD), (.L__movme_tmp.1), (.L__pc.5331.LD)
	.p2align 4
	.L__pc.5331.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5332
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5332: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5333
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5333: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5334: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5335: Dma_PatchSrc (.L__pc.5335.LD), (.L__movme_tmp.1), (.L__pc.5335.LD)
	.p2align 4
	.L__pc.5335.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5336
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5336: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5337
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5337: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5338: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5339: Dma_PatchSrc (.L__pc.5339.LD), (.L__movme_tmp.1), (.L__pc.5339.LD)
	.p2align 4
	.L__pc.5339.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5340
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5340: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5341
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5341: Dma_PatchSrc (.L__pc.5341.LD), (.L__movme_cp.24), (.L__pc.5341.LD)
	.p2align 4
	.L__pc.5341.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5342
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5342: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5343
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5343: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5344: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5345: Dma_PatchSrc (.L__pc.5345.LD), (.L__movme_tmp.1), (.L__pc.5345.LD)
	.p2align 4
	.L__pc.5345.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5346
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5346: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5347
	
	.L__pc.5347: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5348
	
	.p2align 4
	.L__pc.5348: Dma_PatchDst (.L__pc.5348.ST), (.L__movme_cp.70), (.L__pc.5348.ST)
	.L__pc.5348.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5349
	
	.L__pc.5349: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5350
	
	.p2align 4
	.L__pc.5350: Dma_PatchDst (.L__pc.5350.ST), (.L__movme_cp.54), (.L__pc.5350.ST)
	.L__pc.5350.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5351
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5351: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5352
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5352: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5353
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5353: Dma_PatchSrc (.L__pc.5353.LD), (.L__movme_cp.24), (.L__pc.5353.LD)
	.p2align 4
	.L__pc.5353.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5354
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5354: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5355
	.L__pc.5355: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5356
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.5356: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5357: Dma_PatchSrc (.L__pc.5357.LD), (.L__movme_tmp.1), (.L__pc.5357.LD)
	.p2align 4
	.L__pc.5357.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5358
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5358: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5359
	.L__pc.5359: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5360
	
	.L__pc.5360: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5361
	
	.p2align 4
	.L__pc.5361: Dma_PatchDst (.L__pc.5361.ST), (.L__movme_cp.72), (.L__pc.5361.ST)
	.L__pc.5361.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5362
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.5362: Dma_PatchSrc (.L__pc.5362.LD), (.L__movme_cp.72), (.L__pc.5362.LD)
	.p2align 4
	.L__pc.5362.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5363
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5363: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5364
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5364: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5365: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5366: Dma_PatchSrc (.L__pc.5366.LD), (.L__movme_tmp.1), (.L__pc.5366.LD)
	.p2align 4
	.L__pc.5366.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5367
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5367: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5368
	
	.L__pc.5368: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5369
	
	.p2align 4
	.L__pc.5369: Dma_PatchDst (.L__pc.5369.ST), (.L__movme_cp.74), (.L__pc.5369.ST)
	.L__pc.5369.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5370
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5370: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5371: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5372: Dma_PatchSrc (.L__pc.5372.LD), (.L__movme_tmp.1), (.L__pc.5372.LD)
	.p2align 4
	.L__pc.5372.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5373
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5373: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5374
	
	.L__pc.5374: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5375
	
	.p2align 4
	.L__pc.5375: Dma_PatchDst (.L__pc.5375.ST), (.L__movme_cp.76), (.L__pc.5375.ST)
	.L__pc.5375.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5376
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.5376: Dma_PatchSrc (.L__pc.5376.LD), (.L__movme_cp.74), (.L__pc.5376.LD)
	.p2align 4
	.L__pc.5376.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5377
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5377: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5378
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.5378: Dma_PatchSrc (.L__pc.5378.LD), ((.L__movme.reg.eax+0)), (.L__pc.5378.LD)
	.p2align 4
	.L__pc.5378.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5379
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5379: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5380
	
	.L__pc.5380: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5381
	
	.p2align 4
	.L__pc.5381: Dma_PatchDst (.L__pc.5381.ST), (.L__movme_cp.77), (.L__pc.5381.ST)
	.L__pc.5381.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5382
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.5382: Dma_PatchSrc (.L__pc.5382.LD), (.L__movme_cp.77), (.L__pc.5382.LD)
	.p2align 4
	.L__pc.5382.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5383
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5383: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5384
	
	.L__pc.5384: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5385
	
	.p2align 4
	.L__pc.5385: Dma_PatchDst (.L__pc.5385.ST), (.L__movme_cp.21), (.L__pc.5385.ST)
	.L__pc.5385.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5386
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.5386: Dma_PatchSrc (.L__pc.5386.LD), (.L__movme_cp.58), (.L__pc.5386.LD)
	.p2align 4
	.L__pc.5386.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5387
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5387: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5388
	
	.L__pc.5388: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5389
	
	.p2align 4
	.L__pc.5389: Dma_PatchDst (.L__pc.5389.ST), (.L__movme_cp.22), (.L__pc.5389.ST)
	.L__pc.5389.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5390
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5390: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5391
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5391: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5392
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5392: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5393
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5393: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5394
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.5394: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.5395
	
	.p2align 4
	.L__pc.5395: Dma_PatchDst (.L__pc.5395.ST), (.L__movme_cp.24), (.L__pc.5395.ST)
	.L__pc.5395.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5396
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.5396: Dma_PatchSrc (.L__pc.5396.LD), (.L__movme_cp.25), (.L__pc.5396.LD)
	.p2align 4
	.L__pc.5396.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5397
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5397: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5398
	.L__pc.5398: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5399
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.5399: Dma_PatchSrc (.L__pc.5399.LD), (.L__movme_cp.26), (.L__pc.5399.LD)
	.p2align 4
	.L__pc.5399.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5400
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5400: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5401
	.L__pc.5401: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5402
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5402: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5403: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5404: Dma_PatchSrc (.L__pc.5404.LD), (.L__movme_tmp.1), (.L__pc.5404.LD)
	.p2align 4
	.L__pc.5404.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5405
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5405: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5406
	.L__pc.5406: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5407
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5407: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5408: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5409: Dma_PatchSrc (.L__pc.5409.LD), (.L__movme_tmp.1), (.L__pc.5409.LD)
	.p2align 4
	.L__pc.5409.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5410
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5410: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5411
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5411: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5412: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5413: Dma_PatchSrc (.L__pc.5413.LD), (.L__movme_tmp.1), (.L__pc.5413.LD)
	.p2align 4
	.L__pc.5413.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5414
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5414: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5415
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5415: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5416: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5417: Dma_PatchSrc (.L__pc.5417.LD), (.L__movme_tmp.1), (.L__pc.5417.LD)
	.p2align 4
	.L__pc.5417.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5418
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5418: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5419
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5419: Dma_PatchSrc (.L__pc.5419.LD), (.L__movme_cp.24), (.L__pc.5419.LD)
	.p2align 4
	.L__pc.5419.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5420
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5420: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5421
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5421: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5422: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5423: Dma_PatchSrc (.L__pc.5423.LD), (.L__movme_tmp.1), (.L__pc.5423.LD)
	.p2align 4
	.L__pc.5423.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5424
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5424: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5425
	
	.L__pc.5425: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5426
	
	.p2align 4
	.L__pc.5426: Dma_PatchDst (.L__pc.5426.ST), (.L__movme_cp.78), (.L__pc.5426.ST)
	.L__pc.5426.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5427
	
	.L__pc.5427: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5428
	
	.p2align 4
	.L__pc.5428: Dma_PatchDst (.L__pc.5428.ST), (.L__movme_cp.54), (.L__pc.5428.ST)
	.L__pc.5428.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5429
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.5429: Dma_PatchSrc (.L__pc.5429.LD), (.L__movme_cp.30), (.L__pc.5429.LD)
	.p2align 4
	.L__pc.5429.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5430
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5430: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5431
	.L__pc.5431: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5432
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.5432: Dma_PatchSrc (.L__pc.5432.LD), (.L__movme_cp.31), (.L__pc.5432.LD)
	.p2align 4
	.L__pc.5432.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5433
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5433: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5434
	.L__pc.5434: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5435
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5435: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5436: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5437: Dma_PatchSrc (.L__pc.5437.LD), (.L__movme_tmp.1), (.L__pc.5437.LD)
	.p2align 4
	.L__pc.5437.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5438
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5438: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5439
	.L__pc.5439: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5440
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5440: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5441: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5442: Dma_PatchSrc (.L__pc.5442.LD), (.L__movme_tmp.1), (.L__pc.5442.LD)
	.p2align 4
	.L__pc.5442.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5443
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5443: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5444
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5444: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5445: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5446: Dma_PatchSrc (.L__pc.5446.LD), (.L__movme_tmp.1), (.L__pc.5446.LD)
	.p2align 4
	.L__pc.5446.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5447
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5447: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5448
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5448: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5449: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5450: Dma_PatchSrc (.L__pc.5450.LD), (.L__movme_tmp.1), (.L__pc.5450.LD)
	.p2align 4
	.L__pc.5450.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5451
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5451: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5452
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5452: Dma_PatchSrc (.L__pc.5452.LD), (.L__movme_cp.24), (.L__pc.5452.LD)
	.p2align 4
	.L__pc.5452.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5453
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5453: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5454
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5454: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5455: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5456: Dma_PatchSrc (.L__pc.5456.LD), (.L__movme_tmp.1), (.L__pc.5456.LD)
	.p2align 4
	.L__pc.5456.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5457
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5457: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5458
	
	.L__pc.5458: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5459
	
	.p2align 4
	.L__pc.5459: Dma_PatchDst (.L__pc.5459.ST), (.L__movme_cp.79), (.L__pc.5459.ST)
	.L__pc.5459.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5460
	
	.L__pc.5460: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5461
	
	.p2align 4
	.L__pc.5461: Dma_PatchDst (.L__pc.5461.ST), (.L__movme_cp.54), (.L__pc.5461.ST)
	.L__pc.5461.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5462
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.5462: Dma_PatchSrc (.L__pc.5462.LD), (.L__movme_cp.74), (.L__pc.5462.LD)
	.p2align 4
	.L__pc.5462.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5463
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5463: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5464
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.5464: Dma_PatchSrc (.L__pc.5464.LD), (.L__movme_cp.77), (.L__pc.5464.LD)
	.p2align 4
	.L__pc.5464.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5465
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5465: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5466
	
	.L__pc.5466: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5467
	
	.p2align 4
	.L__pc.5467: Dma_PatchDst (.L__pc.5467.ST), ((.L__movme.reg.eax+0)), (.L__pc.5467.ST)
	.L__pc.5467.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5468
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.5468: Dma_PatchSrc (.L__pc.5468.LD), (.L__movme_cp.76), (.L__pc.5468.LD)
	.p2align 4
	.L__pc.5468.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5469
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5469: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5470
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.5470: Dma_PatchSrc (.L__pc.5470.LD), ((.L__movme.reg.eax+0)), (.L__pc.5470.LD)
	.p2align 4
	.L__pc.5470.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5471
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5471: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5472
	
	.L__pc.5472: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5473
	
	.p2align 4
	.L__pc.5473: Dma_PatchDst (.L__pc.5473.ST), (.L__movme_cp.80), (.L__pc.5473.ST)
	.L__pc.5473.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5474
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5474: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5475
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5475: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5476
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.5476: Dma_PatchSrc (.L__pc.5476.LD), (.L__movme_cp.98), (.L__pc.5476.LD)
	.p2align 4
	.L__pc.5476.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5477
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5477: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5478
	.L__pc.5478: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5479
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.86 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.5479: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5480: Dma_PatchSrc (.L__pc.5480.LD), (.L__movme_tmp.1), (.L__pc.5480.LD)
	.p2align 4
	.L__pc.5480.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5481
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5481: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5482
	.L__pc.5482: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5483
	
	.L__pc.5483: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5484
	
	.p2align 4
	.L__pc.5484: Dma_PatchDst (.L__pc.5484.ST), (.L__movme_cp.98), (.L__pc.5484.ST)
	.L__pc.5484.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5485
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.5485: Dma_PatchSrc (.L__pc.5485.LD), (.L__movme_cp.76), (.L__pc.5485.LD)
	.p2align 4
	.L__pc.5485.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5486
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5486: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5487
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.5487: Dma_PatchSrc (.L__pc.5487.LD), (.L__movme_cp.80), (.L__pc.5487.LD)
	.p2align 4
	.L__pc.5487.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5488
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5488: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5489
	
	.L__pc.5489: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5490
	
	.p2align 4
	.L__pc.5490: Dma_PatchDst (.L__pc.5490.ST), ((.L__movme.reg.eax+0)), (.L__pc.5490.ST)
	.L__pc.5490.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5491
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5491: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5492
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5492: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5493
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.5493: Dma_PatchSrc (.L__pc.5493.LD), (.L__movme_cp.97), (.L__pc.5493.LD)
	.p2align 4
	.L__pc.5493.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5494
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5494: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5495
	.L__pc.5495: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5496
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5496: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.87 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5497: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5498: Dma_PatchSrc (.L__pc.5498.LD), (.L__movme_tmp.1), (.L__pc.5498.LD)
	.p2align 4
	.L__pc.5498.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5499
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5499: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5500
	
	.L__pc.5500: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5501
	
	.p2align 4
	.L__pc.5501: Dma_PatchDst (.L__pc.5501.ST), (.L__movme_cp.24), (.L__pc.5501.ST)
	.L__pc.5501.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5502
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5502: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5503
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5503: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5504
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5504: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5505
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5505: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5506
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.5506: Dma_PatchSrc (.L__pc.5506.LD), (.L__movme_cp.63), (.L__pc.5506.LD)
	.p2align 4
	.L__pc.5506.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5507
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5507: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5508
	.L__pc.5508: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5509
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5509: Dma_PatchSrc (.L__pc.5509.LD), (.L__movme_cp.24), (.L__pc.5509.LD)
	.p2align 4
	.L__pc.5509.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5510
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5510: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5511
	.L__pc.5511: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5512
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5512: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5513: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5514: Dma_PatchSrc (.L__pc.5514.LD), (.L__movme_tmp.1), (.L__pc.5514.LD)
	.p2align 4
	.L__pc.5514.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5515
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5515: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5516
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5516: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5517: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5518: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5519: Dma_PatchSrc (.L__pc.5519.LD), (.L__movme_tmp.1), (.L__pc.5519.LD)
	.p2align 4
	.L__pc.5519.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5520
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5520: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5521
	
	.L__pc.5521: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5522
	
	.p2align 4
	.L__pc.5522: Dma_PatchDst (.L__pc.5522.ST), (.L__movme_cp.63), (.L__pc.5522.ST)
	.L__pc.5522.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5523
	
	.L__pc.5523: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5524
	
	.p2align 4
	.L__pc.5524: Dma_PatchDst (.L__pc.5524.ST), (.L__movme_cp.24), (.L__pc.5524.ST)
	.L__pc.5524.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5525
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5525: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5526
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5526: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5527
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5527: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5528
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5528: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5529
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.5529: Dma_PatchSrc (.L__pc.5529.LD), (.L__movme_cp.66), (.L__pc.5529.LD)
	.p2align 4
	.L__pc.5529.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5530
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5530: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5531
	.L__pc.5531: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5532
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5532: Dma_PatchSrc (.L__pc.5532.LD), (.L__movme_cp.24), (.L__pc.5532.LD)
	.p2align 4
	.L__pc.5532.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5533
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5533: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5534
	.L__pc.5534: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5535
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5535: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5536: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5537: Dma_PatchSrc (.L__pc.5537.LD), (.L__movme_tmp.1), (.L__pc.5537.LD)
	.p2align 4
	.L__pc.5537.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5538
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5538: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5539
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5539: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5540: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5541: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5542: Dma_PatchSrc (.L__pc.5542.LD), (.L__movme_tmp.1), (.L__pc.5542.LD)
	.p2align 4
	.L__pc.5542.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5543
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5543: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5544
	
	.L__pc.5544: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5545
	
	.p2align 4
	.L__pc.5545: Dma_PatchDst (.L__pc.5545.ST), (.L__movme_cp.66), (.L__pc.5545.ST)
	.L__pc.5545.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5546
	
	.L__pc.5546: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5547
	
	.p2align 4
	.L__pc.5547: Dma_PatchDst (.L__pc.5547.ST), (.L__movme_cp.24), (.L__pc.5547.ST)
	.L__pc.5547.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5548
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5548: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5549
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5549: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5550
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5550: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5551
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5551: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5552
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.5552: Dma_PatchSrc (.L__pc.5552.LD), (.L__movme_cp.67), (.L__pc.5552.LD)
	.p2align 4
	.L__pc.5552.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5553
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5553: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5554
	.L__pc.5554: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5555
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5555: Dma_PatchSrc (.L__pc.5555.LD), (.L__movme_cp.24), (.L__pc.5555.LD)
	.p2align 4
	.L__pc.5555.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5556
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5556: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5557
	.L__pc.5557: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5558
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5558: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5559: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5560: Dma_PatchSrc (.L__pc.5560.LD), (.L__movme_tmp.1), (.L__pc.5560.LD)
	.p2align 4
	.L__pc.5560.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5561
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5561: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5562
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5562: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5563: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5564: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5565: Dma_PatchSrc (.L__pc.5565.LD), (.L__movme_tmp.1), (.L__pc.5565.LD)
	.p2align 4
	.L__pc.5565.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5566
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5566: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5567
	
	.L__pc.5567: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5568
	
	.p2align 4
	.L__pc.5568: Dma_PatchDst (.L__pc.5568.ST), (.L__movme_cp.67), (.L__pc.5568.ST)
	.L__pc.5568.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5569
	
	.L__pc.5569: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5570
	
	.p2align 4
	.L__pc.5570: Dma_PatchDst (.L__pc.5570.ST), (.L__movme_cp.24), (.L__pc.5570.ST)
	.L__pc.5570.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5571
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5571: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5572
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5572: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5573
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5573: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5574
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5574: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5575
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.5575: Dma_PatchSrc (.L__pc.5575.LD), (.L__movme_cp.68), (.L__pc.5575.LD)
	.p2align 4
	.L__pc.5575.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5576
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5576: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5577
	.L__pc.5577: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5578
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5578: Dma_PatchSrc (.L__pc.5578.LD), (.L__movme_cp.24), (.L__pc.5578.LD)
	.p2align 4
	.L__pc.5578.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5579
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5579: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5580
	.L__pc.5580: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5581
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5581: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5582: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5583: Dma_PatchSrc (.L__pc.5583.LD), (.L__movme_tmp.1), (.L__pc.5583.LD)
	.p2align 4
	.L__pc.5583.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5584
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5584: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5585
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5585: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5586: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5587: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5588: Dma_PatchSrc (.L__pc.5588.LD), (.L__movme_tmp.1), (.L__pc.5588.LD)
	.p2align 4
	.L__pc.5588.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5589
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5589: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5590
	
	.L__pc.5590: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5591
	
	.p2align 4
	.L__pc.5591: Dma_PatchDst (.L__pc.5591.ST), (.L__movme_cp.68), (.L__pc.5591.ST)
	.L__pc.5591.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5592
	
	.L__pc.5592: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5593
	
	.p2align 4
	.L__pc.5593: Dma_PatchDst (.L__pc.5593.ST), (.L__movme_cp.24), (.L__pc.5593.ST)
	.L__pc.5593.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5594
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5594: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5595
	
	.p2align 4
	.L__pc.5595: Dma_PatchDst (.L__pc.5595.ST), (.L__movme_cp.24), (.L__pc.5595.ST)
	.L__pc.5595.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5596
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.5596: Dma_PatchSrc (.L__pc.5596.LD), (.L__movme_cp.60), (.L__pc.5596.LD)
	.p2align 4
	.L__pc.5596.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5597
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5597: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5598
	
	.L__pc.5598: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5599
	
	.p2align 4
	.L__pc.5599: Dma_PatchDst (.L__pc.5599.ST), (.L__movme_cp.21), (.L__pc.5599.ST)
	.L__pc.5599.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5600
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.5600: Dma_PatchSrc (.L__pc.5600.LD), (.L__movme_cp.58), (.L__pc.5600.LD)
	.p2align 4
	.L__pc.5600.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5601
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5601: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5602
	
	.L__pc.5602: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5603
	
	.p2align 4
	.L__pc.5603: Dma_PatchDst (.L__pc.5603.ST), (.L__movme_cp.22), (.L__pc.5603.ST)
	.L__pc.5603.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5604
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5604: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5605
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5605: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5606
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5606: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5607
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5607: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5608
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.5608: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.5609
	
	.p2align 4
	.L__pc.5609: Dma_PatchDst (.L__pc.5609.ST), (.L__movme_cp.24), (.L__pc.5609.ST)
	.L__pc.5609.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5610
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.5610: Dma_PatchSrc (.L__pc.5610.LD), (.L__movme_cp.25), (.L__pc.5610.LD)
	.p2align 4
	.L__pc.5610.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5611
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5611: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5612
	.L__pc.5612: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5613
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.5613: Dma_PatchSrc (.L__pc.5613.LD), (.L__movme_cp.26), (.L__pc.5613.LD)
	.p2align 4
	.L__pc.5613.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5614
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5614: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5615
	.L__pc.5615: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5616
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5616: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5617: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5618: Dma_PatchSrc (.L__pc.5618.LD), (.L__movme_tmp.1), (.L__pc.5618.LD)
	.p2align 4
	.L__pc.5618.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5619
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5619: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5620
	.L__pc.5620: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5621
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5621: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5622: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5623: Dma_PatchSrc (.L__pc.5623.LD), (.L__movme_tmp.1), (.L__pc.5623.LD)
	.p2align 4
	.L__pc.5623.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5624
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5624: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5625
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5625: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5626: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5627: Dma_PatchSrc (.L__pc.5627.LD), (.L__movme_tmp.1), (.L__pc.5627.LD)
	.p2align 4
	.L__pc.5627.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5628
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5628: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5629
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5629: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5630: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5631: Dma_PatchSrc (.L__pc.5631.LD), (.L__movme_tmp.1), (.L__pc.5631.LD)
	.p2align 4
	.L__pc.5631.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5632
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5632: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5633
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5633: Dma_PatchSrc (.L__pc.5633.LD), (.L__movme_cp.24), (.L__pc.5633.LD)
	.p2align 4
	.L__pc.5633.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5634
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5634: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5635
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5635: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5636: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5637: Dma_PatchSrc (.L__pc.5637.LD), (.L__movme_tmp.1), (.L__pc.5637.LD)
	.p2align 4
	.L__pc.5637.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5638
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5638: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5639
	
	.L__pc.5639: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5640
	
	.p2align 4
	.L__pc.5640: Dma_PatchDst (.L__pc.5640.ST), (.L__movme_cp.69), (.L__pc.5640.ST)
	.L__pc.5640.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5641
	
	.L__pc.5641: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5642
	
	.p2align 4
	.L__pc.5642: Dma_PatchDst (.L__pc.5642.ST), (.L__movme_cp.54), (.L__pc.5642.ST)
	.L__pc.5642.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5643
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.5643: Dma_PatchSrc (.L__pc.5643.LD), (.L__movme_cp.30), (.L__pc.5643.LD)
	.p2align 4
	.L__pc.5643.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5644
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5644: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5645
	.L__pc.5645: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5646
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.5646: Dma_PatchSrc (.L__pc.5646.LD), (.L__movme_cp.31), (.L__pc.5646.LD)
	.p2align 4
	.L__pc.5646.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5647
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5647: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5648
	.L__pc.5648: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5649
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5649: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5650: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5651: Dma_PatchSrc (.L__pc.5651.LD), (.L__movme_tmp.1), (.L__pc.5651.LD)
	.p2align 4
	.L__pc.5651.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5652
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5652: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5653
	.L__pc.5653: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5654
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5654: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5655: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5656: Dma_PatchSrc (.L__pc.5656.LD), (.L__movme_tmp.1), (.L__pc.5656.LD)
	.p2align 4
	.L__pc.5656.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5657
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5657: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5658
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5658: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5659: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5660: Dma_PatchSrc (.L__pc.5660.LD), (.L__movme_tmp.1), (.L__pc.5660.LD)
	.p2align 4
	.L__pc.5660.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5661
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5661: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5662
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5662: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5663: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5664: Dma_PatchSrc (.L__pc.5664.LD), (.L__movme_tmp.1), (.L__pc.5664.LD)
	.p2align 4
	.L__pc.5664.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5665
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5665: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5666
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5666: Dma_PatchSrc (.L__pc.5666.LD), (.L__movme_cp.24), (.L__pc.5666.LD)
	.p2align 4
	.L__pc.5666.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5667
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5667: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5668
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5668: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5669: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5670: Dma_PatchSrc (.L__pc.5670.LD), (.L__movme_tmp.1), (.L__pc.5670.LD)
	.p2align 4
	.L__pc.5670.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5671
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5671: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5672
	
	.L__pc.5672: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5673
	
	.p2align 4
	.L__pc.5673: Dma_PatchDst (.L__pc.5673.ST), (.L__movme_cp.70), (.L__pc.5673.ST)
	.L__pc.5673.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5674
	
	.L__pc.5674: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5675
	
	.p2align 4
	.L__pc.5675: Dma_PatchDst (.L__pc.5675.ST), (.L__movme_cp.54), (.L__pc.5675.ST)
	.L__pc.5675.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5676
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5676: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5677
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5677: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5678
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5678: Dma_PatchSrc (.L__pc.5678.LD), (.L__movme_cp.24), (.L__pc.5678.LD)
	.p2align 4
	.L__pc.5678.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5679
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5679: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5680
	.L__pc.5680: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5681
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.5681: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5682: Dma_PatchSrc (.L__pc.5682.LD), (.L__movme_tmp.1), (.L__pc.5682.LD)
	.p2align 4
	.L__pc.5682.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5683
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5683: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5684
	.L__pc.5684: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5685
	
	.L__pc.5685: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5686
	
	.p2align 4
	.L__pc.5686: Dma_PatchDst (.L__pc.5686.ST), (.L__movme_cp.72), (.L__pc.5686.ST)
	.L__pc.5686.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5687
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.5687: Dma_PatchSrc (.L__pc.5687.LD), (.L__movme_cp.72), (.L__pc.5687.LD)
	.p2align 4
	.L__pc.5687.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5688
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5688: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5689
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5689: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5690: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5691: Dma_PatchSrc (.L__pc.5691.LD), (.L__movme_tmp.1), (.L__pc.5691.LD)
	.p2align 4
	.L__pc.5691.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5692
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5692: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5693
	
	.L__pc.5693: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5694
	
	.p2align 4
	.L__pc.5694: Dma_PatchDst (.L__pc.5694.ST), (.L__movme_cp.74), (.L__pc.5694.ST)
	.L__pc.5694.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5695
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5695: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5696: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5697: Dma_PatchSrc (.L__pc.5697.LD), (.L__movme_tmp.1), (.L__pc.5697.LD)
	.p2align 4
	.L__pc.5697.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5698
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5698: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5699
	
	.L__pc.5699: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5700
	
	.p2align 4
	.L__pc.5700: Dma_PatchDst (.L__pc.5700.ST), (.L__movme_cp.76), (.L__pc.5700.ST)
	.L__pc.5700.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5701
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.5701: Dma_PatchSrc (.L__pc.5701.LD), (.L__movme_cp.74), (.L__pc.5701.LD)
	.p2align 4
	.L__pc.5701.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5702
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5702: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5703
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.5703: Dma_PatchSrc (.L__pc.5703.LD), ((.L__movme.reg.eax+0)), (.L__pc.5703.LD)
	.p2align 4
	.L__pc.5703.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5704
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5704: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5705
	
	.L__pc.5705: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5706
	
	.p2align 4
	.L__pc.5706: Dma_PatchDst (.L__pc.5706.ST), (.L__movme_cp.77), (.L__pc.5706.ST)
	.L__pc.5706.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5707
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.5707: Dma_PatchSrc (.L__pc.5707.LD), (.L__movme_cp.77), (.L__pc.5707.LD)
	.p2align 4
	.L__pc.5707.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5708
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5708: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5709
	
	.L__pc.5709: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5710
	
	.p2align 4
	.L__pc.5710: Dma_PatchDst (.L__pc.5710.ST), (.L__movme_cp.21), (.L__pc.5710.ST)
	.L__pc.5710.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5711
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.5711: Dma_PatchSrc (.L__pc.5711.LD), (.L__movme_cp.58), (.L__pc.5711.LD)
	.p2align 4
	.L__pc.5711.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5712
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5712: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5713
	
	.L__pc.5713: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5714
	
	.p2align 4
	.L__pc.5714: Dma_PatchDst (.L__pc.5714.ST), (.L__movme_cp.22), (.L__pc.5714.ST)
	.L__pc.5714.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5715
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5715: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5716
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5716: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5717
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5717: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5718
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5718: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5719
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.5719: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.5720
	
	.p2align 4
	.L__pc.5720: Dma_PatchDst (.L__pc.5720.ST), (.L__movme_cp.24), (.L__pc.5720.ST)
	.L__pc.5720.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5721
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.5721: Dma_PatchSrc (.L__pc.5721.LD), (.L__movme_cp.25), (.L__pc.5721.LD)
	.p2align 4
	.L__pc.5721.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5722
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5722: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5723
	.L__pc.5723: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5724
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.5724: Dma_PatchSrc (.L__pc.5724.LD), (.L__movme_cp.26), (.L__pc.5724.LD)
	.p2align 4
	.L__pc.5724.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5725
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5725: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5726
	.L__pc.5726: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5727
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5727: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5728: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5729: Dma_PatchSrc (.L__pc.5729.LD), (.L__movme_tmp.1), (.L__pc.5729.LD)
	.p2align 4
	.L__pc.5729.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5730
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5730: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5731
	.L__pc.5731: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5732
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5732: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5733: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5734: Dma_PatchSrc (.L__pc.5734.LD), (.L__movme_tmp.1), (.L__pc.5734.LD)
	.p2align 4
	.L__pc.5734.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5735
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5735: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5736
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5736: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5737: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5738: Dma_PatchSrc (.L__pc.5738.LD), (.L__movme_tmp.1), (.L__pc.5738.LD)
	.p2align 4
	.L__pc.5738.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5739
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5739: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5740
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5740: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5741: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5742: Dma_PatchSrc (.L__pc.5742.LD), (.L__movme_tmp.1), (.L__pc.5742.LD)
	.p2align 4
	.L__pc.5742.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5743
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5743: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5744
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5744: Dma_PatchSrc (.L__pc.5744.LD), (.L__movme_cp.24), (.L__pc.5744.LD)
	.p2align 4
	.L__pc.5744.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5745
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5745: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5746
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5746: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5747: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5748: Dma_PatchSrc (.L__pc.5748.LD), (.L__movme_tmp.1), (.L__pc.5748.LD)
	.p2align 4
	.L__pc.5748.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5749
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5749: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5750
	
	.L__pc.5750: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5751
	
	.p2align 4
	.L__pc.5751: Dma_PatchDst (.L__pc.5751.ST), (.L__movme_cp.78), (.L__pc.5751.ST)
	.L__pc.5751.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5752
	
	.L__pc.5752: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5753
	
	.p2align 4
	.L__pc.5753: Dma_PatchDst (.L__pc.5753.ST), (.L__movme_cp.54), (.L__pc.5753.ST)
	.L__pc.5753.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5754
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.5754: Dma_PatchSrc (.L__pc.5754.LD), (.L__movme_cp.30), (.L__pc.5754.LD)
	.p2align 4
	.L__pc.5754.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5755
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5755: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5756
	.L__pc.5756: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5757
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.5757: Dma_PatchSrc (.L__pc.5757.LD), (.L__movme_cp.31), (.L__pc.5757.LD)
	.p2align 4
	.L__pc.5757.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5758
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5758: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5759
	.L__pc.5759: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5760
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5760: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5761: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5762: Dma_PatchSrc (.L__pc.5762.LD), (.L__movme_tmp.1), (.L__pc.5762.LD)
	.p2align 4
	.L__pc.5762.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5763
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5763: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5764
	.L__pc.5764: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5765
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5765: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5766: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5767: Dma_PatchSrc (.L__pc.5767.LD), (.L__movme_tmp.1), (.L__pc.5767.LD)
	.p2align 4
	.L__pc.5767.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5768
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5768: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5769
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5769: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5770: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5771: Dma_PatchSrc (.L__pc.5771.LD), (.L__movme_tmp.1), (.L__pc.5771.LD)
	.p2align 4
	.L__pc.5771.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5772
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5772: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5773
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5773: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5774: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5775: Dma_PatchSrc (.L__pc.5775.LD), (.L__movme_tmp.1), (.L__pc.5775.LD)
	.p2align 4
	.L__pc.5775.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5776
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5776: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5777
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5777: Dma_PatchSrc (.L__pc.5777.LD), (.L__movme_cp.24), (.L__pc.5777.LD)
	.p2align 4
	.L__pc.5777.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5778
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5778: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5779
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5779: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5780: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5781: Dma_PatchSrc (.L__pc.5781.LD), (.L__movme_tmp.1), (.L__pc.5781.LD)
	.p2align 4
	.L__pc.5781.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5782
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5782: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5783
	
	.L__pc.5783: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5784
	
	.p2align 4
	.L__pc.5784: Dma_PatchDst (.L__pc.5784.ST), (.L__movme_cp.79), (.L__pc.5784.ST)
	.L__pc.5784.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5785
	
	.L__pc.5785: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5786
	
	.p2align 4
	.L__pc.5786: Dma_PatchDst (.L__pc.5786.ST), (.L__movme_cp.54), (.L__pc.5786.ST)
	.L__pc.5786.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5787
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.5787: Dma_PatchSrc (.L__pc.5787.LD), (.L__movme_cp.74), (.L__pc.5787.LD)
	.p2align 4
	.L__pc.5787.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5788
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5788: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5789
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.5789: Dma_PatchSrc (.L__pc.5789.LD), (.L__movme_cp.77), (.L__pc.5789.LD)
	.p2align 4
	.L__pc.5789.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5790
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5790: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5791
	
	.L__pc.5791: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5792
	
	.p2align 4
	.L__pc.5792: Dma_PatchDst (.L__pc.5792.ST), ((.L__movme.reg.eax+0)), (.L__pc.5792.ST)
	.L__pc.5792.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5793
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.5793: Dma_PatchSrc (.L__pc.5793.LD), (.L__movme_cp.76), (.L__pc.5793.LD)
	.p2align 4
	.L__pc.5793.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5794
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5794: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5795
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.5795: Dma_PatchSrc (.L__pc.5795.LD), ((.L__movme.reg.eax+0)), (.L__pc.5795.LD)
	.p2align 4
	.L__pc.5795.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5796
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5796: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5797
	
	.L__pc.5797: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5798
	
	.p2align 4
	.L__pc.5798: Dma_PatchDst (.L__pc.5798.ST), (.L__movme_cp.80), (.L__pc.5798.ST)
	.L__pc.5798.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5799
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5799: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5800
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5800: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5801
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.5801: Dma_PatchSrc (.L__pc.5801.LD), (.L__movme_cp.98), (.L__pc.5801.LD)
	.p2align 4
	.L__pc.5801.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5802
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5802: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5803
	.L__pc.5803: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5804
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.88 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.5804: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5805: Dma_PatchSrc (.L__pc.5805.LD), (.L__movme_tmp.1), (.L__pc.5805.LD)
	.p2align 4
	.L__pc.5805.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5806
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5806: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5807
	.L__pc.5807: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5808
	
	.L__pc.5808: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5809
	
	.p2align 4
	.L__pc.5809: Dma_PatchDst (.L__pc.5809.ST), (.L__movme_cp.98), (.L__pc.5809.ST)
	.L__pc.5809.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5810
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.5810: Dma_PatchSrc (.L__pc.5810.LD), (.L__movme_cp.76), (.L__pc.5810.LD)
	.p2align 4
	.L__pc.5810.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5811
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5811: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5812
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.5812: Dma_PatchSrc (.L__pc.5812.LD), (.L__movme_cp.80), (.L__pc.5812.LD)
	.p2align 4
	.L__pc.5812.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5813
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5813: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5814
	
	.L__pc.5814: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5815
	
	.p2align 4
	.L__pc.5815: Dma_PatchDst (.L__pc.5815.ST), ((.L__movme.reg.eax+0)), (.L__pc.5815.ST)
	.L__pc.5815.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5816
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5816: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5817
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5817: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5818
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.5818: Dma_PatchSrc (.L__pc.5818.LD), (.L__movme_cp.97), (.L__pc.5818.LD)
	.p2align 4
	.L__pc.5818.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5819
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5819: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5820
	.L__pc.5820: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5821
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5821: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.89 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5822: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5823: Dma_PatchSrc (.L__pc.5823.LD), (.L__movme_tmp.1), (.L__pc.5823.LD)
	.p2align 4
	.L__pc.5823.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5824
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5824: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5825
	
	.L__pc.5825: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5826
	
	.p2align 4
	.L__pc.5826: Dma_PatchDst (.L__pc.5826.ST), (.L__movme_cp.24), (.L__pc.5826.ST)
	.L__pc.5826.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5827
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5827: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5828
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5828: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5829
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5829: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5830
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5830: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5831
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.5831: Dma_PatchSrc (.L__pc.5831.LD), (.L__movme_cp.63), (.L__pc.5831.LD)
	.p2align 4
	.L__pc.5831.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5832
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5832: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5833
	.L__pc.5833: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5834
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5834: Dma_PatchSrc (.L__pc.5834.LD), (.L__movme_cp.24), (.L__pc.5834.LD)
	.p2align 4
	.L__pc.5834.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5835
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5835: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5836
	.L__pc.5836: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5837
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5837: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5838: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5839: Dma_PatchSrc (.L__pc.5839.LD), (.L__movme_tmp.1), (.L__pc.5839.LD)
	.p2align 4
	.L__pc.5839.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5840
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5840: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5841
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5841: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5842: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5843: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5844: Dma_PatchSrc (.L__pc.5844.LD), (.L__movme_tmp.1), (.L__pc.5844.LD)
	.p2align 4
	.L__pc.5844.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5845
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5845: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5846
	
	.L__pc.5846: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5847
	
	.p2align 4
	.L__pc.5847: Dma_PatchDst (.L__pc.5847.ST), (.L__movme_cp.63), (.L__pc.5847.ST)
	.L__pc.5847.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5848
	
	.L__pc.5848: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5849
	
	.p2align 4
	.L__pc.5849: Dma_PatchDst (.L__pc.5849.ST), (.L__movme_cp.24), (.L__pc.5849.ST)
	.L__pc.5849.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5850
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5850: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5851
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5851: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5852
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5852: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5853
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5853: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5854
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.5854: Dma_PatchSrc (.L__pc.5854.LD), (.L__movme_cp.66), (.L__pc.5854.LD)
	.p2align 4
	.L__pc.5854.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5855
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5855: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5856
	.L__pc.5856: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5857
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5857: Dma_PatchSrc (.L__pc.5857.LD), (.L__movme_cp.24), (.L__pc.5857.LD)
	.p2align 4
	.L__pc.5857.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5858
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5858: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5859
	.L__pc.5859: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5860
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5860: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5861: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5862: Dma_PatchSrc (.L__pc.5862.LD), (.L__movme_tmp.1), (.L__pc.5862.LD)
	.p2align 4
	.L__pc.5862.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5863
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5863: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5864
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5864: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5865: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5866: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5867: Dma_PatchSrc (.L__pc.5867.LD), (.L__movme_tmp.1), (.L__pc.5867.LD)
	.p2align 4
	.L__pc.5867.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5868
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5868: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5869
	
	.L__pc.5869: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5870
	
	.p2align 4
	.L__pc.5870: Dma_PatchDst (.L__pc.5870.ST), (.L__movme_cp.66), (.L__pc.5870.ST)
	.L__pc.5870.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5871
	
	.L__pc.5871: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5872
	
	.p2align 4
	.L__pc.5872: Dma_PatchDst (.L__pc.5872.ST), (.L__movme_cp.24), (.L__pc.5872.ST)
	.L__pc.5872.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5873
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5873: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5874
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5874: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5875
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5875: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5876
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5876: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5877
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.5877: Dma_PatchSrc (.L__pc.5877.LD), (.L__movme_cp.67), (.L__pc.5877.LD)
	.p2align 4
	.L__pc.5877.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5878
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5878: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5879
	.L__pc.5879: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5880
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5880: Dma_PatchSrc (.L__pc.5880.LD), (.L__movme_cp.24), (.L__pc.5880.LD)
	.p2align 4
	.L__pc.5880.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5881
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5881: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5882
	.L__pc.5882: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5883
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5883: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5884: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5885: Dma_PatchSrc (.L__pc.5885.LD), (.L__movme_tmp.1), (.L__pc.5885.LD)
	.p2align 4
	.L__pc.5885.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5886
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5886: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5887
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5887: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5888: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5889: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5890: Dma_PatchSrc (.L__pc.5890.LD), (.L__movme_tmp.1), (.L__pc.5890.LD)
	.p2align 4
	.L__pc.5890.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5891
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5891: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5892
	
	.L__pc.5892: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5893
	
	.p2align 4
	.L__pc.5893: Dma_PatchDst (.L__pc.5893.ST), (.L__movme_cp.67), (.L__pc.5893.ST)
	.L__pc.5893.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5894
	
	.L__pc.5894: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5895
	
	.p2align 4
	.L__pc.5895: Dma_PatchDst (.L__pc.5895.ST), (.L__movme_cp.24), (.L__pc.5895.ST)
	.L__pc.5895.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5896
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5896: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5897
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5897: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5898
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5898: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5899
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5899: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5900
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.5900: Dma_PatchSrc (.L__pc.5900.LD), (.L__movme_cp.68), (.L__pc.5900.LD)
	.p2align 4
	.L__pc.5900.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5901
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5901: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.5902
	.L__pc.5902: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.5903
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5903: Dma_PatchSrc (.L__pc.5903.LD), (.L__movme_cp.24), (.L__pc.5903.LD)
	.p2align 4
	.L__pc.5903.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5904
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5904: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.5905
	.L__pc.5905: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.5906
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5906: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5907: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5908: Dma_PatchSrc (.L__pc.5908.LD), (.L__movme_tmp.1), (.L__pc.5908.LD)
	.p2align 4
	.L__pc.5908.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5909
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5909: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5910
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.5910: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.5911: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.5912: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5913: Dma_PatchSrc (.L__pc.5913.LD), (.L__movme_tmp.1), (.L__pc.5913.LD)
	.p2align 4
	.L__pc.5913.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5914
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5914: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5915
	
	.L__pc.5915: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.5916
	
	.p2align 4
	.L__pc.5916: Dma_PatchDst (.L__pc.5916.ST), (.L__movme_cp.68), (.L__pc.5916.ST)
	.L__pc.5916.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5917
	
	.L__pc.5917: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.5918
	
	.p2align 4
	.L__pc.5918: Dma_PatchDst (.L__pc.5918.ST), (.L__movme_cp.24), (.L__pc.5918.ST)
	.L__pc.5918.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5919
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5919: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5920
	
	.p2align 4
	.L__pc.5920: Dma_PatchDst (.L__pc.5920.ST), (.L__movme_cp.24), (.L__pc.5920.ST)
	.L__pc.5920.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5921
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.5921: Dma_PatchSrc (.L__pc.5921.LD), (.L__movme_cp.60), (.L__pc.5921.LD)
	.p2align 4
	.L__pc.5921.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5922
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5922: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5923
	
	.L__pc.5923: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5924
	
	.p2align 4
	.L__pc.5924: Dma_PatchDst (.L__pc.5924.ST), (.L__movme_cp.21), (.L__pc.5924.ST)
	.L__pc.5924.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5925
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.5925: Dma_PatchSrc (.L__pc.5925.LD), (.L__movme_cp.58), (.L__pc.5925.LD)
	.p2align 4
	.L__pc.5925.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5926
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5926: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5927
	
	.L__pc.5927: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.5928
	
	.p2align 4
	.L__pc.5928: Dma_PatchDst (.L__pc.5928.ST), (.L__movme_cp.22), (.L__pc.5928.ST)
	.L__pc.5928.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5929
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5929: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5930
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5930: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.5931
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.5931: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.5932
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5932: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5933
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.5933: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.5934
	
	.p2align 4
	.L__pc.5934: Dma_PatchDst (.L__pc.5934.ST), (.L__movme_cp.24), (.L__pc.5934.ST)
	.L__pc.5934.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5935
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.5935: Dma_PatchSrc (.L__pc.5935.LD), (.L__movme_cp.25), (.L__pc.5935.LD)
	.p2align 4
	.L__pc.5935.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5936
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5936: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5937
	.L__pc.5937: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5938
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.5938: Dma_PatchSrc (.L__pc.5938.LD), (.L__movme_cp.26), (.L__pc.5938.LD)
	.p2align 4
	.L__pc.5938.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5939
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5939: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5940
	.L__pc.5940: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5941
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5941: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5942: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5943: Dma_PatchSrc (.L__pc.5943.LD), (.L__movme_tmp.1), (.L__pc.5943.LD)
	.p2align 4
	.L__pc.5943.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5944
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5944: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5945
	.L__pc.5945: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5946
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5946: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5947: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5948: Dma_PatchSrc (.L__pc.5948.LD), (.L__movme_tmp.1), (.L__pc.5948.LD)
	.p2align 4
	.L__pc.5948.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5949
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5949: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5950
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5950: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5951: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5952: Dma_PatchSrc (.L__pc.5952.LD), (.L__movme_tmp.1), (.L__pc.5952.LD)
	.p2align 4
	.L__pc.5952.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5953
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5953: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5954
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5954: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5955: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5956: Dma_PatchSrc (.L__pc.5956.LD), (.L__movme_tmp.1), (.L__pc.5956.LD)
	.p2align 4
	.L__pc.5956.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5957
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5957: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5958
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5958: Dma_PatchSrc (.L__pc.5958.LD), (.L__movme_cp.24), (.L__pc.5958.LD)
	.p2align 4
	.L__pc.5958.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5959
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5959: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5960
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5960: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5961: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5962: Dma_PatchSrc (.L__pc.5962.LD), (.L__movme_tmp.1), (.L__pc.5962.LD)
	.p2align 4
	.L__pc.5962.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5963
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5963: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5964
	
	.L__pc.5964: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5965
	
	.p2align 4
	.L__pc.5965: Dma_PatchDst (.L__pc.5965.ST), (.L__movme_cp.69), (.L__pc.5965.ST)
	.L__pc.5965.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5966
	
	.L__pc.5966: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.5967
	
	.p2align 4
	.L__pc.5967: Dma_PatchDst (.L__pc.5967.ST), (.L__movme_cp.54), (.L__pc.5967.ST)
	.L__pc.5967.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5968
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.5968: Dma_PatchSrc (.L__pc.5968.LD), (.L__movme_cp.30), (.L__pc.5968.LD)
	.p2align 4
	.L__pc.5968.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5969
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.5969: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.5970
	.L__pc.5970: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.5971
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.5971: Dma_PatchSrc (.L__pc.5971.LD), (.L__movme_cp.31), (.L__pc.5971.LD)
	.p2align 4
	.L__pc.5971.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5972
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5972: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5973
	.L__pc.5973: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5974
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.5974: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5975: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5976: Dma_PatchSrc (.L__pc.5976.LD), (.L__movme_tmp.1), (.L__pc.5976.LD)
	.p2align 4
	.L__pc.5976.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5977
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5977: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.5978
	.L__pc.5978: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.5979
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.5979: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5980: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5981: Dma_PatchSrc (.L__pc.5981.LD), (.L__movme_tmp.1), (.L__pc.5981.LD)
	.p2align 4
	.L__pc.5981.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5982
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5982: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5983
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5983: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5984: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5985: Dma_PatchSrc (.L__pc.5985.LD), (.L__movme_tmp.1), (.L__pc.5985.LD)
	.p2align 4
	.L__pc.5985.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5986
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5986: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5987
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.5987: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5988: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5989: Dma_PatchSrc (.L__pc.5989.LD), (.L__movme_tmp.1), (.L__pc.5989.LD)
	.p2align 4
	.L__pc.5989.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5990
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5990: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5991
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.5991: Dma_PatchSrc (.L__pc.5991.LD), (.L__movme_cp.24), (.L__pc.5991.LD)
	.p2align 4
	.L__pc.5991.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5992
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.5992: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.5993
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.5993: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.5994: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.5995: Dma_PatchSrc (.L__pc.5995.LD), (.L__movme_tmp.1), (.L__pc.5995.LD)
	.p2align 4
	.L__pc.5995.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.5996
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.5996: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.5997
	
	.L__pc.5997: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.5998
	
	.p2align 4
	.L__pc.5998: Dma_PatchDst (.L__pc.5998.ST), (.L__movme_cp.70), (.L__pc.5998.ST)
	.L__pc.5998.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.5999
	
	.L__pc.5999: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6000
	
	.p2align 4
	.L__pc.6000: Dma_PatchDst (.L__pc.6000.ST), (.L__movme_cp.54), (.L__pc.6000.ST)
	.L__pc.6000.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6001
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6001: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6002
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6002: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6003
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6003: Dma_PatchSrc (.L__pc.6003.LD), (.L__movme_cp.24), (.L__pc.6003.LD)
	.p2align 4
	.L__pc.6003.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6004
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6004: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6005
	.L__pc.6005: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6006
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.6006: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6007: Dma_PatchSrc (.L__pc.6007.LD), (.L__movme_tmp.1), (.L__pc.6007.LD)
	.p2align 4
	.L__pc.6007.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6008
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6008: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6009
	.L__pc.6009: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6010
	
	.L__pc.6010: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6011
	
	.p2align 4
	.L__pc.6011: Dma_PatchDst (.L__pc.6011.ST), (.L__movme_cp.72), (.L__pc.6011.ST)
	.L__pc.6011.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6012
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.6012: Dma_PatchSrc (.L__pc.6012.LD), (.L__movme_cp.72), (.L__pc.6012.LD)
	.p2align 4
	.L__pc.6012.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6013
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6013: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6014
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6014: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6015: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6016: Dma_PatchSrc (.L__pc.6016.LD), (.L__movme_tmp.1), (.L__pc.6016.LD)
	.p2align 4
	.L__pc.6016.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6017
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6017: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6018
	
	.L__pc.6018: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6019
	
	.p2align 4
	.L__pc.6019: Dma_PatchDst (.L__pc.6019.ST), (.L__movme_cp.74), (.L__pc.6019.ST)
	.L__pc.6019.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6020
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6020: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6021: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6022: Dma_PatchSrc (.L__pc.6022.LD), (.L__movme_tmp.1), (.L__pc.6022.LD)
	.p2align 4
	.L__pc.6022.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6023
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6023: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6024
	
	.L__pc.6024: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6025
	
	.p2align 4
	.L__pc.6025: Dma_PatchDst (.L__pc.6025.ST), (.L__movme_cp.76), (.L__pc.6025.ST)
	.L__pc.6025.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6026
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.6026: Dma_PatchSrc (.L__pc.6026.LD), (.L__movme_cp.74), (.L__pc.6026.LD)
	.p2align 4
	.L__pc.6026.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6027
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6027: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6028
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.6028: Dma_PatchSrc (.L__pc.6028.LD), ((.L__movme.reg.eax+0)), (.L__pc.6028.LD)
	.p2align 4
	.L__pc.6028.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6029
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6029: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6030
	
	.L__pc.6030: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6031
	
	.p2align 4
	.L__pc.6031: Dma_PatchDst (.L__pc.6031.ST), (.L__movme_cp.77), (.L__pc.6031.ST)
	.L__pc.6031.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6032
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.6032: Dma_PatchSrc (.L__pc.6032.LD), (.L__movme_cp.77), (.L__pc.6032.LD)
	.p2align 4
	.L__pc.6032.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6033
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6033: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6034
	
	.L__pc.6034: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6035
	
	.p2align 4
	.L__pc.6035: Dma_PatchDst (.L__pc.6035.ST), (.L__movme_cp.21), (.L__pc.6035.ST)
	.L__pc.6035.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6036
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.6036: Dma_PatchSrc (.L__pc.6036.LD), (.L__movme_cp.58), (.L__pc.6036.LD)
	.p2align 4
	.L__pc.6036.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6037
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6037: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6038
	
	.L__pc.6038: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6039
	
	.p2align 4
	.L__pc.6039: Dma_PatchDst (.L__pc.6039.ST), (.L__movme_cp.22), (.L__pc.6039.ST)
	.L__pc.6039.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6040
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6040: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6041
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6041: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6042
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6042: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6043
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6043: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6044
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.6044: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.6045
	
	.p2align 4
	.L__pc.6045: Dma_PatchDst (.L__pc.6045.ST), (.L__movme_cp.24), (.L__pc.6045.ST)
	.L__pc.6045.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6046
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.6046: Dma_PatchSrc (.L__pc.6046.LD), (.L__movme_cp.25), (.L__pc.6046.LD)
	.p2align 4
	.L__pc.6046.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6047
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6047: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6048
	.L__pc.6048: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6049
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.6049: Dma_PatchSrc (.L__pc.6049.LD), (.L__movme_cp.26), (.L__pc.6049.LD)
	.p2align 4
	.L__pc.6049.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6050
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6050: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6051
	.L__pc.6051: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6052
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6052: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6053: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6054: Dma_PatchSrc (.L__pc.6054.LD), (.L__movme_tmp.1), (.L__pc.6054.LD)
	.p2align 4
	.L__pc.6054.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6055
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6055: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6056
	.L__pc.6056: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6057
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6057: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6058: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6059: Dma_PatchSrc (.L__pc.6059.LD), (.L__movme_tmp.1), (.L__pc.6059.LD)
	.p2align 4
	.L__pc.6059.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6060
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6060: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6061
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6061: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6062: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6063: Dma_PatchSrc (.L__pc.6063.LD), (.L__movme_tmp.1), (.L__pc.6063.LD)
	.p2align 4
	.L__pc.6063.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6064
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6064: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6065
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6065: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6066: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6067: Dma_PatchSrc (.L__pc.6067.LD), (.L__movme_tmp.1), (.L__pc.6067.LD)
	.p2align 4
	.L__pc.6067.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6068
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6068: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6069
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6069: Dma_PatchSrc (.L__pc.6069.LD), (.L__movme_cp.24), (.L__pc.6069.LD)
	.p2align 4
	.L__pc.6069.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6070
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6070: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6071
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6071: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6072: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6073: Dma_PatchSrc (.L__pc.6073.LD), (.L__movme_tmp.1), (.L__pc.6073.LD)
	.p2align 4
	.L__pc.6073.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6074
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6074: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6075
	
	.L__pc.6075: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6076
	
	.p2align 4
	.L__pc.6076: Dma_PatchDst (.L__pc.6076.ST), (.L__movme_cp.78), (.L__pc.6076.ST)
	.L__pc.6076.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6077
	
	.L__pc.6077: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6078
	
	.p2align 4
	.L__pc.6078: Dma_PatchDst (.L__pc.6078.ST), (.L__movme_cp.54), (.L__pc.6078.ST)
	.L__pc.6078.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6079
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.6079: Dma_PatchSrc (.L__pc.6079.LD), (.L__movme_cp.30), (.L__pc.6079.LD)
	.p2align 4
	.L__pc.6079.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6080
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6080: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6081
	.L__pc.6081: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6082
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.6082: Dma_PatchSrc (.L__pc.6082.LD), (.L__movme_cp.31), (.L__pc.6082.LD)
	.p2align 4
	.L__pc.6082.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6083
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6083: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6084
	.L__pc.6084: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6085
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6085: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6086: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6087: Dma_PatchSrc (.L__pc.6087.LD), (.L__movme_tmp.1), (.L__pc.6087.LD)
	.p2align 4
	.L__pc.6087.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6088
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6088: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6089
	.L__pc.6089: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6090
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6090: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6091: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6092: Dma_PatchSrc (.L__pc.6092.LD), (.L__movme_tmp.1), (.L__pc.6092.LD)
	.p2align 4
	.L__pc.6092.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6093
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6093: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6094
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6094: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6095: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6096: Dma_PatchSrc (.L__pc.6096.LD), (.L__movme_tmp.1), (.L__pc.6096.LD)
	.p2align 4
	.L__pc.6096.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6097
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6097: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6098
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6098: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6099: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6100: Dma_PatchSrc (.L__pc.6100.LD), (.L__movme_tmp.1), (.L__pc.6100.LD)
	.p2align 4
	.L__pc.6100.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6101
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6101: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6102
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6102: Dma_PatchSrc (.L__pc.6102.LD), (.L__movme_cp.24), (.L__pc.6102.LD)
	.p2align 4
	.L__pc.6102.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6103
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6103: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6104
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6104: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6105: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6106: Dma_PatchSrc (.L__pc.6106.LD), (.L__movme_tmp.1), (.L__pc.6106.LD)
	.p2align 4
	.L__pc.6106.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6107
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6107: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6108
	
	.L__pc.6108: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6109
	
	.p2align 4
	.L__pc.6109: Dma_PatchDst (.L__pc.6109.ST), (.L__movme_cp.79), (.L__pc.6109.ST)
	.L__pc.6109.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6110
	
	.L__pc.6110: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6111
	
	.p2align 4
	.L__pc.6111: Dma_PatchDst (.L__pc.6111.ST), (.L__movme_cp.54), (.L__pc.6111.ST)
	.L__pc.6111.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6112
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.6112: Dma_PatchSrc (.L__pc.6112.LD), (.L__movme_cp.74), (.L__pc.6112.LD)
	.p2align 4
	.L__pc.6112.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6113
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6113: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6114
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.6114: Dma_PatchSrc (.L__pc.6114.LD), (.L__movme_cp.77), (.L__pc.6114.LD)
	.p2align 4
	.L__pc.6114.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6115
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6115: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6116
	
	.L__pc.6116: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6117
	
	.p2align 4
	.L__pc.6117: Dma_PatchDst (.L__pc.6117.ST), ((.L__movme.reg.eax+0)), (.L__pc.6117.ST)
	.L__pc.6117.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6118
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.6118: Dma_PatchSrc (.L__pc.6118.LD), (.L__movme_cp.76), (.L__pc.6118.LD)
	.p2align 4
	.L__pc.6118.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6119
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6119: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6120
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.6120: Dma_PatchSrc (.L__pc.6120.LD), ((.L__movme.reg.eax+0)), (.L__pc.6120.LD)
	.p2align 4
	.L__pc.6120.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6121
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6121: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6122
	
	.L__pc.6122: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6123
	
	.p2align 4
	.L__pc.6123: Dma_PatchDst (.L__pc.6123.ST), (.L__movme_cp.80), (.L__pc.6123.ST)
	.L__pc.6123.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6124
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6124: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6125
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6125: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6126
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.6126: Dma_PatchSrc (.L__pc.6126.LD), (.L__movme_cp.98), (.L__pc.6126.LD)
	.p2align 4
	.L__pc.6126.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6127
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6127: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6128
	.L__pc.6128: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6129
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.90 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.6129: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6130: Dma_PatchSrc (.L__pc.6130.LD), (.L__movme_tmp.1), (.L__pc.6130.LD)
	.p2align 4
	.L__pc.6130.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6131
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6131: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6132
	.L__pc.6132: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6133
	
	.L__pc.6133: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6134
	
	.p2align 4
	.L__pc.6134: Dma_PatchDst (.L__pc.6134.ST), (.L__movme_cp.98), (.L__pc.6134.ST)
	.L__pc.6134.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6135
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.6135: Dma_PatchSrc (.L__pc.6135.LD), (.L__movme_cp.76), (.L__pc.6135.LD)
	.p2align 4
	.L__pc.6135.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6136
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6136: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6137
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.6137: Dma_PatchSrc (.L__pc.6137.LD), (.L__movme_cp.80), (.L__pc.6137.LD)
	.p2align 4
	.L__pc.6137.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6138
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6138: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6139
	
	.L__pc.6139: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6140
	
	.p2align 4
	.L__pc.6140: Dma_PatchDst (.L__pc.6140.ST), ((.L__movme.reg.eax+0)), (.L__pc.6140.ST)
	.L__pc.6140.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6141
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6141: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6142
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6142: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6143
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.6143: Dma_PatchSrc (.L__pc.6143.LD), (.L__movme_cp.97), (.L__pc.6143.LD)
	.p2align 4
	.L__pc.6143.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6144
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6144: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6145
	.L__pc.6145: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6146
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6146: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.91 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6147: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6148: Dma_PatchSrc (.L__pc.6148.LD), (.L__movme_tmp.1), (.L__pc.6148.LD)
	.p2align 4
	.L__pc.6148.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6149
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6149: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6150
	
	.L__pc.6150: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6151
	
	.p2align 4
	.L__pc.6151: Dma_PatchDst (.L__pc.6151.ST), (.L__movme_cp.24), (.L__pc.6151.ST)
	.L__pc.6151.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6152
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6152: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6153
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6153: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6154
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6154: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6155
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6155: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6156
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.6156: Dma_PatchSrc (.L__pc.6156.LD), (.L__movme_cp.63), (.L__pc.6156.LD)
	.p2align 4
	.L__pc.6156.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6157
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6157: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6158
	.L__pc.6158: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6159
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6159: Dma_PatchSrc (.L__pc.6159.LD), (.L__movme_cp.24), (.L__pc.6159.LD)
	.p2align 4
	.L__pc.6159.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6160
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6160: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6161
	.L__pc.6161: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6162
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6162: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6163: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6164: Dma_PatchSrc (.L__pc.6164.LD), (.L__movme_tmp.1), (.L__pc.6164.LD)
	.p2align 4
	.L__pc.6164.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6165
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6165: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6166
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6166: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6167: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6168: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6169: Dma_PatchSrc (.L__pc.6169.LD), (.L__movme_tmp.1), (.L__pc.6169.LD)
	.p2align 4
	.L__pc.6169.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6170
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6170: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6171
	
	.L__pc.6171: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6172
	
	.p2align 4
	.L__pc.6172: Dma_PatchDst (.L__pc.6172.ST), (.L__movme_cp.63), (.L__pc.6172.ST)
	.L__pc.6172.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6173
	
	.L__pc.6173: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6174
	
	.p2align 4
	.L__pc.6174: Dma_PatchDst (.L__pc.6174.ST), (.L__movme_cp.24), (.L__pc.6174.ST)
	.L__pc.6174.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6175
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6175: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6176
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6176: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6177
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6177: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6178
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6178: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6179
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.6179: Dma_PatchSrc (.L__pc.6179.LD), (.L__movme_cp.66), (.L__pc.6179.LD)
	.p2align 4
	.L__pc.6179.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6180
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6180: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6181
	.L__pc.6181: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6182
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6182: Dma_PatchSrc (.L__pc.6182.LD), (.L__movme_cp.24), (.L__pc.6182.LD)
	.p2align 4
	.L__pc.6182.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6183
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6183: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6184
	.L__pc.6184: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6185
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6185: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6186: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6187: Dma_PatchSrc (.L__pc.6187.LD), (.L__movme_tmp.1), (.L__pc.6187.LD)
	.p2align 4
	.L__pc.6187.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6188
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6188: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6189
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6189: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6190: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6191: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6192: Dma_PatchSrc (.L__pc.6192.LD), (.L__movme_tmp.1), (.L__pc.6192.LD)
	.p2align 4
	.L__pc.6192.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6193
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6193: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6194
	
	.L__pc.6194: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6195
	
	.p2align 4
	.L__pc.6195: Dma_PatchDst (.L__pc.6195.ST), (.L__movme_cp.66), (.L__pc.6195.ST)
	.L__pc.6195.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6196
	
	.L__pc.6196: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6197
	
	.p2align 4
	.L__pc.6197: Dma_PatchDst (.L__pc.6197.ST), (.L__movme_cp.24), (.L__pc.6197.ST)
	.L__pc.6197.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6198
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6198: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6199
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6199: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6200
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6200: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6201
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6201: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6202
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.6202: Dma_PatchSrc (.L__pc.6202.LD), (.L__movme_cp.67), (.L__pc.6202.LD)
	.p2align 4
	.L__pc.6202.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6203
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6203: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6204
	.L__pc.6204: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6205
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6205: Dma_PatchSrc (.L__pc.6205.LD), (.L__movme_cp.24), (.L__pc.6205.LD)
	.p2align 4
	.L__pc.6205.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6206
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6206: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6207
	.L__pc.6207: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6208
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6208: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6209: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6210: Dma_PatchSrc (.L__pc.6210.LD), (.L__movme_tmp.1), (.L__pc.6210.LD)
	.p2align 4
	.L__pc.6210.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6211
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6211: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6212
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6212: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6213: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6214: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6215: Dma_PatchSrc (.L__pc.6215.LD), (.L__movme_tmp.1), (.L__pc.6215.LD)
	.p2align 4
	.L__pc.6215.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6216
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6216: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6217
	
	.L__pc.6217: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6218
	
	.p2align 4
	.L__pc.6218: Dma_PatchDst (.L__pc.6218.ST), (.L__movme_cp.67), (.L__pc.6218.ST)
	.L__pc.6218.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6219
	
	.L__pc.6219: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6220
	
	.p2align 4
	.L__pc.6220: Dma_PatchDst (.L__pc.6220.ST), (.L__movme_cp.24), (.L__pc.6220.ST)
	.L__pc.6220.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6221
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6221: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6222
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6222: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6223
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6223: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6224
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6224: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6225
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.6225: Dma_PatchSrc (.L__pc.6225.LD), (.L__movme_cp.68), (.L__pc.6225.LD)
	.p2align 4
	.L__pc.6225.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6226
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6226: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6227
	.L__pc.6227: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6228
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6228: Dma_PatchSrc (.L__pc.6228.LD), (.L__movme_cp.24), (.L__pc.6228.LD)
	.p2align 4
	.L__pc.6228.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6229
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6229: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6230
	.L__pc.6230: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6231
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6231: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6232: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6233: Dma_PatchSrc (.L__pc.6233.LD), (.L__movme_tmp.1), (.L__pc.6233.LD)
	.p2align 4
	.L__pc.6233.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6234
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6234: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6235
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6235: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6236: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6237: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6238: Dma_PatchSrc (.L__pc.6238.LD), (.L__movme_tmp.1), (.L__pc.6238.LD)
	.p2align 4
	.L__pc.6238.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6239
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6239: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6240
	
	.L__pc.6240: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6241
	
	.p2align 4
	.L__pc.6241: Dma_PatchDst (.L__pc.6241.ST), (.L__movme_cp.68), (.L__pc.6241.ST)
	.L__pc.6241.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6242
	
	.L__pc.6242: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6243
	
	.p2align 4
	.L__pc.6243: Dma_PatchDst (.L__pc.6243.ST), (.L__movme_cp.24), (.L__pc.6243.ST)
	.L__pc.6243.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6244
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6244: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6245
	
	.p2align 4
	.L__pc.6245: Dma_PatchDst (.L__pc.6245.ST), (.L__movme_cp.24), (.L__pc.6245.ST)
	.L__pc.6245.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6246
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.6246: Dma_PatchSrc (.L__pc.6246.LD), (.L__movme_cp.60), (.L__pc.6246.LD)
	.p2align 4
	.L__pc.6246.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6247
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6247: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6248
	
	.L__pc.6248: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6249
	
	.p2align 4
	.L__pc.6249: Dma_PatchDst (.L__pc.6249.ST), (.L__movme_cp.21), (.L__pc.6249.ST)
	.L__pc.6249.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6250
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.6250: Dma_PatchSrc (.L__pc.6250.LD), (.L__movme_cp.58), (.L__pc.6250.LD)
	.p2align 4
	.L__pc.6250.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6251
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6251: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6252
	
	.L__pc.6252: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6253
	
	.p2align 4
	.L__pc.6253: Dma_PatchDst (.L__pc.6253.ST), (.L__movme_cp.22), (.L__pc.6253.ST)
	.L__pc.6253.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6254
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6254: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6255
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6255: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6256
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6256: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6257
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6257: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6258
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.6258: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.6259
	
	.p2align 4
	.L__pc.6259: Dma_PatchDst (.L__pc.6259.ST), (.L__movme_cp.24), (.L__pc.6259.ST)
	.L__pc.6259.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6260
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.6260: Dma_PatchSrc (.L__pc.6260.LD), (.L__movme_cp.25), (.L__pc.6260.LD)
	.p2align 4
	.L__pc.6260.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6261
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6261: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6262
	.L__pc.6262: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6263
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.6263: Dma_PatchSrc (.L__pc.6263.LD), (.L__movme_cp.26), (.L__pc.6263.LD)
	.p2align 4
	.L__pc.6263.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6264
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6264: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6265
	.L__pc.6265: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6266
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6266: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6267: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6268: Dma_PatchSrc (.L__pc.6268.LD), (.L__movme_tmp.1), (.L__pc.6268.LD)
	.p2align 4
	.L__pc.6268.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6269
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6269: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6270
	.L__pc.6270: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6271
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6271: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6272: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6273: Dma_PatchSrc (.L__pc.6273.LD), (.L__movme_tmp.1), (.L__pc.6273.LD)
	.p2align 4
	.L__pc.6273.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6274
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6274: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6275
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6275: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6276: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6277: Dma_PatchSrc (.L__pc.6277.LD), (.L__movme_tmp.1), (.L__pc.6277.LD)
	.p2align 4
	.L__pc.6277.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6278
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6278: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6279
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6279: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6280: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6281: Dma_PatchSrc (.L__pc.6281.LD), (.L__movme_tmp.1), (.L__pc.6281.LD)
	.p2align 4
	.L__pc.6281.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6282
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6282: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6283
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6283: Dma_PatchSrc (.L__pc.6283.LD), (.L__movme_cp.24), (.L__pc.6283.LD)
	.p2align 4
	.L__pc.6283.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6284
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6284: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6285
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6285: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6286: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6287: Dma_PatchSrc (.L__pc.6287.LD), (.L__movme_tmp.1), (.L__pc.6287.LD)
	.p2align 4
	.L__pc.6287.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6288
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6288: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6289
	
	.L__pc.6289: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6290
	
	.p2align 4
	.L__pc.6290: Dma_PatchDst (.L__pc.6290.ST), (.L__movme_cp.69), (.L__pc.6290.ST)
	.L__pc.6290.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6291
	
	.L__pc.6291: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6292
	
	.p2align 4
	.L__pc.6292: Dma_PatchDst (.L__pc.6292.ST), (.L__movme_cp.54), (.L__pc.6292.ST)
	.L__pc.6292.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6293
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.6293: Dma_PatchSrc (.L__pc.6293.LD), (.L__movme_cp.30), (.L__pc.6293.LD)
	.p2align 4
	.L__pc.6293.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6294
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6294: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6295
	.L__pc.6295: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6296
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.6296: Dma_PatchSrc (.L__pc.6296.LD), (.L__movme_cp.31), (.L__pc.6296.LD)
	.p2align 4
	.L__pc.6296.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6297
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6297: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6298
	.L__pc.6298: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6299
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6299: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6300: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6301: Dma_PatchSrc (.L__pc.6301.LD), (.L__movme_tmp.1), (.L__pc.6301.LD)
	.p2align 4
	.L__pc.6301.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6302
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6302: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6303
	.L__pc.6303: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6304
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6304: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6305: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6306: Dma_PatchSrc (.L__pc.6306.LD), (.L__movme_tmp.1), (.L__pc.6306.LD)
	.p2align 4
	.L__pc.6306.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6307
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6307: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6308
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6308: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6309: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6310: Dma_PatchSrc (.L__pc.6310.LD), (.L__movme_tmp.1), (.L__pc.6310.LD)
	.p2align 4
	.L__pc.6310.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6311
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6311: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6312
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6312: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6313: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6314: Dma_PatchSrc (.L__pc.6314.LD), (.L__movme_tmp.1), (.L__pc.6314.LD)
	.p2align 4
	.L__pc.6314.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6315
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6315: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6316
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6316: Dma_PatchSrc (.L__pc.6316.LD), (.L__movme_cp.24), (.L__pc.6316.LD)
	.p2align 4
	.L__pc.6316.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6317
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6317: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6318
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6318: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6319: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6320: Dma_PatchSrc (.L__pc.6320.LD), (.L__movme_tmp.1), (.L__pc.6320.LD)
	.p2align 4
	.L__pc.6320.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6321
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6321: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6322
	
	.L__pc.6322: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6323
	
	.p2align 4
	.L__pc.6323: Dma_PatchDst (.L__pc.6323.ST), (.L__movme_cp.70), (.L__pc.6323.ST)
	.L__pc.6323.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6324
	
	.L__pc.6324: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6325
	
	.p2align 4
	.L__pc.6325: Dma_PatchDst (.L__pc.6325.ST), (.L__movme_cp.54), (.L__pc.6325.ST)
	.L__pc.6325.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6326
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6326: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6327
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6327: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6328
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6328: Dma_PatchSrc (.L__pc.6328.LD), (.L__movme_cp.24), (.L__pc.6328.LD)
	.p2align 4
	.L__pc.6328.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6329
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6329: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6330
	.L__pc.6330: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6331
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.6331: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6332: Dma_PatchSrc (.L__pc.6332.LD), (.L__movme_tmp.1), (.L__pc.6332.LD)
	.p2align 4
	.L__pc.6332.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6333
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6333: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6334
	.L__pc.6334: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6335
	
	.L__pc.6335: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6336
	
	.p2align 4
	.L__pc.6336: Dma_PatchDst (.L__pc.6336.ST), (.L__movme_cp.72), (.L__pc.6336.ST)
	.L__pc.6336.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6337
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.6337: Dma_PatchSrc (.L__pc.6337.LD), (.L__movme_cp.72), (.L__pc.6337.LD)
	.p2align 4
	.L__pc.6337.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6338
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6338: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6339
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6339: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6340: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6341: Dma_PatchSrc (.L__pc.6341.LD), (.L__movme_tmp.1), (.L__pc.6341.LD)
	.p2align 4
	.L__pc.6341.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6342
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6342: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6343
	
	.L__pc.6343: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6344
	
	.p2align 4
	.L__pc.6344: Dma_PatchDst (.L__pc.6344.ST), (.L__movme_cp.74), (.L__pc.6344.ST)
	.L__pc.6344.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6345
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6345: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6346: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6347: Dma_PatchSrc (.L__pc.6347.LD), (.L__movme_tmp.1), (.L__pc.6347.LD)
	.p2align 4
	.L__pc.6347.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6348
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6348: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6349
	
	.L__pc.6349: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6350
	
	.p2align 4
	.L__pc.6350: Dma_PatchDst (.L__pc.6350.ST), (.L__movme_cp.76), (.L__pc.6350.ST)
	.L__pc.6350.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6351
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.6351: Dma_PatchSrc (.L__pc.6351.LD), (.L__movme_cp.74), (.L__pc.6351.LD)
	.p2align 4
	.L__pc.6351.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6352
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6352: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6353
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.6353: Dma_PatchSrc (.L__pc.6353.LD), ((.L__movme.reg.eax+0)), (.L__pc.6353.LD)
	.p2align 4
	.L__pc.6353.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6354
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6354: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6355
	
	.L__pc.6355: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6356
	
	.p2align 4
	.L__pc.6356: Dma_PatchDst (.L__pc.6356.ST), (.L__movme_cp.77), (.L__pc.6356.ST)
	.L__pc.6356.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6357
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.6357: Dma_PatchSrc (.L__pc.6357.LD), (.L__movme_cp.77), (.L__pc.6357.LD)
	.p2align 4
	.L__pc.6357.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6358
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6358: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6359
	
	.L__pc.6359: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6360
	
	.p2align 4
	.L__pc.6360: Dma_PatchDst (.L__pc.6360.ST), (.L__movme_cp.21), (.L__pc.6360.ST)
	.L__pc.6360.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6361
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.6361: Dma_PatchSrc (.L__pc.6361.LD), (.L__movme_cp.58), (.L__pc.6361.LD)
	.p2align 4
	.L__pc.6361.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6362
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6362: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6363
	
	.L__pc.6363: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6364
	
	.p2align 4
	.L__pc.6364: Dma_PatchDst (.L__pc.6364.ST), (.L__movme_cp.22), (.L__pc.6364.ST)
	.L__pc.6364.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6365
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6365: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6366
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6366: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6367
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6367: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6368
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6368: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6369
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.6369: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.6370
	
	.p2align 4
	.L__pc.6370: Dma_PatchDst (.L__pc.6370.ST), (.L__movme_cp.24), (.L__pc.6370.ST)
	.L__pc.6370.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6371
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.6371: Dma_PatchSrc (.L__pc.6371.LD), (.L__movme_cp.25), (.L__pc.6371.LD)
	.p2align 4
	.L__pc.6371.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6372
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6372: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6373
	.L__pc.6373: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6374
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.6374: Dma_PatchSrc (.L__pc.6374.LD), (.L__movme_cp.26), (.L__pc.6374.LD)
	.p2align 4
	.L__pc.6374.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6375
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6375: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6376
	.L__pc.6376: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6377
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6377: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6378: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6379: Dma_PatchSrc (.L__pc.6379.LD), (.L__movme_tmp.1), (.L__pc.6379.LD)
	.p2align 4
	.L__pc.6379.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6380
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6380: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6381
	.L__pc.6381: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6382
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6382: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6383: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6384: Dma_PatchSrc (.L__pc.6384.LD), (.L__movme_tmp.1), (.L__pc.6384.LD)
	.p2align 4
	.L__pc.6384.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6385
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6385: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6386
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6386: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6387: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6388: Dma_PatchSrc (.L__pc.6388.LD), (.L__movme_tmp.1), (.L__pc.6388.LD)
	.p2align 4
	.L__pc.6388.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6389
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6389: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6390
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6390: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6391: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6392: Dma_PatchSrc (.L__pc.6392.LD), (.L__movme_tmp.1), (.L__pc.6392.LD)
	.p2align 4
	.L__pc.6392.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6393
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6393: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6394
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6394: Dma_PatchSrc (.L__pc.6394.LD), (.L__movme_cp.24), (.L__pc.6394.LD)
	.p2align 4
	.L__pc.6394.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6395
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6395: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6396
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6396: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6397: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6398: Dma_PatchSrc (.L__pc.6398.LD), (.L__movme_tmp.1), (.L__pc.6398.LD)
	.p2align 4
	.L__pc.6398.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6399
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6399: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6400
	
	.L__pc.6400: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6401
	
	.p2align 4
	.L__pc.6401: Dma_PatchDst (.L__pc.6401.ST), (.L__movme_cp.78), (.L__pc.6401.ST)
	.L__pc.6401.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6402
	
	.L__pc.6402: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6403
	
	.p2align 4
	.L__pc.6403: Dma_PatchDst (.L__pc.6403.ST), (.L__movme_cp.54), (.L__pc.6403.ST)
	.L__pc.6403.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6404
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.6404: Dma_PatchSrc (.L__pc.6404.LD), (.L__movme_cp.30), (.L__pc.6404.LD)
	.p2align 4
	.L__pc.6404.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6405
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6405: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6406
	.L__pc.6406: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6407
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.6407: Dma_PatchSrc (.L__pc.6407.LD), (.L__movme_cp.31), (.L__pc.6407.LD)
	.p2align 4
	.L__pc.6407.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6408
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6408: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6409
	.L__pc.6409: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6410
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6410: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6411: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6412: Dma_PatchSrc (.L__pc.6412.LD), (.L__movme_tmp.1), (.L__pc.6412.LD)
	.p2align 4
	.L__pc.6412.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6413
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6413: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6414
	.L__pc.6414: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6415
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6415: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6416: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6417: Dma_PatchSrc (.L__pc.6417.LD), (.L__movme_tmp.1), (.L__pc.6417.LD)
	.p2align 4
	.L__pc.6417.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6418
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6418: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6419
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6419: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6420: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6421: Dma_PatchSrc (.L__pc.6421.LD), (.L__movme_tmp.1), (.L__pc.6421.LD)
	.p2align 4
	.L__pc.6421.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6422
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6422: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6423
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6423: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6424: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6425: Dma_PatchSrc (.L__pc.6425.LD), (.L__movme_tmp.1), (.L__pc.6425.LD)
	.p2align 4
	.L__pc.6425.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6426
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6426: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6427
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6427: Dma_PatchSrc (.L__pc.6427.LD), (.L__movme_cp.24), (.L__pc.6427.LD)
	.p2align 4
	.L__pc.6427.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6428
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6428: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6429
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6429: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6430: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6431: Dma_PatchSrc (.L__pc.6431.LD), (.L__movme_tmp.1), (.L__pc.6431.LD)
	.p2align 4
	.L__pc.6431.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6432
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6432: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6433
	
	.L__pc.6433: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6434
	
	.p2align 4
	.L__pc.6434: Dma_PatchDst (.L__pc.6434.ST), (.L__movme_cp.79), (.L__pc.6434.ST)
	.L__pc.6434.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6435
	
	.L__pc.6435: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6436
	
	.p2align 4
	.L__pc.6436: Dma_PatchDst (.L__pc.6436.ST), (.L__movme_cp.54), (.L__pc.6436.ST)
	.L__pc.6436.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6437
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.6437: Dma_PatchSrc (.L__pc.6437.LD), (.L__movme_cp.74), (.L__pc.6437.LD)
	.p2align 4
	.L__pc.6437.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6438
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6438: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6439
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.6439: Dma_PatchSrc (.L__pc.6439.LD), (.L__movme_cp.77), (.L__pc.6439.LD)
	.p2align 4
	.L__pc.6439.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6440
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6440: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6441
	
	.L__pc.6441: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6442
	
	.p2align 4
	.L__pc.6442: Dma_PatchDst (.L__pc.6442.ST), ((.L__movme.reg.eax+0)), (.L__pc.6442.ST)
	.L__pc.6442.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6443
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.6443: Dma_PatchSrc (.L__pc.6443.LD), (.L__movme_cp.76), (.L__pc.6443.LD)
	.p2align 4
	.L__pc.6443.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6444
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6444: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6445
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.6445: Dma_PatchSrc (.L__pc.6445.LD), ((.L__movme.reg.eax+0)), (.L__pc.6445.LD)
	.p2align 4
	.L__pc.6445.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6446
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6446: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6447
	
	.L__pc.6447: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6448
	
	.p2align 4
	.L__pc.6448: Dma_PatchDst (.L__pc.6448.ST), (.L__movme_cp.80), (.L__pc.6448.ST)
	.L__pc.6448.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6449
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6449: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6450
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6450: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6451
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.6451: Dma_PatchSrc (.L__pc.6451.LD), (.L__movme_cp.98), (.L__pc.6451.LD)
	.p2align 4
	.L__pc.6451.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6452
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6452: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6453
	.L__pc.6453: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6454
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.92 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.6454: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6455: Dma_PatchSrc (.L__pc.6455.LD), (.L__movme_tmp.1), (.L__pc.6455.LD)
	.p2align 4
	.L__pc.6455.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6456
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6456: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6457
	.L__pc.6457: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6458
	
	.L__pc.6458: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6459
	
	.p2align 4
	.L__pc.6459: Dma_PatchDst (.L__pc.6459.ST), (.L__movme_cp.98), (.L__pc.6459.ST)
	.L__pc.6459.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6460
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.6460: Dma_PatchSrc (.L__pc.6460.LD), (.L__movme_cp.76), (.L__pc.6460.LD)
	.p2align 4
	.L__pc.6460.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6461
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6461: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6462
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.6462: Dma_PatchSrc (.L__pc.6462.LD), (.L__movme_cp.80), (.L__pc.6462.LD)
	.p2align 4
	.L__pc.6462.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6463
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6463: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6464
	
	.L__pc.6464: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6465
	
	.p2align 4
	.L__pc.6465: Dma_PatchDst (.L__pc.6465.ST), ((.L__movme.reg.eax+0)), (.L__pc.6465.ST)
	.L__pc.6465.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6466
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6466: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6467
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6467: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6468
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.6468: Dma_PatchSrc (.L__pc.6468.LD), (.L__movme_cp.97), (.L__pc.6468.LD)
	.p2align 4
	.L__pc.6468.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6469
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6469: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6470
	.L__pc.6470: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6471
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6471: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.93 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6472: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6473: Dma_PatchSrc (.L__pc.6473.LD), (.L__movme_tmp.1), (.L__pc.6473.LD)
	.p2align 4
	.L__pc.6473.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6474
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6474: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6475
	
	.L__pc.6475: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6476
	
	.p2align 4
	.L__pc.6476: Dma_PatchDst (.L__pc.6476.ST), (.L__movme_cp.24), (.L__pc.6476.ST)
	.L__pc.6476.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6477
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6477: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6478
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6478: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6479
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6479: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6480
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6480: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6481
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.6481: Dma_PatchSrc (.L__pc.6481.LD), (.L__movme_cp.63), (.L__pc.6481.LD)
	.p2align 4
	.L__pc.6481.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6482
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6482: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6483
	.L__pc.6483: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6484
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6484: Dma_PatchSrc (.L__pc.6484.LD), (.L__movme_cp.24), (.L__pc.6484.LD)
	.p2align 4
	.L__pc.6484.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6485
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6485: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6486
	.L__pc.6486: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6487
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6487: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6488: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6489: Dma_PatchSrc (.L__pc.6489.LD), (.L__movme_tmp.1), (.L__pc.6489.LD)
	.p2align 4
	.L__pc.6489.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6490
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6490: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6491
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6491: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6492: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6493: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6494: Dma_PatchSrc (.L__pc.6494.LD), (.L__movme_tmp.1), (.L__pc.6494.LD)
	.p2align 4
	.L__pc.6494.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6495
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6495: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6496
	
	.L__pc.6496: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6497
	
	.p2align 4
	.L__pc.6497: Dma_PatchDst (.L__pc.6497.ST), (.L__movme_cp.63), (.L__pc.6497.ST)
	.L__pc.6497.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6498
	
	.L__pc.6498: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6499
	
	.p2align 4
	.L__pc.6499: Dma_PatchDst (.L__pc.6499.ST), (.L__movme_cp.24), (.L__pc.6499.ST)
	.L__pc.6499.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6500
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6500: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6501
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6501: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6502
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6502: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6503
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6503: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6504
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.6504: Dma_PatchSrc (.L__pc.6504.LD), (.L__movme_cp.66), (.L__pc.6504.LD)
	.p2align 4
	.L__pc.6504.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6505
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6505: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6506
	.L__pc.6506: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6507
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6507: Dma_PatchSrc (.L__pc.6507.LD), (.L__movme_cp.24), (.L__pc.6507.LD)
	.p2align 4
	.L__pc.6507.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6508
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6508: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6509
	.L__pc.6509: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6510
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6510: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6511: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6512: Dma_PatchSrc (.L__pc.6512.LD), (.L__movme_tmp.1), (.L__pc.6512.LD)
	.p2align 4
	.L__pc.6512.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6513
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6513: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6514
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6514: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6515: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6516: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6517: Dma_PatchSrc (.L__pc.6517.LD), (.L__movme_tmp.1), (.L__pc.6517.LD)
	.p2align 4
	.L__pc.6517.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6518
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6518: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6519
	
	.L__pc.6519: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6520
	
	.p2align 4
	.L__pc.6520: Dma_PatchDst (.L__pc.6520.ST), (.L__movme_cp.66), (.L__pc.6520.ST)
	.L__pc.6520.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6521
	
	.L__pc.6521: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6522
	
	.p2align 4
	.L__pc.6522: Dma_PatchDst (.L__pc.6522.ST), (.L__movme_cp.24), (.L__pc.6522.ST)
	.L__pc.6522.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6523
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6523: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6524
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6524: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6525
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6525: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6526
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6526: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6527
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.6527: Dma_PatchSrc (.L__pc.6527.LD), (.L__movme_cp.67), (.L__pc.6527.LD)
	.p2align 4
	.L__pc.6527.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6528
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6528: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6529
	.L__pc.6529: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6530
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6530: Dma_PatchSrc (.L__pc.6530.LD), (.L__movme_cp.24), (.L__pc.6530.LD)
	.p2align 4
	.L__pc.6530.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6531
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6531: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6532
	.L__pc.6532: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6533
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6533: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6534: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6535: Dma_PatchSrc (.L__pc.6535.LD), (.L__movme_tmp.1), (.L__pc.6535.LD)
	.p2align 4
	.L__pc.6535.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6536
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6536: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6537
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6537: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6538: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6539: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6540: Dma_PatchSrc (.L__pc.6540.LD), (.L__movme_tmp.1), (.L__pc.6540.LD)
	.p2align 4
	.L__pc.6540.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6541
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6541: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6542
	
	.L__pc.6542: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6543
	
	.p2align 4
	.L__pc.6543: Dma_PatchDst (.L__pc.6543.ST), (.L__movme_cp.67), (.L__pc.6543.ST)
	.L__pc.6543.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6544
	
	.L__pc.6544: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6545
	
	.p2align 4
	.L__pc.6545: Dma_PatchDst (.L__pc.6545.ST), (.L__movme_cp.24), (.L__pc.6545.ST)
	.L__pc.6545.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6546
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6546: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6547
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6547: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6548
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6548: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6549
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6549: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6550
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.6550: Dma_PatchSrc (.L__pc.6550.LD), (.L__movme_cp.68), (.L__pc.6550.LD)
	.p2align 4
	.L__pc.6550.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6551
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6551: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6552
	.L__pc.6552: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6553
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6553: Dma_PatchSrc (.L__pc.6553.LD), (.L__movme_cp.24), (.L__pc.6553.LD)
	.p2align 4
	.L__pc.6553.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6554
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6554: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6555
	.L__pc.6555: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6556
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6556: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6557: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6558: Dma_PatchSrc (.L__pc.6558.LD), (.L__movme_tmp.1), (.L__pc.6558.LD)
	.p2align 4
	.L__pc.6558.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6559
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6559: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6560
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6560: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6561: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6562: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6563: Dma_PatchSrc (.L__pc.6563.LD), (.L__movme_tmp.1), (.L__pc.6563.LD)
	.p2align 4
	.L__pc.6563.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6564
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6564: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6565
	
	.L__pc.6565: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6566
	
	.p2align 4
	.L__pc.6566: Dma_PatchDst (.L__pc.6566.ST), (.L__movme_cp.68), (.L__pc.6566.ST)
	.L__pc.6566.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6567
	
	.L__pc.6567: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6568
	
	.p2align 4
	.L__pc.6568: Dma_PatchDst (.L__pc.6568.ST), (.L__movme_cp.24), (.L__pc.6568.ST)
	.L__pc.6568.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6569
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6569: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6570
	
	.p2align 4
	.L__pc.6570: Dma_PatchDst (.L__pc.6570.ST), (.L__movme_cp.24), (.L__pc.6570.ST)
	.L__pc.6570.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6571
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.6571: Dma_PatchSrc (.L__pc.6571.LD), (.L__movme_cp.60), (.L__pc.6571.LD)
	.p2align 4
	.L__pc.6571.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6572
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6572: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6573
	
	.L__pc.6573: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6574
	
	.p2align 4
	.L__pc.6574: Dma_PatchDst (.L__pc.6574.ST), (.L__movme_cp.21), (.L__pc.6574.ST)
	.L__pc.6574.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6575
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.6575: Dma_PatchSrc (.L__pc.6575.LD), (.L__movme_cp.58), (.L__pc.6575.LD)
	.p2align 4
	.L__pc.6575.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6576
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6576: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6577
	
	.L__pc.6577: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6578
	
	.p2align 4
	.L__pc.6578: Dma_PatchDst (.L__pc.6578.ST), (.L__movme_cp.22), (.L__pc.6578.ST)
	.L__pc.6578.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6579
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6579: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6580
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6580: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6581
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6581: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6582
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6582: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6583
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.6583: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.6584
	
	.p2align 4
	.L__pc.6584: Dma_PatchDst (.L__pc.6584.ST), (.L__movme_cp.24), (.L__pc.6584.ST)
	.L__pc.6584.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6585
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.6585: Dma_PatchSrc (.L__pc.6585.LD), (.L__movme_cp.25), (.L__pc.6585.LD)
	.p2align 4
	.L__pc.6585.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6586
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6586: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6587
	.L__pc.6587: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6588
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.6588: Dma_PatchSrc (.L__pc.6588.LD), (.L__movme_cp.26), (.L__pc.6588.LD)
	.p2align 4
	.L__pc.6588.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6589
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6589: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6590
	.L__pc.6590: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6591
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6591: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6592: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6593: Dma_PatchSrc (.L__pc.6593.LD), (.L__movme_tmp.1), (.L__pc.6593.LD)
	.p2align 4
	.L__pc.6593.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6594
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6594: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6595
	.L__pc.6595: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6596
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6596: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6597: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6598: Dma_PatchSrc (.L__pc.6598.LD), (.L__movme_tmp.1), (.L__pc.6598.LD)
	.p2align 4
	.L__pc.6598.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6599
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6599: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6600
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6600: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6601: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6602: Dma_PatchSrc (.L__pc.6602.LD), (.L__movme_tmp.1), (.L__pc.6602.LD)
	.p2align 4
	.L__pc.6602.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6603
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6603: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6604
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6604: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6605: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6606: Dma_PatchSrc (.L__pc.6606.LD), (.L__movme_tmp.1), (.L__pc.6606.LD)
	.p2align 4
	.L__pc.6606.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6607
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6607: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6608
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6608: Dma_PatchSrc (.L__pc.6608.LD), (.L__movme_cp.24), (.L__pc.6608.LD)
	.p2align 4
	.L__pc.6608.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6609
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6609: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6610
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6610: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6611: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6612: Dma_PatchSrc (.L__pc.6612.LD), (.L__movme_tmp.1), (.L__pc.6612.LD)
	.p2align 4
	.L__pc.6612.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6613
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6613: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6614
	
	.L__pc.6614: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6615
	
	.p2align 4
	.L__pc.6615: Dma_PatchDst (.L__pc.6615.ST), (.L__movme_cp.69), (.L__pc.6615.ST)
	.L__pc.6615.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6616
	
	.L__pc.6616: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6617
	
	.p2align 4
	.L__pc.6617: Dma_PatchDst (.L__pc.6617.ST), (.L__movme_cp.54), (.L__pc.6617.ST)
	.L__pc.6617.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6618
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.6618: Dma_PatchSrc (.L__pc.6618.LD), (.L__movme_cp.30), (.L__pc.6618.LD)
	.p2align 4
	.L__pc.6618.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6619
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6619: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6620
	.L__pc.6620: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6621
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.6621: Dma_PatchSrc (.L__pc.6621.LD), (.L__movme_cp.31), (.L__pc.6621.LD)
	.p2align 4
	.L__pc.6621.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6622
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6622: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6623
	.L__pc.6623: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6624
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6624: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6625: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6626: Dma_PatchSrc (.L__pc.6626.LD), (.L__movme_tmp.1), (.L__pc.6626.LD)
	.p2align 4
	.L__pc.6626.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6627
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6627: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6628
	.L__pc.6628: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6629
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6629: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6630: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6631: Dma_PatchSrc (.L__pc.6631.LD), (.L__movme_tmp.1), (.L__pc.6631.LD)
	.p2align 4
	.L__pc.6631.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6632
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6632: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6633
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6633: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6634: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6635: Dma_PatchSrc (.L__pc.6635.LD), (.L__movme_tmp.1), (.L__pc.6635.LD)
	.p2align 4
	.L__pc.6635.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6636
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6636: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6637
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6637: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6638: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6639: Dma_PatchSrc (.L__pc.6639.LD), (.L__movme_tmp.1), (.L__pc.6639.LD)
	.p2align 4
	.L__pc.6639.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6640
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6640: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6641
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6641: Dma_PatchSrc (.L__pc.6641.LD), (.L__movme_cp.24), (.L__pc.6641.LD)
	.p2align 4
	.L__pc.6641.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6642
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6642: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6643
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6643: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6644: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6645: Dma_PatchSrc (.L__pc.6645.LD), (.L__movme_tmp.1), (.L__pc.6645.LD)
	.p2align 4
	.L__pc.6645.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6646
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6646: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6647
	
	.L__pc.6647: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6648
	
	.p2align 4
	.L__pc.6648: Dma_PatchDst (.L__pc.6648.ST), (.L__movme_cp.70), (.L__pc.6648.ST)
	.L__pc.6648.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6649
	
	.L__pc.6649: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6650
	
	.p2align 4
	.L__pc.6650: Dma_PatchDst (.L__pc.6650.ST), (.L__movme_cp.54), (.L__pc.6650.ST)
	.L__pc.6650.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6651
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6651: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6652
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6652: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6653
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6653: Dma_PatchSrc (.L__pc.6653.LD), (.L__movme_cp.24), (.L__pc.6653.LD)
	.p2align 4
	.L__pc.6653.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6654
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6654: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6655
	.L__pc.6655: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6656
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.6656: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6657: Dma_PatchSrc (.L__pc.6657.LD), (.L__movme_tmp.1), (.L__pc.6657.LD)
	.p2align 4
	.L__pc.6657.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6658
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6658: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6659
	.L__pc.6659: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6660
	
	.L__pc.6660: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6661
	
	.p2align 4
	.L__pc.6661: Dma_PatchDst (.L__pc.6661.ST), (.L__movme_cp.72), (.L__pc.6661.ST)
	.L__pc.6661.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6662
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.6662: Dma_PatchSrc (.L__pc.6662.LD), (.L__movme_cp.72), (.L__pc.6662.LD)
	.p2align 4
	.L__pc.6662.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6663
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6663: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6664
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6664: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6665: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6666: Dma_PatchSrc (.L__pc.6666.LD), (.L__movme_tmp.1), (.L__pc.6666.LD)
	.p2align 4
	.L__pc.6666.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6667
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6667: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6668
	
	.L__pc.6668: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6669
	
	.p2align 4
	.L__pc.6669: Dma_PatchDst (.L__pc.6669.ST), (.L__movme_cp.74), (.L__pc.6669.ST)
	.L__pc.6669.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6670
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6670: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6671: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6672: Dma_PatchSrc (.L__pc.6672.LD), (.L__movme_tmp.1), (.L__pc.6672.LD)
	.p2align 4
	.L__pc.6672.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6673
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6673: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6674
	
	.L__pc.6674: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6675
	
	.p2align 4
	.L__pc.6675: Dma_PatchDst (.L__pc.6675.ST), (.L__movme_cp.76), (.L__pc.6675.ST)
	.L__pc.6675.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6676
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.6676: Dma_PatchSrc (.L__pc.6676.LD), (.L__movme_cp.74), (.L__pc.6676.LD)
	.p2align 4
	.L__pc.6676.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6677
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6677: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6678
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.6678: Dma_PatchSrc (.L__pc.6678.LD), ((.L__movme.reg.eax+0)), (.L__pc.6678.LD)
	.p2align 4
	.L__pc.6678.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6679
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6679: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6680
	
	.L__pc.6680: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6681
	
	.p2align 4
	.L__pc.6681: Dma_PatchDst (.L__pc.6681.ST), (.L__movme_cp.77), (.L__pc.6681.ST)
	.L__pc.6681.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6682
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.6682: Dma_PatchSrc (.L__pc.6682.LD), (.L__movme_cp.77), (.L__pc.6682.LD)
	.p2align 4
	.L__pc.6682.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6683
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6683: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6684
	
	.L__pc.6684: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6685
	
	.p2align 4
	.L__pc.6685: Dma_PatchDst (.L__pc.6685.ST), (.L__movme_cp.21), (.L__pc.6685.ST)
	.L__pc.6685.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6686
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.6686: Dma_PatchSrc (.L__pc.6686.LD), (.L__movme_cp.58), (.L__pc.6686.LD)
	.p2align 4
	.L__pc.6686.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6687
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6687: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6688
	
	.L__pc.6688: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6689
	
	.p2align 4
	.L__pc.6689: Dma_PatchDst (.L__pc.6689.ST), (.L__movme_cp.22), (.L__pc.6689.ST)
	.L__pc.6689.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6690
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6690: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6691
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6691: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6692
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6692: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6693
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6693: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6694
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.6694: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.6695
	
	.p2align 4
	.L__pc.6695: Dma_PatchDst (.L__pc.6695.ST), (.L__movme_cp.24), (.L__pc.6695.ST)
	.L__pc.6695.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6696
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.6696: Dma_PatchSrc (.L__pc.6696.LD), (.L__movme_cp.25), (.L__pc.6696.LD)
	.p2align 4
	.L__pc.6696.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6697
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6697: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6698
	.L__pc.6698: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6699
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.6699: Dma_PatchSrc (.L__pc.6699.LD), (.L__movme_cp.26), (.L__pc.6699.LD)
	.p2align 4
	.L__pc.6699.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6700
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6700: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6701
	.L__pc.6701: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6702
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6702: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6703: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6704: Dma_PatchSrc (.L__pc.6704.LD), (.L__movme_tmp.1), (.L__pc.6704.LD)
	.p2align 4
	.L__pc.6704.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6705
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6705: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6706
	.L__pc.6706: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6707
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6707: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6708: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6709: Dma_PatchSrc (.L__pc.6709.LD), (.L__movme_tmp.1), (.L__pc.6709.LD)
	.p2align 4
	.L__pc.6709.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6710
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6710: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6711
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6711: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6712: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6713: Dma_PatchSrc (.L__pc.6713.LD), (.L__movme_tmp.1), (.L__pc.6713.LD)
	.p2align 4
	.L__pc.6713.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6714
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6714: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6715
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6715: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6716: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6717: Dma_PatchSrc (.L__pc.6717.LD), (.L__movme_tmp.1), (.L__pc.6717.LD)
	.p2align 4
	.L__pc.6717.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6718
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6718: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6719
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6719: Dma_PatchSrc (.L__pc.6719.LD), (.L__movme_cp.24), (.L__pc.6719.LD)
	.p2align 4
	.L__pc.6719.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6720
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6720: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6721
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6721: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6722: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6723: Dma_PatchSrc (.L__pc.6723.LD), (.L__movme_tmp.1), (.L__pc.6723.LD)
	.p2align 4
	.L__pc.6723.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6724
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6724: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6725
	
	.L__pc.6725: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6726
	
	.p2align 4
	.L__pc.6726: Dma_PatchDst (.L__pc.6726.ST), (.L__movme_cp.78), (.L__pc.6726.ST)
	.L__pc.6726.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6727
	
	.L__pc.6727: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6728
	
	.p2align 4
	.L__pc.6728: Dma_PatchDst (.L__pc.6728.ST), (.L__movme_cp.54), (.L__pc.6728.ST)
	.L__pc.6728.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6729
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.6729: Dma_PatchSrc (.L__pc.6729.LD), (.L__movme_cp.30), (.L__pc.6729.LD)
	.p2align 4
	.L__pc.6729.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6730
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6730: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6731
	.L__pc.6731: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6732
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.6732: Dma_PatchSrc (.L__pc.6732.LD), (.L__movme_cp.31), (.L__pc.6732.LD)
	.p2align 4
	.L__pc.6732.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6733
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6733: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6734
	.L__pc.6734: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6735
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6735: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6736: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6737: Dma_PatchSrc (.L__pc.6737.LD), (.L__movme_tmp.1), (.L__pc.6737.LD)
	.p2align 4
	.L__pc.6737.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6738
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6738: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6739
	.L__pc.6739: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6740
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6740: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6741: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6742: Dma_PatchSrc (.L__pc.6742.LD), (.L__movme_tmp.1), (.L__pc.6742.LD)
	.p2align 4
	.L__pc.6742.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6743
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6743: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6744
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6744: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6745: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6746: Dma_PatchSrc (.L__pc.6746.LD), (.L__movme_tmp.1), (.L__pc.6746.LD)
	.p2align 4
	.L__pc.6746.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6747
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6747: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6748
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6748: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6749: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6750: Dma_PatchSrc (.L__pc.6750.LD), (.L__movme_tmp.1), (.L__pc.6750.LD)
	.p2align 4
	.L__pc.6750.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6751
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6751: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6752
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6752: Dma_PatchSrc (.L__pc.6752.LD), (.L__movme_cp.24), (.L__pc.6752.LD)
	.p2align 4
	.L__pc.6752.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6753
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6753: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6754
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6754: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6755: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6756: Dma_PatchSrc (.L__pc.6756.LD), (.L__movme_tmp.1), (.L__pc.6756.LD)
	.p2align 4
	.L__pc.6756.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6757
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6757: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6758
	
	.L__pc.6758: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6759
	
	.p2align 4
	.L__pc.6759: Dma_PatchDst (.L__pc.6759.ST), (.L__movme_cp.79), (.L__pc.6759.ST)
	.L__pc.6759.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6760
	
	.L__pc.6760: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6761
	
	.p2align 4
	.L__pc.6761: Dma_PatchDst (.L__pc.6761.ST), (.L__movme_cp.54), (.L__pc.6761.ST)
	.L__pc.6761.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6762
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.6762: Dma_PatchSrc (.L__pc.6762.LD), (.L__movme_cp.74), (.L__pc.6762.LD)
	.p2align 4
	.L__pc.6762.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6763
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6763: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6764
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.6764: Dma_PatchSrc (.L__pc.6764.LD), (.L__movme_cp.77), (.L__pc.6764.LD)
	.p2align 4
	.L__pc.6764.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6765
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6765: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6766
	
	.L__pc.6766: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6767
	
	.p2align 4
	.L__pc.6767: Dma_PatchDst (.L__pc.6767.ST), ((.L__movme.reg.eax+0)), (.L__pc.6767.ST)
	.L__pc.6767.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6768
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.6768: Dma_PatchSrc (.L__pc.6768.LD), (.L__movme_cp.76), (.L__pc.6768.LD)
	.p2align 4
	.L__pc.6768.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6769
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6769: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6770
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.6770: Dma_PatchSrc (.L__pc.6770.LD), ((.L__movme.reg.eax+0)), (.L__pc.6770.LD)
	.p2align 4
	.L__pc.6770.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6771
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6771: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6772
	
	.L__pc.6772: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6773
	
	.p2align 4
	.L__pc.6773: Dma_PatchDst (.L__pc.6773.ST), (.L__movme_cp.80), (.L__pc.6773.ST)
	.L__pc.6773.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6774
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6774: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6775
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6775: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6776
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.6776: Dma_PatchSrc (.L__pc.6776.LD), (.L__movme_cp.98), (.L__pc.6776.LD)
	.p2align 4
	.L__pc.6776.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6777
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6777: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6778
	.L__pc.6778: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6779
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.94 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.6779: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6780: Dma_PatchSrc (.L__pc.6780.LD), (.L__movme_tmp.1), (.L__pc.6780.LD)
	.p2align 4
	.L__pc.6780.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6781
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6781: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6782
	.L__pc.6782: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6783
	
	.L__pc.6783: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6784
	
	.p2align 4
	.L__pc.6784: Dma_PatchDst (.L__pc.6784.ST), (.L__movme_cp.98), (.L__pc.6784.ST)
	.L__pc.6784.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6785
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.6785: Dma_PatchSrc (.L__pc.6785.LD), (.L__movme_cp.76), (.L__pc.6785.LD)
	.p2align 4
	.L__pc.6785.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6786
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6786: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6787
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.6787: Dma_PatchSrc (.L__pc.6787.LD), (.L__movme_cp.80), (.L__pc.6787.LD)
	.p2align 4
	.L__pc.6787.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6788
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6788: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6789
	
	.L__pc.6789: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6790
	
	.p2align 4
	.L__pc.6790: Dma_PatchDst (.L__pc.6790.ST), ((.L__movme.reg.eax+0)), (.L__pc.6790.ST)
	.L__pc.6790.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6791
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6791: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6792
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6792: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6793
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.6793: Dma_PatchSrc (.L__pc.6793.LD), (.L__movme_cp.97), (.L__pc.6793.LD)
	.p2align 4
	.L__pc.6793.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6794
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6794: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6795
	.L__pc.6795: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6796
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6796: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.95 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6797: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6798: Dma_PatchSrc (.L__pc.6798.LD), (.L__movme_tmp.1), (.L__pc.6798.LD)
	.p2align 4
	.L__pc.6798.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6799
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6799: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6800
	
	.L__pc.6800: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6801
	
	.p2align 4
	.L__pc.6801: Dma_PatchDst (.L__pc.6801.ST), (.L__movme_cp.24), (.L__pc.6801.ST)
	.L__pc.6801.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6802
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6802: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6803
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6803: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6804
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6804: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6805
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6805: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6806
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.6806: Dma_PatchSrc (.L__pc.6806.LD), (.L__movme_cp.63), (.L__pc.6806.LD)
	.p2align 4
	.L__pc.6806.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6807
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6807: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6808
	.L__pc.6808: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6809
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6809: Dma_PatchSrc (.L__pc.6809.LD), (.L__movme_cp.24), (.L__pc.6809.LD)
	.p2align 4
	.L__pc.6809.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6810
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6810: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6811
	.L__pc.6811: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6812
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6812: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6813: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6814: Dma_PatchSrc (.L__pc.6814.LD), (.L__movme_tmp.1), (.L__pc.6814.LD)
	.p2align 4
	.L__pc.6814.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6815
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6815: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6816
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6816: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6817: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6818: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6819: Dma_PatchSrc (.L__pc.6819.LD), (.L__movme_tmp.1), (.L__pc.6819.LD)
	.p2align 4
	.L__pc.6819.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6820
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6820: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6821
	
	.L__pc.6821: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6822
	
	.p2align 4
	.L__pc.6822: Dma_PatchDst (.L__pc.6822.ST), (.L__movme_cp.63), (.L__pc.6822.ST)
	.L__pc.6822.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6823
	
	.L__pc.6823: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6824
	
	.p2align 4
	.L__pc.6824: Dma_PatchDst (.L__pc.6824.ST), (.L__movme_cp.24), (.L__pc.6824.ST)
	.L__pc.6824.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6825
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6825: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6826
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6826: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6827
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6827: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6828
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6828: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6829
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.6829: Dma_PatchSrc (.L__pc.6829.LD), (.L__movme_cp.66), (.L__pc.6829.LD)
	.p2align 4
	.L__pc.6829.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6830
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6830: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6831
	.L__pc.6831: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6832
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6832: Dma_PatchSrc (.L__pc.6832.LD), (.L__movme_cp.24), (.L__pc.6832.LD)
	.p2align 4
	.L__pc.6832.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6833
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6833: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6834
	.L__pc.6834: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6835
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6835: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6836: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6837: Dma_PatchSrc (.L__pc.6837.LD), (.L__movme_tmp.1), (.L__pc.6837.LD)
	.p2align 4
	.L__pc.6837.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6838
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6838: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6839
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6839: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6840: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6841: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6842: Dma_PatchSrc (.L__pc.6842.LD), (.L__movme_tmp.1), (.L__pc.6842.LD)
	.p2align 4
	.L__pc.6842.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6843
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6843: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6844
	
	.L__pc.6844: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6845
	
	.p2align 4
	.L__pc.6845: Dma_PatchDst (.L__pc.6845.ST), (.L__movme_cp.66), (.L__pc.6845.ST)
	.L__pc.6845.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6846
	
	.L__pc.6846: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6847
	
	.p2align 4
	.L__pc.6847: Dma_PatchDst (.L__pc.6847.ST), (.L__movme_cp.24), (.L__pc.6847.ST)
	.L__pc.6847.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6848
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6848: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6849
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6849: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6850
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6850: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6851
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6851: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6852
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.6852: Dma_PatchSrc (.L__pc.6852.LD), (.L__movme_cp.67), (.L__pc.6852.LD)
	.p2align 4
	.L__pc.6852.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6853
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6853: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6854
	.L__pc.6854: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6855
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6855: Dma_PatchSrc (.L__pc.6855.LD), (.L__movme_cp.24), (.L__pc.6855.LD)
	.p2align 4
	.L__pc.6855.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6856
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6856: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6857
	.L__pc.6857: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6858
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6858: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6859: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6860: Dma_PatchSrc (.L__pc.6860.LD), (.L__movme_tmp.1), (.L__pc.6860.LD)
	.p2align 4
	.L__pc.6860.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6861
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6861: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6862
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6862: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6863: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6864: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6865: Dma_PatchSrc (.L__pc.6865.LD), (.L__movme_tmp.1), (.L__pc.6865.LD)
	.p2align 4
	.L__pc.6865.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6866
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6866: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6867
	
	.L__pc.6867: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6868
	
	.p2align 4
	.L__pc.6868: Dma_PatchDst (.L__pc.6868.ST), (.L__movme_cp.67), (.L__pc.6868.ST)
	.L__pc.6868.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6869
	
	.L__pc.6869: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6870
	
	.p2align 4
	.L__pc.6870: Dma_PatchDst (.L__pc.6870.ST), (.L__movme_cp.24), (.L__pc.6870.ST)
	.L__pc.6870.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6871
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6871: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6872
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6872: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6873
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6873: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6874
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6874: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6875
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.6875: Dma_PatchSrc (.L__pc.6875.LD), (.L__movme_cp.68), (.L__pc.6875.LD)
	.p2align 4
	.L__pc.6875.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6876
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6876: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6877
	.L__pc.6877: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6878
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6878: Dma_PatchSrc (.L__pc.6878.LD), (.L__movme_cp.24), (.L__pc.6878.LD)
	.p2align 4
	.L__pc.6878.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6879
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6879: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.6880
	.L__pc.6880: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.6881
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6881: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6882: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6883: Dma_PatchSrc (.L__pc.6883.LD), (.L__movme_tmp.1), (.L__pc.6883.LD)
	.p2align 4
	.L__pc.6883.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6884
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6884: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6885
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.6885: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.6886: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.6887: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6888: Dma_PatchSrc (.L__pc.6888.LD), (.L__movme_tmp.1), (.L__pc.6888.LD)
	.p2align 4
	.L__pc.6888.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6889
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6889: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6890
	
	.L__pc.6890: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.6891
	
	.p2align 4
	.L__pc.6891: Dma_PatchDst (.L__pc.6891.ST), (.L__movme_cp.68), (.L__pc.6891.ST)
	.L__pc.6891.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6892
	
	.L__pc.6892: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.6893
	
	.p2align 4
	.L__pc.6893: Dma_PatchDst (.L__pc.6893.ST), (.L__movme_cp.24), (.L__pc.6893.ST)
	.L__pc.6893.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6894
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6894: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6895
	
	.p2align 4
	.L__pc.6895: Dma_PatchDst (.L__pc.6895.ST), (.L__movme_cp.24), (.L__pc.6895.ST)
	.L__pc.6895.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6896
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.6896: Dma_PatchSrc (.L__pc.6896.LD), (.L__movme_cp.60), (.L__pc.6896.LD)
	.p2align 4
	.L__pc.6896.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6897
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6897: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6898
	
	.L__pc.6898: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6899
	
	.p2align 4
	.L__pc.6899: Dma_PatchDst (.L__pc.6899.ST), (.L__movme_cp.21), (.L__pc.6899.ST)
	.L__pc.6899.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6900
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.6900: Dma_PatchSrc (.L__pc.6900.LD), (.L__movme_cp.58), (.L__pc.6900.LD)
	.p2align 4
	.L__pc.6900.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6901
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6901: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6902
	
	.L__pc.6902: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6903
	
	.p2align 4
	.L__pc.6903: Dma_PatchDst (.L__pc.6903.ST), (.L__movme_cp.22), (.L__pc.6903.ST)
	.L__pc.6903.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6904
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6904: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6905
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6905: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6906
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6906: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6907
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6907: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6908
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.6908: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.6909
	
	.p2align 4
	.L__pc.6909: Dma_PatchDst (.L__pc.6909.ST), (.L__movme_cp.24), (.L__pc.6909.ST)
	.L__pc.6909.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6910
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.6910: Dma_PatchSrc (.L__pc.6910.LD), (.L__movme_cp.25), (.L__pc.6910.LD)
	.p2align 4
	.L__pc.6910.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6911
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6911: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6912
	.L__pc.6912: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6913
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.6913: Dma_PatchSrc (.L__pc.6913.LD), (.L__movme_cp.26), (.L__pc.6913.LD)
	.p2align 4
	.L__pc.6913.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6914
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6914: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6915
	.L__pc.6915: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6916
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6916: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6917: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6918: Dma_PatchSrc (.L__pc.6918.LD), (.L__movme_tmp.1), (.L__pc.6918.LD)
	.p2align 4
	.L__pc.6918.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6919
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6919: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6920
	.L__pc.6920: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6921
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6921: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6922: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6923: Dma_PatchSrc (.L__pc.6923.LD), (.L__movme_tmp.1), (.L__pc.6923.LD)
	.p2align 4
	.L__pc.6923.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6924
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6924: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6925
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6925: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6926: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6927: Dma_PatchSrc (.L__pc.6927.LD), (.L__movme_tmp.1), (.L__pc.6927.LD)
	.p2align 4
	.L__pc.6927.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6928
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6928: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6929
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6929: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6930: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6931: Dma_PatchSrc (.L__pc.6931.LD), (.L__movme_tmp.1), (.L__pc.6931.LD)
	.p2align 4
	.L__pc.6931.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6932
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6932: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6933
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6933: Dma_PatchSrc (.L__pc.6933.LD), (.L__movme_cp.24), (.L__pc.6933.LD)
	.p2align 4
	.L__pc.6933.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6934
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6934: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6935
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6935: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6936: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6937: Dma_PatchSrc (.L__pc.6937.LD), (.L__movme_tmp.1), (.L__pc.6937.LD)
	.p2align 4
	.L__pc.6937.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6938
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6938: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6939
	
	.L__pc.6939: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6940
	
	.p2align 4
	.L__pc.6940: Dma_PatchDst (.L__pc.6940.ST), (.L__movme_cp.69), (.L__pc.6940.ST)
	.L__pc.6940.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6941
	
	.L__pc.6941: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6942
	
	.p2align 4
	.L__pc.6942: Dma_PatchDst (.L__pc.6942.ST), (.L__movme_cp.54), (.L__pc.6942.ST)
	.L__pc.6942.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6943
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.6943: Dma_PatchSrc (.L__pc.6943.LD), (.L__movme_cp.30), (.L__pc.6943.LD)
	.p2align 4
	.L__pc.6943.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6944
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6944: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.6945
	.L__pc.6945: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.6946
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.6946: Dma_PatchSrc (.L__pc.6946.LD), (.L__movme_cp.31), (.L__pc.6946.LD)
	.p2align 4
	.L__pc.6946.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6947
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6947: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6948
	.L__pc.6948: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6949
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.6949: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6950: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6951: Dma_PatchSrc (.L__pc.6951.LD), (.L__movme_tmp.1), (.L__pc.6951.LD)
	.p2align 4
	.L__pc.6951.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6952
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6952: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.6953
	.L__pc.6953: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.6954
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6954: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6955: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6956: Dma_PatchSrc (.L__pc.6956.LD), (.L__movme_tmp.1), (.L__pc.6956.LD)
	.p2align 4
	.L__pc.6956.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6957
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6957: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6958
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6958: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6959: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6960: Dma_PatchSrc (.L__pc.6960.LD), (.L__movme_tmp.1), (.L__pc.6960.LD)
	.p2align 4
	.L__pc.6960.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6961
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6961: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6962
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.6962: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6963: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6964: Dma_PatchSrc (.L__pc.6964.LD), (.L__movme_tmp.1), (.L__pc.6964.LD)
	.p2align 4
	.L__pc.6964.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6965
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6965: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6966
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6966: Dma_PatchSrc (.L__pc.6966.LD), (.L__movme_cp.24), (.L__pc.6966.LD)
	.p2align 4
	.L__pc.6966.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6967
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.6967: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.6968
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.6968: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6969: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6970: Dma_PatchSrc (.L__pc.6970.LD), (.L__movme_tmp.1), (.L__pc.6970.LD)
	.p2align 4
	.L__pc.6970.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6971
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6971: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6972
	
	.L__pc.6972: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.6973
	
	.p2align 4
	.L__pc.6973: Dma_PatchDst (.L__pc.6973.ST), (.L__movme_cp.70), (.L__pc.6973.ST)
	.L__pc.6973.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6974
	
	.L__pc.6974: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6975
	
	.p2align 4
	.L__pc.6975: Dma_PatchDst (.L__pc.6975.ST), (.L__movme_cp.54), (.L__pc.6975.ST)
	.L__pc.6975.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6976
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.6976: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.6977
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6977: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6978
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.6978: Dma_PatchSrc (.L__pc.6978.LD), (.L__movme_cp.24), (.L__pc.6978.LD)
	.p2align 4
	.L__pc.6978.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6979
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6979: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6980
	.L__pc.6980: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6981
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.6981: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6982: Dma_PatchSrc (.L__pc.6982.LD), (.L__movme_tmp.1), (.L__pc.6982.LD)
	.p2align 4
	.L__pc.6982.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6983
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6983: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.6984
	.L__pc.6984: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.6985
	
	.L__pc.6985: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.6986
	
	.p2align 4
	.L__pc.6986: Dma_PatchDst (.L__pc.6986.ST), (.L__movme_cp.72), (.L__pc.6986.ST)
	.L__pc.6986.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6987
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.6987: Dma_PatchSrc (.L__pc.6987.LD), (.L__movme_cp.72), (.L__pc.6987.LD)
	.p2align 4
	.L__pc.6987.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6988
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.6988: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.6989
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6989: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6990: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6991: Dma_PatchSrc (.L__pc.6991.LD), (.L__movme_tmp.1), (.L__pc.6991.LD)
	.p2align 4
	.L__pc.6991.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6992
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6992: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6993
	
	.L__pc.6993: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.6994
	
	.p2align 4
	.L__pc.6994: Dma_PatchDst (.L__pc.6994.ST), (.L__movme_cp.74), (.L__pc.6994.ST)
	.L__pc.6994.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.6995
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.6995: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.6996: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.6997: Dma_PatchSrc (.L__pc.6997.LD), (.L__movme_tmp.1), (.L__pc.6997.LD)
	.p2align 4
	.L__pc.6997.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.6998
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.6998: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.6999
	
	.L__pc.6999: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7000
	
	.p2align 4
	.L__pc.7000: Dma_PatchDst (.L__pc.7000.ST), (.L__movme_cp.76), (.L__pc.7000.ST)
	.L__pc.7000.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7001
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.7001: Dma_PatchSrc (.L__pc.7001.LD), (.L__movme_cp.74), (.L__pc.7001.LD)
	.p2align 4
	.L__pc.7001.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7002
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7002: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7003
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.7003: Dma_PatchSrc (.L__pc.7003.LD), ((.L__movme.reg.eax+0)), (.L__pc.7003.LD)
	.p2align 4
	.L__pc.7003.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7004
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7004: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7005
	
	.L__pc.7005: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7006
	
	.p2align 4
	.L__pc.7006: Dma_PatchDst (.L__pc.7006.ST), (.L__movme_cp.77), (.L__pc.7006.ST)
	.L__pc.7006.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7007
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.7007: Dma_PatchSrc (.L__pc.7007.LD), (.L__movme_cp.77), (.L__pc.7007.LD)
	.p2align 4
	.L__pc.7007.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7008
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7008: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7009
	
	.L__pc.7009: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7010
	
	.p2align 4
	.L__pc.7010: Dma_PatchDst (.L__pc.7010.ST), (.L__movme_cp.21), (.L__pc.7010.ST)
	.L__pc.7010.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7011
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.7011: Dma_PatchSrc (.L__pc.7011.LD), (.L__movme_cp.58), (.L__pc.7011.LD)
	.p2align 4
	.L__pc.7011.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7012
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7012: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7013
	
	.L__pc.7013: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7014
	
	.p2align 4
	.L__pc.7014: Dma_PatchDst (.L__pc.7014.ST), (.L__movme_cp.22), (.L__pc.7014.ST)
	.L__pc.7014.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7015
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7015: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7016
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7016: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7017
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7017: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7018
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7018: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7019
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.7019: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.7020
	
	.p2align 4
	.L__pc.7020: Dma_PatchDst (.L__pc.7020.ST), (.L__movme_cp.24), (.L__pc.7020.ST)
	.L__pc.7020.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7021
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.7021: Dma_PatchSrc (.L__pc.7021.LD), (.L__movme_cp.25), (.L__pc.7021.LD)
	.p2align 4
	.L__pc.7021.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7022
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7022: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7023
	.L__pc.7023: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7024
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.7024: Dma_PatchSrc (.L__pc.7024.LD), (.L__movme_cp.26), (.L__pc.7024.LD)
	.p2align 4
	.L__pc.7024.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7025
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7025: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7026
	.L__pc.7026: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7027
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7027: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7028: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7029: Dma_PatchSrc (.L__pc.7029.LD), (.L__movme_tmp.1), (.L__pc.7029.LD)
	.p2align 4
	.L__pc.7029.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7030
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7030: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7031
	.L__pc.7031: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7032
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7032: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7033: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7034: Dma_PatchSrc (.L__pc.7034.LD), (.L__movme_tmp.1), (.L__pc.7034.LD)
	.p2align 4
	.L__pc.7034.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7035
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7035: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7036
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7036: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7037: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7038: Dma_PatchSrc (.L__pc.7038.LD), (.L__movme_tmp.1), (.L__pc.7038.LD)
	.p2align 4
	.L__pc.7038.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7039
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7039: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7040
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7040: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7041: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7042: Dma_PatchSrc (.L__pc.7042.LD), (.L__movme_tmp.1), (.L__pc.7042.LD)
	.p2align 4
	.L__pc.7042.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7043
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7043: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7044
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7044: Dma_PatchSrc (.L__pc.7044.LD), (.L__movme_cp.24), (.L__pc.7044.LD)
	.p2align 4
	.L__pc.7044.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7045
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7045: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7046
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7046: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7047: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7048: Dma_PatchSrc (.L__pc.7048.LD), (.L__movme_tmp.1), (.L__pc.7048.LD)
	.p2align 4
	.L__pc.7048.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7049
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7049: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7050
	
	.L__pc.7050: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7051
	
	.p2align 4
	.L__pc.7051: Dma_PatchDst (.L__pc.7051.ST), (.L__movme_cp.78), (.L__pc.7051.ST)
	.L__pc.7051.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7052
	
	.L__pc.7052: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7053
	
	.p2align 4
	.L__pc.7053: Dma_PatchDst (.L__pc.7053.ST), (.L__movme_cp.54), (.L__pc.7053.ST)
	.L__pc.7053.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7054
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.7054: Dma_PatchSrc (.L__pc.7054.LD), (.L__movme_cp.30), (.L__pc.7054.LD)
	.p2align 4
	.L__pc.7054.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7055
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7055: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7056
	.L__pc.7056: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7057
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.7057: Dma_PatchSrc (.L__pc.7057.LD), (.L__movme_cp.31), (.L__pc.7057.LD)
	.p2align 4
	.L__pc.7057.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7058
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7058: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7059
	.L__pc.7059: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7060
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7060: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7061: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7062: Dma_PatchSrc (.L__pc.7062.LD), (.L__movme_tmp.1), (.L__pc.7062.LD)
	.p2align 4
	.L__pc.7062.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7063
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7063: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7064
	.L__pc.7064: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7065
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7065: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7066: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7067: Dma_PatchSrc (.L__pc.7067.LD), (.L__movme_tmp.1), (.L__pc.7067.LD)
	.p2align 4
	.L__pc.7067.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7068
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7068: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7069
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7069: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7070: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7071: Dma_PatchSrc (.L__pc.7071.LD), (.L__movme_tmp.1), (.L__pc.7071.LD)
	.p2align 4
	.L__pc.7071.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7072
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7072: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7073
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7073: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7074: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7075: Dma_PatchSrc (.L__pc.7075.LD), (.L__movme_tmp.1), (.L__pc.7075.LD)
	.p2align 4
	.L__pc.7075.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7076
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7076: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7077
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7077: Dma_PatchSrc (.L__pc.7077.LD), (.L__movme_cp.24), (.L__pc.7077.LD)
	.p2align 4
	.L__pc.7077.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7078
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7078: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7079
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7079: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7080: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7081: Dma_PatchSrc (.L__pc.7081.LD), (.L__movme_tmp.1), (.L__pc.7081.LD)
	.p2align 4
	.L__pc.7081.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7082
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7082: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7083
	
	.L__pc.7083: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7084
	
	.p2align 4
	.L__pc.7084: Dma_PatchDst (.L__pc.7084.ST), (.L__movme_cp.79), (.L__pc.7084.ST)
	.L__pc.7084.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7085
	
	.L__pc.7085: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7086
	
	.p2align 4
	.L__pc.7086: Dma_PatchDst (.L__pc.7086.ST), (.L__movme_cp.54), (.L__pc.7086.ST)
	.L__pc.7086.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7087
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.7087: Dma_PatchSrc (.L__pc.7087.LD), (.L__movme_cp.74), (.L__pc.7087.LD)
	.p2align 4
	.L__pc.7087.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7088
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7088: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7089
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.7089: Dma_PatchSrc (.L__pc.7089.LD), (.L__movme_cp.77), (.L__pc.7089.LD)
	.p2align 4
	.L__pc.7089.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7090
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7090: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7091
	
	.L__pc.7091: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7092
	
	.p2align 4
	.L__pc.7092: Dma_PatchDst (.L__pc.7092.ST), ((.L__movme.reg.eax+0)), (.L__pc.7092.ST)
	.L__pc.7092.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7093
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.7093: Dma_PatchSrc (.L__pc.7093.LD), (.L__movme_cp.76), (.L__pc.7093.LD)
	.p2align 4
	.L__pc.7093.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7094
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7094: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7095
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.7095: Dma_PatchSrc (.L__pc.7095.LD), ((.L__movme.reg.eax+0)), (.L__pc.7095.LD)
	.p2align 4
	.L__pc.7095.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7096
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7096: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7097
	
	.L__pc.7097: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7098
	
	.p2align 4
	.L__pc.7098: Dma_PatchDst (.L__pc.7098.ST), (.L__movme_cp.80), (.L__pc.7098.ST)
	.L__pc.7098.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7099
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7099: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7100
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7100: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7101
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.7101: Dma_PatchSrc (.L__pc.7101.LD), (.L__movme_cp.98), (.L__pc.7101.LD)
	.p2align 4
	.L__pc.7101.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7102
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7102: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7103
	.L__pc.7103: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7104
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.96 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.7104: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7105: Dma_PatchSrc (.L__pc.7105.LD), (.L__movme_tmp.1), (.L__pc.7105.LD)
	.p2align 4
	.L__pc.7105.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7106
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7106: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7107
	.L__pc.7107: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7108
	
	.L__pc.7108: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7109
	
	.p2align 4
	.L__pc.7109: Dma_PatchDst (.L__pc.7109.ST), (.L__movme_cp.98), (.L__pc.7109.ST)
	.L__pc.7109.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7110
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.7110: Dma_PatchSrc (.L__pc.7110.LD), (.L__movme_cp.76), (.L__pc.7110.LD)
	.p2align 4
	.L__pc.7110.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7111
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7111: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7112
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.7112: Dma_PatchSrc (.L__pc.7112.LD), (.L__movme_cp.80), (.L__pc.7112.LD)
	.p2align 4
	.L__pc.7112.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7113
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7113: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7114
	
	.L__pc.7114: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7115
	
	.p2align 4
	.L__pc.7115: Dma_PatchDst (.L__pc.7115.ST), ((.L__movme.reg.eax+0)), (.L__pc.7115.ST)
	.L__pc.7115.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7116
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7116: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7117
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7117: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7118
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.7118: Dma_PatchSrc (.L__pc.7118.LD), (.L__movme_cp.99), (.L__pc.7118.LD)
	.p2align 4
	.L__pc.7118.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7119
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7119: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7120
	.L__pc.7120: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7121
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7121: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.62 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7122: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7123: Dma_PatchSrc (.L__pc.7123.LD), (.L__movme_tmp.1), (.L__pc.7123.LD)
	.p2align 4
	.L__pc.7123.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7124
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7124: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7125
	
	.L__pc.7125: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7126
	
	.p2align 4
	.L__pc.7126: Dma_PatchDst (.L__pc.7126.ST), (.L__movme_cp.24), (.L__pc.7126.ST)
	.L__pc.7126.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7127
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7127: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7128
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7128: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7129
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7129: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7130
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7130: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7131
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.7131: Dma_PatchSrc (.L__pc.7131.LD), (.L__movme_cp.63), (.L__pc.7131.LD)
	.p2align 4
	.L__pc.7131.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7132
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7132: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7133
	.L__pc.7133: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7134
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7134: Dma_PatchSrc (.L__pc.7134.LD), (.L__movme_cp.24), (.L__pc.7134.LD)
	.p2align 4
	.L__pc.7134.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7135
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7135: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7136
	.L__pc.7136: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7137
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7137: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7138: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7139: Dma_PatchSrc (.L__pc.7139.LD), (.L__movme_tmp.1), (.L__pc.7139.LD)
	.p2align 4
	.L__pc.7139.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7140
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7140: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7141
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7141: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7142: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7143: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7144: Dma_PatchSrc (.L__pc.7144.LD), (.L__movme_tmp.1), (.L__pc.7144.LD)
	.p2align 4
	.L__pc.7144.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7145
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7145: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7146
	
	.L__pc.7146: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7147
	
	.p2align 4
	.L__pc.7147: Dma_PatchDst (.L__pc.7147.ST), (.L__movme_cp.63), (.L__pc.7147.ST)
	.L__pc.7147.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7148
	
	.L__pc.7148: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7149
	
	.p2align 4
	.L__pc.7149: Dma_PatchDst (.L__pc.7149.ST), (.L__movme_cp.24), (.L__pc.7149.ST)
	.L__pc.7149.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7150
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7150: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7151
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7151: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7152
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7152: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7153
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7153: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7154
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.7154: Dma_PatchSrc (.L__pc.7154.LD), (.L__movme_cp.66), (.L__pc.7154.LD)
	.p2align 4
	.L__pc.7154.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7155
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7155: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7156
	.L__pc.7156: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7157
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7157: Dma_PatchSrc (.L__pc.7157.LD), (.L__movme_cp.24), (.L__pc.7157.LD)
	.p2align 4
	.L__pc.7157.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7158
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7158: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7159
	.L__pc.7159: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7160
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7160: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7161: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7162: Dma_PatchSrc (.L__pc.7162.LD), (.L__movme_tmp.1), (.L__pc.7162.LD)
	.p2align 4
	.L__pc.7162.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7163
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7163: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7164
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7164: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7165: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7166: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7167: Dma_PatchSrc (.L__pc.7167.LD), (.L__movme_tmp.1), (.L__pc.7167.LD)
	.p2align 4
	.L__pc.7167.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7168
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7168: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7169
	
	.L__pc.7169: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7170
	
	.p2align 4
	.L__pc.7170: Dma_PatchDst (.L__pc.7170.ST), (.L__movme_cp.66), (.L__pc.7170.ST)
	.L__pc.7170.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7171
	
	.L__pc.7171: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7172
	
	.p2align 4
	.L__pc.7172: Dma_PatchDst (.L__pc.7172.ST), (.L__movme_cp.24), (.L__pc.7172.ST)
	.L__pc.7172.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7173
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7173: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7174
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7174: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7175
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7175: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7176
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7176: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7177
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.7177: Dma_PatchSrc (.L__pc.7177.LD), (.L__movme_cp.67), (.L__pc.7177.LD)
	.p2align 4
	.L__pc.7177.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7178
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7178: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7179
	.L__pc.7179: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7180
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7180: Dma_PatchSrc (.L__pc.7180.LD), (.L__movme_cp.24), (.L__pc.7180.LD)
	.p2align 4
	.L__pc.7180.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7181
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7181: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7182
	.L__pc.7182: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7183
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7183: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7184: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7185: Dma_PatchSrc (.L__pc.7185.LD), (.L__movme_tmp.1), (.L__pc.7185.LD)
	.p2align 4
	.L__pc.7185.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7186
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7186: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7187
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7187: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7188: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7189: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7190: Dma_PatchSrc (.L__pc.7190.LD), (.L__movme_tmp.1), (.L__pc.7190.LD)
	.p2align 4
	.L__pc.7190.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7191
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7191: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7192
	
	.L__pc.7192: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7193
	
	.p2align 4
	.L__pc.7193: Dma_PatchDst (.L__pc.7193.ST), (.L__movme_cp.67), (.L__pc.7193.ST)
	.L__pc.7193.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7194
	
	.L__pc.7194: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7195
	
	.p2align 4
	.L__pc.7195: Dma_PatchDst (.L__pc.7195.ST), (.L__movme_cp.24), (.L__pc.7195.ST)
	.L__pc.7195.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7196
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7196: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7197
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7197: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7198
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7198: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7199
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7199: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7200
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.7200: Dma_PatchSrc (.L__pc.7200.LD), (.L__movme_cp.68), (.L__pc.7200.LD)
	.p2align 4
	.L__pc.7200.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7201
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7201: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7202
	.L__pc.7202: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7203
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7203: Dma_PatchSrc (.L__pc.7203.LD), (.L__movme_cp.24), (.L__pc.7203.LD)
	.p2align 4
	.L__pc.7203.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7204
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7204: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7205
	.L__pc.7205: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7206
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7206: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7207: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7208: Dma_PatchSrc (.L__pc.7208.LD), (.L__movme_tmp.1), (.L__pc.7208.LD)
	.p2align 4
	.L__pc.7208.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7209
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7209: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7210
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7210: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7211: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7212: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7213: Dma_PatchSrc (.L__pc.7213.LD), (.L__movme_tmp.1), (.L__pc.7213.LD)
	.p2align 4
	.L__pc.7213.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7214
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7214: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7215
	
	.L__pc.7215: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7216
	
	.p2align 4
	.L__pc.7216: Dma_PatchDst (.L__pc.7216.ST), (.L__movme_cp.68), (.L__pc.7216.ST)
	.L__pc.7216.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7217
	
	.L__pc.7217: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7218
	
	.p2align 4
	.L__pc.7218: Dma_PatchDst (.L__pc.7218.ST), (.L__movme_cp.24), (.L__pc.7218.ST)
	.L__pc.7218.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7219
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7219: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7220
	
	.p2align 4
	.L__pc.7220: Dma_PatchDst (.L__pc.7220.ST), (.L__movme_cp.24), (.L__pc.7220.ST)
	.L__pc.7220.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7221
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.7221: Dma_PatchSrc (.L__pc.7221.LD), (.L__movme_cp.60), (.L__pc.7221.LD)
	.p2align 4
	.L__pc.7221.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7222
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7222: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7223
	
	.L__pc.7223: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7224
	
	.p2align 4
	.L__pc.7224: Dma_PatchDst (.L__pc.7224.ST), (.L__movme_cp.21), (.L__pc.7224.ST)
	.L__pc.7224.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7225
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.7225: Dma_PatchSrc (.L__pc.7225.LD), (.L__movme_cp.58), (.L__pc.7225.LD)
	.p2align 4
	.L__pc.7225.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7226
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7226: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7227
	
	.L__pc.7227: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7228
	
	.p2align 4
	.L__pc.7228: Dma_PatchDst (.L__pc.7228.ST), (.L__movme_cp.22), (.L__pc.7228.ST)
	.L__pc.7228.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7229
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7229: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7230
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7230: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7231
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7231: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7232
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7232: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7233
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.7233: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.7234
	
	.p2align 4
	.L__pc.7234: Dma_PatchDst (.L__pc.7234.ST), (.L__movme_cp.24), (.L__pc.7234.ST)
	.L__pc.7234.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7235
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.7235: Dma_PatchSrc (.L__pc.7235.LD), (.L__movme_cp.25), (.L__pc.7235.LD)
	.p2align 4
	.L__pc.7235.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7236
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7236: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7237
	.L__pc.7237: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7238
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.7238: Dma_PatchSrc (.L__pc.7238.LD), (.L__movme_cp.26), (.L__pc.7238.LD)
	.p2align 4
	.L__pc.7238.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7239
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7239: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7240
	.L__pc.7240: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7241
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7241: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7242: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7243: Dma_PatchSrc (.L__pc.7243.LD), (.L__movme_tmp.1), (.L__pc.7243.LD)
	.p2align 4
	.L__pc.7243.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7244
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7244: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7245
	.L__pc.7245: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7246
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7246: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7247: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7248: Dma_PatchSrc (.L__pc.7248.LD), (.L__movme_tmp.1), (.L__pc.7248.LD)
	.p2align 4
	.L__pc.7248.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7249
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7249: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7250
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7250: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7251: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7252: Dma_PatchSrc (.L__pc.7252.LD), (.L__movme_tmp.1), (.L__pc.7252.LD)
	.p2align 4
	.L__pc.7252.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7253
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7253: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7254
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7254: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7255: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7256: Dma_PatchSrc (.L__pc.7256.LD), (.L__movme_tmp.1), (.L__pc.7256.LD)
	.p2align 4
	.L__pc.7256.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7257
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7257: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7258
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7258: Dma_PatchSrc (.L__pc.7258.LD), (.L__movme_cp.24), (.L__pc.7258.LD)
	.p2align 4
	.L__pc.7258.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7259
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7259: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7260
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7260: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7261: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7262: Dma_PatchSrc (.L__pc.7262.LD), (.L__movme_tmp.1), (.L__pc.7262.LD)
	.p2align 4
	.L__pc.7262.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7263
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7263: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7264
	
	.L__pc.7264: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7265
	
	.p2align 4
	.L__pc.7265: Dma_PatchDst (.L__pc.7265.ST), (.L__movme_cp.69), (.L__pc.7265.ST)
	.L__pc.7265.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7266
	
	.L__pc.7266: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7267
	
	.p2align 4
	.L__pc.7267: Dma_PatchDst (.L__pc.7267.ST), (.L__movme_cp.54), (.L__pc.7267.ST)
	.L__pc.7267.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7268
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.7268: Dma_PatchSrc (.L__pc.7268.LD), (.L__movme_cp.30), (.L__pc.7268.LD)
	.p2align 4
	.L__pc.7268.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7269
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7269: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7270
	.L__pc.7270: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7271
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.7271: Dma_PatchSrc (.L__pc.7271.LD), (.L__movme_cp.31), (.L__pc.7271.LD)
	.p2align 4
	.L__pc.7271.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7272
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7272: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7273
	.L__pc.7273: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7274
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7274: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7275: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7276: Dma_PatchSrc (.L__pc.7276.LD), (.L__movme_tmp.1), (.L__pc.7276.LD)
	.p2align 4
	.L__pc.7276.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7277
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7277: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7278
	.L__pc.7278: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7279
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7279: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7280: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7281: Dma_PatchSrc (.L__pc.7281.LD), (.L__movme_tmp.1), (.L__pc.7281.LD)
	.p2align 4
	.L__pc.7281.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7282
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7282: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7283
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7283: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7284: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7285: Dma_PatchSrc (.L__pc.7285.LD), (.L__movme_tmp.1), (.L__pc.7285.LD)
	.p2align 4
	.L__pc.7285.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7286
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7286: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7287
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7287: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7288: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7289: Dma_PatchSrc (.L__pc.7289.LD), (.L__movme_tmp.1), (.L__pc.7289.LD)
	.p2align 4
	.L__pc.7289.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7290
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7290: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7291
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7291: Dma_PatchSrc (.L__pc.7291.LD), (.L__movme_cp.24), (.L__pc.7291.LD)
	.p2align 4
	.L__pc.7291.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7292
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7292: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7293
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7293: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7294: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7295: Dma_PatchSrc (.L__pc.7295.LD), (.L__movme_tmp.1), (.L__pc.7295.LD)
	.p2align 4
	.L__pc.7295.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7296
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7296: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7297
	
	.L__pc.7297: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7298
	
	.p2align 4
	.L__pc.7298: Dma_PatchDst (.L__pc.7298.ST), (.L__movme_cp.70), (.L__pc.7298.ST)
	.L__pc.7298.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7299
	
	.L__pc.7299: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7300
	
	.p2align 4
	.L__pc.7300: Dma_PatchDst (.L__pc.7300.ST), (.L__movme_cp.54), (.L__pc.7300.ST)
	.L__pc.7300.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7301
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7301: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7302
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7302: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7303
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7303: Dma_PatchSrc (.L__pc.7303.LD), (.L__movme_cp.24), (.L__pc.7303.LD)
	.p2align 4
	.L__pc.7303.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7304
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7304: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7305
	.L__pc.7305: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7306
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.7306: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7307: Dma_PatchSrc (.L__pc.7307.LD), (.L__movme_tmp.1), (.L__pc.7307.LD)
	.p2align 4
	.L__pc.7307.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7308
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7308: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7309
	.L__pc.7309: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7310
	
	.L__pc.7310: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7311
	
	.p2align 4
	.L__pc.7311: Dma_PatchDst (.L__pc.7311.ST), (.L__movme_cp.72), (.L__pc.7311.ST)
	.L__pc.7311.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7312
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.7312: Dma_PatchSrc (.L__pc.7312.LD), (.L__movme_cp.72), (.L__pc.7312.LD)
	.p2align 4
	.L__pc.7312.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7313
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7313: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7314
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7314: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7315: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7316: Dma_PatchSrc (.L__pc.7316.LD), (.L__movme_tmp.1), (.L__pc.7316.LD)
	.p2align 4
	.L__pc.7316.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7317
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7317: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7318
	
	.L__pc.7318: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7319
	
	.p2align 4
	.L__pc.7319: Dma_PatchDst (.L__pc.7319.ST), (.L__movme_cp.74), (.L__pc.7319.ST)
	.L__pc.7319.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7320
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7320: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7321: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7322: Dma_PatchSrc (.L__pc.7322.LD), (.L__movme_tmp.1), (.L__pc.7322.LD)
	.p2align 4
	.L__pc.7322.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7323
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7323: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7324
	
	.L__pc.7324: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7325
	
	.p2align 4
	.L__pc.7325: Dma_PatchDst (.L__pc.7325.ST), (.L__movme_cp.76), (.L__pc.7325.ST)
	.L__pc.7325.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7326
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.7326: Dma_PatchSrc (.L__pc.7326.LD), (.L__movme_cp.74), (.L__pc.7326.LD)
	.p2align 4
	.L__pc.7326.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7327
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7327: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7328
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.7328: Dma_PatchSrc (.L__pc.7328.LD), ((.L__movme.reg.eax+0)), (.L__pc.7328.LD)
	.p2align 4
	.L__pc.7328.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7329
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7329: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7330
	
	.L__pc.7330: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7331
	
	.p2align 4
	.L__pc.7331: Dma_PatchDst (.L__pc.7331.ST), (.L__movme_cp.77), (.L__pc.7331.ST)
	.L__pc.7331.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7332
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.7332: Dma_PatchSrc (.L__pc.7332.LD), (.L__movme_cp.77), (.L__pc.7332.LD)
	.p2align 4
	.L__pc.7332.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7333
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7333: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7334
	
	.L__pc.7334: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7335
	
	.p2align 4
	.L__pc.7335: Dma_PatchDst (.L__pc.7335.ST), (.L__movme_cp.21), (.L__pc.7335.ST)
	.L__pc.7335.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7336
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.7336: Dma_PatchSrc (.L__pc.7336.LD), (.L__movme_cp.58), (.L__pc.7336.LD)
	.p2align 4
	.L__pc.7336.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7337
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7337: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7338
	
	.L__pc.7338: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7339
	
	.p2align 4
	.L__pc.7339: Dma_PatchDst (.L__pc.7339.ST), (.L__movme_cp.22), (.L__pc.7339.ST)
	.L__pc.7339.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7340
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7340: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7341
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7341: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7342
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7342: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7343
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7343: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7344
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.7344: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.7345
	
	.p2align 4
	.L__pc.7345: Dma_PatchDst (.L__pc.7345.ST), (.L__movme_cp.24), (.L__pc.7345.ST)
	.L__pc.7345.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7346
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.7346: Dma_PatchSrc (.L__pc.7346.LD), (.L__movme_cp.25), (.L__pc.7346.LD)
	.p2align 4
	.L__pc.7346.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7347
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7347: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7348
	.L__pc.7348: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7349
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.7349: Dma_PatchSrc (.L__pc.7349.LD), (.L__movme_cp.26), (.L__pc.7349.LD)
	.p2align 4
	.L__pc.7349.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7350
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7350: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7351
	.L__pc.7351: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7352
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7352: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7353: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7354: Dma_PatchSrc (.L__pc.7354.LD), (.L__movme_tmp.1), (.L__pc.7354.LD)
	.p2align 4
	.L__pc.7354.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7355
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7355: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7356
	.L__pc.7356: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7357
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7357: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7358: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7359: Dma_PatchSrc (.L__pc.7359.LD), (.L__movme_tmp.1), (.L__pc.7359.LD)
	.p2align 4
	.L__pc.7359.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7360
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7360: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7361
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7361: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7362: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7363: Dma_PatchSrc (.L__pc.7363.LD), (.L__movme_tmp.1), (.L__pc.7363.LD)
	.p2align 4
	.L__pc.7363.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7364
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7364: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7365
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7365: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7366: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7367: Dma_PatchSrc (.L__pc.7367.LD), (.L__movme_tmp.1), (.L__pc.7367.LD)
	.p2align 4
	.L__pc.7367.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7368
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7368: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7369
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7369: Dma_PatchSrc (.L__pc.7369.LD), (.L__movme_cp.24), (.L__pc.7369.LD)
	.p2align 4
	.L__pc.7369.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7370
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7370: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7371
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7371: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7372: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7373: Dma_PatchSrc (.L__pc.7373.LD), (.L__movme_tmp.1), (.L__pc.7373.LD)
	.p2align 4
	.L__pc.7373.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7374
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7374: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7375
	
	.L__pc.7375: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7376
	
	.p2align 4
	.L__pc.7376: Dma_PatchDst (.L__pc.7376.ST), (.L__movme_cp.78), (.L__pc.7376.ST)
	.L__pc.7376.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7377
	
	.L__pc.7377: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7378
	
	.p2align 4
	.L__pc.7378: Dma_PatchDst (.L__pc.7378.ST), (.L__movme_cp.54), (.L__pc.7378.ST)
	.L__pc.7378.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7379
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.7379: Dma_PatchSrc (.L__pc.7379.LD), (.L__movme_cp.30), (.L__pc.7379.LD)
	.p2align 4
	.L__pc.7379.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7380
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7380: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7381
	.L__pc.7381: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7382
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.7382: Dma_PatchSrc (.L__pc.7382.LD), (.L__movme_cp.31), (.L__pc.7382.LD)
	.p2align 4
	.L__pc.7382.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7383
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7383: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7384
	.L__pc.7384: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7385
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7385: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7386: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7387: Dma_PatchSrc (.L__pc.7387.LD), (.L__movme_tmp.1), (.L__pc.7387.LD)
	.p2align 4
	.L__pc.7387.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7388
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7388: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7389
	.L__pc.7389: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7390
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7390: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7391: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7392: Dma_PatchSrc (.L__pc.7392.LD), (.L__movme_tmp.1), (.L__pc.7392.LD)
	.p2align 4
	.L__pc.7392.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7393
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7393: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7394
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7394: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7395: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7396: Dma_PatchSrc (.L__pc.7396.LD), (.L__movme_tmp.1), (.L__pc.7396.LD)
	.p2align 4
	.L__pc.7396.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7397
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7397: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7398
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7398: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7399: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7400: Dma_PatchSrc (.L__pc.7400.LD), (.L__movme_tmp.1), (.L__pc.7400.LD)
	.p2align 4
	.L__pc.7400.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7401
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7401: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7402
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7402: Dma_PatchSrc (.L__pc.7402.LD), (.L__movme_cp.24), (.L__pc.7402.LD)
	.p2align 4
	.L__pc.7402.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7403
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7403: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7404
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7404: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7405: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7406: Dma_PatchSrc (.L__pc.7406.LD), (.L__movme_tmp.1), (.L__pc.7406.LD)
	.p2align 4
	.L__pc.7406.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7407
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7407: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7408
	
	.L__pc.7408: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7409
	
	.p2align 4
	.L__pc.7409: Dma_PatchDst (.L__pc.7409.ST), (.L__movme_cp.79), (.L__pc.7409.ST)
	.L__pc.7409.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7410
	
	.L__pc.7410: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7411
	
	.p2align 4
	.L__pc.7411: Dma_PatchDst (.L__pc.7411.ST), (.L__movme_cp.54), (.L__pc.7411.ST)
	.L__pc.7411.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7412
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.7412: Dma_PatchSrc (.L__pc.7412.LD), (.L__movme_cp.74), (.L__pc.7412.LD)
	.p2align 4
	.L__pc.7412.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7413
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7413: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7414
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.7414: Dma_PatchSrc (.L__pc.7414.LD), (.L__movme_cp.77), (.L__pc.7414.LD)
	.p2align 4
	.L__pc.7414.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7415
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7415: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7416
	
	.L__pc.7416: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7417
	
	.p2align 4
	.L__pc.7417: Dma_PatchDst (.L__pc.7417.ST), ((.L__movme.reg.eax+0)), (.L__pc.7417.ST)
	.L__pc.7417.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7418
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.7418: Dma_PatchSrc (.L__pc.7418.LD), (.L__movme_cp.76), (.L__pc.7418.LD)
	.p2align 4
	.L__pc.7418.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7419
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7419: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7420
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.7420: Dma_PatchSrc (.L__pc.7420.LD), ((.L__movme.reg.eax+0)), (.L__pc.7420.LD)
	.p2align 4
	.L__pc.7420.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7421
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7421: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7422
	
	.L__pc.7422: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7423
	
	.p2align 4
	.L__pc.7423: Dma_PatchDst (.L__pc.7423.ST), (.L__movme_cp.80), (.L__pc.7423.ST)
	.L__pc.7423.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7424
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7424: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7425
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7425: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7426
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.7426: Dma_PatchSrc (.L__pc.7426.LD), (.L__movme_cp.100), (.L__pc.7426.LD)
	.p2align 4
	.L__pc.7426.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7427
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7427: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7428
	.L__pc.7428: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7429
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.82 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.7429: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7430: Dma_PatchSrc (.L__pc.7430.LD), (.L__movme_tmp.1), (.L__pc.7430.LD)
	.p2align 4
	.L__pc.7430.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7431
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7431: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7432
	.L__pc.7432: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7433
	
	.L__pc.7433: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7434
	
	.p2align 4
	.L__pc.7434: Dma_PatchDst (.L__pc.7434.ST), (.L__movme_cp.100), (.L__pc.7434.ST)
	.L__pc.7434.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7435
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.7435: Dma_PatchSrc (.L__pc.7435.LD), (.L__movme_cp.76), (.L__pc.7435.LD)
	.p2align 4
	.L__pc.7435.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7436
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7436: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7437
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.7437: Dma_PatchSrc (.L__pc.7437.LD), (.L__movme_cp.80), (.L__pc.7437.LD)
	.p2align 4
	.L__pc.7437.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7438
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7438: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7439
	
	.L__pc.7439: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7440
	
	.p2align 4
	.L__pc.7440: Dma_PatchDst (.L__pc.7440.ST), ((.L__movme.reg.eax+0)), (.L__pc.7440.ST)
	.L__pc.7440.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7441
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7441: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7442
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7442: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7443
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.7443: Dma_PatchSrc (.L__pc.7443.LD), (.L__movme_cp.99), (.L__pc.7443.LD)
	.p2align 4
	.L__pc.7443.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7444
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7444: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7445
	.L__pc.7445: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7446
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7446: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.83 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7447: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7448: Dma_PatchSrc (.L__pc.7448.LD), (.L__movme_tmp.1), (.L__pc.7448.LD)
	.p2align 4
	.L__pc.7448.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7449
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7449: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7450
	
	.L__pc.7450: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7451
	
	.p2align 4
	.L__pc.7451: Dma_PatchDst (.L__pc.7451.ST), (.L__movme_cp.24), (.L__pc.7451.ST)
	.L__pc.7451.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7452
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7452: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7453
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7453: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7454
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7454: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7455
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7455: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7456
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.7456: Dma_PatchSrc (.L__pc.7456.LD), (.L__movme_cp.63), (.L__pc.7456.LD)
	.p2align 4
	.L__pc.7456.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7457
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7457: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7458
	.L__pc.7458: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7459
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7459: Dma_PatchSrc (.L__pc.7459.LD), (.L__movme_cp.24), (.L__pc.7459.LD)
	.p2align 4
	.L__pc.7459.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7460
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7460: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7461
	.L__pc.7461: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7462
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7462: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7463: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7464: Dma_PatchSrc (.L__pc.7464.LD), (.L__movme_tmp.1), (.L__pc.7464.LD)
	.p2align 4
	.L__pc.7464.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7465
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7465: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7466
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7466: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7467: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7468: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7469: Dma_PatchSrc (.L__pc.7469.LD), (.L__movme_tmp.1), (.L__pc.7469.LD)
	.p2align 4
	.L__pc.7469.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7470
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7470: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7471
	
	.L__pc.7471: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7472
	
	.p2align 4
	.L__pc.7472: Dma_PatchDst (.L__pc.7472.ST), (.L__movme_cp.63), (.L__pc.7472.ST)
	.L__pc.7472.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7473
	
	.L__pc.7473: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7474
	
	.p2align 4
	.L__pc.7474: Dma_PatchDst (.L__pc.7474.ST), (.L__movme_cp.24), (.L__pc.7474.ST)
	.L__pc.7474.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7475
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7475: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7476
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7476: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7477
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7477: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7478
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7478: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7479
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.7479: Dma_PatchSrc (.L__pc.7479.LD), (.L__movme_cp.66), (.L__pc.7479.LD)
	.p2align 4
	.L__pc.7479.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7480
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7480: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7481
	.L__pc.7481: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7482
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7482: Dma_PatchSrc (.L__pc.7482.LD), (.L__movme_cp.24), (.L__pc.7482.LD)
	.p2align 4
	.L__pc.7482.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7483
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7483: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7484
	.L__pc.7484: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7485
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7485: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7486: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7487: Dma_PatchSrc (.L__pc.7487.LD), (.L__movme_tmp.1), (.L__pc.7487.LD)
	.p2align 4
	.L__pc.7487.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7488
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7488: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7489
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7489: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7490: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7491: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7492: Dma_PatchSrc (.L__pc.7492.LD), (.L__movme_tmp.1), (.L__pc.7492.LD)
	.p2align 4
	.L__pc.7492.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7493
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7493: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7494
	
	.L__pc.7494: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7495
	
	.p2align 4
	.L__pc.7495: Dma_PatchDst (.L__pc.7495.ST), (.L__movme_cp.66), (.L__pc.7495.ST)
	.L__pc.7495.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7496
	
	.L__pc.7496: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7497
	
	.p2align 4
	.L__pc.7497: Dma_PatchDst (.L__pc.7497.ST), (.L__movme_cp.24), (.L__pc.7497.ST)
	.L__pc.7497.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7498
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7498: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7499
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7499: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7500
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7500: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7501
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7501: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7502
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.7502: Dma_PatchSrc (.L__pc.7502.LD), (.L__movme_cp.67), (.L__pc.7502.LD)
	.p2align 4
	.L__pc.7502.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7503
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7503: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7504
	.L__pc.7504: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7505
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7505: Dma_PatchSrc (.L__pc.7505.LD), (.L__movme_cp.24), (.L__pc.7505.LD)
	.p2align 4
	.L__pc.7505.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7506
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7506: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7507
	.L__pc.7507: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7508
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7508: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7509: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7510: Dma_PatchSrc (.L__pc.7510.LD), (.L__movme_tmp.1), (.L__pc.7510.LD)
	.p2align 4
	.L__pc.7510.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7511
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7511: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7512
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7512: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7513: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7514: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7515: Dma_PatchSrc (.L__pc.7515.LD), (.L__movme_tmp.1), (.L__pc.7515.LD)
	.p2align 4
	.L__pc.7515.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7516
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7516: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7517
	
	.L__pc.7517: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7518
	
	.p2align 4
	.L__pc.7518: Dma_PatchDst (.L__pc.7518.ST), (.L__movme_cp.67), (.L__pc.7518.ST)
	.L__pc.7518.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7519
	
	.L__pc.7519: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7520
	
	.p2align 4
	.L__pc.7520: Dma_PatchDst (.L__pc.7520.ST), (.L__movme_cp.24), (.L__pc.7520.ST)
	.L__pc.7520.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7521
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7521: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7522
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7522: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7523
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7523: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7524
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7524: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7525
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.7525: Dma_PatchSrc (.L__pc.7525.LD), (.L__movme_cp.68), (.L__pc.7525.LD)
	.p2align 4
	.L__pc.7525.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7526
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7526: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7527
	.L__pc.7527: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7528
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7528: Dma_PatchSrc (.L__pc.7528.LD), (.L__movme_cp.24), (.L__pc.7528.LD)
	.p2align 4
	.L__pc.7528.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7529
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7529: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7530
	.L__pc.7530: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7531
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7531: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7532: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7533: Dma_PatchSrc (.L__pc.7533.LD), (.L__movme_tmp.1), (.L__pc.7533.LD)
	.p2align 4
	.L__pc.7533.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7534
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7534: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7535
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7535: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7536: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7537: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7538: Dma_PatchSrc (.L__pc.7538.LD), (.L__movme_tmp.1), (.L__pc.7538.LD)
	.p2align 4
	.L__pc.7538.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7539
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7539: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7540
	
	.L__pc.7540: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7541
	
	.p2align 4
	.L__pc.7541: Dma_PatchDst (.L__pc.7541.ST), (.L__movme_cp.68), (.L__pc.7541.ST)
	.L__pc.7541.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7542
	
	.L__pc.7542: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7543
	
	.p2align 4
	.L__pc.7543: Dma_PatchDst (.L__pc.7543.ST), (.L__movme_cp.24), (.L__pc.7543.ST)
	.L__pc.7543.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7544
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7544: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7545
	
	.p2align 4
	.L__pc.7545: Dma_PatchDst (.L__pc.7545.ST), (.L__movme_cp.24), (.L__pc.7545.ST)
	.L__pc.7545.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7546
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.7546: Dma_PatchSrc (.L__pc.7546.LD), (.L__movme_cp.60), (.L__pc.7546.LD)
	.p2align 4
	.L__pc.7546.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7547
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7547: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7548
	
	.L__pc.7548: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7549
	
	.p2align 4
	.L__pc.7549: Dma_PatchDst (.L__pc.7549.ST), (.L__movme_cp.21), (.L__pc.7549.ST)
	.L__pc.7549.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7550
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.7550: Dma_PatchSrc (.L__pc.7550.LD), (.L__movme_cp.58), (.L__pc.7550.LD)
	.p2align 4
	.L__pc.7550.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7551
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7551: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7552
	
	.L__pc.7552: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7553
	
	.p2align 4
	.L__pc.7553: Dma_PatchDst (.L__pc.7553.ST), (.L__movme_cp.22), (.L__pc.7553.ST)
	.L__pc.7553.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7554
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7554: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7555
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7555: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7556
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7556: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7557
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7557: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7558
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.7558: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.7559
	
	.p2align 4
	.L__pc.7559: Dma_PatchDst (.L__pc.7559.ST), (.L__movme_cp.24), (.L__pc.7559.ST)
	.L__pc.7559.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7560
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.7560: Dma_PatchSrc (.L__pc.7560.LD), (.L__movme_cp.25), (.L__pc.7560.LD)
	.p2align 4
	.L__pc.7560.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7561
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7561: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7562
	.L__pc.7562: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7563
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.7563: Dma_PatchSrc (.L__pc.7563.LD), (.L__movme_cp.26), (.L__pc.7563.LD)
	.p2align 4
	.L__pc.7563.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7564
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7564: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7565
	.L__pc.7565: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7566
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7566: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7567: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7568: Dma_PatchSrc (.L__pc.7568.LD), (.L__movme_tmp.1), (.L__pc.7568.LD)
	.p2align 4
	.L__pc.7568.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7569
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7569: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7570
	.L__pc.7570: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7571
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7571: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7572: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7573: Dma_PatchSrc (.L__pc.7573.LD), (.L__movme_tmp.1), (.L__pc.7573.LD)
	.p2align 4
	.L__pc.7573.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7574
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7574: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7575
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7575: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7576: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7577: Dma_PatchSrc (.L__pc.7577.LD), (.L__movme_tmp.1), (.L__pc.7577.LD)
	.p2align 4
	.L__pc.7577.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7578
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7578: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7579
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7579: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7580: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7581: Dma_PatchSrc (.L__pc.7581.LD), (.L__movme_tmp.1), (.L__pc.7581.LD)
	.p2align 4
	.L__pc.7581.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7582
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7582: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7583
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7583: Dma_PatchSrc (.L__pc.7583.LD), (.L__movme_cp.24), (.L__pc.7583.LD)
	.p2align 4
	.L__pc.7583.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7584
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7584: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7585
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7585: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7586: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7587: Dma_PatchSrc (.L__pc.7587.LD), (.L__movme_tmp.1), (.L__pc.7587.LD)
	.p2align 4
	.L__pc.7587.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7588
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7588: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7589
	
	.L__pc.7589: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7590
	
	.p2align 4
	.L__pc.7590: Dma_PatchDst (.L__pc.7590.ST), (.L__movme_cp.69), (.L__pc.7590.ST)
	.L__pc.7590.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7591
	
	.L__pc.7591: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7592
	
	.p2align 4
	.L__pc.7592: Dma_PatchDst (.L__pc.7592.ST), (.L__movme_cp.54), (.L__pc.7592.ST)
	.L__pc.7592.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7593
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.7593: Dma_PatchSrc (.L__pc.7593.LD), (.L__movme_cp.30), (.L__pc.7593.LD)
	.p2align 4
	.L__pc.7593.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7594
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7594: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7595
	.L__pc.7595: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7596
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.7596: Dma_PatchSrc (.L__pc.7596.LD), (.L__movme_cp.31), (.L__pc.7596.LD)
	.p2align 4
	.L__pc.7596.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7597
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7597: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7598
	.L__pc.7598: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7599
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7599: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7600: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7601: Dma_PatchSrc (.L__pc.7601.LD), (.L__movme_tmp.1), (.L__pc.7601.LD)
	.p2align 4
	.L__pc.7601.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7602
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7602: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7603
	.L__pc.7603: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7604
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7604: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7605: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7606: Dma_PatchSrc (.L__pc.7606.LD), (.L__movme_tmp.1), (.L__pc.7606.LD)
	.p2align 4
	.L__pc.7606.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7607
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7607: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7608
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7608: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7609: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7610: Dma_PatchSrc (.L__pc.7610.LD), (.L__movme_tmp.1), (.L__pc.7610.LD)
	.p2align 4
	.L__pc.7610.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7611
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7611: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7612
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7612: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7613: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7614: Dma_PatchSrc (.L__pc.7614.LD), (.L__movme_tmp.1), (.L__pc.7614.LD)
	.p2align 4
	.L__pc.7614.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7615
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7615: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7616
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7616: Dma_PatchSrc (.L__pc.7616.LD), (.L__movme_cp.24), (.L__pc.7616.LD)
	.p2align 4
	.L__pc.7616.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7617
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7617: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7618
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7618: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7619: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7620: Dma_PatchSrc (.L__pc.7620.LD), (.L__movme_tmp.1), (.L__pc.7620.LD)
	.p2align 4
	.L__pc.7620.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7621
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7621: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7622
	
	.L__pc.7622: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7623
	
	.p2align 4
	.L__pc.7623: Dma_PatchDst (.L__pc.7623.ST), (.L__movme_cp.70), (.L__pc.7623.ST)
	.L__pc.7623.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7624
	
	.L__pc.7624: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7625
	
	.p2align 4
	.L__pc.7625: Dma_PatchDst (.L__pc.7625.ST), (.L__movme_cp.54), (.L__pc.7625.ST)
	.L__pc.7625.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7626
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7626: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7627
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7627: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7628
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7628: Dma_PatchSrc (.L__pc.7628.LD), (.L__movme_cp.24), (.L__pc.7628.LD)
	.p2align 4
	.L__pc.7628.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7629
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7629: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7630
	.L__pc.7630: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7631
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.7631: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7632: Dma_PatchSrc (.L__pc.7632.LD), (.L__movme_tmp.1), (.L__pc.7632.LD)
	.p2align 4
	.L__pc.7632.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7633
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7633: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7634
	.L__pc.7634: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7635
	
	.L__pc.7635: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7636
	
	.p2align 4
	.L__pc.7636: Dma_PatchDst (.L__pc.7636.ST), (.L__movme_cp.72), (.L__pc.7636.ST)
	.L__pc.7636.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7637
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.7637: Dma_PatchSrc (.L__pc.7637.LD), (.L__movme_cp.72), (.L__pc.7637.LD)
	.p2align 4
	.L__pc.7637.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7638
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7638: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7639
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7639: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7640: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7641: Dma_PatchSrc (.L__pc.7641.LD), (.L__movme_tmp.1), (.L__pc.7641.LD)
	.p2align 4
	.L__pc.7641.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7642
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7642: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7643
	
	.L__pc.7643: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7644
	
	.p2align 4
	.L__pc.7644: Dma_PatchDst (.L__pc.7644.ST), (.L__movme_cp.74), (.L__pc.7644.ST)
	.L__pc.7644.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7645
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7645: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7646: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7647: Dma_PatchSrc (.L__pc.7647.LD), (.L__movme_tmp.1), (.L__pc.7647.LD)
	.p2align 4
	.L__pc.7647.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7648
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7648: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7649
	
	.L__pc.7649: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7650
	
	.p2align 4
	.L__pc.7650: Dma_PatchDst (.L__pc.7650.ST), (.L__movme_cp.76), (.L__pc.7650.ST)
	.L__pc.7650.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7651
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.7651: Dma_PatchSrc (.L__pc.7651.LD), (.L__movme_cp.74), (.L__pc.7651.LD)
	.p2align 4
	.L__pc.7651.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7652
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7652: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7653
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.7653: Dma_PatchSrc (.L__pc.7653.LD), ((.L__movme.reg.eax+0)), (.L__pc.7653.LD)
	.p2align 4
	.L__pc.7653.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7654
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7654: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7655
	
	.L__pc.7655: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7656
	
	.p2align 4
	.L__pc.7656: Dma_PatchDst (.L__pc.7656.ST), (.L__movme_cp.77), (.L__pc.7656.ST)
	.L__pc.7656.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7657
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.7657: Dma_PatchSrc (.L__pc.7657.LD), (.L__movme_cp.77), (.L__pc.7657.LD)
	.p2align 4
	.L__pc.7657.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7658
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7658: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7659
	
	.L__pc.7659: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7660
	
	.p2align 4
	.L__pc.7660: Dma_PatchDst (.L__pc.7660.ST), (.L__movme_cp.21), (.L__pc.7660.ST)
	.L__pc.7660.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7661
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.7661: Dma_PatchSrc (.L__pc.7661.LD), (.L__movme_cp.58), (.L__pc.7661.LD)
	.p2align 4
	.L__pc.7661.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7662
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7662: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7663
	
	.L__pc.7663: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7664
	
	.p2align 4
	.L__pc.7664: Dma_PatchDst (.L__pc.7664.ST), (.L__movme_cp.22), (.L__pc.7664.ST)
	.L__pc.7664.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7665
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7665: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7666
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7666: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7667
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7667: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7668
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7668: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7669
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.7669: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.7670
	
	.p2align 4
	.L__pc.7670: Dma_PatchDst (.L__pc.7670.ST), (.L__movme_cp.24), (.L__pc.7670.ST)
	.L__pc.7670.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7671
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.7671: Dma_PatchSrc (.L__pc.7671.LD), (.L__movme_cp.25), (.L__pc.7671.LD)
	.p2align 4
	.L__pc.7671.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7672
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7672: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7673
	.L__pc.7673: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7674
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.7674: Dma_PatchSrc (.L__pc.7674.LD), (.L__movme_cp.26), (.L__pc.7674.LD)
	.p2align 4
	.L__pc.7674.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7675
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7675: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7676
	.L__pc.7676: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7677
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7677: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7678: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7679: Dma_PatchSrc (.L__pc.7679.LD), (.L__movme_tmp.1), (.L__pc.7679.LD)
	.p2align 4
	.L__pc.7679.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7680
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7680: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7681
	.L__pc.7681: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7682
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7682: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7683: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7684: Dma_PatchSrc (.L__pc.7684.LD), (.L__movme_tmp.1), (.L__pc.7684.LD)
	.p2align 4
	.L__pc.7684.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7685
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7685: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7686
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7686: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7687: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7688: Dma_PatchSrc (.L__pc.7688.LD), (.L__movme_tmp.1), (.L__pc.7688.LD)
	.p2align 4
	.L__pc.7688.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7689
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7689: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7690
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7690: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7691: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7692: Dma_PatchSrc (.L__pc.7692.LD), (.L__movme_tmp.1), (.L__pc.7692.LD)
	.p2align 4
	.L__pc.7692.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7693
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7693: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7694
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7694: Dma_PatchSrc (.L__pc.7694.LD), (.L__movme_cp.24), (.L__pc.7694.LD)
	.p2align 4
	.L__pc.7694.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7695
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7695: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7696
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7696: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7697: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7698: Dma_PatchSrc (.L__pc.7698.LD), (.L__movme_tmp.1), (.L__pc.7698.LD)
	.p2align 4
	.L__pc.7698.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7699
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7699: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7700
	
	.L__pc.7700: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7701
	
	.p2align 4
	.L__pc.7701: Dma_PatchDst (.L__pc.7701.ST), (.L__movme_cp.78), (.L__pc.7701.ST)
	.L__pc.7701.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7702
	
	.L__pc.7702: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7703
	
	.p2align 4
	.L__pc.7703: Dma_PatchDst (.L__pc.7703.ST), (.L__movme_cp.54), (.L__pc.7703.ST)
	.L__pc.7703.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7704
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.7704: Dma_PatchSrc (.L__pc.7704.LD), (.L__movme_cp.30), (.L__pc.7704.LD)
	.p2align 4
	.L__pc.7704.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7705
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7705: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7706
	.L__pc.7706: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7707
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.7707: Dma_PatchSrc (.L__pc.7707.LD), (.L__movme_cp.31), (.L__pc.7707.LD)
	.p2align 4
	.L__pc.7707.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7708
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7708: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7709
	.L__pc.7709: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7710
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7710: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7711: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7712: Dma_PatchSrc (.L__pc.7712.LD), (.L__movme_tmp.1), (.L__pc.7712.LD)
	.p2align 4
	.L__pc.7712.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7713
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7713: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7714
	.L__pc.7714: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7715
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7715: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7716: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7717: Dma_PatchSrc (.L__pc.7717.LD), (.L__movme_tmp.1), (.L__pc.7717.LD)
	.p2align 4
	.L__pc.7717.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7718
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7718: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7719
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7719: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7720: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7721: Dma_PatchSrc (.L__pc.7721.LD), (.L__movme_tmp.1), (.L__pc.7721.LD)
	.p2align 4
	.L__pc.7721.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7722
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7722: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7723
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7723: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7724: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7725: Dma_PatchSrc (.L__pc.7725.LD), (.L__movme_tmp.1), (.L__pc.7725.LD)
	.p2align 4
	.L__pc.7725.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7726
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7726: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7727
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7727: Dma_PatchSrc (.L__pc.7727.LD), (.L__movme_cp.24), (.L__pc.7727.LD)
	.p2align 4
	.L__pc.7727.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7728
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7728: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7729
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7729: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7730: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7731: Dma_PatchSrc (.L__pc.7731.LD), (.L__movme_tmp.1), (.L__pc.7731.LD)
	.p2align 4
	.L__pc.7731.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7732
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7732: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7733
	
	.L__pc.7733: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7734
	
	.p2align 4
	.L__pc.7734: Dma_PatchDst (.L__pc.7734.ST), (.L__movme_cp.79), (.L__pc.7734.ST)
	.L__pc.7734.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7735
	
	.L__pc.7735: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7736
	
	.p2align 4
	.L__pc.7736: Dma_PatchDst (.L__pc.7736.ST), (.L__movme_cp.54), (.L__pc.7736.ST)
	.L__pc.7736.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7737
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.7737: Dma_PatchSrc (.L__pc.7737.LD), (.L__movme_cp.74), (.L__pc.7737.LD)
	.p2align 4
	.L__pc.7737.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7738
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7738: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7739
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.7739: Dma_PatchSrc (.L__pc.7739.LD), (.L__movme_cp.77), (.L__pc.7739.LD)
	.p2align 4
	.L__pc.7739.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7740
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7740: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7741
	
	.L__pc.7741: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7742
	
	.p2align 4
	.L__pc.7742: Dma_PatchDst (.L__pc.7742.ST), ((.L__movme.reg.eax+0)), (.L__pc.7742.ST)
	.L__pc.7742.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7743
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.7743: Dma_PatchSrc (.L__pc.7743.LD), (.L__movme_cp.76), (.L__pc.7743.LD)
	.p2align 4
	.L__pc.7743.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7744
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7744: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7745
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.7745: Dma_PatchSrc (.L__pc.7745.LD), ((.L__movme.reg.eax+0)), (.L__pc.7745.LD)
	.p2align 4
	.L__pc.7745.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7746
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7746: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7747
	
	.L__pc.7747: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7748
	
	.p2align 4
	.L__pc.7748: Dma_PatchDst (.L__pc.7748.ST), (.L__movme_cp.80), (.L__pc.7748.ST)
	.L__pc.7748.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7749
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7749: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7750
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7750: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7751
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.7751: Dma_PatchSrc (.L__pc.7751.LD), (.L__movme_cp.100), (.L__pc.7751.LD)
	.p2align 4
	.L__pc.7751.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7752
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7752: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7753
	.L__pc.7753: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7754
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.84 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.7754: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7755: Dma_PatchSrc (.L__pc.7755.LD), (.L__movme_tmp.1), (.L__pc.7755.LD)
	.p2align 4
	.L__pc.7755.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7756
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7756: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7757
	.L__pc.7757: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7758
	
	.L__pc.7758: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7759
	
	.p2align 4
	.L__pc.7759: Dma_PatchDst (.L__pc.7759.ST), (.L__movme_cp.100), (.L__pc.7759.ST)
	.L__pc.7759.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7760
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.7760: Dma_PatchSrc (.L__pc.7760.LD), (.L__movme_cp.76), (.L__pc.7760.LD)
	.p2align 4
	.L__pc.7760.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7761
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7761: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7762
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.7762: Dma_PatchSrc (.L__pc.7762.LD), (.L__movme_cp.80), (.L__pc.7762.LD)
	.p2align 4
	.L__pc.7762.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7763
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7763: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7764
	
	.L__pc.7764: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7765
	
	.p2align 4
	.L__pc.7765: Dma_PatchDst (.L__pc.7765.ST), ((.L__movme.reg.eax+0)), (.L__pc.7765.ST)
	.L__pc.7765.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7766
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7766: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7767
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7767: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7768
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.7768: Dma_PatchSrc (.L__pc.7768.LD), (.L__movme_cp.99), (.L__pc.7768.LD)
	.p2align 4
	.L__pc.7768.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7769
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7769: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7770
	.L__pc.7770: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7771
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7771: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.85 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7772: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7773: Dma_PatchSrc (.L__pc.7773.LD), (.L__movme_tmp.1), (.L__pc.7773.LD)
	.p2align 4
	.L__pc.7773.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7774
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7774: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7775
	
	.L__pc.7775: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7776
	
	.p2align 4
	.L__pc.7776: Dma_PatchDst (.L__pc.7776.ST), (.L__movme_cp.24), (.L__pc.7776.ST)
	.L__pc.7776.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7777
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7777: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7778
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7778: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7779
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7779: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7780
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7780: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7781
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.7781: Dma_PatchSrc (.L__pc.7781.LD), (.L__movme_cp.63), (.L__pc.7781.LD)
	.p2align 4
	.L__pc.7781.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7782
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7782: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7783
	.L__pc.7783: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7784
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7784: Dma_PatchSrc (.L__pc.7784.LD), (.L__movme_cp.24), (.L__pc.7784.LD)
	.p2align 4
	.L__pc.7784.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7785
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7785: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7786
	.L__pc.7786: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7787
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7787: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7788: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7789: Dma_PatchSrc (.L__pc.7789.LD), (.L__movme_tmp.1), (.L__pc.7789.LD)
	.p2align 4
	.L__pc.7789.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7790
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7790: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7791
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7791: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7792: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7793: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7794: Dma_PatchSrc (.L__pc.7794.LD), (.L__movme_tmp.1), (.L__pc.7794.LD)
	.p2align 4
	.L__pc.7794.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7795
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7795: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7796
	
	.L__pc.7796: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7797
	
	.p2align 4
	.L__pc.7797: Dma_PatchDst (.L__pc.7797.ST), (.L__movme_cp.63), (.L__pc.7797.ST)
	.L__pc.7797.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7798
	
	.L__pc.7798: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7799
	
	.p2align 4
	.L__pc.7799: Dma_PatchDst (.L__pc.7799.ST), (.L__movme_cp.24), (.L__pc.7799.ST)
	.L__pc.7799.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7800
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7800: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7801
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7801: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7802
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7802: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7803
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7803: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7804
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.7804: Dma_PatchSrc (.L__pc.7804.LD), (.L__movme_cp.66), (.L__pc.7804.LD)
	.p2align 4
	.L__pc.7804.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7805
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7805: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7806
	.L__pc.7806: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7807
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7807: Dma_PatchSrc (.L__pc.7807.LD), (.L__movme_cp.24), (.L__pc.7807.LD)
	.p2align 4
	.L__pc.7807.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7808
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7808: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7809
	.L__pc.7809: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7810
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7810: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7811: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7812: Dma_PatchSrc (.L__pc.7812.LD), (.L__movme_tmp.1), (.L__pc.7812.LD)
	.p2align 4
	.L__pc.7812.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7813
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7813: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7814
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7814: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7815: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7816: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7817: Dma_PatchSrc (.L__pc.7817.LD), (.L__movme_tmp.1), (.L__pc.7817.LD)
	.p2align 4
	.L__pc.7817.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7818
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7818: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7819
	
	.L__pc.7819: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7820
	
	.p2align 4
	.L__pc.7820: Dma_PatchDst (.L__pc.7820.ST), (.L__movme_cp.66), (.L__pc.7820.ST)
	.L__pc.7820.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7821
	
	.L__pc.7821: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7822
	
	.p2align 4
	.L__pc.7822: Dma_PatchDst (.L__pc.7822.ST), (.L__movme_cp.24), (.L__pc.7822.ST)
	.L__pc.7822.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7823
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7823: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7824
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7824: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7825
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7825: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7826
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7826: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7827
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.7827: Dma_PatchSrc (.L__pc.7827.LD), (.L__movme_cp.67), (.L__pc.7827.LD)
	.p2align 4
	.L__pc.7827.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7828
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7828: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7829
	.L__pc.7829: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7830
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7830: Dma_PatchSrc (.L__pc.7830.LD), (.L__movme_cp.24), (.L__pc.7830.LD)
	.p2align 4
	.L__pc.7830.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7831
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7831: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7832
	.L__pc.7832: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7833
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7833: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7834: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7835: Dma_PatchSrc (.L__pc.7835.LD), (.L__movme_tmp.1), (.L__pc.7835.LD)
	.p2align 4
	.L__pc.7835.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7836
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7836: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7837
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7837: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7838: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7839: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7840: Dma_PatchSrc (.L__pc.7840.LD), (.L__movme_tmp.1), (.L__pc.7840.LD)
	.p2align 4
	.L__pc.7840.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7841
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7841: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7842
	
	.L__pc.7842: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7843
	
	.p2align 4
	.L__pc.7843: Dma_PatchDst (.L__pc.7843.ST), (.L__movme_cp.67), (.L__pc.7843.ST)
	.L__pc.7843.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7844
	
	.L__pc.7844: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7845
	
	.p2align 4
	.L__pc.7845: Dma_PatchDst (.L__pc.7845.ST), (.L__movme_cp.24), (.L__pc.7845.ST)
	.L__pc.7845.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7846
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7846: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7847
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7847: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7848
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7848: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7849
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7849: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7850
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.7850: Dma_PatchSrc (.L__pc.7850.LD), (.L__movme_cp.68), (.L__pc.7850.LD)
	.p2align 4
	.L__pc.7850.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7851
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7851: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7852
	.L__pc.7852: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7853
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7853: Dma_PatchSrc (.L__pc.7853.LD), (.L__movme_cp.24), (.L__pc.7853.LD)
	.p2align 4
	.L__pc.7853.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7854
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7854: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.7855
	.L__pc.7855: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.7856
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7856: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7857: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7858: Dma_PatchSrc (.L__pc.7858.LD), (.L__movme_tmp.1), (.L__pc.7858.LD)
	.p2align 4
	.L__pc.7858.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7859
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7859: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7860
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.7860: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.7861: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.7862: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7863: Dma_PatchSrc (.L__pc.7863.LD), (.L__movme_tmp.1), (.L__pc.7863.LD)
	.p2align 4
	.L__pc.7863.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7864
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7864: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7865
	
	.L__pc.7865: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.7866
	
	.p2align 4
	.L__pc.7866: Dma_PatchDst (.L__pc.7866.ST), (.L__movme_cp.68), (.L__pc.7866.ST)
	.L__pc.7866.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7867
	
	.L__pc.7867: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.7868
	
	.p2align 4
	.L__pc.7868: Dma_PatchDst (.L__pc.7868.ST), (.L__movme_cp.24), (.L__pc.7868.ST)
	.L__pc.7868.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7869
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7869: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7870
	
	.p2align 4
	.L__pc.7870: Dma_PatchDst (.L__pc.7870.ST), (.L__movme_cp.24), (.L__pc.7870.ST)
	.L__pc.7870.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7871
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.7871: Dma_PatchSrc (.L__pc.7871.LD), (.L__movme_cp.60), (.L__pc.7871.LD)
	.p2align 4
	.L__pc.7871.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7872
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7872: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7873
	
	.L__pc.7873: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7874
	
	.p2align 4
	.L__pc.7874: Dma_PatchDst (.L__pc.7874.ST), (.L__movme_cp.21), (.L__pc.7874.ST)
	.L__pc.7874.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7875
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.7875: Dma_PatchSrc (.L__pc.7875.LD), (.L__movme_cp.58), (.L__pc.7875.LD)
	.p2align 4
	.L__pc.7875.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7876
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7876: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7877
	
	.L__pc.7877: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7878
	
	.p2align 4
	.L__pc.7878: Dma_PatchDst (.L__pc.7878.ST), (.L__movme_cp.22), (.L__pc.7878.ST)
	.L__pc.7878.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7879
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7879: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7880
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7880: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7881
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7881: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7882
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7882: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7883
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.7883: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.7884
	
	.p2align 4
	.L__pc.7884: Dma_PatchDst (.L__pc.7884.ST), (.L__movme_cp.24), (.L__pc.7884.ST)
	.L__pc.7884.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7885
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.7885: Dma_PatchSrc (.L__pc.7885.LD), (.L__movme_cp.25), (.L__pc.7885.LD)
	.p2align 4
	.L__pc.7885.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7886
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7886: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7887
	.L__pc.7887: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7888
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.7888: Dma_PatchSrc (.L__pc.7888.LD), (.L__movme_cp.26), (.L__pc.7888.LD)
	.p2align 4
	.L__pc.7888.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7889
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7889: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7890
	.L__pc.7890: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7891
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7891: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7892: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7893: Dma_PatchSrc (.L__pc.7893.LD), (.L__movme_tmp.1), (.L__pc.7893.LD)
	.p2align 4
	.L__pc.7893.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7894
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7894: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7895
	.L__pc.7895: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7896
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7896: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7897: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7898: Dma_PatchSrc (.L__pc.7898.LD), (.L__movme_tmp.1), (.L__pc.7898.LD)
	.p2align 4
	.L__pc.7898.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7899
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7899: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7900
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7900: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7901: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7902: Dma_PatchSrc (.L__pc.7902.LD), (.L__movme_tmp.1), (.L__pc.7902.LD)
	.p2align 4
	.L__pc.7902.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7903
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7903: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7904
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7904: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7905: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7906: Dma_PatchSrc (.L__pc.7906.LD), (.L__movme_tmp.1), (.L__pc.7906.LD)
	.p2align 4
	.L__pc.7906.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7907
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7907: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7908
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7908: Dma_PatchSrc (.L__pc.7908.LD), (.L__movme_cp.24), (.L__pc.7908.LD)
	.p2align 4
	.L__pc.7908.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7909
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7909: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7910
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7910: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7911: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7912: Dma_PatchSrc (.L__pc.7912.LD), (.L__movme_tmp.1), (.L__pc.7912.LD)
	.p2align 4
	.L__pc.7912.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7913
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7913: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7914
	
	.L__pc.7914: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7915
	
	.p2align 4
	.L__pc.7915: Dma_PatchDst (.L__pc.7915.ST), (.L__movme_cp.69), (.L__pc.7915.ST)
	.L__pc.7915.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7916
	
	.L__pc.7916: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7917
	
	.p2align 4
	.L__pc.7917: Dma_PatchDst (.L__pc.7917.ST), (.L__movme_cp.54), (.L__pc.7917.ST)
	.L__pc.7917.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7918
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.7918: Dma_PatchSrc (.L__pc.7918.LD), (.L__movme_cp.30), (.L__pc.7918.LD)
	.p2align 4
	.L__pc.7918.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7919
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7919: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7920
	.L__pc.7920: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7921
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.7921: Dma_PatchSrc (.L__pc.7921.LD), (.L__movme_cp.31), (.L__pc.7921.LD)
	.p2align 4
	.L__pc.7921.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7922
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7922: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7923
	.L__pc.7923: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7924
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.7924: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7925: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7926: Dma_PatchSrc (.L__pc.7926.LD), (.L__movme_tmp.1), (.L__pc.7926.LD)
	.p2align 4
	.L__pc.7926.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7927
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7927: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.7928
	.L__pc.7928: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.7929
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7929: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7930: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7931: Dma_PatchSrc (.L__pc.7931.LD), (.L__movme_tmp.1), (.L__pc.7931.LD)
	.p2align 4
	.L__pc.7931.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7932
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7932: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7933
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7933: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7934: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7935: Dma_PatchSrc (.L__pc.7935.LD), (.L__movme_tmp.1), (.L__pc.7935.LD)
	.p2align 4
	.L__pc.7935.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7936
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7936: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7937
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.7937: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7938: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7939: Dma_PatchSrc (.L__pc.7939.LD), (.L__movme_tmp.1), (.L__pc.7939.LD)
	.p2align 4
	.L__pc.7939.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7940
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7940: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7941
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7941: Dma_PatchSrc (.L__pc.7941.LD), (.L__movme_cp.24), (.L__pc.7941.LD)
	.p2align 4
	.L__pc.7941.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7942
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7942: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7943
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.7943: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7944: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7945: Dma_PatchSrc (.L__pc.7945.LD), (.L__movme_tmp.1), (.L__pc.7945.LD)
	.p2align 4
	.L__pc.7945.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7946
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7946: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7947
	
	.L__pc.7947: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.7948
	
	.p2align 4
	.L__pc.7948: Dma_PatchDst (.L__pc.7948.ST), (.L__movme_cp.70), (.L__pc.7948.ST)
	.L__pc.7948.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7949
	
	.L__pc.7949: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7950
	
	.p2align 4
	.L__pc.7950: Dma_PatchDst (.L__pc.7950.ST), (.L__movme_cp.54), (.L__pc.7950.ST)
	.L__pc.7950.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7951
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7951: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7952
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7952: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7953
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.7953: Dma_PatchSrc (.L__pc.7953.LD), (.L__movme_cp.24), (.L__pc.7953.LD)
	.p2align 4
	.L__pc.7953.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7954
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7954: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7955
	.L__pc.7955: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7956
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.7956: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7957: Dma_PatchSrc (.L__pc.7957.LD), (.L__movme_tmp.1), (.L__pc.7957.LD)
	.p2align 4
	.L__pc.7957.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7958
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7958: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.7959
	.L__pc.7959: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.7960
	
	.L__pc.7960: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7961
	
	.p2align 4
	.L__pc.7961: Dma_PatchDst (.L__pc.7961.ST), (.L__movme_cp.72), (.L__pc.7961.ST)
	.L__pc.7961.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7962
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.7962: Dma_PatchSrc (.L__pc.7962.LD), (.L__movme_cp.72), (.L__pc.7962.LD)
	.p2align 4
	.L__pc.7962.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7963
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7963: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7964
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7964: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7965: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7966: Dma_PatchSrc (.L__pc.7966.LD), (.L__movme_tmp.1), (.L__pc.7966.LD)
	.p2align 4
	.L__pc.7966.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7967
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7967: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7968
	
	.L__pc.7968: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7969
	
	.p2align 4
	.L__pc.7969: Dma_PatchDst (.L__pc.7969.ST), (.L__movme_cp.74), (.L__pc.7969.ST)
	.L__pc.7969.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7970
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.7970: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.7971: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.7972: Dma_PatchSrc (.L__pc.7972.LD), (.L__movme_tmp.1), (.L__pc.7972.LD)
	.p2align 4
	.L__pc.7972.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7973
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.7973: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.7974
	
	.L__pc.7974: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.7975
	
	.p2align 4
	.L__pc.7975: Dma_PatchDst (.L__pc.7975.ST), (.L__movme_cp.76), (.L__pc.7975.ST)
	.L__pc.7975.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7976
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.7976: Dma_PatchSrc (.L__pc.7976.LD), (.L__movme_cp.74), (.L__pc.7976.LD)
	.p2align 4
	.L__pc.7976.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7977
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7977: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7978
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.7978: Dma_PatchSrc (.L__pc.7978.LD), ((.L__movme.reg.eax+0)), (.L__pc.7978.LD)
	.p2align 4
	.L__pc.7978.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7979
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7979: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7980
	
	.L__pc.7980: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7981
	
	.p2align 4
	.L__pc.7981: Dma_PatchDst (.L__pc.7981.ST), (.L__movme_cp.77), (.L__pc.7981.ST)
	.L__pc.7981.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7982
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.7982: Dma_PatchSrc (.L__pc.7982.LD), (.L__movme_cp.77), (.L__pc.7982.LD)
	.p2align 4
	.L__pc.7982.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7983
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7983: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7984
	
	.L__pc.7984: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7985
	
	.p2align 4
	.L__pc.7985: Dma_PatchDst (.L__pc.7985.ST), (.L__movme_cp.21), (.L__pc.7985.ST)
	.L__pc.7985.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7986
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.7986: Dma_PatchSrc (.L__pc.7986.LD), (.L__movme_cp.58), (.L__pc.7986.LD)
	.p2align 4
	.L__pc.7986.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7987
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7987: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7988
	
	.L__pc.7988: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.7989
	
	.p2align 4
	.L__pc.7989: Dma_PatchDst (.L__pc.7989.ST), (.L__movme_cp.22), (.L__pc.7989.ST)
	.L__pc.7989.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7990
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7990: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7991
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7991: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.7992
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.7992: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.7993
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.7993: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.7994
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.7994: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.7995
	
	.p2align 4
	.L__pc.7995: Dma_PatchDst (.L__pc.7995.ST), (.L__movme_cp.24), (.L__pc.7995.ST)
	.L__pc.7995.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.7996
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.7996: Dma_PatchSrc (.L__pc.7996.LD), (.L__movme_cp.25), (.L__pc.7996.LD)
	.p2align 4
	.L__pc.7996.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.7997
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.7997: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.7998
	.L__pc.7998: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.7999
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.7999: Dma_PatchSrc (.L__pc.7999.LD), (.L__movme_cp.26), (.L__pc.7999.LD)
	.p2align 4
	.L__pc.7999.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8000
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8000: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8001
	.L__pc.8001: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8002
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8002: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8003: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8004: Dma_PatchSrc (.L__pc.8004.LD), (.L__movme_tmp.1), (.L__pc.8004.LD)
	.p2align 4
	.L__pc.8004.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8005
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8005: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8006
	.L__pc.8006: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8007
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8007: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8008: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8009: Dma_PatchSrc (.L__pc.8009.LD), (.L__movme_tmp.1), (.L__pc.8009.LD)
	.p2align 4
	.L__pc.8009.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8010
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8010: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8011
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8011: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8012: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8013: Dma_PatchSrc (.L__pc.8013.LD), (.L__movme_tmp.1), (.L__pc.8013.LD)
	.p2align 4
	.L__pc.8013.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8014
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8014: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8015
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8015: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8016: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8017: Dma_PatchSrc (.L__pc.8017.LD), (.L__movme_tmp.1), (.L__pc.8017.LD)
	.p2align 4
	.L__pc.8017.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8018
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8018: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8019
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8019: Dma_PatchSrc (.L__pc.8019.LD), (.L__movme_cp.24), (.L__pc.8019.LD)
	.p2align 4
	.L__pc.8019.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8020
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8020: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8021
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8021: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8022: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8023: Dma_PatchSrc (.L__pc.8023.LD), (.L__movme_tmp.1), (.L__pc.8023.LD)
	.p2align 4
	.L__pc.8023.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8024
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8024: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8025
	
	.L__pc.8025: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8026
	
	.p2align 4
	.L__pc.8026: Dma_PatchDst (.L__pc.8026.ST), (.L__movme_cp.78), (.L__pc.8026.ST)
	.L__pc.8026.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8027
	
	.L__pc.8027: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8028
	
	.p2align 4
	.L__pc.8028: Dma_PatchDst (.L__pc.8028.ST), (.L__movme_cp.54), (.L__pc.8028.ST)
	.L__pc.8028.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8029
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.8029: Dma_PatchSrc (.L__pc.8029.LD), (.L__movme_cp.30), (.L__pc.8029.LD)
	.p2align 4
	.L__pc.8029.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8030
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8030: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8031
	.L__pc.8031: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8032
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.8032: Dma_PatchSrc (.L__pc.8032.LD), (.L__movme_cp.31), (.L__pc.8032.LD)
	.p2align 4
	.L__pc.8032.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8033
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8033: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8034
	.L__pc.8034: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8035
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8035: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8036: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8037: Dma_PatchSrc (.L__pc.8037.LD), (.L__movme_tmp.1), (.L__pc.8037.LD)
	.p2align 4
	.L__pc.8037.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8038
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8038: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8039
	.L__pc.8039: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8040
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8040: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8041: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8042: Dma_PatchSrc (.L__pc.8042.LD), (.L__movme_tmp.1), (.L__pc.8042.LD)
	.p2align 4
	.L__pc.8042.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8043
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8043: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8044
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8044: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8045: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8046: Dma_PatchSrc (.L__pc.8046.LD), (.L__movme_tmp.1), (.L__pc.8046.LD)
	.p2align 4
	.L__pc.8046.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8047
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8047: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8048
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8048: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8049: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8050: Dma_PatchSrc (.L__pc.8050.LD), (.L__movme_tmp.1), (.L__pc.8050.LD)
	.p2align 4
	.L__pc.8050.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8051
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8051: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8052
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8052: Dma_PatchSrc (.L__pc.8052.LD), (.L__movme_cp.24), (.L__pc.8052.LD)
	.p2align 4
	.L__pc.8052.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8053
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8053: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8054
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8054: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8055: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8056: Dma_PatchSrc (.L__pc.8056.LD), (.L__movme_tmp.1), (.L__pc.8056.LD)
	.p2align 4
	.L__pc.8056.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8057
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8057: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8058
	
	.L__pc.8058: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8059
	
	.p2align 4
	.L__pc.8059: Dma_PatchDst (.L__pc.8059.ST), (.L__movme_cp.79), (.L__pc.8059.ST)
	.L__pc.8059.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8060
	
	.L__pc.8060: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8061
	
	.p2align 4
	.L__pc.8061: Dma_PatchDst (.L__pc.8061.ST), (.L__movme_cp.54), (.L__pc.8061.ST)
	.L__pc.8061.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8062
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.8062: Dma_PatchSrc (.L__pc.8062.LD), (.L__movme_cp.74), (.L__pc.8062.LD)
	.p2align 4
	.L__pc.8062.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8063
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8063: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8064
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.8064: Dma_PatchSrc (.L__pc.8064.LD), (.L__movme_cp.77), (.L__pc.8064.LD)
	.p2align 4
	.L__pc.8064.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8065
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8065: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8066
	
	.L__pc.8066: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8067
	
	.p2align 4
	.L__pc.8067: Dma_PatchDst (.L__pc.8067.ST), ((.L__movme.reg.eax+0)), (.L__pc.8067.ST)
	.L__pc.8067.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8068
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.8068: Dma_PatchSrc (.L__pc.8068.LD), (.L__movme_cp.76), (.L__pc.8068.LD)
	.p2align 4
	.L__pc.8068.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8069
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8069: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8070
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.8070: Dma_PatchSrc (.L__pc.8070.LD), ((.L__movme.reg.eax+0)), (.L__pc.8070.LD)
	.p2align 4
	.L__pc.8070.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8071
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8071: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8072
	
	.L__pc.8072: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8073
	
	.p2align 4
	.L__pc.8073: Dma_PatchDst (.L__pc.8073.ST), (.L__movme_cp.80), (.L__pc.8073.ST)
	.L__pc.8073.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8074
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8074: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8075
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8075: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8076
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.8076: Dma_PatchSrc (.L__pc.8076.LD), (.L__movme_cp.100), (.L__pc.8076.LD)
	.p2align 4
	.L__pc.8076.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8077
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8077: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8078
	.L__pc.8078: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8079
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.86 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.8079: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8080: Dma_PatchSrc (.L__pc.8080.LD), (.L__movme_tmp.1), (.L__pc.8080.LD)
	.p2align 4
	.L__pc.8080.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8081
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8081: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8082
	.L__pc.8082: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8083
	
	.L__pc.8083: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8084
	
	.p2align 4
	.L__pc.8084: Dma_PatchDst (.L__pc.8084.ST), (.L__movme_cp.100), (.L__pc.8084.ST)
	.L__pc.8084.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8085
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.8085: Dma_PatchSrc (.L__pc.8085.LD), (.L__movme_cp.76), (.L__pc.8085.LD)
	.p2align 4
	.L__pc.8085.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8086
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8086: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8087
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.8087: Dma_PatchSrc (.L__pc.8087.LD), (.L__movme_cp.80), (.L__pc.8087.LD)
	.p2align 4
	.L__pc.8087.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8088
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8088: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8089
	
	.L__pc.8089: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8090
	
	.p2align 4
	.L__pc.8090: Dma_PatchDst (.L__pc.8090.ST), ((.L__movme.reg.eax+0)), (.L__pc.8090.ST)
	.L__pc.8090.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8091
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8091: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8092
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8092: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8093
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.8093: Dma_PatchSrc (.L__pc.8093.LD), (.L__movme_cp.99), (.L__pc.8093.LD)
	.p2align 4
	.L__pc.8093.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8094
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8094: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8095
	.L__pc.8095: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8096
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8096: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.87 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8097: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8098: Dma_PatchSrc (.L__pc.8098.LD), (.L__movme_tmp.1), (.L__pc.8098.LD)
	.p2align 4
	.L__pc.8098.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8099
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8099: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8100
	
	.L__pc.8100: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8101
	
	.p2align 4
	.L__pc.8101: Dma_PatchDst (.L__pc.8101.ST), (.L__movme_cp.24), (.L__pc.8101.ST)
	.L__pc.8101.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8102
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8102: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8103
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8103: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8104
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8104: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8105
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8105: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8106
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.8106: Dma_PatchSrc (.L__pc.8106.LD), (.L__movme_cp.63), (.L__pc.8106.LD)
	.p2align 4
	.L__pc.8106.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8107
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8107: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8108
	.L__pc.8108: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8109
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8109: Dma_PatchSrc (.L__pc.8109.LD), (.L__movme_cp.24), (.L__pc.8109.LD)
	.p2align 4
	.L__pc.8109.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8110
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8110: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8111
	.L__pc.8111: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8112
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8112: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8113: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8114: Dma_PatchSrc (.L__pc.8114.LD), (.L__movme_tmp.1), (.L__pc.8114.LD)
	.p2align 4
	.L__pc.8114.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8115
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8115: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8116
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8116: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8117: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8118: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8119: Dma_PatchSrc (.L__pc.8119.LD), (.L__movme_tmp.1), (.L__pc.8119.LD)
	.p2align 4
	.L__pc.8119.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8120
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8120: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8121
	
	.L__pc.8121: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8122
	
	.p2align 4
	.L__pc.8122: Dma_PatchDst (.L__pc.8122.ST), (.L__movme_cp.63), (.L__pc.8122.ST)
	.L__pc.8122.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8123
	
	.L__pc.8123: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8124
	
	.p2align 4
	.L__pc.8124: Dma_PatchDst (.L__pc.8124.ST), (.L__movme_cp.24), (.L__pc.8124.ST)
	.L__pc.8124.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8125
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8125: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8126
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8126: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8127
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8127: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8128
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8128: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8129
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.8129: Dma_PatchSrc (.L__pc.8129.LD), (.L__movme_cp.66), (.L__pc.8129.LD)
	.p2align 4
	.L__pc.8129.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8130
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8130: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8131
	.L__pc.8131: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8132
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8132: Dma_PatchSrc (.L__pc.8132.LD), (.L__movme_cp.24), (.L__pc.8132.LD)
	.p2align 4
	.L__pc.8132.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8133
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8133: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8134
	.L__pc.8134: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8135
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8135: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8136: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8137: Dma_PatchSrc (.L__pc.8137.LD), (.L__movme_tmp.1), (.L__pc.8137.LD)
	.p2align 4
	.L__pc.8137.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8138
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8138: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8139
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8139: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8140: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8141: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8142: Dma_PatchSrc (.L__pc.8142.LD), (.L__movme_tmp.1), (.L__pc.8142.LD)
	.p2align 4
	.L__pc.8142.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8143
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8143: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8144
	
	.L__pc.8144: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8145
	
	.p2align 4
	.L__pc.8145: Dma_PatchDst (.L__pc.8145.ST), (.L__movme_cp.66), (.L__pc.8145.ST)
	.L__pc.8145.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8146
	
	.L__pc.8146: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8147
	
	.p2align 4
	.L__pc.8147: Dma_PatchDst (.L__pc.8147.ST), (.L__movme_cp.24), (.L__pc.8147.ST)
	.L__pc.8147.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8148
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8148: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8149
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8149: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8150
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8150: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8151
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8151: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8152
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.8152: Dma_PatchSrc (.L__pc.8152.LD), (.L__movme_cp.67), (.L__pc.8152.LD)
	.p2align 4
	.L__pc.8152.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8153
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8153: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8154
	.L__pc.8154: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8155
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8155: Dma_PatchSrc (.L__pc.8155.LD), (.L__movme_cp.24), (.L__pc.8155.LD)
	.p2align 4
	.L__pc.8155.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8156
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8156: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8157
	.L__pc.8157: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8158
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8158: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8159: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8160: Dma_PatchSrc (.L__pc.8160.LD), (.L__movme_tmp.1), (.L__pc.8160.LD)
	.p2align 4
	.L__pc.8160.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8161
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8161: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8162
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8162: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8163: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8164: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8165: Dma_PatchSrc (.L__pc.8165.LD), (.L__movme_tmp.1), (.L__pc.8165.LD)
	.p2align 4
	.L__pc.8165.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8166
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8166: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8167
	
	.L__pc.8167: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8168
	
	.p2align 4
	.L__pc.8168: Dma_PatchDst (.L__pc.8168.ST), (.L__movme_cp.67), (.L__pc.8168.ST)
	.L__pc.8168.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8169
	
	.L__pc.8169: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8170
	
	.p2align 4
	.L__pc.8170: Dma_PatchDst (.L__pc.8170.ST), (.L__movme_cp.24), (.L__pc.8170.ST)
	.L__pc.8170.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8171
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8171: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8172
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8172: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8173
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8173: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8174
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8174: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8175
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.8175: Dma_PatchSrc (.L__pc.8175.LD), (.L__movme_cp.68), (.L__pc.8175.LD)
	.p2align 4
	.L__pc.8175.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8176
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8176: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8177
	.L__pc.8177: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8178
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8178: Dma_PatchSrc (.L__pc.8178.LD), (.L__movme_cp.24), (.L__pc.8178.LD)
	.p2align 4
	.L__pc.8178.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8179
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8179: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8180
	.L__pc.8180: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8181
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8181: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8182: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8183: Dma_PatchSrc (.L__pc.8183.LD), (.L__movme_tmp.1), (.L__pc.8183.LD)
	.p2align 4
	.L__pc.8183.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8184
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8184: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8185
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8185: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8186: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8187: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8188: Dma_PatchSrc (.L__pc.8188.LD), (.L__movme_tmp.1), (.L__pc.8188.LD)
	.p2align 4
	.L__pc.8188.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8189
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8189: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8190
	
	.L__pc.8190: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8191
	
	.p2align 4
	.L__pc.8191: Dma_PatchDst (.L__pc.8191.ST), (.L__movme_cp.68), (.L__pc.8191.ST)
	.L__pc.8191.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8192
	
	.L__pc.8192: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8193
	
	.p2align 4
	.L__pc.8193: Dma_PatchDst (.L__pc.8193.ST), (.L__movme_cp.24), (.L__pc.8193.ST)
	.L__pc.8193.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8194
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8194: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8195
	
	.p2align 4
	.L__pc.8195: Dma_PatchDst (.L__pc.8195.ST), (.L__movme_cp.24), (.L__pc.8195.ST)
	.L__pc.8195.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8196
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.8196: Dma_PatchSrc (.L__pc.8196.LD), (.L__movme_cp.60), (.L__pc.8196.LD)
	.p2align 4
	.L__pc.8196.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8197
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8197: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8198
	
	.L__pc.8198: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8199
	
	.p2align 4
	.L__pc.8199: Dma_PatchDst (.L__pc.8199.ST), (.L__movme_cp.21), (.L__pc.8199.ST)
	.L__pc.8199.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8200
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.8200: Dma_PatchSrc (.L__pc.8200.LD), (.L__movme_cp.58), (.L__pc.8200.LD)
	.p2align 4
	.L__pc.8200.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8201
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8201: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8202
	
	.L__pc.8202: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8203
	
	.p2align 4
	.L__pc.8203: Dma_PatchDst (.L__pc.8203.ST), (.L__movme_cp.22), (.L__pc.8203.ST)
	.L__pc.8203.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8204
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8204: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8205
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8205: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8206
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8206: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8207
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8207: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8208
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.8208: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.8209
	
	.p2align 4
	.L__pc.8209: Dma_PatchDst (.L__pc.8209.ST), (.L__movme_cp.24), (.L__pc.8209.ST)
	.L__pc.8209.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8210
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.8210: Dma_PatchSrc (.L__pc.8210.LD), (.L__movme_cp.25), (.L__pc.8210.LD)
	.p2align 4
	.L__pc.8210.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8211
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8211: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8212
	.L__pc.8212: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8213
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.8213: Dma_PatchSrc (.L__pc.8213.LD), (.L__movme_cp.26), (.L__pc.8213.LD)
	.p2align 4
	.L__pc.8213.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8214
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8214: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8215
	.L__pc.8215: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8216
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8216: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8217: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8218: Dma_PatchSrc (.L__pc.8218.LD), (.L__movme_tmp.1), (.L__pc.8218.LD)
	.p2align 4
	.L__pc.8218.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8219
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8219: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8220
	.L__pc.8220: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8221
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8221: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8222: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8223: Dma_PatchSrc (.L__pc.8223.LD), (.L__movme_tmp.1), (.L__pc.8223.LD)
	.p2align 4
	.L__pc.8223.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8224
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8224: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8225
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8225: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8226: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8227: Dma_PatchSrc (.L__pc.8227.LD), (.L__movme_tmp.1), (.L__pc.8227.LD)
	.p2align 4
	.L__pc.8227.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8228
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8228: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8229
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8229: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8230: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8231: Dma_PatchSrc (.L__pc.8231.LD), (.L__movme_tmp.1), (.L__pc.8231.LD)
	.p2align 4
	.L__pc.8231.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8232
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8232: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8233
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8233: Dma_PatchSrc (.L__pc.8233.LD), (.L__movme_cp.24), (.L__pc.8233.LD)
	.p2align 4
	.L__pc.8233.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8234
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8234: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8235
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8235: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8236: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8237: Dma_PatchSrc (.L__pc.8237.LD), (.L__movme_tmp.1), (.L__pc.8237.LD)
	.p2align 4
	.L__pc.8237.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8238
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8238: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8239
	
	.L__pc.8239: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8240
	
	.p2align 4
	.L__pc.8240: Dma_PatchDst (.L__pc.8240.ST), (.L__movme_cp.69), (.L__pc.8240.ST)
	.L__pc.8240.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8241
	
	.L__pc.8241: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8242
	
	.p2align 4
	.L__pc.8242: Dma_PatchDst (.L__pc.8242.ST), (.L__movme_cp.54), (.L__pc.8242.ST)
	.L__pc.8242.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8243
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.8243: Dma_PatchSrc (.L__pc.8243.LD), (.L__movme_cp.30), (.L__pc.8243.LD)
	.p2align 4
	.L__pc.8243.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8244
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8244: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8245
	.L__pc.8245: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8246
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.8246: Dma_PatchSrc (.L__pc.8246.LD), (.L__movme_cp.31), (.L__pc.8246.LD)
	.p2align 4
	.L__pc.8246.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8247
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8247: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8248
	.L__pc.8248: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8249
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8249: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8250: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8251: Dma_PatchSrc (.L__pc.8251.LD), (.L__movme_tmp.1), (.L__pc.8251.LD)
	.p2align 4
	.L__pc.8251.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8252
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8252: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8253
	.L__pc.8253: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8254
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8254: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8255: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8256: Dma_PatchSrc (.L__pc.8256.LD), (.L__movme_tmp.1), (.L__pc.8256.LD)
	.p2align 4
	.L__pc.8256.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8257
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8257: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8258
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8258: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8259: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8260: Dma_PatchSrc (.L__pc.8260.LD), (.L__movme_tmp.1), (.L__pc.8260.LD)
	.p2align 4
	.L__pc.8260.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8261
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8261: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8262
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8262: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8263: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8264: Dma_PatchSrc (.L__pc.8264.LD), (.L__movme_tmp.1), (.L__pc.8264.LD)
	.p2align 4
	.L__pc.8264.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8265
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8265: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8266
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8266: Dma_PatchSrc (.L__pc.8266.LD), (.L__movme_cp.24), (.L__pc.8266.LD)
	.p2align 4
	.L__pc.8266.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8267
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8267: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8268
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8268: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8269: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8270: Dma_PatchSrc (.L__pc.8270.LD), (.L__movme_tmp.1), (.L__pc.8270.LD)
	.p2align 4
	.L__pc.8270.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8271
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8271: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8272
	
	.L__pc.8272: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8273
	
	.p2align 4
	.L__pc.8273: Dma_PatchDst (.L__pc.8273.ST), (.L__movme_cp.70), (.L__pc.8273.ST)
	.L__pc.8273.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8274
	
	.L__pc.8274: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8275
	
	.p2align 4
	.L__pc.8275: Dma_PatchDst (.L__pc.8275.ST), (.L__movme_cp.54), (.L__pc.8275.ST)
	.L__pc.8275.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8276
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8276: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8277
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8277: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8278
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8278: Dma_PatchSrc (.L__pc.8278.LD), (.L__movme_cp.24), (.L__pc.8278.LD)
	.p2align 4
	.L__pc.8278.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8279
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8279: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8280
	.L__pc.8280: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8281
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.8281: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8282: Dma_PatchSrc (.L__pc.8282.LD), (.L__movme_tmp.1), (.L__pc.8282.LD)
	.p2align 4
	.L__pc.8282.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8283
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8283: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8284
	.L__pc.8284: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8285
	
	.L__pc.8285: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8286
	
	.p2align 4
	.L__pc.8286: Dma_PatchDst (.L__pc.8286.ST), (.L__movme_cp.72), (.L__pc.8286.ST)
	.L__pc.8286.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8287
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.8287: Dma_PatchSrc (.L__pc.8287.LD), (.L__movme_cp.72), (.L__pc.8287.LD)
	.p2align 4
	.L__pc.8287.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8288
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8288: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8289
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8289: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8290: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8291: Dma_PatchSrc (.L__pc.8291.LD), (.L__movme_tmp.1), (.L__pc.8291.LD)
	.p2align 4
	.L__pc.8291.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8292
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8292: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8293
	
	.L__pc.8293: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8294
	
	.p2align 4
	.L__pc.8294: Dma_PatchDst (.L__pc.8294.ST), (.L__movme_cp.74), (.L__pc.8294.ST)
	.L__pc.8294.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8295
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8295: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8296: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8297: Dma_PatchSrc (.L__pc.8297.LD), (.L__movme_tmp.1), (.L__pc.8297.LD)
	.p2align 4
	.L__pc.8297.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8298
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8298: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8299
	
	.L__pc.8299: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8300
	
	.p2align 4
	.L__pc.8300: Dma_PatchDst (.L__pc.8300.ST), (.L__movme_cp.76), (.L__pc.8300.ST)
	.L__pc.8300.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8301
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.8301: Dma_PatchSrc (.L__pc.8301.LD), (.L__movme_cp.74), (.L__pc.8301.LD)
	.p2align 4
	.L__pc.8301.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8302
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8302: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8303
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.8303: Dma_PatchSrc (.L__pc.8303.LD), ((.L__movme.reg.eax+0)), (.L__pc.8303.LD)
	.p2align 4
	.L__pc.8303.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8304
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8304: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8305
	
	.L__pc.8305: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8306
	
	.p2align 4
	.L__pc.8306: Dma_PatchDst (.L__pc.8306.ST), (.L__movme_cp.77), (.L__pc.8306.ST)
	.L__pc.8306.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8307
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.8307: Dma_PatchSrc (.L__pc.8307.LD), (.L__movme_cp.77), (.L__pc.8307.LD)
	.p2align 4
	.L__pc.8307.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8308
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8308: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8309
	
	.L__pc.8309: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8310
	
	.p2align 4
	.L__pc.8310: Dma_PatchDst (.L__pc.8310.ST), (.L__movme_cp.21), (.L__pc.8310.ST)
	.L__pc.8310.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8311
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.8311: Dma_PatchSrc (.L__pc.8311.LD), (.L__movme_cp.58), (.L__pc.8311.LD)
	.p2align 4
	.L__pc.8311.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8312
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8312: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8313
	
	.L__pc.8313: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8314
	
	.p2align 4
	.L__pc.8314: Dma_PatchDst (.L__pc.8314.ST), (.L__movme_cp.22), (.L__pc.8314.ST)
	.L__pc.8314.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8315
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8315: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8316
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8316: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8317
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8317: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8318
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8318: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8319
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.8319: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.8320
	
	.p2align 4
	.L__pc.8320: Dma_PatchDst (.L__pc.8320.ST), (.L__movme_cp.24), (.L__pc.8320.ST)
	.L__pc.8320.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8321
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.8321: Dma_PatchSrc (.L__pc.8321.LD), (.L__movme_cp.25), (.L__pc.8321.LD)
	.p2align 4
	.L__pc.8321.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8322
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8322: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8323
	.L__pc.8323: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8324
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.8324: Dma_PatchSrc (.L__pc.8324.LD), (.L__movme_cp.26), (.L__pc.8324.LD)
	.p2align 4
	.L__pc.8324.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8325
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8325: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8326
	.L__pc.8326: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8327
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8327: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8328: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8329: Dma_PatchSrc (.L__pc.8329.LD), (.L__movme_tmp.1), (.L__pc.8329.LD)
	.p2align 4
	.L__pc.8329.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8330
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8330: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8331
	.L__pc.8331: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8332
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8332: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8333: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8334: Dma_PatchSrc (.L__pc.8334.LD), (.L__movme_tmp.1), (.L__pc.8334.LD)
	.p2align 4
	.L__pc.8334.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8335
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8335: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8336
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8336: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8337: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8338: Dma_PatchSrc (.L__pc.8338.LD), (.L__movme_tmp.1), (.L__pc.8338.LD)
	.p2align 4
	.L__pc.8338.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8339
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8339: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8340
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8340: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8341: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8342: Dma_PatchSrc (.L__pc.8342.LD), (.L__movme_tmp.1), (.L__pc.8342.LD)
	.p2align 4
	.L__pc.8342.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8343
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8343: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8344
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8344: Dma_PatchSrc (.L__pc.8344.LD), (.L__movme_cp.24), (.L__pc.8344.LD)
	.p2align 4
	.L__pc.8344.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8345
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8345: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8346
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8346: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8347: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8348: Dma_PatchSrc (.L__pc.8348.LD), (.L__movme_tmp.1), (.L__pc.8348.LD)
	.p2align 4
	.L__pc.8348.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8349
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8349: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8350
	
	.L__pc.8350: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8351
	
	.p2align 4
	.L__pc.8351: Dma_PatchDst (.L__pc.8351.ST), (.L__movme_cp.78), (.L__pc.8351.ST)
	.L__pc.8351.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8352
	
	.L__pc.8352: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8353
	
	.p2align 4
	.L__pc.8353: Dma_PatchDst (.L__pc.8353.ST), (.L__movme_cp.54), (.L__pc.8353.ST)
	.L__pc.8353.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8354
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.8354: Dma_PatchSrc (.L__pc.8354.LD), (.L__movme_cp.30), (.L__pc.8354.LD)
	.p2align 4
	.L__pc.8354.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8355
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8355: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8356
	.L__pc.8356: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8357
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.8357: Dma_PatchSrc (.L__pc.8357.LD), (.L__movme_cp.31), (.L__pc.8357.LD)
	.p2align 4
	.L__pc.8357.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8358
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8358: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8359
	.L__pc.8359: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8360
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8360: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8361: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8362: Dma_PatchSrc (.L__pc.8362.LD), (.L__movme_tmp.1), (.L__pc.8362.LD)
	.p2align 4
	.L__pc.8362.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8363
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8363: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8364
	.L__pc.8364: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8365
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8365: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8366: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8367: Dma_PatchSrc (.L__pc.8367.LD), (.L__movme_tmp.1), (.L__pc.8367.LD)
	.p2align 4
	.L__pc.8367.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8368
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8368: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8369
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8369: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8370: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8371: Dma_PatchSrc (.L__pc.8371.LD), (.L__movme_tmp.1), (.L__pc.8371.LD)
	.p2align 4
	.L__pc.8371.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8372
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8372: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8373
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8373: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8374: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8375: Dma_PatchSrc (.L__pc.8375.LD), (.L__movme_tmp.1), (.L__pc.8375.LD)
	.p2align 4
	.L__pc.8375.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8376
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8376: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8377
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8377: Dma_PatchSrc (.L__pc.8377.LD), (.L__movme_cp.24), (.L__pc.8377.LD)
	.p2align 4
	.L__pc.8377.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8378
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8378: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8379
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8379: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8380: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8381: Dma_PatchSrc (.L__pc.8381.LD), (.L__movme_tmp.1), (.L__pc.8381.LD)
	.p2align 4
	.L__pc.8381.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8382
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8382: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8383
	
	.L__pc.8383: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8384
	
	.p2align 4
	.L__pc.8384: Dma_PatchDst (.L__pc.8384.ST), (.L__movme_cp.79), (.L__pc.8384.ST)
	.L__pc.8384.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8385
	
	.L__pc.8385: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8386
	
	.p2align 4
	.L__pc.8386: Dma_PatchDst (.L__pc.8386.ST), (.L__movme_cp.54), (.L__pc.8386.ST)
	.L__pc.8386.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8387
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.8387: Dma_PatchSrc (.L__pc.8387.LD), (.L__movme_cp.74), (.L__pc.8387.LD)
	.p2align 4
	.L__pc.8387.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8388
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8388: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8389
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.8389: Dma_PatchSrc (.L__pc.8389.LD), (.L__movme_cp.77), (.L__pc.8389.LD)
	.p2align 4
	.L__pc.8389.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8390
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8390: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8391
	
	.L__pc.8391: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8392
	
	.p2align 4
	.L__pc.8392: Dma_PatchDst (.L__pc.8392.ST), ((.L__movme.reg.eax+0)), (.L__pc.8392.ST)
	.L__pc.8392.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8393
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.8393: Dma_PatchSrc (.L__pc.8393.LD), (.L__movme_cp.76), (.L__pc.8393.LD)
	.p2align 4
	.L__pc.8393.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8394
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8394: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8395
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.8395: Dma_PatchSrc (.L__pc.8395.LD), ((.L__movme.reg.eax+0)), (.L__pc.8395.LD)
	.p2align 4
	.L__pc.8395.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8396
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8396: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8397
	
	.L__pc.8397: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8398
	
	.p2align 4
	.L__pc.8398: Dma_PatchDst (.L__pc.8398.ST), (.L__movme_cp.80), (.L__pc.8398.ST)
	.L__pc.8398.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8399
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8399: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8400
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8400: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8401
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.8401: Dma_PatchSrc (.L__pc.8401.LD), (.L__movme_cp.100), (.L__pc.8401.LD)
	.p2align 4
	.L__pc.8401.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8402
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8402: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8403
	.L__pc.8403: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8404
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.88 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.8404: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8405: Dma_PatchSrc (.L__pc.8405.LD), (.L__movme_tmp.1), (.L__pc.8405.LD)
	.p2align 4
	.L__pc.8405.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8406
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8406: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8407
	.L__pc.8407: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8408
	
	.L__pc.8408: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8409
	
	.p2align 4
	.L__pc.8409: Dma_PatchDst (.L__pc.8409.ST), (.L__movme_cp.100), (.L__pc.8409.ST)
	.L__pc.8409.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8410
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.8410: Dma_PatchSrc (.L__pc.8410.LD), (.L__movme_cp.76), (.L__pc.8410.LD)
	.p2align 4
	.L__pc.8410.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8411
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8411: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8412
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.8412: Dma_PatchSrc (.L__pc.8412.LD), (.L__movme_cp.80), (.L__pc.8412.LD)
	.p2align 4
	.L__pc.8412.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8413
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8413: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8414
	
	.L__pc.8414: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8415
	
	.p2align 4
	.L__pc.8415: Dma_PatchDst (.L__pc.8415.ST), ((.L__movme.reg.eax+0)), (.L__pc.8415.ST)
	.L__pc.8415.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8416
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8416: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8417
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8417: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8418
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.8418: Dma_PatchSrc (.L__pc.8418.LD), (.L__movme_cp.99), (.L__pc.8418.LD)
	.p2align 4
	.L__pc.8418.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8419
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8419: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8420
	.L__pc.8420: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8421
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8421: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.89 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8422: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8423: Dma_PatchSrc (.L__pc.8423.LD), (.L__movme_tmp.1), (.L__pc.8423.LD)
	.p2align 4
	.L__pc.8423.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8424
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8424: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8425
	
	.L__pc.8425: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8426
	
	.p2align 4
	.L__pc.8426: Dma_PatchDst (.L__pc.8426.ST), (.L__movme_cp.24), (.L__pc.8426.ST)
	.L__pc.8426.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8427
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8427: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8428
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8428: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8429
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8429: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8430
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8430: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8431
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.8431: Dma_PatchSrc (.L__pc.8431.LD), (.L__movme_cp.63), (.L__pc.8431.LD)
	.p2align 4
	.L__pc.8431.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8432
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8432: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8433
	.L__pc.8433: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8434
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8434: Dma_PatchSrc (.L__pc.8434.LD), (.L__movme_cp.24), (.L__pc.8434.LD)
	.p2align 4
	.L__pc.8434.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8435
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8435: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8436
	.L__pc.8436: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8437
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8437: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8438: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8439: Dma_PatchSrc (.L__pc.8439.LD), (.L__movme_tmp.1), (.L__pc.8439.LD)
	.p2align 4
	.L__pc.8439.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8440
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8440: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8441
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8441: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8442: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8443: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8444: Dma_PatchSrc (.L__pc.8444.LD), (.L__movme_tmp.1), (.L__pc.8444.LD)
	.p2align 4
	.L__pc.8444.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8445
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8445: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8446
	
	.L__pc.8446: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8447
	
	.p2align 4
	.L__pc.8447: Dma_PatchDst (.L__pc.8447.ST), (.L__movme_cp.63), (.L__pc.8447.ST)
	.L__pc.8447.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8448
	
	.L__pc.8448: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8449
	
	.p2align 4
	.L__pc.8449: Dma_PatchDst (.L__pc.8449.ST), (.L__movme_cp.24), (.L__pc.8449.ST)
	.L__pc.8449.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8450
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8450: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8451
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8451: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8452
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8452: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8453
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8453: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8454
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.8454: Dma_PatchSrc (.L__pc.8454.LD), (.L__movme_cp.66), (.L__pc.8454.LD)
	.p2align 4
	.L__pc.8454.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8455
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8455: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8456
	.L__pc.8456: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8457
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8457: Dma_PatchSrc (.L__pc.8457.LD), (.L__movme_cp.24), (.L__pc.8457.LD)
	.p2align 4
	.L__pc.8457.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8458
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8458: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8459
	.L__pc.8459: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8460
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8460: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8461: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8462: Dma_PatchSrc (.L__pc.8462.LD), (.L__movme_tmp.1), (.L__pc.8462.LD)
	.p2align 4
	.L__pc.8462.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8463
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8463: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8464
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8464: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8465: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8466: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8467: Dma_PatchSrc (.L__pc.8467.LD), (.L__movme_tmp.1), (.L__pc.8467.LD)
	.p2align 4
	.L__pc.8467.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8468
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8468: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8469
	
	.L__pc.8469: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8470
	
	.p2align 4
	.L__pc.8470: Dma_PatchDst (.L__pc.8470.ST), (.L__movme_cp.66), (.L__pc.8470.ST)
	.L__pc.8470.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8471
	
	.L__pc.8471: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8472
	
	.p2align 4
	.L__pc.8472: Dma_PatchDst (.L__pc.8472.ST), (.L__movme_cp.24), (.L__pc.8472.ST)
	.L__pc.8472.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8473
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8473: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8474
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8474: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8475
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8475: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8476
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8476: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8477
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.8477: Dma_PatchSrc (.L__pc.8477.LD), (.L__movme_cp.67), (.L__pc.8477.LD)
	.p2align 4
	.L__pc.8477.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8478
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8478: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8479
	.L__pc.8479: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8480
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8480: Dma_PatchSrc (.L__pc.8480.LD), (.L__movme_cp.24), (.L__pc.8480.LD)
	.p2align 4
	.L__pc.8480.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8481
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8481: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8482
	.L__pc.8482: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8483
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8483: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8484: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8485: Dma_PatchSrc (.L__pc.8485.LD), (.L__movme_tmp.1), (.L__pc.8485.LD)
	.p2align 4
	.L__pc.8485.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8486
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8486: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8487
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8487: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8488: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8489: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8490: Dma_PatchSrc (.L__pc.8490.LD), (.L__movme_tmp.1), (.L__pc.8490.LD)
	.p2align 4
	.L__pc.8490.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8491
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8491: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8492
	
	.L__pc.8492: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8493
	
	.p2align 4
	.L__pc.8493: Dma_PatchDst (.L__pc.8493.ST), (.L__movme_cp.67), (.L__pc.8493.ST)
	.L__pc.8493.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8494
	
	.L__pc.8494: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8495
	
	.p2align 4
	.L__pc.8495: Dma_PatchDst (.L__pc.8495.ST), (.L__movme_cp.24), (.L__pc.8495.ST)
	.L__pc.8495.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8496
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8496: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8497
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8497: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8498
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8498: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8499
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8499: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8500
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.8500: Dma_PatchSrc (.L__pc.8500.LD), (.L__movme_cp.68), (.L__pc.8500.LD)
	.p2align 4
	.L__pc.8500.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8501
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8501: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8502
	.L__pc.8502: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8503
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8503: Dma_PatchSrc (.L__pc.8503.LD), (.L__movme_cp.24), (.L__pc.8503.LD)
	.p2align 4
	.L__pc.8503.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8504
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8504: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8505
	.L__pc.8505: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8506
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8506: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8507: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8508: Dma_PatchSrc (.L__pc.8508.LD), (.L__movme_tmp.1), (.L__pc.8508.LD)
	.p2align 4
	.L__pc.8508.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8509
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8509: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8510
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8510: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8511: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8512: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8513: Dma_PatchSrc (.L__pc.8513.LD), (.L__movme_tmp.1), (.L__pc.8513.LD)
	.p2align 4
	.L__pc.8513.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8514
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8514: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8515
	
	.L__pc.8515: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8516
	
	.p2align 4
	.L__pc.8516: Dma_PatchDst (.L__pc.8516.ST), (.L__movme_cp.68), (.L__pc.8516.ST)
	.L__pc.8516.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8517
	
	.L__pc.8517: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8518
	
	.p2align 4
	.L__pc.8518: Dma_PatchDst (.L__pc.8518.ST), (.L__movme_cp.24), (.L__pc.8518.ST)
	.L__pc.8518.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8519
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8519: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8520
	
	.p2align 4
	.L__pc.8520: Dma_PatchDst (.L__pc.8520.ST), (.L__movme_cp.24), (.L__pc.8520.ST)
	.L__pc.8520.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8521
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.8521: Dma_PatchSrc (.L__pc.8521.LD), (.L__movme_cp.60), (.L__pc.8521.LD)
	.p2align 4
	.L__pc.8521.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8522
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8522: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8523
	
	.L__pc.8523: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8524
	
	.p2align 4
	.L__pc.8524: Dma_PatchDst (.L__pc.8524.ST), (.L__movme_cp.21), (.L__pc.8524.ST)
	.L__pc.8524.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8525
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.8525: Dma_PatchSrc (.L__pc.8525.LD), (.L__movme_cp.58), (.L__pc.8525.LD)
	.p2align 4
	.L__pc.8525.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8526
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8526: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8527
	
	.L__pc.8527: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8528
	
	.p2align 4
	.L__pc.8528: Dma_PatchDst (.L__pc.8528.ST), (.L__movme_cp.22), (.L__pc.8528.ST)
	.L__pc.8528.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8529
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8529: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8530
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8530: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8531
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8531: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8532
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8532: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8533
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.8533: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.8534
	
	.p2align 4
	.L__pc.8534: Dma_PatchDst (.L__pc.8534.ST), (.L__movme_cp.24), (.L__pc.8534.ST)
	.L__pc.8534.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8535
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.8535: Dma_PatchSrc (.L__pc.8535.LD), (.L__movme_cp.25), (.L__pc.8535.LD)
	.p2align 4
	.L__pc.8535.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8536
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8536: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8537
	.L__pc.8537: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8538
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.8538: Dma_PatchSrc (.L__pc.8538.LD), (.L__movme_cp.26), (.L__pc.8538.LD)
	.p2align 4
	.L__pc.8538.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8539
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8539: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8540
	.L__pc.8540: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8541
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8541: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8542: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8543: Dma_PatchSrc (.L__pc.8543.LD), (.L__movme_tmp.1), (.L__pc.8543.LD)
	.p2align 4
	.L__pc.8543.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8544
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8544: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8545
	.L__pc.8545: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8546
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8546: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8547: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8548: Dma_PatchSrc (.L__pc.8548.LD), (.L__movme_tmp.1), (.L__pc.8548.LD)
	.p2align 4
	.L__pc.8548.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8549
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8549: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8550
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8550: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8551: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8552: Dma_PatchSrc (.L__pc.8552.LD), (.L__movme_tmp.1), (.L__pc.8552.LD)
	.p2align 4
	.L__pc.8552.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8553
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8553: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8554
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8554: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8555: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8556: Dma_PatchSrc (.L__pc.8556.LD), (.L__movme_tmp.1), (.L__pc.8556.LD)
	.p2align 4
	.L__pc.8556.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8557
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8557: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8558
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8558: Dma_PatchSrc (.L__pc.8558.LD), (.L__movme_cp.24), (.L__pc.8558.LD)
	.p2align 4
	.L__pc.8558.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8559
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8559: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8560
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8560: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8561: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8562: Dma_PatchSrc (.L__pc.8562.LD), (.L__movme_tmp.1), (.L__pc.8562.LD)
	.p2align 4
	.L__pc.8562.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8563
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8563: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8564
	
	.L__pc.8564: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8565
	
	.p2align 4
	.L__pc.8565: Dma_PatchDst (.L__pc.8565.ST), (.L__movme_cp.69), (.L__pc.8565.ST)
	.L__pc.8565.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8566
	
	.L__pc.8566: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8567
	
	.p2align 4
	.L__pc.8567: Dma_PatchDst (.L__pc.8567.ST), (.L__movme_cp.54), (.L__pc.8567.ST)
	.L__pc.8567.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8568
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.8568: Dma_PatchSrc (.L__pc.8568.LD), (.L__movme_cp.30), (.L__pc.8568.LD)
	.p2align 4
	.L__pc.8568.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8569
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8569: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8570
	.L__pc.8570: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8571
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.8571: Dma_PatchSrc (.L__pc.8571.LD), (.L__movme_cp.31), (.L__pc.8571.LD)
	.p2align 4
	.L__pc.8571.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8572
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8572: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8573
	.L__pc.8573: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8574
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8574: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8575: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8576: Dma_PatchSrc (.L__pc.8576.LD), (.L__movme_tmp.1), (.L__pc.8576.LD)
	.p2align 4
	.L__pc.8576.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8577
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8577: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8578
	.L__pc.8578: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8579
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8579: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8580: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8581: Dma_PatchSrc (.L__pc.8581.LD), (.L__movme_tmp.1), (.L__pc.8581.LD)
	.p2align 4
	.L__pc.8581.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8582
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8582: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8583
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8583: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8584: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8585: Dma_PatchSrc (.L__pc.8585.LD), (.L__movme_tmp.1), (.L__pc.8585.LD)
	.p2align 4
	.L__pc.8585.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8586
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8586: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8587
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8587: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8588: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8589: Dma_PatchSrc (.L__pc.8589.LD), (.L__movme_tmp.1), (.L__pc.8589.LD)
	.p2align 4
	.L__pc.8589.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8590
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8590: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8591
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8591: Dma_PatchSrc (.L__pc.8591.LD), (.L__movme_cp.24), (.L__pc.8591.LD)
	.p2align 4
	.L__pc.8591.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8592
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8592: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8593
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8593: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8594: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8595: Dma_PatchSrc (.L__pc.8595.LD), (.L__movme_tmp.1), (.L__pc.8595.LD)
	.p2align 4
	.L__pc.8595.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8596
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8596: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8597
	
	.L__pc.8597: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8598
	
	.p2align 4
	.L__pc.8598: Dma_PatchDst (.L__pc.8598.ST), (.L__movme_cp.70), (.L__pc.8598.ST)
	.L__pc.8598.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8599
	
	.L__pc.8599: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8600
	
	.p2align 4
	.L__pc.8600: Dma_PatchDst (.L__pc.8600.ST), (.L__movme_cp.54), (.L__pc.8600.ST)
	.L__pc.8600.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8601
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8601: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8602
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8602: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8603
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8603: Dma_PatchSrc (.L__pc.8603.LD), (.L__movme_cp.24), (.L__pc.8603.LD)
	.p2align 4
	.L__pc.8603.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8604
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8604: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8605
	.L__pc.8605: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8606
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.8606: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8607: Dma_PatchSrc (.L__pc.8607.LD), (.L__movme_tmp.1), (.L__pc.8607.LD)
	.p2align 4
	.L__pc.8607.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8608
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8608: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8609
	.L__pc.8609: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8610
	
	.L__pc.8610: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8611
	
	.p2align 4
	.L__pc.8611: Dma_PatchDst (.L__pc.8611.ST), (.L__movme_cp.72), (.L__pc.8611.ST)
	.L__pc.8611.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8612
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.8612: Dma_PatchSrc (.L__pc.8612.LD), (.L__movme_cp.72), (.L__pc.8612.LD)
	.p2align 4
	.L__pc.8612.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8613
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8613: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8614
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8614: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8615: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8616: Dma_PatchSrc (.L__pc.8616.LD), (.L__movme_tmp.1), (.L__pc.8616.LD)
	.p2align 4
	.L__pc.8616.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8617
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8617: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8618
	
	.L__pc.8618: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8619
	
	.p2align 4
	.L__pc.8619: Dma_PatchDst (.L__pc.8619.ST), (.L__movme_cp.74), (.L__pc.8619.ST)
	.L__pc.8619.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8620
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8620: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8621: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8622: Dma_PatchSrc (.L__pc.8622.LD), (.L__movme_tmp.1), (.L__pc.8622.LD)
	.p2align 4
	.L__pc.8622.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8623
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8623: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8624
	
	.L__pc.8624: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8625
	
	.p2align 4
	.L__pc.8625: Dma_PatchDst (.L__pc.8625.ST), (.L__movme_cp.76), (.L__pc.8625.ST)
	.L__pc.8625.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8626
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.8626: Dma_PatchSrc (.L__pc.8626.LD), (.L__movme_cp.74), (.L__pc.8626.LD)
	.p2align 4
	.L__pc.8626.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8627
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8627: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8628
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.8628: Dma_PatchSrc (.L__pc.8628.LD), ((.L__movme.reg.eax+0)), (.L__pc.8628.LD)
	.p2align 4
	.L__pc.8628.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8629
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8629: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8630
	
	.L__pc.8630: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8631
	
	.p2align 4
	.L__pc.8631: Dma_PatchDst (.L__pc.8631.ST), (.L__movme_cp.77), (.L__pc.8631.ST)
	.L__pc.8631.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8632
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.8632: Dma_PatchSrc (.L__pc.8632.LD), (.L__movme_cp.77), (.L__pc.8632.LD)
	.p2align 4
	.L__pc.8632.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8633
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8633: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8634
	
	.L__pc.8634: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8635
	
	.p2align 4
	.L__pc.8635: Dma_PatchDst (.L__pc.8635.ST), (.L__movme_cp.21), (.L__pc.8635.ST)
	.L__pc.8635.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8636
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.8636: Dma_PatchSrc (.L__pc.8636.LD), (.L__movme_cp.58), (.L__pc.8636.LD)
	.p2align 4
	.L__pc.8636.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8637
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8637: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8638
	
	.L__pc.8638: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8639
	
	.p2align 4
	.L__pc.8639: Dma_PatchDst (.L__pc.8639.ST), (.L__movme_cp.22), (.L__pc.8639.ST)
	.L__pc.8639.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8640
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8640: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8641
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8641: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8642
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8642: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8643
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8643: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8644
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.8644: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.8645
	
	.p2align 4
	.L__pc.8645: Dma_PatchDst (.L__pc.8645.ST), (.L__movme_cp.24), (.L__pc.8645.ST)
	.L__pc.8645.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8646
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.8646: Dma_PatchSrc (.L__pc.8646.LD), (.L__movme_cp.25), (.L__pc.8646.LD)
	.p2align 4
	.L__pc.8646.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8647
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8647: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8648
	.L__pc.8648: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8649
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.8649: Dma_PatchSrc (.L__pc.8649.LD), (.L__movme_cp.26), (.L__pc.8649.LD)
	.p2align 4
	.L__pc.8649.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8650
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8650: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8651
	.L__pc.8651: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8652
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8652: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8653: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8654: Dma_PatchSrc (.L__pc.8654.LD), (.L__movme_tmp.1), (.L__pc.8654.LD)
	.p2align 4
	.L__pc.8654.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8655
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8655: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8656
	.L__pc.8656: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8657
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8657: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8658: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8659: Dma_PatchSrc (.L__pc.8659.LD), (.L__movme_tmp.1), (.L__pc.8659.LD)
	.p2align 4
	.L__pc.8659.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8660
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8660: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8661
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8661: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8662: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8663: Dma_PatchSrc (.L__pc.8663.LD), (.L__movme_tmp.1), (.L__pc.8663.LD)
	.p2align 4
	.L__pc.8663.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8664
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8664: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8665
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8665: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8666: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8667: Dma_PatchSrc (.L__pc.8667.LD), (.L__movme_tmp.1), (.L__pc.8667.LD)
	.p2align 4
	.L__pc.8667.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8668
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8668: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8669
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8669: Dma_PatchSrc (.L__pc.8669.LD), (.L__movme_cp.24), (.L__pc.8669.LD)
	.p2align 4
	.L__pc.8669.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8670
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8670: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8671
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8671: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8672: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8673: Dma_PatchSrc (.L__pc.8673.LD), (.L__movme_tmp.1), (.L__pc.8673.LD)
	.p2align 4
	.L__pc.8673.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8674
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8674: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8675
	
	.L__pc.8675: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8676
	
	.p2align 4
	.L__pc.8676: Dma_PatchDst (.L__pc.8676.ST), (.L__movme_cp.78), (.L__pc.8676.ST)
	.L__pc.8676.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8677
	
	.L__pc.8677: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8678
	
	.p2align 4
	.L__pc.8678: Dma_PatchDst (.L__pc.8678.ST), (.L__movme_cp.54), (.L__pc.8678.ST)
	.L__pc.8678.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8679
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.8679: Dma_PatchSrc (.L__pc.8679.LD), (.L__movme_cp.30), (.L__pc.8679.LD)
	.p2align 4
	.L__pc.8679.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8680
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8680: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8681
	.L__pc.8681: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8682
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.8682: Dma_PatchSrc (.L__pc.8682.LD), (.L__movme_cp.31), (.L__pc.8682.LD)
	.p2align 4
	.L__pc.8682.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8683
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8683: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8684
	.L__pc.8684: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8685
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8685: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8686: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8687: Dma_PatchSrc (.L__pc.8687.LD), (.L__movme_tmp.1), (.L__pc.8687.LD)
	.p2align 4
	.L__pc.8687.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8688
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8688: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8689
	.L__pc.8689: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8690
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8690: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8691: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8692: Dma_PatchSrc (.L__pc.8692.LD), (.L__movme_tmp.1), (.L__pc.8692.LD)
	.p2align 4
	.L__pc.8692.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8693
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8693: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8694
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8694: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8695: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8696: Dma_PatchSrc (.L__pc.8696.LD), (.L__movme_tmp.1), (.L__pc.8696.LD)
	.p2align 4
	.L__pc.8696.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8697
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8697: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8698
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8698: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8699: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8700: Dma_PatchSrc (.L__pc.8700.LD), (.L__movme_tmp.1), (.L__pc.8700.LD)
	.p2align 4
	.L__pc.8700.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8701
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8701: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8702
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8702: Dma_PatchSrc (.L__pc.8702.LD), (.L__movme_cp.24), (.L__pc.8702.LD)
	.p2align 4
	.L__pc.8702.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8703
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8703: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8704
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8704: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8705: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8706: Dma_PatchSrc (.L__pc.8706.LD), (.L__movme_tmp.1), (.L__pc.8706.LD)
	.p2align 4
	.L__pc.8706.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8707
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8707: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8708
	
	.L__pc.8708: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8709
	
	.p2align 4
	.L__pc.8709: Dma_PatchDst (.L__pc.8709.ST), (.L__movme_cp.79), (.L__pc.8709.ST)
	.L__pc.8709.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8710
	
	.L__pc.8710: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8711
	
	.p2align 4
	.L__pc.8711: Dma_PatchDst (.L__pc.8711.ST), (.L__movme_cp.54), (.L__pc.8711.ST)
	.L__pc.8711.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8712
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.8712: Dma_PatchSrc (.L__pc.8712.LD), (.L__movme_cp.74), (.L__pc.8712.LD)
	.p2align 4
	.L__pc.8712.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8713
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8713: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8714
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.8714: Dma_PatchSrc (.L__pc.8714.LD), (.L__movme_cp.77), (.L__pc.8714.LD)
	.p2align 4
	.L__pc.8714.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8715
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8715: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8716
	
	.L__pc.8716: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8717
	
	.p2align 4
	.L__pc.8717: Dma_PatchDst (.L__pc.8717.ST), ((.L__movme.reg.eax+0)), (.L__pc.8717.ST)
	.L__pc.8717.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8718
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.8718: Dma_PatchSrc (.L__pc.8718.LD), (.L__movme_cp.76), (.L__pc.8718.LD)
	.p2align 4
	.L__pc.8718.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8719
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8719: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8720
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.8720: Dma_PatchSrc (.L__pc.8720.LD), ((.L__movme.reg.eax+0)), (.L__pc.8720.LD)
	.p2align 4
	.L__pc.8720.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8721
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8721: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8722
	
	.L__pc.8722: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8723
	
	.p2align 4
	.L__pc.8723: Dma_PatchDst (.L__pc.8723.ST), (.L__movme_cp.80), (.L__pc.8723.ST)
	.L__pc.8723.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8724
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8724: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8725
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8725: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8726
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.8726: Dma_PatchSrc (.L__pc.8726.LD), (.L__movme_cp.100), (.L__pc.8726.LD)
	.p2align 4
	.L__pc.8726.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8727
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8727: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8728
	.L__pc.8728: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8729
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.90 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.8729: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8730: Dma_PatchSrc (.L__pc.8730.LD), (.L__movme_tmp.1), (.L__pc.8730.LD)
	.p2align 4
	.L__pc.8730.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8731
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8731: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8732
	.L__pc.8732: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8733
	
	.L__pc.8733: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8734
	
	.p2align 4
	.L__pc.8734: Dma_PatchDst (.L__pc.8734.ST), (.L__movme_cp.100), (.L__pc.8734.ST)
	.L__pc.8734.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8735
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.8735: Dma_PatchSrc (.L__pc.8735.LD), (.L__movme_cp.76), (.L__pc.8735.LD)
	.p2align 4
	.L__pc.8735.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8736
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8736: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8737
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.8737: Dma_PatchSrc (.L__pc.8737.LD), (.L__movme_cp.80), (.L__pc.8737.LD)
	.p2align 4
	.L__pc.8737.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8738
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8738: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8739
	
	.L__pc.8739: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8740
	
	.p2align 4
	.L__pc.8740: Dma_PatchDst (.L__pc.8740.ST), ((.L__movme.reg.eax+0)), (.L__pc.8740.ST)
	.L__pc.8740.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8741
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8741: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8742
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8742: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8743
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.8743: Dma_PatchSrc (.L__pc.8743.LD), (.L__movme_cp.99), (.L__pc.8743.LD)
	.p2align 4
	.L__pc.8743.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8744
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8744: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8745
	.L__pc.8745: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8746
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8746: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.91 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8747: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8748: Dma_PatchSrc (.L__pc.8748.LD), (.L__movme_tmp.1), (.L__pc.8748.LD)
	.p2align 4
	.L__pc.8748.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8749
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8749: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8750
	
	.L__pc.8750: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8751
	
	.p2align 4
	.L__pc.8751: Dma_PatchDst (.L__pc.8751.ST), (.L__movme_cp.24), (.L__pc.8751.ST)
	.L__pc.8751.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8752
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8752: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8753
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8753: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8754
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8754: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8755
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8755: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8756
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.8756: Dma_PatchSrc (.L__pc.8756.LD), (.L__movme_cp.63), (.L__pc.8756.LD)
	.p2align 4
	.L__pc.8756.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8757
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8757: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8758
	.L__pc.8758: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8759
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8759: Dma_PatchSrc (.L__pc.8759.LD), (.L__movme_cp.24), (.L__pc.8759.LD)
	.p2align 4
	.L__pc.8759.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8760
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8760: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8761
	.L__pc.8761: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8762
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8762: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8763: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8764: Dma_PatchSrc (.L__pc.8764.LD), (.L__movme_tmp.1), (.L__pc.8764.LD)
	.p2align 4
	.L__pc.8764.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8765
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8765: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8766
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8766: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8767: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8768: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8769: Dma_PatchSrc (.L__pc.8769.LD), (.L__movme_tmp.1), (.L__pc.8769.LD)
	.p2align 4
	.L__pc.8769.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8770
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8770: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8771
	
	.L__pc.8771: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8772
	
	.p2align 4
	.L__pc.8772: Dma_PatchDst (.L__pc.8772.ST), (.L__movme_cp.63), (.L__pc.8772.ST)
	.L__pc.8772.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8773
	
	.L__pc.8773: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8774
	
	.p2align 4
	.L__pc.8774: Dma_PatchDst (.L__pc.8774.ST), (.L__movme_cp.24), (.L__pc.8774.ST)
	.L__pc.8774.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8775
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8775: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8776
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8776: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8777
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8777: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8778
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8778: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8779
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.8779: Dma_PatchSrc (.L__pc.8779.LD), (.L__movme_cp.66), (.L__pc.8779.LD)
	.p2align 4
	.L__pc.8779.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8780
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8780: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8781
	.L__pc.8781: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8782
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8782: Dma_PatchSrc (.L__pc.8782.LD), (.L__movme_cp.24), (.L__pc.8782.LD)
	.p2align 4
	.L__pc.8782.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8783
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8783: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8784
	.L__pc.8784: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8785
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8785: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8786: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8787: Dma_PatchSrc (.L__pc.8787.LD), (.L__movme_tmp.1), (.L__pc.8787.LD)
	.p2align 4
	.L__pc.8787.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8788
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8788: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8789
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8789: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8790: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8791: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8792: Dma_PatchSrc (.L__pc.8792.LD), (.L__movme_tmp.1), (.L__pc.8792.LD)
	.p2align 4
	.L__pc.8792.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8793
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8793: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8794
	
	.L__pc.8794: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8795
	
	.p2align 4
	.L__pc.8795: Dma_PatchDst (.L__pc.8795.ST), (.L__movme_cp.66), (.L__pc.8795.ST)
	.L__pc.8795.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8796
	
	.L__pc.8796: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8797
	
	.p2align 4
	.L__pc.8797: Dma_PatchDst (.L__pc.8797.ST), (.L__movme_cp.24), (.L__pc.8797.ST)
	.L__pc.8797.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8798
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8798: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8799
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8799: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8800
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8800: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8801
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8801: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8802
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.8802: Dma_PatchSrc (.L__pc.8802.LD), (.L__movme_cp.67), (.L__pc.8802.LD)
	.p2align 4
	.L__pc.8802.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8803
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8803: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8804
	.L__pc.8804: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8805
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8805: Dma_PatchSrc (.L__pc.8805.LD), (.L__movme_cp.24), (.L__pc.8805.LD)
	.p2align 4
	.L__pc.8805.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8806
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8806: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8807
	.L__pc.8807: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8808
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8808: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8809: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8810: Dma_PatchSrc (.L__pc.8810.LD), (.L__movme_tmp.1), (.L__pc.8810.LD)
	.p2align 4
	.L__pc.8810.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8811
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8811: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8812
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8812: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8813: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8814: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8815: Dma_PatchSrc (.L__pc.8815.LD), (.L__movme_tmp.1), (.L__pc.8815.LD)
	.p2align 4
	.L__pc.8815.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8816
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8816: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8817
	
	.L__pc.8817: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8818
	
	.p2align 4
	.L__pc.8818: Dma_PatchDst (.L__pc.8818.ST), (.L__movme_cp.67), (.L__pc.8818.ST)
	.L__pc.8818.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8819
	
	.L__pc.8819: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8820
	
	.p2align 4
	.L__pc.8820: Dma_PatchDst (.L__pc.8820.ST), (.L__movme_cp.24), (.L__pc.8820.ST)
	.L__pc.8820.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8821
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8821: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8822
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8822: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8823
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8823: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8824
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8824: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8825
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.8825: Dma_PatchSrc (.L__pc.8825.LD), (.L__movme_cp.68), (.L__pc.8825.LD)
	.p2align 4
	.L__pc.8825.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8826
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8826: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8827
	.L__pc.8827: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8828
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8828: Dma_PatchSrc (.L__pc.8828.LD), (.L__movme_cp.24), (.L__pc.8828.LD)
	.p2align 4
	.L__pc.8828.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8829
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8829: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.8830
	.L__pc.8830: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.8831
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8831: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8832: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8833: Dma_PatchSrc (.L__pc.8833.LD), (.L__movme_tmp.1), (.L__pc.8833.LD)
	.p2align 4
	.L__pc.8833.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8834
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8834: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8835
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.8835: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.8836: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.8837: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8838: Dma_PatchSrc (.L__pc.8838.LD), (.L__movme_tmp.1), (.L__pc.8838.LD)
	.p2align 4
	.L__pc.8838.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8839
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8839: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8840
	
	.L__pc.8840: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.8841
	
	.p2align 4
	.L__pc.8841: Dma_PatchDst (.L__pc.8841.ST), (.L__movme_cp.68), (.L__pc.8841.ST)
	.L__pc.8841.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8842
	
	.L__pc.8842: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.8843
	
	.p2align 4
	.L__pc.8843: Dma_PatchDst (.L__pc.8843.ST), (.L__movme_cp.24), (.L__pc.8843.ST)
	.L__pc.8843.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8844
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8844: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8845
	
	.p2align 4
	.L__pc.8845: Dma_PatchDst (.L__pc.8845.ST), (.L__movme_cp.24), (.L__pc.8845.ST)
	.L__pc.8845.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8846
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.8846: Dma_PatchSrc (.L__pc.8846.LD), (.L__movme_cp.60), (.L__pc.8846.LD)
	.p2align 4
	.L__pc.8846.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8847
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8847: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8848
	
	.L__pc.8848: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8849
	
	.p2align 4
	.L__pc.8849: Dma_PatchDst (.L__pc.8849.ST), (.L__movme_cp.21), (.L__pc.8849.ST)
	.L__pc.8849.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8850
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.8850: Dma_PatchSrc (.L__pc.8850.LD), (.L__movme_cp.58), (.L__pc.8850.LD)
	.p2align 4
	.L__pc.8850.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8851
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8851: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8852
	
	.L__pc.8852: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8853
	
	.p2align 4
	.L__pc.8853: Dma_PatchDst (.L__pc.8853.ST), (.L__movme_cp.22), (.L__pc.8853.ST)
	.L__pc.8853.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8854
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8854: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8855
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8855: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8856
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8856: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8857
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8857: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8858
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.8858: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.8859
	
	.p2align 4
	.L__pc.8859: Dma_PatchDst (.L__pc.8859.ST), (.L__movme_cp.24), (.L__pc.8859.ST)
	.L__pc.8859.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8860
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.8860: Dma_PatchSrc (.L__pc.8860.LD), (.L__movme_cp.25), (.L__pc.8860.LD)
	.p2align 4
	.L__pc.8860.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8861
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8861: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8862
	.L__pc.8862: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8863
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.8863: Dma_PatchSrc (.L__pc.8863.LD), (.L__movme_cp.26), (.L__pc.8863.LD)
	.p2align 4
	.L__pc.8863.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8864
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8864: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8865
	.L__pc.8865: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8866
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8866: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8867: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8868: Dma_PatchSrc (.L__pc.8868.LD), (.L__movme_tmp.1), (.L__pc.8868.LD)
	.p2align 4
	.L__pc.8868.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8869
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8869: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8870
	.L__pc.8870: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8871
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8871: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8872: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8873: Dma_PatchSrc (.L__pc.8873.LD), (.L__movme_tmp.1), (.L__pc.8873.LD)
	.p2align 4
	.L__pc.8873.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8874
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8874: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8875
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8875: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8876: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8877: Dma_PatchSrc (.L__pc.8877.LD), (.L__movme_tmp.1), (.L__pc.8877.LD)
	.p2align 4
	.L__pc.8877.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8878
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8878: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8879
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8879: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8880: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8881: Dma_PatchSrc (.L__pc.8881.LD), (.L__movme_tmp.1), (.L__pc.8881.LD)
	.p2align 4
	.L__pc.8881.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8882
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8882: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8883
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8883: Dma_PatchSrc (.L__pc.8883.LD), (.L__movme_cp.24), (.L__pc.8883.LD)
	.p2align 4
	.L__pc.8883.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8884
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8884: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8885
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8885: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8886: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8887: Dma_PatchSrc (.L__pc.8887.LD), (.L__movme_tmp.1), (.L__pc.8887.LD)
	.p2align 4
	.L__pc.8887.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8888
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8888: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8889
	
	.L__pc.8889: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8890
	
	.p2align 4
	.L__pc.8890: Dma_PatchDst (.L__pc.8890.ST), (.L__movme_cp.69), (.L__pc.8890.ST)
	.L__pc.8890.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8891
	
	.L__pc.8891: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8892
	
	.p2align 4
	.L__pc.8892: Dma_PatchDst (.L__pc.8892.ST), (.L__movme_cp.54), (.L__pc.8892.ST)
	.L__pc.8892.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8893
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.8893: Dma_PatchSrc (.L__pc.8893.LD), (.L__movme_cp.30), (.L__pc.8893.LD)
	.p2align 4
	.L__pc.8893.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8894
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8894: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8895
	.L__pc.8895: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8896
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.8896: Dma_PatchSrc (.L__pc.8896.LD), (.L__movme_cp.31), (.L__pc.8896.LD)
	.p2align 4
	.L__pc.8896.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8897
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8897: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8898
	.L__pc.8898: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8899
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8899: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8900: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8901: Dma_PatchSrc (.L__pc.8901.LD), (.L__movme_tmp.1), (.L__pc.8901.LD)
	.p2align 4
	.L__pc.8901.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8902
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8902: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8903
	.L__pc.8903: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8904
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8904: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8905: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8906: Dma_PatchSrc (.L__pc.8906.LD), (.L__movme_tmp.1), (.L__pc.8906.LD)
	.p2align 4
	.L__pc.8906.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8907
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8907: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8908
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8908: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8909: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8910: Dma_PatchSrc (.L__pc.8910.LD), (.L__movme_tmp.1), (.L__pc.8910.LD)
	.p2align 4
	.L__pc.8910.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8911
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8911: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8912
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8912: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8913: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8914: Dma_PatchSrc (.L__pc.8914.LD), (.L__movme_tmp.1), (.L__pc.8914.LD)
	.p2align 4
	.L__pc.8914.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8915
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8915: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8916
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8916: Dma_PatchSrc (.L__pc.8916.LD), (.L__movme_cp.24), (.L__pc.8916.LD)
	.p2align 4
	.L__pc.8916.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8917
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8917: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8918
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8918: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8919: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8920: Dma_PatchSrc (.L__pc.8920.LD), (.L__movme_tmp.1), (.L__pc.8920.LD)
	.p2align 4
	.L__pc.8920.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8921
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8921: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8922
	
	.L__pc.8922: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.8923
	
	.p2align 4
	.L__pc.8923: Dma_PatchDst (.L__pc.8923.ST), (.L__movme_cp.70), (.L__pc.8923.ST)
	.L__pc.8923.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8924
	
	.L__pc.8924: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8925
	
	.p2align 4
	.L__pc.8925: Dma_PatchDst (.L__pc.8925.ST), (.L__movme_cp.54), (.L__pc.8925.ST)
	.L__pc.8925.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8926
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8926: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8927
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8927: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8928
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8928: Dma_PatchSrc (.L__pc.8928.LD), (.L__movme_cp.24), (.L__pc.8928.LD)
	.p2align 4
	.L__pc.8928.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8929
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8929: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8930
	.L__pc.8930: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8931
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.8931: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8932: Dma_PatchSrc (.L__pc.8932.LD), (.L__movme_tmp.1), (.L__pc.8932.LD)
	.p2align 4
	.L__pc.8932.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8933
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8933: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.8934
	.L__pc.8934: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.8935
	
	.L__pc.8935: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8936
	
	.p2align 4
	.L__pc.8936: Dma_PatchDst (.L__pc.8936.ST), (.L__movme_cp.72), (.L__pc.8936.ST)
	.L__pc.8936.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8937
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.8937: Dma_PatchSrc (.L__pc.8937.LD), (.L__movme_cp.72), (.L__pc.8937.LD)
	.p2align 4
	.L__pc.8937.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8938
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8938: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8939
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8939: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8940: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8941: Dma_PatchSrc (.L__pc.8941.LD), (.L__movme_tmp.1), (.L__pc.8941.LD)
	.p2align 4
	.L__pc.8941.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8942
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8942: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8943
	
	.L__pc.8943: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8944
	
	.p2align 4
	.L__pc.8944: Dma_PatchDst (.L__pc.8944.ST), (.L__movme_cp.74), (.L__pc.8944.ST)
	.L__pc.8944.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8945
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8945: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8946: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8947: Dma_PatchSrc (.L__pc.8947.LD), (.L__movme_tmp.1), (.L__pc.8947.LD)
	.p2align 4
	.L__pc.8947.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8948
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8948: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8949
	
	.L__pc.8949: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.8950
	
	.p2align 4
	.L__pc.8950: Dma_PatchDst (.L__pc.8950.ST), (.L__movme_cp.76), (.L__pc.8950.ST)
	.L__pc.8950.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8951
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.8951: Dma_PatchSrc (.L__pc.8951.LD), (.L__movme_cp.74), (.L__pc.8951.LD)
	.p2align 4
	.L__pc.8951.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8952
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8952: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8953
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.8953: Dma_PatchSrc (.L__pc.8953.LD), ((.L__movme.reg.eax+0)), (.L__pc.8953.LD)
	.p2align 4
	.L__pc.8953.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8954
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8954: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8955
	
	.L__pc.8955: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8956
	
	.p2align 4
	.L__pc.8956: Dma_PatchDst (.L__pc.8956.ST), (.L__movme_cp.77), (.L__pc.8956.ST)
	.L__pc.8956.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8957
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.8957: Dma_PatchSrc (.L__pc.8957.LD), (.L__movme_cp.77), (.L__pc.8957.LD)
	.p2align 4
	.L__pc.8957.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8958
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8958: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8959
	
	.L__pc.8959: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8960
	
	.p2align 4
	.L__pc.8960: Dma_PatchDst (.L__pc.8960.ST), (.L__movme_cp.21), (.L__pc.8960.ST)
	.L__pc.8960.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8961
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.8961: Dma_PatchSrc (.L__pc.8961.LD), (.L__movme_cp.58), (.L__pc.8961.LD)
	.p2align 4
	.L__pc.8961.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8962
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8962: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8963
	
	.L__pc.8963: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.8964
	
	.p2align 4
	.L__pc.8964: Dma_PatchDst (.L__pc.8964.ST), (.L__movme_cp.22), (.L__pc.8964.ST)
	.L__pc.8964.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8965
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8965: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8966
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8966: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.8967
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.8967: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.8968
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8968: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8969
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.8969: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.8970
	
	.p2align 4
	.L__pc.8970: Dma_PatchDst (.L__pc.8970.ST), (.L__movme_cp.24), (.L__pc.8970.ST)
	.L__pc.8970.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.8971
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.8971: Dma_PatchSrc (.L__pc.8971.LD), (.L__movme_cp.25), (.L__pc.8971.LD)
	.p2align 4
	.L__pc.8971.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8972
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.8972: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.8973
	.L__pc.8973: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.8974
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.8974: Dma_PatchSrc (.L__pc.8974.LD), (.L__movme_cp.26), (.L__pc.8974.LD)
	.p2align 4
	.L__pc.8974.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8975
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8975: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8976
	.L__pc.8976: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8977
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.8977: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8978: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8979: Dma_PatchSrc (.L__pc.8979.LD), (.L__movme_tmp.1), (.L__pc.8979.LD)
	.p2align 4
	.L__pc.8979.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8980
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8980: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.8981
	.L__pc.8981: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.8982
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.8982: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8983: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8984: Dma_PatchSrc (.L__pc.8984.LD), (.L__movme_tmp.1), (.L__pc.8984.LD)
	.p2align 4
	.L__pc.8984.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8985
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8985: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8986
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8986: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8987: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8988: Dma_PatchSrc (.L__pc.8988.LD), (.L__movme_tmp.1), (.L__pc.8988.LD)
	.p2align 4
	.L__pc.8988.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8989
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8989: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8990
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.8990: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8991: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8992: Dma_PatchSrc (.L__pc.8992.LD), (.L__movme_tmp.1), (.L__pc.8992.LD)
	.p2align 4
	.L__pc.8992.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8993
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8993: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.8994
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.8994: Dma_PatchSrc (.L__pc.8994.LD), (.L__movme_cp.24), (.L__pc.8994.LD)
	.p2align 4
	.L__pc.8994.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8995
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.8995: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.8996
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.8996: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.8997: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.8998: Dma_PatchSrc (.L__pc.8998.LD), (.L__movme_tmp.1), (.L__pc.8998.LD)
	.p2align 4
	.L__pc.8998.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.8999
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.8999: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9000
	
	.L__pc.9000: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9001
	
	.p2align 4
	.L__pc.9001: Dma_PatchDst (.L__pc.9001.ST), (.L__movme_cp.78), (.L__pc.9001.ST)
	.L__pc.9001.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9002
	
	.L__pc.9002: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9003
	
	.p2align 4
	.L__pc.9003: Dma_PatchDst (.L__pc.9003.ST), (.L__movme_cp.54), (.L__pc.9003.ST)
	.L__pc.9003.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9004
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.9004: Dma_PatchSrc (.L__pc.9004.LD), (.L__movme_cp.30), (.L__pc.9004.LD)
	.p2align 4
	.L__pc.9004.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9005
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9005: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9006
	.L__pc.9006: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9007
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.9007: Dma_PatchSrc (.L__pc.9007.LD), (.L__movme_cp.31), (.L__pc.9007.LD)
	.p2align 4
	.L__pc.9007.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9008
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9008: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9009
	.L__pc.9009: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9010
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9010: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9011: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9012: Dma_PatchSrc (.L__pc.9012.LD), (.L__movme_tmp.1), (.L__pc.9012.LD)
	.p2align 4
	.L__pc.9012.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9013
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9013: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9014
	.L__pc.9014: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9015
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9015: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9016: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9017: Dma_PatchSrc (.L__pc.9017.LD), (.L__movme_tmp.1), (.L__pc.9017.LD)
	.p2align 4
	.L__pc.9017.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9018
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9018: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9019
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9019: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9020: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9021: Dma_PatchSrc (.L__pc.9021.LD), (.L__movme_tmp.1), (.L__pc.9021.LD)
	.p2align 4
	.L__pc.9021.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9022
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9022: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9023
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9023: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9024: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9025: Dma_PatchSrc (.L__pc.9025.LD), (.L__movme_tmp.1), (.L__pc.9025.LD)
	.p2align 4
	.L__pc.9025.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9026
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9026: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9027
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9027: Dma_PatchSrc (.L__pc.9027.LD), (.L__movme_cp.24), (.L__pc.9027.LD)
	.p2align 4
	.L__pc.9027.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9028
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9028: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9029
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9029: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9030: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9031: Dma_PatchSrc (.L__pc.9031.LD), (.L__movme_tmp.1), (.L__pc.9031.LD)
	.p2align 4
	.L__pc.9031.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9032
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9032: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9033
	
	.L__pc.9033: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9034
	
	.p2align 4
	.L__pc.9034: Dma_PatchDst (.L__pc.9034.ST), (.L__movme_cp.79), (.L__pc.9034.ST)
	.L__pc.9034.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9035
	
	.L__pc.9035: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9036
	
	.p2align 4
	.L__pc.9036: Dma_PatchDst (.L__pc.9036.ST), (.L__movme_cp.54), (.L__pc.9036.ST)
	.L__pc.9036.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9037
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.9037: Dma_PatchSrc (.L__pc.9037.LD), (.L__movme_cp.74), (.L__pc.9037.LD)
	.p2align 4
	.L__pc.9037.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9038
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9038: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9039
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.9039: Dma_PatchSrc (.L__pc.9039.LD), (.L__movme_cp.77), (.L__pc.9039.LD)
	.p2align 4
	.L__pc.9039.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9040
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9040: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9041
	
	.L__pc.9041: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9042
	
	.p2align 4
	.L__pc.9042: Dma_PatchDst (.L__pc.9042.ST), ((.L__movme.reg.eax+0)), (.L__pc.9042.ST)
	.L__pc.9042.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9043
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.9043: Dma_PatchSrc (.L__pc.9043.LD), (.L__movme_cp.76), (.L__pc.9043.LD)
	.p2align 4
	.L__pc.9043.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9044
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9044: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9045
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.9045: Dma_PatchSrc (.L__pc.9045.LD), ((.L__movme.reg.eax+0)), (.L__pc.9045.LD)
	.p2align 4
	.L__pc.9045.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9046
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9046: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9047
	
	.L__pc.9047: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9048
	
	.p2align 4
	.L__pc.9048: Dma_PatchDst (.L__pc.9048.ST), (.L__movme_cp.80), (.L__pc.9048.ST)
	.L__pc.9048.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9049
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9049: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9050
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9050: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9051
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.9051: Dma_PatchSrc (.L__pc.9051.LD), (.L__movme_cp.100), (.L__pc.9051.LD)
	.p2align 4
	.L__pc.9051.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9052
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9052: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9053
	.L__pc.9053: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9054
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.92 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.9054: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9055: Dma_PatchSrc (.L__pc.9055.LD), (.L__movme_tmp.1), (.L__pc.9055.LD)
	.p2align 4
	.L__pc.9055.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9056
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9056: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9057
	.L__pc.9057: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9058
	
	.L__pc.9058: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9059
	
	.p2align 4
	.L__pc.9059: Dma_PatchDst (.L__pc.9059.ST), (.L__movme_cp.100), (.L__pc.9059.ST)
	.L__pc.9059.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9060
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.9060: Dma_PatchSrc (.L__pc.9060.LD), (.L__movme_cp.76), (.L__pc.9060.LD)
	.p2align 4
	.L__pc.9060.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9061
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9061: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9062
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.9062: Dma_PatchSrc (.L__pc.9062.LD), (.L__movme_cp.80), (.L__pc.9062.LD)
	.p2align 4
	.L__pc.9062.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9063
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9063: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9064
	
	.L__pc.9064: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9065
	
	.p2align 4
	.L__pc.9065: Dma_PatchDst (.L__pc.9065.ST), ((.L__movme.reg.eax+0)), (.L__pc.9065.ST)
	.L__pc.9065.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9066
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9066: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9067
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9067: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9068
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.9068: Dma_PatchSrc (.L__pc.9068.LD), (.L__movme_cp.99), (.L__pc.9068.LD)
	.p2align 4
	.L__pc.9068.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9069
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9069: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9070
	.L__pc.9070: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9071
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9071: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.93 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9072: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9073: Dma_PatchSrc (.L__pc.9073.LD), (.L__movme_tmp.1), (.L__pc.9073.LD)
	.p2align 4
	.L__pc.9073.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9074
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9074: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9075
	
	.L__pc.9075: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9076
	
	.p2align 4
	.L__pc.9076: Dma_PatchDst (.L__pc.9076.ST), (.L__movme_cp.24), (.L__pc.9076.ST)
	.L__pc.9076.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9077
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9077: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9078
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9078: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9079
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9079: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9080
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9080: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9081
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.9081: Dma_PatchSrc (.L__pc.9081.LD), (.L__movme_cp.63), (.L__pc.9081.LD)
	.p2align 4
	.L__pc.9081.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9082
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9082: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9083
	.L__pc.9083: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9084
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9084: Dma_PatchSrc (.L__pc.9084.LD), (.L__movme_cp.24), (.L__pc.9084.LD)
	.p2align 4
	.L__pc.9084.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9085
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9085: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9086
	.L__pc.9086: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9087
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9087: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9088: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9089: Dma_PatchSrc (.L__pc.9089.LD), (.L__movme_tmp.1), (.L__pc.9089.LD)
	.p2align 4
	.L__pc.9089.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9090
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9090: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9091
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9091: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9092: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9093: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9094: Dma_PatchSrc (.L__pc.9094.LD), (.L__movme_tmp.1), (.L__pc.9094.LD)
	.p2align 4
	.L__pc.9094.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9095
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9095: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9096
	
	.L__pc.9096: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9097
	
	.p2align 4
	.L__pc.9097: Dma_PatchDst (.L__pc.9097.ST), (.L__movme_cp.63), (.L__pc.9097.ST)
	.L__pc.9097.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9098
	
	.L__pc.9098: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9099
	
	.p2align 4
	.L__pc.9099: Dma_PatchDst (.L__pc.9099.ST), (.L__movme_cp.24), (.L__pc.9099.ST)
	.L__pc.9099.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9100
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9100: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9101
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9101: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9102
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9102: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9103
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9103: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9104
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.9104: Dma_PatchSrc (.L__pc.9104.LD), (.L__movme_cp.66), (.L__pc.9104.LD)
	.p2align 4
	.L__pc.9104.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9105
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9105: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9106
	.L__pc.9106: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9107
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9107: Dma_PatchSrc (.L__pc.9107.LD), (.L__movme_cp.24), (.L__pc.9107.LD)
	.p2align 4
	.L__pc.9107.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9108
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9108: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9109
	.L__pc.9109: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9110
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9110: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9111: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9112: Dma_PatchSrc (.L__pc.9112.LD), (.L__movme_tmp.1), (.L__pc.9112.LD)
	.p2align 4
	.L__pc.9112.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9113
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9113: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9114
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9114: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9115: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9116: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9117: Dma_PatchSrc (.L__pc.9117.LD), (.L__movme_tmp.1), (.L__pc.9117.LD)
	.p2align 4
	.L__pc.9117.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9118
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9118: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9119
	
	.L__pc.9119: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9120
	
	.p2align 4
	.L__pc.9120: Dma_PatchDst (.L__pc.9120.ST), (.L__movme_cp.66), (.L__pc.9120.ST)
	.L__pc.9120.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9121
	
	.L__pc.9121: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9122
	
	.p2align 4
	.L__pc.9122: Dma_PatchDst (.L__pc.9122.ST), (.L__movme_cp.24), (.L__pc.9122.ST)
	.L__pc.9122.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9123
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9123: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9124
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9124: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9125
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9125: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9126
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9126: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9127
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.9127: Dma_PatchSrc (.L__pc.9127.LD), (.L__movme_cp.67), (.L__pc.9127.LD)
	.p2align 4
	.L__pc.9127.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9128
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9128: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9129
	.L__pc.9129: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9130
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9130: Dma_PatchSrc (.L__pc.9130.LD), (.L__movme_cp.24), (.L__pc.9130.LD)
	.p2align 4
	.L__pc.9130.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9131
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9131: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9132
	.L__pc.9132: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9133
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9133: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9134: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9135: Dma_PatchSrc (.L__pc.9135.LD), (.L__movme_tmp.1), (.L__pc.9135.LD)
	.p2align 4
	.L__pc.9135.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9136
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9136: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9137
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9137: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9138: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9139: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9140: Dma_PatchSrc (.L__pc.9140.LD), (.L__movme_tmp.1), (.L__pc.9140.LD)
	.p2align 4
	.L__pc.9140.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9141
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9141: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9142
	
	.L__pc.9142: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9143
	
	.p2align 4
	.L__pc.9143: Dma_PatchDst (.L__pc.9143.ST), (.L__movme_cp.67), (.L__pc.9143.ST)
	.L__pc.9143.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9144
	
	.L__pc.9144: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9145
	
	.p2align 4
	.L__pc.9145: Dma_PatchDst (.L__pc.9145.ST), (.L__movme_cp.24), (.L__pc.9145.ST)
	.L__pc.9145.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9146
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9146: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9147
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9147: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9148
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9148: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9149
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9149: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9150
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.9150: Dma_PatchSrc (.L__pc.9150.LD), (.L__movme_cp.68), (.L__pc.9150.LD)
	.p2align 4
	.L__pc.9150.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9151
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9151: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9152
	.L__pc.9152: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9153
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9153: Dma_PatchSrc (.L__pc.9153.LD), (.L__movme_cp.24), (.L__pc.9153.LD)
	.p2align 4
	.L__pc.9153.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9154
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9154: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9155
	.L__pc.9155: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9156
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9156: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9157: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9158: Dma_PatchSrc (.L__pc.9158.LD), (.L__movme_tmp.1), (.L__pc.9158.LD)
	.p2align 4
	.L__pc.9158.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9159
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9159: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9160
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9160: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9161: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9162: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9163: Dma_PatchSrc (.L__pc.9163.LD), (.L__movme_tmp.1), (.L__pc.9163.LD)
	.p2align 4
	.L__pc.9163.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9164
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9164: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9165
	
	.L__pc.9165: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9166
	
	.p2align 4
	.L__pc.9166: Dma_PatchDst (.L__pc.9166.ST), (.L__movme_cp.68), (.L__pc.9166.ST)
	.L__pc.9166.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9167
	
	.L__pc.9167: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9168
	
	.p2align 4
	.L__pc.9168: Dma_PatchDst (.L__pc.9168.ST), (.L__movme_cp.24), (.L__pc.9168.ST)
	.L__pc.9168.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9169
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9169: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9170
	
	.p2align 4
	.L__pc.9170: Dma_PatchDst (.L__pc.9170.ST), (.L__movme_cp.24), (.L__pc.9170.ST)
	.L__pc.9170.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9171
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.9171: Dma_PatchSrc (.L__pc.9171.LD), (.L__movme_cp.60), (.L__pc.9171.LD)
	.p2align 4
	.L__pc.9171.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9172
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9172: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9173
	
	.L__pc.9173: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9174
	
	.p2align 4
	.L__pc.9174: Dma_PatchDst (.L__pc.9174.ST), (.L__movme_cp.21), (.L__pc.9174.ST)
	.L__pc.9174.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9175
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.9175: Dma_PatchSrc (.L__pc.9175.LD), (.L__movme_cp.58), (.L__pc.9175.LD)
	.p2align 4
	.L__pc.9175.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9176
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9176: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9177
	
	.L__pc.9177: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9178
	
	.p2align 4
	.L__pc.9178: Dma_PatchDst (.L__pc.9178.ST), (.L__movme_cp.22), (.L__pc.9178.ST)
	.L__pc.9178.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9179
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9179: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9180
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9180: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9181
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9181: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9182
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9182: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9183
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.9183: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.9184
	
	.p2align 4
	.L__pc.9184: Dma_PatchDst (.L__pc.9184.ST), (.L__movme_cp.24), (.L__pc.9184.ST)
	.L__pc.9184.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9185
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.9185: Dma_PatchSrc (.L__pc.9185.LD), (.L__movme_cp.25), (.L__pc.9185.LD)
	.p2align 4
	.L__pc.9185.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9186
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9186: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9187
	.L__pc.9187: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9188
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.9188: Dma_PatchSrc (.L__pc.9188.LD), (.L__movme_cp.26), (.L__pc.9188.LD)
	.p2align 4
	.L__pc.9188.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9189
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9189: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9190
	.L__pc.9190: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9191
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9191: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9192: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9193: Dma_PatchSrc (.L__pc.9193.LD), (.L__movme_tmp.1), (.L__pc.9193.LD)
	.p2align 4
	.L__pc.9193.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9194
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9194: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9195
	.L__pc.9195: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9196
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9196: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9197: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9198: Dma_PatchSrc (.L__pc.9198.LD), (.L__movme_tmp.1), (.L__pc.9198.LD)
	.p2align 4
	.L__pc.9198.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9199
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9199: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9200
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9200: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9201: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9202: Dma_PatchSrc (.L__pc.9202.LD), (.L__movme_tmp.1), (.L__pc.9202.LD)
	.p2align 4
	.L__pc.9202.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9203
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9203: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9204
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9204: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9205: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9206: Dma_PatchSrc (.L__pc.9206.LD), (.L__movme_tmp.1), (.L__pc.9206.LD)
	.p2align 4
	.L__pc.9206.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9207
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9207: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9208
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9208: Dma_PatchSrc (.L__pc.9208.LD), (.L__movme_cp.24), (.L__pc.9208.LD)
	.p2align 4
	.L__pc.9208.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9209
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9209: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9210
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9210: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9211: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9212: Dma_PatchSrc (.L__pc.9212.LD), (.L__movme_tmp.1), (.L__pc.9212.LD)
	.p2align 4
	.L__pc.9212.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9213
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9213: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9214
	
	.L__pc.9214: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9215
	
	.p2align 4
	.L__pc.9215: Dma_PatchDst (.L__pc.9215.ST), (.L__movme_cp.69), (.L__pc.9215.ST)
	.L__pc.9215.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9216
	
	.L__pc.9216: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9217
	
	.p2align 4
	.L__pc.9217: Dma_PatchDst (.L__pc.9217.ST), (.L__movme_cp.54), (.L__pc.9217.ST)
	.L__pc.9217.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9218
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.9218: Dma_PatchSrc (.L__pc.9218.LD), (.L__movme_cp.30), (.L__pc.9218.LD)
	.p2align 4
	.L__pc.9218.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9219
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9219: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9220
	.L__pc.9220: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9221
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.9221: Dma_PatchSrc (.L__pc.9221.LD), (.L__movme_cp.31), (.L__pc.9221.LD)
	.p2align 4
	.L__pc.9221.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9222
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9222: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9223
	.L__pc.9223: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9224
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9224: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9225: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9226: Dma_PatchSrc (.L__pc.9226.LD), (.L__movme_tmp.1), (.L__pc.9226.LD)
	.p2align 4
	.L__pc.9226.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9227
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9227: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9228
	.L__pc.9228: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9229
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9229: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9230: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9231: Dma_PatchSrc (.L__pc.9231.LD), (.L__movme_tmp.1), (.L__pc.9231.LD)
	.p2align 4
	.L__pc.9231.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9232
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9232: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9233
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9233: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9234: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9235: Dma_PatchSrc (.L__pc.9235.LD), (.L__movme_tmp.1), (.L__pc.9235.LD)
	.p2align 4
	.L__pc.9235.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9236
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9236: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9237
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9237: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9238: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9239: Dma_PatchSrc (.L__pc.9239.LD), (.L__movme_tmp.1), (.L__pc.9239.LD)
	.p2align 4
	.L__pc.9239.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9240
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9240: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9241
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9241: Dma_PatchSrc (.L__pc.9241.LD), (.L__movme_cp.24), (.L__pc.9241.LD)
	.p2align 4
	.L__pc.9241.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9242
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9242: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9243
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9243: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9244: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9245: Dma_PatchSrc (.L__pc.9245.LD), (.L__movme_tmp.1), (.L__pc.9245.LD)
	.p2align 4
	.L__pc.9245.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9246
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9246: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9247
	
	.L__pc.9247: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9248
	
	.p2align 4
	.L__pc.9248: Dma_PatchDst (.L__pc.9248.ST), (.L__movme_cp.70), (.L__pc.9248.ST)
	.L__pc.9248.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9249
	
	.L__pc.9249: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9250
	
	.p2align 4
	.L__pc.9250: Dma_PatchDst (.L__pc.9250.ST), (.L__movme_cp.54), (.L__pc.9250.ST)
	.L__pc.9250.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9251
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9251: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9252
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9252: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9253
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9253: Dma_PatchSrc (.L__pc.9253.LD), (.L__movme_cp.24), (.L__pc.9253.LD)
	.p2align 4
	.L__pc.9253.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9254
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9254: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9255
	.L__pc.9255: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9256
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.9256: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9257: Dma_PatchSrc (.L__pc.9257.LD), (.L__movme_tmp.1), (.L__pc.9257.LD)
	.p2align 4
	.L__pc.9257.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9258
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9258: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9259
	.L__pc.9259: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9260
	
	.L__pc.9260: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9261
	
	.p2align 4
	.L__pc.9261: Dma_PatchDst (.L__pc.9261.ST), (.L__movme_cp.72), (.L__pc.9261.ST)
	.L__pc.9261.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9262
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.9262: Dma_PatchSrc (.L__pc.9262.LD), (.L__movme_cp.72), (.L__pc.9262.LD)
	.p2align 4
	.L__pc.9262.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9263
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9263: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9264
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9264: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9265: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9266: Dma_PatchSrc (.L__pc.9266.LD), (.L__movme_tmp.1), (.L__pc.9266.LD)
	.p2align 4
	.L__pc.9266.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9267
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9267: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9268
	
	.L__pc.9268: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9269
	
	.p2align 4
	.L__pc.9269: Dma_PatchDst (.L__pc.9269.ST), (.L__movme_cp.74), (.L__pc.9269.ST)
	.L__pc.9269.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9270
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9270: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9271: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9272: Dma_PatchSrc (.L__pc.9272.LD), (.L__movme_tmp.1), (.L__pc.9272.LD)
	.p2align 4
	.L__pc.9272.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9273
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9273: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9274
	
	.L__pc.9274: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9275
	
	.p2align 4
	.L__pc.9275: Dma_PatchDst (.L__pc.9275.ST), (.L__movme_cp.76), (.L__pc.9275.ST)
	.L__pc.9275.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9276
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.9276: Dma_PatchSrc (.L__pc.9276.LD), (.L__movme_cp.74), (.L__pc.9276.LD)
	.p2align 4
	.L__pc.9276.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9277
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9277: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9278
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.9278: Dma_PatchSrc (.L__pc.9278.LD), ((.L__movme.reg.eax+0)), (.L__pc.9278.LD)
	.p2align 4
	.L__pc.9278.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9279
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9279: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9280
	
	.L__pc.9280: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9281
	
	.p2align 4
	.L__pc.9281: Dma_PatchDst (.L__pc.9281.ST), (.L__movme_cp.77), (.L__pc.9281.ST)
	.L__pc.9281.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9282
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.9282: Dma_PatchSrc (.L__pc.9282.LD), (.L__movme_cp.77), (.L__pc.9282.LD)
	.p2align 4
	.L__pc.9282.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9283
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9283: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9284
	
	.L__pc.9284: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9285
	
	.p2align 4
	.L__pc.9285: Dma_PatchDst (.L__pc.9285.ST), (.L__movme_cp.21), (.L__pc.9285.ST)
	.L__pc.9285.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9286
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.9286: Dma_PatchSrc (.L__pc.9286.LD), (.L__movme_cp.58), (.L__pc.9286.LD)
	.p2align 4
	.L__pc.9286.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9287
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9287: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9288
	
	.L__pc.9288: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9289
	
	.p2align 4
	.L__pc.9289: Dma_PatchDst (.L__pc.9289.ST), (.L__movme_cp.22), (.L__pc.9289.ST)
	.L__pc.9289.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9290
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9290: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9291
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9291: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9292
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9292: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9293
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9293: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9294
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.9294: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.9295
	
	.p2align 4
	.L__pc.9295: Dma_PatchDst (.L__pc.9295.ST), (.L__movme_cp.24), (.L__pc.9295.ST)
	.L__pc.9295.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9296
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.9296: Dma_PatchSrc (.L__pc.9296.LD), (.L__movme_cp.25), (.L__pc.9296.LD)
	.p2align 4
	.L__pc.9296.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9297
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9297: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9298
	.L__pc.9298: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9299
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.9299: Dma_PatchSrc (.L__pc.9299.LD), (.L__movme_cp.26), (.L__pc.9299.LD)
	.p2align 4
	.L__pc.9299.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9300
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9300: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9301
	.L__pc.9301: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9302
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9302: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9303: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9304: Dma_PatchSrc (.L__pc.9304.LD), (.L__movme_tmp.1), (.L__pc.9304.LD)
	.p2align 4
	.L__pc.9304.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9305
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9305: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9306
	.L__pc.9306: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9307
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9307: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9308: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9309: Dma_PatchSrc (.L__pc.9309.LD), (.L__movme_tmp.1), (.L__pc.9309.LD)
	.p2align 4
	.L__pc.9309.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9310
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9310: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9311
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9311: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9312: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9313: Dma_PatchSrc (.L__pc.9313.LD), (.L__movme_tmp.1), (.L__pc.9313.LD)
	.p2align 4
	.L__pc.9313.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9314
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9314: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9315
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9315: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9316: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9317: Dma_PatchSrc (.L__pc.9317.LD), (.L__movme_tmp.1), (.L__pc.9317.LD)
	.p2align 4
	.L__pc.9317.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9318
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9318: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9319
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9319: Dma_PatchSrc (.L__pc.9319.LD), (.L__movme_cp.24), (.L__pc.9319.LD)
	.p2align 4
	.L__pc.9319.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9320
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9320: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9321
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9321: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9322: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9323: Dma_PatchSrc (.L__pc.9323.LD), (.L__movme_tmp.1), (.L__pc.9323.LD)
	.p2align 4
	.L__pc.9323.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9324
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9324: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9325
	
	.L__pc.9325: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9326
	
	.p2align 4
	.L__pc.9326: Dma_PatchDst (.L__pc.9326.ST), (.L__movme_cp.78), (.L__pc.9326.ST)
	.L__pc.9326.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9327
	
	.L__pc.9327: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9328
	
	.p2align 4
	.L__pc.9328: Dma_PatchDst (.L__pc.9328.ST), (.L__movme_cp.54), (.L__pc.9328.ST)
	.L__pc.9328.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9329
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.9329: Dma_PatchSrc (.L__pc.9329.LD), (.L__movme_cp.30), (.L__pc.9329.LD)
	.p2align 4
	.L__pc.9329.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9330
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9330: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9331
	.L__pc.9331: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9332
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.9332: Dma_PatchSrc (.L__pc.9332.LD), (.L__movme_cp.31), (.L__pc.9332.LD)
	.p2align 4
	.L__pc.9332.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9333
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9333: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9334
	.L__pc.9334: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9335
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9335: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9336: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9337: Dma_PatchSrc (.L__pc.9337.LD), (.L__movme_tmp.1), (.L__pc.9337.LD)
	.p2align 4
	.L__pc.9337.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9338
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9338: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9339
	.L__pc.9339: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9340
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9340: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9341: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9342: Dma_PatchSrc (.L__pc.9342.LD), (.L__movme_tmp.1), (.L__pc.9342.LD)
	.p2align 4
	.L__pc.9342.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9343
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9343: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9344
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9344: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9345: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9346: Dma_PatchSrc (.L__pc.9346.LD), (.L__movme_tmp.1), (.L__pc.9346.LD)
	.p2align 4
	.L__pc.9346.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9347
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9347: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9348
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9348: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9349: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9350: Dma_PatchSrc (.L__pc.9350.LD), (.L__movme_tmp.1), (.L__pc.9350.LD)
	.p2align 4
	.L__pc.9350.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9351
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9351: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9352
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9352: Dma_PatchSrc (.L__pc.9352.LD), (.L__movme_cp.24), (.L__pc.9352.LD)
	.p2align 4
	.L__pc.9352.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9353
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9353: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9354
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9354: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9355: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9356: Dma_PatchSrc (.L__pc.9356.LD), (.L__movme_tmp.1), (.L__pc.9356.LD)
	.p2align 4
	.L__pc.9356.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9357
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9357: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9358
	
	.L__pc.9358: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9359
	
	.p2align 4
	.L__pc.9359: Dma_PatchDst (.L__pc.9359.ST), (.L__movme_cp.79), (.L__pc.9359.ST)
	.L__pc.9359.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9360
	
	.L__pc.9360: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9361
	
	.p2align 4
	.L__pc.9361: Dma_PatchDst (.L__pc.9361.ST), (.L__movme_cp.54), (.L__pc.9361.ST)
	.L__pc.9361.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9362
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.9362: Dma_PatchSrc (.L__pc.9362.LD), (.L__movme_cp.74), (.L__pc.9362.LD)
	.p2align 4
	.L__pc.9362.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9363
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9363: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9364
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.9364: Dma_PatchSrc (.L__pc.9364.LD), (.L__movme_cp.77), (.L__pc.9364.LD)
	.p2align 4
	.L__pc.9364.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9365
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9365: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9366
	
	.L__pc.9366: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9367
	
	.p2align 4
	.L__pc.9367: Dma_PatchDst (.L__pc.9367.ST), ((.L__movme.reg.eax+0)), (.L__pc.9367.ST)
	.L__pc.9367.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9368
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.9368: Dma_PatchSrc (.L__pc.9368.LD), (.L__movme_cp.76), (.L__pc.9368.LD)
	.p2align 4
	.L__pc.9368.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9369
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9369: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9370
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.9370: Dma_PatchSrc (.L__pc.9370.LD), ((.L__movme.reg.eax+0)), (.L__pc.9370.LD)
	.p2align 4
	.L__pc.9370.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9371
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9371: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9372
	
	.L__pc.9372: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9373
	
	.p2align 4
	.L__pc.9373: Dma_PatchDst (.L__pc.9373.ST), (.L__movme_cp.80), (.L__pc.9373.ST)
	.L__pc.9373.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9374
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9374: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9375
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9375: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9376
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.9376: Dma_PatchSrc (.L__pc.9376.LD), (.L__movme_cp.100), (.L__pc.9376.LD)
	.p2align 4
	.L__pc.9376.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9377
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9377: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9378
	.L__pc.9378: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9379
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.94 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.9379: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9380: Dma_PatchSrc (.L__pc.9380.LD), (.L__movme_tmp.1), (.L__pc.9380.LD)
	.p2align 4
	.L__pc.9380.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9381
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9381: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9382
	.L__pc.9382: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9383
	
	.L__pc.9383: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9384
	
	.p2align 4
	.L__pc.9384: Dma_PatchDst (.L__pc.9384.ST), (.L__movme_cp.100), (.L__pc.9384.ST)
	.L__pc.9384.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9385
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.9385: Dma_PatchSrc (.L__pc.9385.LD), (.L__movme_cp.76), (.L__pc.9385.LD)
	.p2align 4
	.L__pc.9385.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9386
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9386: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9387
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.9387: Dma_PatchSrc (.L__pc.9387.LD), (.L__movme_cp.80), (.L__pc.9387.LD)
	.p2align 4
	.L__pc.9387.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9388
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9388: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9389
	
	.L__pc.9389: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9390
	
	.p2align 4
	.L__pc.9390: Dma_PatchDst (.L__pc.9390.ST), ((.L__movme.reg.eax+0)), (.L__pc.9390.ST)
	.L__pc.9390.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9391
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9391: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9392
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9392: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9393
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.9393: Dma_PatchSrc (.L__pc.9393.LD), (.L__movme_cp.99), (.L__pc.9393.LD)
	.p2align 4
	.L__pc.9393.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9394
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9394: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9395
	.L__pc.9395: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9396
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9396: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.95 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9397: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9398: Dma_PatchSrc (.L__pc.9398.LD), (.L__movme_tmp.1), (.L__pc.9398.LD)
	.p2align 4
	.L__pc.9398.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9399
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9399: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9400
	
	.L__pc.9400: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9401
	
	.p2align 4
	.L__pc.9401: Dma_PatchDst (.L__pc.9401.ST), (.L__movme_cp.24), (.L__pc.9401.ST)
	.L__pc.9401.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9402
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9402: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9403
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9403: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9404
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9404: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9405
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9405: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9406
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.9406: Dma_PatchSrc (.L__pc.9406.LD), (.L__movme_cp.63), (.L__pc.9406.LD)
	.p2align 4
	.L__pc.9406.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9407
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9407: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9408
	.L__pc.9408: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9409
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9409: Dma_PatchSrc (.L__pc.9409.LD), (.L__movme_cp.24), (.L__pc.9409.LD)
	.p2align 4
	.L__pc.9409.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9410
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9410: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9411
	.L__pc.9411: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9412
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9412: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9413: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9414: Dma_PatchSrc (.L__pc.9414.LD), (.L__movme_tmp.1), (.L__pc.9414.LD)
	.p2align 4
	.L__pc.9414.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9415
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9415: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9416
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9416: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9417: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9418: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9419: Dma_PatchSrc (.L__pc.9419.LD), (.L__movme_tmp.1), (.L__pc.9419.LD)
	.p2align 4
	.L__pc.9419.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9420
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9420: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9421
	
	.L__pc.9421: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9422
	
	.p2align 4
	.L__pc.9422: Dma_PatchDst (.L__pc.9422.ST), (.L__movme_cp.63), (.L__pc.9422.ST)
	.L__pc.9422.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9423
	
	.L__pc.9423: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9424
	
	.p2align 4
	.L__pc.9424: Dma_PatchDst (.L__pc.9424.ST), (.L__movme_cp.24), (.L__pc.9424.ST)
	.L__pc.9424.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9425
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9425: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9426
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9426: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9427
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9427: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9428
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9428: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9429
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.9429: Dma_PatchSrc (.L__pc.9429.LD), (.L__movme_cp.66), (.L__pc.9429.LD)
	.p2align 4
	.L__pc.9429.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9430
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9430: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9431
	.L__pc.9431: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9432
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9432: Dma_PatchSrc (.L__pc.9432.LD), (.L__movme_cp.24), (.L__pc.9432.LD)
	.p2align 4
	.L__pc.9432.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9433
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9433: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9434
	.L__pc.9434: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9435
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9435: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9436: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9437: Dma_PatchSrc (.L__pc.9437.LD), (.L__movme_tmp.1), (.L__pc.9437.LD)
	.p2align 4
	.L__pc.9437.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9438
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9438: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9439
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9439: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9440: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9441: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9442: Dma_PatchSrc (.L__pc.9442.LD), (.L__movme_tmp.1), (.L__pc.9442.LD)
	.p2align 4
	.L__pc.9442.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9443
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9443: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9444
	
	.L__pc.9444: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9445
	
	.p2align 4
	.L__pc.9445: Dma_PatchDst (.L__pc.9445.ST), (.L__movme_cp.66), (.L__pc.9445.ST)
	.L__pc.9445.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9446
	
	.L__pc.9446: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9447
	
	.p2align 4
	.L__pc.9447: Dma_PatchDst (.L__pc.9447.ST), (.L__movme_cp.24), (.L__pc.9447.ST)
	.L__pc.9447.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9448
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9448: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9449
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9449: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9450
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9450: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9451
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9451: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9452
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.9452: Dma_PatchSrc (.L__pc.9452.LD), (.L__movme_cp.67), (.L__pc.9452.LD)
	.p2align 4
	.L__pc.9452.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9453
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9453: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9454
	.L__pc.9454: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9455
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9455: Dma_PatchSrc (.L__pc.9455.LD), (.L__movme_cp.24), (.L__pc.9455.LD)
	.p2align 4
	.L__pc.9455.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9456
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9456: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9457
	.L__pc.9457: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9458
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9458: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9459: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9460: Dma_PatchSrc (.L__pc.9460.LD), (.L__movme_tmp.1), (.L__pc.9460.LD)
	.p2align 4
	.L__pc.9460.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9461
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9461: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9462
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9462: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9463: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9464: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9465: Dma_PatchSrc (.L__pc.9465.LD), (.L__movme_tmp.1), (.L__pc.9465.LD)
	.p2align 4
	.L__pc.9465.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9466
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9466: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9467
	
	.L__pc.9467: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9468
	
	.p2align 4
	.L__pc.9468: Dma_PatchDst (.L__pc.9468.ST), (.L__movme_cp.67), (.L__pc.9468.ST)
	.L__pc.9468.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9469
	
	.L__pc.9469: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9470
	
	.p2align 4
	.L__pc.9470: Dma_PatchDst (.L__pc.9470.ST), (.L__movme_cp.24), (.L__pc.9470.ST)
	.L__pc.9470.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9471
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9471: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9472
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9472: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9473
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9473: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9474
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9474: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9475
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.9475: Dma_PatchSrc (.L__pc.9475.LD), (.L__movme_cp.68), (.L__pc.9475.LD)
	.p2align 4
	.L__pc.9475.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9476
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9476: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9477
	.L__pc.9477: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9478
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9478: Dma_PatchSrc (.L__pc.9478.LD), (.L__movme_cp.24), (.L__pc.9478.LD)
	.p2align 4
	.L__pc.9478.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9479
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9479: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9480
	.L__pc.9480: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9481
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9481: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9482: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9483: Dma_PatchSrc (.L__pc.9483.LD), (.L__movme_tmp.1), (.L__pc.9483.LD)
	.p2align 4
	.L__pc.9483.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9484
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9484: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9485
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9485: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9486: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9487: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9488: Dma_PatchSrc (.L__pc.9488.LD), (.L__movme_tmp.1), (.L__pc.9488.LD)
	.p2align 4
	.L__pc.9488.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9489
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9489: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9490
	
	.L__pc.9490: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9491
	
	.p2align 4
	.L__pc.9491: Dma_PatchDst (.L__pc.9491.ST), (.L__movme_cp.68), (.L__pc.9491.ST)
	.L__pc.9491.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9492
	
	.L__pc.9492: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9493
	
	.p2align 4
	.L__pc.9493: Dma_PatchDst (.L__pc.9493.ST), (.L__movme_cp.24), (.L__pc.9493.ST)
	.L__pc.9493.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9494
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9494: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9495
	
	.p2align 4
	.L__pc.9495: Dma_PatchDst (.L__pc.9495.ST), (.L__movme_cp.24), (.L__pc.9495.ST)
	.L__pc.9495.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9496
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.9496: Dma_PatchSrc (.L__pc.9496.LD), (.L__movme_cp.60), (.L__pc.9496.LD)
	.p2align 4
	.L__pc.9496.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9497
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9497: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9498
	
	.L__pc.9498: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9499
	
	.p2align 4
	.L__pc.9499: Dma_PatchDst (.L__pc.9499.ST), (.L__movme_cp.21), (.L__pc.9499.ST)
	.L__pc.9499.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9500
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.9500: Dma_PatchSrc (.L__pc.9500.LD), (.L__movme_cp.58), (.L__pc.9500.LD)
	.p2align 4
	.L__pc.9500.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9501
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9501: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9502
	
	.L__pc.9502: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9503
	
	.p2align 4
	.L__pc.9503: Dma_PatchDst (.L__pc.9503.ST), (.L__movme_cp.22), (.L__pc.9503.ST)
	.L__pc.9503.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9504
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9504: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9505
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9505: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9506
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9506: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9507
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9507: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9508
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.9508: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.9509
	
	.p2align 4
	.L__pc.9509: Dma_PatchDst (.L__pc.9509.ST), (.L__movme_cp.24), (.L__pc.9509.ST)
	.L__pc.9509.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9510
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.9510: Dma_PatchSrc (.L__pc.9510.LD), (.L__movme_cp.25), (.L__pc.9510.LD)
	.p2align 4
	.L__pc.9510.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9511
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9511: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9512
	.L__pc.9512: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9513
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.9513: Dma_PatchSrc (.L__pc.9513.LD), (.L__movme_cp.26), (.L__pc.9513.LD)
	.p2align 4
	.L__pc.9513.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9514
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9514: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9515
	.L__pc.9515: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9516
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9516: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9517: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9518: Dma_PatchSrc (.L__pc.9518.LD), (.L__movme_tmp.1), (.L__pc.9518.LD)
	.p2align 4
	.L__pc.9518.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9519
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9519: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9520
	.L__pc.9520: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9521
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9521: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9522: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9523: Dma_PatchSrc (.L__pc.9523.LD), (.L__movme_tmp.1), (.L__pc.9523.LD)
	.p2align 4
	.L__pc.9523.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9524
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9524: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9525
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9525: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9526: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9527: Dma_PatchSrc (.L__pc.9527.LD), (.L__movme_tmp.1), (.L__pc.9527.LD)
	.p2align 4
	.L__pc.9527.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9528
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9528: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9529
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9529: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9530: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9531: Dma_PatchSrc (.L__pc.9531.LD), (.L__movme_tmp.1), (.L__pc.9531.LD)
	.p2align 4
	.L__pc.9531.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9532
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9532: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9533
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9533: Dma_PatchSrc (.L__pc.9533.LD), (.L__movme_cp.24), (.L__pc.9533.LD)
	.p2align 4
	.L__pc.9533.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9534
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9534: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9535
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9535: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9536: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9537: Dma_PatchSrc (.L__pc.9537.LD), (.L__movme_tmp.1), (.L__pc.9537.LD)
	.p2align 4
	.L__pc.9537.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9538
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9538: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9539
	
	.L__pc.9539: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9540
	
	.p2align 4
	.L__pc.9540: Dma_PatchDst (.L__pc.9540.ST), (.L__movme_cp.69), (.L__pc.9540.ST)
	.L__pc.9540.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9541
	
	.L__pc.9541: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9542
	
	.p2align 4
	.L__pc.9542: Dma_PatchDst (.L__pc.9542.ST), (.L__movme_cp.54), (.L__pc.9542.ST)
	.L__pc.9542.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9543
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.9543: Dma_PatchSrc (.L__pc.9543.LD), (.L__movme_cp.30), (.L__pc.9543.LD)
	.p2align 4
	.L__pc.9543.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9544
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9544: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9545
	.L__pc.9545: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9546
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.9546: Dma_PatchSrc (.L__pc.9546.LD), (.L__movme_cp.31), (.L__pc.9546.LD)
	.p2align 4
	.L__pc.9546.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9547
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9547: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9548
	.L__pc.9548: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9549
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9549: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9550: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9551: Dma_PatchSrc (.L__pc.9551.LD), (.L__movme_tmp.1), (.L__pc.9551.LD)
	.p2align 4
	.L__pc.9551.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9552
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9552: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9553
	.L__pc.9553: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9554
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9554: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9555: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9556: Dma_PatchSrc (.L__pc.9556.LD), (.L__movme_tmp.1), (.L__pc.9556.LD)
	.p2align 4
	.L__pc.9556.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9557
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9557: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9558
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9558: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9559: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9560: Dma_PatchSrc (.L__pc.9560.LD), (.L__movme_tmp.1), (.L__pc.9560.LD)
	.p2align 4
	.L__pc.9560.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9561
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9561: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9562
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9562: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9563: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9564: Dma_PatchSrc (.L__pc.9564.LD), (.L__movme_tmp.1), (.L__pc.9564.LD)
	.p2align 4
	.L__pc.9564.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9565
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9565: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9566
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9566: Dma_PatchSrc (.L__pc.9566.LD), (.L__movme_cp.24), (.L__pc.9566.LD)
	.p2align 4
	.L__pc.9566.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9567
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9567: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9568
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9568: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9569: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9570: Dma_PatchSrc (.L__pc.9570.LD), (.L__movme_tmp.1), (.L__pc.9570.LD)
	.p2align 4
	.L__pc.9570.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9571
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9571: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9572
	
	.L__pc.9572: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9573
	
	.p2align 4
	.L__pc.9573: Dma_PatchDst (.L__pc.9573.ST), (.L__movme_cp.70), (.L__pc.9573.ST)
	.L__pc.9573.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9574
	
	.L__pc.9574: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9575
	
	.p2align 4
	.L__pc.9575: Dma_PatchDst (.L__pc.9575.ST), (.L__movme_cp.54), (.L__pc.9575.ST)
	.L__pc.9575.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9576
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9576: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9577
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9577: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9578
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9578: Dma_PatchSrc (.L__pc.9578.LD), (.L__movme_cp.24), (.L__pc.9578.LD)
	.p2align 4
	.L__pc.9578.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9579
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9579: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9580
	.L__pc.9580: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9581
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.9581: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9582: Dma_PatchSrc (.L__pc.9582.LD), (.L__movme_tmp.1), (.L__pc.9582.LD)
	.p2align 4
	.L__pc.9582.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9583
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9583: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9584
	.L__pc.9584: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9585
	
	.L__pc.9585: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9586
	
	.p2align 4
	.L__pc.9586: Dma_PatchDst (.L__pc.9586.ST), (.L__movme_cp.72), (.L__pc.9586.ST)
	.L__pc.9586.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9587
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.9587: Dma_PatchSrc (.L__pc.9587.LD), (.L__movme_cp.72), (.L__pc.9587.LD)
	.p2align 4
	.L__pc.9587.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9588
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9588: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9589
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9589: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9590: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9591: Dma_PatchSrc (.L__pc.9591.LD), (.L__movme_tmp.1), (.L__pc.9591.LD)
	.p2align 4
	.L__pc.9591.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9592
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9592: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9593
	
	.L__pc.9593: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9594
	
	.p2align 4
	.L__pc.9594: Dma_PatchDst (.L__pc.9594.ST), (.L__movme_cp.74), (.L__pc.9594.ST)
	.L__pc.9594.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9595
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9595: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9596: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9597: Dma_PatchSrc (.L__pc.9597.LD), (.L__movme_tmp.1), (.L__pc.9597.LD)
	.p2align 4
	.L__pc.9597.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9598
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9598: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9599
	
	.L__pc.9599: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9600
	
	.p2align 4
	.L__pc.9600: Dma_PatchDst (.L__pc.9600.ST), (.L__movme_cp.76), (.L__pc.9600.ST)
	.L__pc.9600.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9601
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.9601: Dma_PatchSrc (.L__pc.9601.LD), (.L__movme_cp.74), (.L__pc.9601.LD)
	.p2align 4
	.L__pc.9601.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9602
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9602: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9603
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.9603: Dma_PatchSrc (.L__pc.9603.LD), ((.L__movme.reg.eax+0)), (.L__pc.9603.LD)
	.p2align 4
	.L__pc.9603.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9604
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9604: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9605
	
	.L__pc.9605: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9606
	
	.p2align 4
	.L__pc.9606: Dma_PatchDst (.L__pc.9606.ST), (.L__movme_cp.77), (.L__pc.9606.ST)
	.L__pc.9606.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9607
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.9607: Dma_PatchSrc (.L__pc.9607.LD), (.L__movme_cp.77), (.L__pc.9607.LD)
	.p2align 4
	.L__pc.9607.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9608
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9608: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9609
	
	.L__pc.9609: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9610
	
	.p2align 4
	.L__pc.9610: Dma_PatchDst (.L__pc.9610.ST), (.L__movme_cp.21), (.L__pc.9610.ST)
	.L__pc.9610.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9611
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.9611: Dma_PatchSrc (.L__pc.9611.LD), (.L__movme_cp.58), (.L__pc.9611.LD)
	.p2align 4
	.L__pc.9611.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9612
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9612: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9613
	
	.L__pc.9613: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9614
	
	.p2align 4
	.L__pc.9614: Dma_PatchDst (.L__pc.9614.ST), (.L__movme_cp.22), (.L__pc.9614.ST)
	.L__pc.9614.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9615
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9615: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9616
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9616: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9617
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9617: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9618
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9618: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9619
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.9619: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.9620
	
	.p2align 4
	.L__pc.9620: Dma_PatchDst (.L__pc.9620.ST), (.L__movme_cp.24), (.L__pc.9620.ST)
	.L__pc.9620.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9621
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.9621: Dma_PatchSrc (.L__pc.9621.LD), (.L__movme_cp.25), (.L__pc.9621.LD)
	.p2align 4
	.L__pc.9621.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9622
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9622: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9623
	.L__pc.9623: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9624
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.9624: Dma_PatchSrc (.L__pc.9624.LD), (.L__movme_cp.26), (.L__pc.9624.LD)
	.p2align 4
	.L__pc.9624.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9625
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9625: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9626
	.L__pc.9626: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9627
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9627: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9628: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9629: Dma_PatchSrc (.L__pc.9629.LD), (.L__movme_tmp.1), (.L__pc.9629.LD)
	.p2align 4
	.L__pc.9629.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9630
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9630: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9631
	.L__pc.9631: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9632
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9632: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9633: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9634: Dma_PatchSrc (.L__pc.9634.LD), (.L__movme_tmp.1), (.L__pc.9634.LD)
	.p2align 4
	.L__pc.9634.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9635
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9635: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9636
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9636: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9637: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9638: Dma_PatchSrc (.L__pc.9638.LD), (.L__movme_tmp.1), (.L__pc.9638.LD)
	.p2align 4
	.L__pc.9638.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9639
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9639: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9640
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9640: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9641: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9642: Dma_PatchSrc (.L__pc.9642.LD), (.L__movme_tmp.1), (.L__pc.9642.LD)
	.p2align 4
	.L__pc.9642.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9643
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9643: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9644
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9644: Dma_PatchSrc (.L__pc.9644.LD), (.L__movme_cp.24), (.L__pc.9644.LD)
	.p2align 4
	.L__pc.9644.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9645
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9645: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9646
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9646: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9647: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9648: Dma_PatchSrc (.L__pc.9648.LD), (.L__movme_tmp.1), (.L__pc.9648.LD)
	.p2align 4
	.L__pc.9648.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9649
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9649: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9650
	
	.L__pc.9650: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9651
	
	.p2align 4
	.L__pc.9651: Dma_PatchDst (.L__pc.9651.ST), (.L__movme_cp.78), (.L__pc.9651.ST)
	.L__pc.9651.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9652
	
	.L__pc.9652: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9653
	
	.p2align 4
	.L__pc.9653: Dma_PatchDst (.L__pc.9653.ST), (.L__movme_cp.54), (.L__pc.9653.ST)
	.L__pc.9653.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9654
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.9654: Dma_PatchSrc (.L__pc.9654.LD), (.L__movme_cp.30), (.L__pc.9654.LD)
	.p2align 4
	.L__pc.9654.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9655
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9655: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9656
	.L__pc.9656: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9657
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.9657: Dma_PatchSrc (.L__pc.9657.LD), (.L__movme_cp.31), (.L__pc.9657.LD)
	.p2align 4
	.L__pc.9657.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9658
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9658: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9659
	.L__pc.9659: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9660
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9660: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9661: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9662: Dma_PatchSrc (.L__pc.9662.LD), (.L__movme_tmp.1), (.L__pc.9662.LD)
	.p2align 4
	.L__pc.9662.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9663
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9663: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9664
	.L__pc.9664: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9665
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9665: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9666: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9667: Dma_PatchSrc (.L__pc.9667.LD), (.L__movme_tmp.1), (.L__pc.9667.LD)
	.p2align 4
	.L__pc.9667.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9668
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9668: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9669
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9669: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9670: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9671: Dma_PatchSrc (.L__pc.9671.LD), (.L__movme_tmp.1), (.L__pc.9671.LD)
	.p2align 4
	.L__pc.9671.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9672
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9672: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9673
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9673: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9674: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9675: Dma_PatchSrc (.L__pc.9675.LD), (.L__movme_tmp.1), (.L__pc.9675.LD)
	.p2align 4
	.L__pc.9675.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9676
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9676: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9677
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9677: Dma_PatchSrc (.L__pc.9677.LD), (.L__movme_cp.24), (.L__pc.9677.LD)
	.p2align 4
	.L__pc.9677.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9678
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9678: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9679
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9679: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9680: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9681: Dma_PatchSrc (.L__pc.9681.LD), (.L__movme_tmp.1), (.L__pc.9681.LD)
	.p2align 4
	.L__pc.9681.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9682
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9682: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9683
	
	.L__pc.9683: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9684
	
	.p2align 4
	.L__pc.9684: Dma_PatchDst (.L__pc.9684.ST), (.L__movme_cp.79), (.L__pc.9684.ST)
	.L__pc.9684.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9685
	
	.L__pc.9685: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9686
	
	.p2align 4
	.L__pc.9686: Dma_PatchDst (.L__pc.9686.ST), (.L__movme_cp.54), (.L__pc.9686.ST)
	.L__pc.9686.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9687
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.9687: Dma_PatchSrc (.L__pc.9687.LD), (.L__movme_cp.74), (.L__pc.9687.LD)
	.p2align 4
	.L__pc.9687.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9688
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9688: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9689
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.9689: Dma_PatchSrc (.L__pc.9689.LD), (.L__movme_cp.77), (.L__pc.9689.LD)
	.p2align 4
	.L__pc.9689.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9690
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9690: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9691
	
	.L__pc.9691: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9692
	
	.p2align 4
	.L__pc.9692: Dma_PatchDst (.L__pc.9692.ST), ((.L__movme.reg.eax+0)), (.L__pc.9692.ST)
	.L__pc.9692.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9693
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.9693: Dma_PatchSrc (.L__pc.9693.LD), (.L__movme_cp.76), (.L__pc.9693.LD)
	.p2align 4
	.L__pc.9693.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9694
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9694: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9695
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.9695: Dma_PatchSrc (.L__pc.9695.LD), ((.L__movme.reg.eax+0)), (.L__pc.9695.LD)
	.p2align 4
	.L__pc.9695.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9696
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9696: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9697
	
	.L__pc.9697: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9698
	
	.p2align 4
	.L__pc.9698: Dma_PatchDst (.L__pc.9698.ST), (.L__movme_cp.80), (.L__pc.9698.ST)
	.L__pc.9698.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9699
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9699: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9700
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9700: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9701
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.9701: Dma_PatchSrc (.L__pc.9701.LD), (.L__movme_cp.100), (.L__pc.9701.LD)
	.p2align 4
	.L__pc.9701.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9702
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9702: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9703
	.L__pc.9703: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9704
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.96 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.9704: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9705: Dma_PatchSrc (.L__pc.9705.LD), (.L__movme_tmp.1), (.L__pc.9705.LD)
	.p2align 4
	.L__pc.9705.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9706
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9706: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9707
	.L__pc.9707: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9708
	
	.L__pc.9708: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9709
	
	.p2align 4
	.L__pc.9709: Dma_PatchDst (.L__pc.9709.ST), (.L__movme_cp.100), (.L__pc.9709.ST)
	.L__pc.9709.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9710
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.9710: Dma_PatchSrc (.L__pc.9710.LD), (.L__movme_cp.76), (.L__pc.9710.LD)
	.p2align 4
	.L__pc.9710.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9711
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9711: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9712
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.9712: Dma_PatchSrc (.L__pc.9712.LD), (.L__movme_cp.80), (.L__pc.9712.LD)
	.p2align 4
	.L__pc.9712.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9713
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9713: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9714
	
	.L__pc.9714: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9715
	
	.p2align 4
	.L__pc.9715: Dma_PatchDst (.L__pc.9715.ST), ((.L__movme.reg.eax+0)), (.L__pc.9715.ST)
	.L__pc.9715.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9716
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9716: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9717
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9717: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9718
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.9718: Dma_PatchSrc (.L__pc.9718.LD), (.L__movme_cp.101), (.L__pc.9718.LD)
	.p2align 4
	.L__pc.9718.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9719
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9719: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9720
	.L__pc.9720: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9721
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9721: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.62 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9722: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9723: Dma_PatchSrc (.L__pc.9723.LD), (.L__movme_tmp.1), (.L__pc.9723.LD)
	.p2align 4
	.L__pc.9723.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9724
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9724: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9725
	
	.L__pc.9725: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9726
	
	.p2align 4
	.L__pc.9726: Dma_PatchDst (.L__pc.9726.ST), (.L__movme_cp.24), (.L__pc.9726.ST)
	.L__pc.9726.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9727
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9727: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9728
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9728: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9729
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9729: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9730
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9730: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9731
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.9731: Dma_PatchSrc (.L__pc.9731.LD), (.L__movme_cp.63), (.L__pc.9731.LD)
	.p2align 4
	.L__pc.9731.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9732
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9732: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9733
	.L__pc.9733: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9734
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9734: Dma_PatchSrc (.L__pc.9734.LD), (.L__movme_cp.24), (.L__pc.9734.LD)
	.p2align 4
	.L__pc.9734.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9735
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9735: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9736
	.L__pc.9736: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9737
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9737: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9738: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9739: Dma_PatchSrc (.L__pc.9739.LD), (.L__movme_tmp.1), (.L__pc.9739.LD)
	.p2align 4
	.L__pc.9739.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9740
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9740: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9741
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9741: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9742: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9743: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9744: Dma_PatchSrc (.L__pc.9744.LD), (.L__movme_tmp.1), (.L__pc.9744.LD)
	.p2align 4
	.L__pc.9744.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9745
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9745: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9746
	
	.L__pc.9746: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9747
	
	.p2align 4
	.L__pc.9747: Dma_PatchDst (.L__pc.9747.ST), (.L__movme_cp.63), (.L__pc.9747.ST)
	.L__pc.9747.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9748
	
	.L__pc.9748: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9749
	
	.p2align 4
	.L__pc.9749: Dma_PatchDst (.L__pc.9749.ST), (.L__movme_cp.24), (.L__pc.9749.ST)
	.L__pc.9749.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9750
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9750: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9751
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9751: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9752
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9752: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9753
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9753: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9754
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.9754: Dma_PatchSrc (.L__pc.9754.LD), (.L__movme_cp.66), (.L__pc.9754.LD)
	.p2align 4
	.L__pc.9754.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9755
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9755: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9756
	.L__pc.9756: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9757
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9757: Dma_PatchSrc (.L__pc.9757.LD), (.L__movme_cp.24), (.L__pc.9757.LD)
	.p2align 4
	.L__pc.9757.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9758
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9758: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9759
	.L__pc.9759: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9760
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9760: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9761: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9762: Dma_PatchSrc (.L__pc.9762.LD), (.L__movme_tmp.1), (.L__pc.9762.LD)
	.p2align 4
	.L__pc.9762.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9763
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9763: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9764
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9764: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9765: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9766: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9767: Dma_PatchSrc (.L__pc.9767.LD), (.L__movme_tmp.1), (.L__pc.9767.LD)
	.p2align 4
	.L__pc.9767.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9768
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9768: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9769
	
	.L__pc.9769: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9770
	
	.p2align 4
	.L__pc.9770: Dma_PatchDst (.L__pc.9770.ST), (.L__movme_cp.66), (.L__pc.9770.ST)
	.L__pc.9770.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9771
	
	.L__pc.9771: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9772
	
	.p2align 4
	.L__pc.9772: Dma_PatchDst (.L__pc.9772.ST), (.L__movme_cp.24), (.L__pc.9772.ST)
	.L__pc.9772.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9773
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9773: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9774
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9774: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9775
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9775: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9776
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9776: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9777
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.9777: Dma_PatchSrc (.L__pc.9777.LD), (.L__movme_cp.67), (.L__pc.9777.LD)
	.p2align 4
	.L__pc.9777.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9778
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9778: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9779
	.L__pc.9779: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9780
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9780: Dma_PatchSrc (.L__pc.9780.LD), (.L__movme_cp.24), (.L__pc.9780.LD)
	.p2align 4
	.L__pc.9780.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9781
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9781: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9782
	.L__pc.9782: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9783
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9783: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9784: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9785: Dma_PatchSrc (.L__pc.9785.LD), (.L__movme_tmp.1), (.L__pc.9785.LD)
	.p2align 4
	.L__pc.9785.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9786
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9786: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9787
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9787: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9788: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9789: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9790: Dma_PatchSrc (.L__pc.9790.LD), (.L__movme_tmp.1), (.L__pc.9790.LD)
	.p2align 4
	.L__pc.9790.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9791
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9791: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9792
	
	.L__pc.9792: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9793
	
	.p2align 4
	.L__pc.9793: Dma_PatchDst (.L__pc.9793.ST), (.L__movme_cp.67), (.L__pc.9793.ST)
	.L__pc.9793.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9794
	
	.L__pc.9794: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9795
	
	.p2align 4
	.L__pc.9795: Dma_PatchDst (.L__pc.9795.ST), (.L__movme_cp.24), (.L__pc.9795.ST)
	.L__pc.9795.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9796
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9796: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9797
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9797: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9798
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9798: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9799
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9799: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9800
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.9800: Dma_PatchSrc (.L__pc.9800.LD), (.L__movme_cp.68), (.L__pc.9800.LD)
	.p2align 4
	.L__pc.9800.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9801
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9801: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9802
	.L__pc.9802: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9803
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9803: Dma_PatchSrc (.L__pc.9803.LD), (.L__movme_cp.24), (.L__pc.9803.LD)
	.p2align 4
	.L__pc.9803.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9804
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9804: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.9805
	.L__pc.9805: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.9806
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9806: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9807: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9808: Dma_PatchSrc (.L__pc.9808.LD), (.L__movme_tmp.1), (.L__pc.9808.LD)
	.p2align 4
	.L__pc.9808.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9809
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9809: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9810
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.9810: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.9811: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.9812: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9813: Dma_PatchSrc (.L__pc.9813.LD), (.L__movme_tmp.1), (.L__pc.9813.LD)
	.p2align 4
	.L__pc.9813.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9814
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9814: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9815
	
	.L__pc.9815: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.9816
	
	.p2align 4
	.L__pc.9816: Dma_PatchDst (.L__pc.9816.ST), (.L__movme_cp.68), (.L__pc.9816.ST)
	.L__pc.9816.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9817
	
	.L__pc.9817: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.9818
	
	.p2align 4
	.L__pc.9818: Dma_PatchDst (.L__pc.9818.ST), (.L__movme_cp.24), (.L__pc.9818.ST)
	.L__pc.9818.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9819
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9819: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9820
	
	.p2align 4
	.L__pc.9820: Dma_PatchDst (.L__pc.9820.ST), (.L__movme_cp.24), (.L__pc.9820.ST)
	.L__pc.9820.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9821
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.9821: Dma_PatchSrc (.L__pc.9821.LD), (.L__movme_cp.60), (.L__pc.9821.LD)
	.p2align 4
	.L__pc.9821.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9822
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9822: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9823
	
	.L__pc.9823: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9824
	
	.p2align 4
	.L__pc.9824: Dma_PatchDst (.L__pc.9824.ST), (.L__movme_cp.21), (.L__pc.9824.ST)
	.L__pc.9824.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9825
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.9825: Dma_PatchSrc (.L__pc.9825.LD), (.L__movme_cp.58), (.L__pc.9825.LD)
	.p2align 4
	.L__pc.9825.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9826
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9826: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9827
	
	.L__pc.9827: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9828
	
	.p2align 4
	.L__pc.9828: Dma_PatchDst (.L__pc.9828.ST), (.L__movme_cp.22), (.L__pc.9828.ST)
	.L__pc.9828.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9829
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9829: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9830
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9830: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9831
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9831: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9832
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9832: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9833
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.9833: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.9834
	
	.p2align 4
	.L__pc.9834: Dma_PatchDst (.L__pc.9834.ST), (.L__movme_cp.24), (.L__pc.9834.ST)
	.L__pc.9834.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9835
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.9835: Dma_PatchSrc (.L__pc.9835.LD), (.L__movme_cp.25), (.L__pc.9835.LD)
	.p2align 4
	.L__pc.9835.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9836
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9836: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9837
	.L__pc.9837: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9838
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.9838: Dma_PatchSrc (.L__pc.9838.LD), (.L__movme_cp.26), (.L__pc.9838.LD)
	.p2align 4
	.L__pc.9838.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9839
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9839: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9840
	.L__pc.9840: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9841
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9841: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9842: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9843: Dma_PatchSrc (.L__pc.9843.LD), (.L__movme_tmp.1), (.L__pc.9843.LD)
	.p2align 4
	.L__pc.9843.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9844
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9844: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9845
	.L__pc.9845: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9846
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9846: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9847: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9848: Dma_PatchSrc (.L__pc.9848.LD), (.L__movme_tmp.1), (.L__pc.9848.LD)
	.p2align 4
	.L__pc.9848.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9849
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9849: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9850
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9850: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9851: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9852: Dma_PatchSrc (.L__pc.9852.LD), (.L__movme_tmp.1), (.L__pc.9852.LD)
	.p2align 4
	.L__pc.9852.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9853
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9853: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9854
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9854: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9855: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9856: Dma_PatchSrc (.L__pc.9856.LD), (.L__movme_tmp.1), (.L__pc.9856.LD)
	.p2align 4
	.L__pc.9856.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9857
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9857: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9858
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9858: Dma_PatchSrc (.L__pc.9858.LD), (.L__movme_cp.24), (.L__pc.9858.LD)
	.p2align 4
	.L__pc.9858.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9859
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9859: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9860
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9860: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9861: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9862: Dma_PatchSrc (.L__pc.9862.LD), (.L__movme_tmp.1), (.L__pc.9862.LD)
	.p2align 4
	.L__pc.9862.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9863
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9863: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9864
	
	.L__pc.9864: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9865
	
	.p2align 4
	.L__pc.9865: Dma_PatchDst (.L__pc.9865.ST), (.L__movme_cp.69), (.L__pc.9865.ST)
	.L__pc.9865.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9866
	
	.L__pc.9866: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9867
	
	.p2align 4
	.L__pc.9867: Dma_PatchDst (.L__pc.9867.ST), (.L__movme_cp.54), (.L__pc.9867.ST)
	.L__pc.9867.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9868
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.9868: Dma_PatchSrc (.L__pc.9868.LD), (.L__movme_cp.30), (.L__pc.9868.LD)
	.p2align 4
	.L__pc.9868.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9869
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9869: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9870
	.L__pc.9870: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9871
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.9871: Dma_PatchSrc (.L__pc.9871.LD), (.L__movme_cp.31), (.L__pc.9871.LD)
	.p2align 4
	.L__pc.9871.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9872
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9872: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9873
	.L__pc.9873: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9874
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9874: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9875: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9876: Dma_PatchSrc (.L__pc.9876.LD), (.L__movme_tmp.1), (.L__pc.9876.LD)
	.p2align 4
	.L__pc.9876.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9877
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9877: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9878
	.L__pc.9878: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9879
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9879: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9880: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9881: Dma_PatchSrc (.L__pc.9881.LD), (.L__movme_tmp.1), (.L__pc.9881.LD)
	.p2align 4
	.L__pc.9881.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9882
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9882: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9883
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9883: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9884: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9885: Dma_PatchSrc (.L__pc.9885.LD), (.L__movme_tmp.1), (.L__pc.9885.LD)
	.p2align 4
	.L__pc.9885.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9886
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9886: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9887
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9887: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9888: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9889: Dma_PatchSrc (.L__pc.9889.LD), (.L__movme_tmp.1), (.L__pc.9889.LD)
	.p2align 4
	.L__pc.9889.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9890
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9890: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9891
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9891: Dma_PatchSrc (.L__pc.9891.LD), (.L__movme_cp.24), (.L__pc.9891.LD)
	.p2align 4
	.L__pc.9891.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9892
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9892: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9893
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9893: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9894: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9895: Dma_PatchSrc (.L__pc.9895.LD), (.L__movme_tmp.1), (.L__pc.9895.LD)
	.p2align 4
	.L__pc.9895.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9896
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9896: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9897
	
	.L__pc.9897: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9898
	
	.p2align 4
	.L__pc.9898: Dma_PatchDst (.L__pc.9898.ST), (.L__movme_cp.70), (.L__pc.9898.ST)
	.L__pc.9898.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9899
	
	.L__pc.9899: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9900
	
	.p2align 4
	.L__pc.9900: Dma_PatchDst (.L__pc.9900.ST), (.L__movme_cp.54), (.L__pc.9900.ST)
	.L__pc.9900.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9901
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9901: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9902
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9902: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9903
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9903: Dma_PatchSrc (.L__pc.9903.LD), (.L__movme_cp.24), (.L__pc.9903.LD)
	.p2align 4
	.L__pc.9903.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9904
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9904: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9905
	.L__pc.9905: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9906
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.9906: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9907: Dma_PatchSrc (.L__pc.9907.LD), (.L__movme_tmp.1), (.L__pc.9907.LD)
	.p2align 4
	.L__pc.9907.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9908
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9908: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.9909
	.L__pc.9909: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.9910
	
	.L__pc.9910: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9911
	
	.p2align 4
	.L__pc.9911: Dma_PatchDst (.L__pc.9911.ST), (.L__movme_cp.72), (.L__pc.9911.ST)
	.L__pc.9911.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9912
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.9912: Dma_PatchSrc (.L__pc.9912.LD), (.L__movme_cp.72), (.L__pc.9912.LD)
	.p2align 4
	.L__pc.9912.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9913
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9913: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9914
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9914: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9915: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9916: Dma_PatchSrc (.L__pc.9916.LD), (.L__movme_tmp.1), (.L__pc.9916.LD)
	.p2align 4
	.L__pc.9916.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9917
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9917: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9918
	
	.L__pc.9918: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9919
	
	.p2align 4
	.L__pc.9919: Dma_PatchDst (.L__pc.9919.ST), (.L__movme_cp.74), (.L__pc.9919.ST)
	.L__pc.9919.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9920
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9920: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9921: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9922: Dma_PatchSrc (.L__pc.9922.LD), (.L__movme_tmp.1), (.L__pc.9922.LD)
	.p2align 4
	.L__pc.9922.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9923
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9923: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9924
	
	.L__pc.9924: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9925
	
	.p2align 4
	.L__pc.9925: Dma_PatchDst (.L__pc.9925.ST), (.L__movme_cp.76), (.L__pc.9925.ST)
	.L__pc.9925.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9926
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.9926: Dma_PatchSrc (.L__pc.9926.LD), (.L__movme_cp.74), (.L__pc.9926.LD)
	.p2align 4
	.L__pc.9926.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9927
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9927: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9928
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.9928: Dma_PatchSrc (.L__pc.9928.LD), ((.L__movme.reg.eax+0)), (.L__pc.9928.LD)
	.p2align 4
	.L__pc.9928.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9929
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9929: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9930
	
	.L__pc.9930: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9931
	
	.p2align 4
	.L__pc.9931: Dma_PatchDst (.L__pc.9931.ST), (.L__movme_cp.77), (.L__pc.9931.ST)
	.L__pc.9931.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9932
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.9932: Dma_PatchSrc (.L__pc.9932.LD), (.L__movme_cp.77), (.L__pc.9932.LD)
	.p2align 4
	.L__pc.9932.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9933
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9933: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9934
	
	.L__pc.9934: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9935
	
	.p2align 4
	.L__pc.9935: Dma_PatchDst (.L__pc.9935.ST), (.L__movme_cp.21), (.L__pc.9935.ST)
	.L__pc.9935.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9936
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.9936: Dma_PatchSrc (.L__pc.9936.LD), (.L__movme_cp.58), (.L__pc.9936.LD)
	.p2align 4
	.L__pc.9936.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9937
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9937: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9938
	
	.L__pc.9938: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.9939
	
	.p2align 4
	.L__pc.9939: Dma_PatchDst (.L__pc.9939.ST), (.L__movme_cp.22), (.L__pc.9939.ST)
	.L__pc.9939.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9940
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9940: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9941
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9941: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.9942
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.9942: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.9943
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9943: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9944
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.9944: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.9945
	
	.p2align 4
	.L__pc.9945: Dma_PatchDst (.L__pc.9945.ST), (.L__movme_cp.24), (.L__pc.9945.ST)
	.L__pc.9945.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9946
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.9946: Dma_PatchSrc (.L__pc.9946.LD), (.L__movme_cp.25), (.L__pc.9946.LD)
	.p2align 4
	.L__pc.9946.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9947
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9947: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9948
	.L__pc.9948: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9949
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.9949: Dma_PatchSrc (.L__pc.9949.LD), (.L__movme_cp.26), (.L__pc.9949.LD)
	.p2align 4
	.L__pc.9949.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9950
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9950: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9951
	.L__pc.9951: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9952
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9952: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9953: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9954: Dma_PatchSrc (.L__pc.9954.LD), (.L__movme_tmp.1), (.L__pc.9954.LD)
	.p2align 4
	.L__pc.9954.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9955
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9955: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9956
	.L__pc.9956: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9957
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9957: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9958: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9959: Dma_PatchSrc (.L__pc.9959.LD), (.L__movme_tmp.1), (.L__pc.9959.LD)
	.p2align 4
	.L__pc.9959.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9960
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9960: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9961
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9961: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9962: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9963: Dma_PatchSrc (.L__pc.9963.LD), (.L__movme_tmp.1), (.L__pc.9963.LD)
	.p2align 4
	.L__pc.9963.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9964
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9964: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9965
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9965: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9966: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9967: Dma_PatchSrc (.L__pc.9967.LD), (.L__movme_tmp.1), (.L__pc.9967.LD)
	.p2align 4
	.L__pc.9967.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9968
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9968: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9969
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.9969: Dma_PatchSrc (.L__pc.9969.LD), (.L__movme_cp.24), (.L__pc.9969.LD)
	.p2align 4
	.L__pc.9969.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9970
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9970: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.9971
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9971: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9972: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9973: Dma_PatchSrc (.L__pc.9973.LD), (.L__movme_tmp.1), (.L__pc.9973.LD)
	.p2align 4
	.L__pc.9973.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9974
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9974: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9975
	
	.L__pc.9975: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.9976
	
	.p2align 4
	.L__pc.9976: Dma_PatchDst (.L__pc.9976.ST), (.L__movme_cp.78), (.L__pc.9976.ST)
	.L__pc.9976.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9977
	
	.L__pc.9977: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.9978
	
	.p2align 4
	.L__pc.9978: Dma_PatchDst (.L__pc.9978.ST), (.L__movme_cp.54), (.L__pc.9978.ST)
	.L__pc.9978.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.9979
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.9979: Dma_PatchSrc (.L__pc.9979.LD), (.L__movme_cp.30), (.L__pc.9979.LD)
	.p2align 4
	.L__pc.9979.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9980
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.9980: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.9981
	.L__pc.9981: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.9982
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.9982: Dma_PatchSrc (.L__pc.9982.LD), (.L__movme_cp.31), (.L__pc.9982.LD)
	.p2align 4
	.L__pc.9982.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9983
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9983: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9984
	.L__pc.9984: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9985
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.9985: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9986: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9987: Dma_PatchSrc (.L__pc.9987.LD), (.L__movme_tmp.1), (.L__pc.9987.LD)
	.p2align 4
	.L__pc.9987.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9988
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.9988: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.9989
	.L__pc.9989: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.9990
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.9990: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9991: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9992: Dma_PatchSrc (.L__pc.9992.LD), (.L__movme_tmp.1), (.L__pc.9992.LD)
	.p2align 4
	.L__pc.9992.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9993
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9993: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9994
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.9994: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9995: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.9996: Dma_PatchSrc (.L__pc.9996.LD), (.L__movme_tmp.1), (.L__pc.9996.LD)
	.p2align 4
	.L__pc.9996.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.9997
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.9997: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.9998
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.9998: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.9999: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10000: Dma_PatchSrc (.L__pc.10000.LD), (.L__movme_tmp.1), (.L__pc.10000.LD)
	.p2align 4
	.L__pc.10000.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10001
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10001: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10002
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10002: Dma_PatchSrc (.L__pc.10002.LD), (.L__movme_cp.24), (.L__pc.10002.LD)
	.p2align 4
	.L__pc.10002.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10003
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10003: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10004
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10004: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10005: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10006: Dma_PatchSrc (.L__pc.10006.LD), (.L__movme_tmp.1), (.L__pc.10006.LD)
	.p2align 4
	.L__pc.10006.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10007
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10007: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10008
	
	.L__pc.10008: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10009
	
	.p2align 4
	.L__pc.10009: Dma_PatchDst (.L__pc.10009.ST), (.L__movme_cp.79), (.L__pc.10009.ST)
	.L__pc.10009.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10010
	
	.L__pc.10010: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10011
	
	.p2align 4
	.L__pc.10011: Dma_PatchDst (.L__pc.10011.ST), (.L__movme_cp.54), (.L__pc.10011.ST)
	.L__pc.10011.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10012
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.10012: Dma_PatchSrc (.L__pc.10012.LD), (.L__movme_cp.74), (.L__pc.10012.LD)
	.p2align 4
	.L__pc.10012.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10013
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10013: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10014
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.10014: Dma_PatchSrc (.L__pc.10014.LD), (.L__movme_cp.77), (.L__pc.10014.LD)
	.p2align 4
	.L__pc.10014.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10015
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10015: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10016
	
	.L__pc.10016: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10017
	
	.p2align 4
	.L__pc.10017: Dma_PatchDst (.L__pc.10017.ST), ((.L__movme.reg.eax+0)), (.L__pc.10017.ST)
	.L__pc.10017.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10018
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.10018: Dma_PatchSrc (.L__pc.10018.LD), (.L__movme_cp.76), (.L__pc.10018.LD)
	.p2align 4
	.L__pc.10018.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10019
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10019: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10020
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.10020: Dma_PatchSrc (.L__pc.10020.LD), ((.L__movme.reg.eax+0)), (.L__pc.10020.LD)
	.p2align 4
	.L__pc.10020.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10021
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10021: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10022
	
	.L__pc.10022: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10023
	
	.p2align 4
	.L__pc.10023: Dma_PatchDst (.L__pc.10023.ST), (.L__movme_cp.80), (.L__pc.10023.ST)
	.L__pc.10023.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10024
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10024: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10025
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10025: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10026
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.10026: Dma_PatchSrc (.L__pc.10026.LD), (.L__movme_cp.102), (.L__pc.10026.LD)
	.p2align 4
	.L__pc.10026.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10027
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10027: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10028
	.L__pc.10028: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10029
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.82 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.10029: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10030: Dma_PatchSrc (.L__pc.10030.LD), (.L__movme_tmp.1), (.L__pc.10030.LD)
	.p2align 4
	.L__pc.10030.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10031
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10031: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10032
	.L__pc.10032: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10033
	
	.L__pc.10033: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10034
	
	.p2align 4
	.L__pc.10034: Dma_PatchDst (.L__pc.10034.ST), (.L__movme_cp.102), (.L__pc.10034.ST)
	.L__pc.10034.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10035
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.10035: Dma_PatchSrc (.L__pc.10035.LD), (.L__movme_cp.76), (.L__pc.10035.LD)
	.p2align 4
	.L__pc.10035.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10036
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10036: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10037
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.10037: Dma_PatchSrc (.L__pc.10037.LD), (.L__movme_cp.80), (.L__pc.10037.LD)
	.p2align 4
	.L__pc.10037.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10038
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10038: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10039
	
	.L__pc.10039: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10040
	
	.p2align 4
	.L__pc.10040: Dma_PatchDst (.L__pc.10040.ST), ((.L__movme.reg.eax+0)), (.L__pc.10040.ST)
	.L__pc.10040.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10041
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10041: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10042
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10042: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10043
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.10043: Dma_PatchSrc (.L__pc.10043.LD), (.L__movme_cp.101), (.L__pc.10043.LD)
	.p2align 4
	.L__pc.10043.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10044
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10044: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10045
	.L__pc.10045: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10046
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10046: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.83 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10047: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10048: Dma_PatchSrc (.L__pc.10048.LD), (.L__movme_tmp.1), (.L__pc.10048.LD)
	.p2align 4
	.L__pc.10048.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10049
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10049: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10050
	
	.L__pc.10050: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10051
	
	.p2align 4
	.L__pc.10051: Dma_PatchDst (.L__pc.10051.ST), (.L__movme_cp.24), (.L__pc.10051.ST)
	.L__pc.10051.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10052
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10052: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10053
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10053: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10054
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10054: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10055
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10055: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10056
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.10056: Dma_PatchSrc (.L__pc.10056.LD), (.L__movme_cp.63), (.L__pc.10056.LD)
	.p2align 4
	.L__pc.10056.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10057
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10057: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10058
	.L__pc.10058: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10059
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10059: Dma_PatchSrc (.L__pc.10059.LD), (.L__movme_cp.24), (.L__pc.10059.LD)
	.p2align 4
	.L__pc.10059.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10060
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10060: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10061
	.L__pc.10061: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10062
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10062: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10063: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10064: Dma_PatchSrc (.L__pc.10064.LD), (.L__movme_tmp.1), (.L__pc.10064.LD)
	.p2align 4
	.L__pc.10064.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10065
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10065: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10066
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10066: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10067: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10068: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10069: Dma_PatchSrc (.L__pc.10069.LD), (.L__movme_tmp.1), (.L__pc.10069.LD)
	.p2align 4
	.L__pc.10069.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10070
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10070: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10071
	
	.L__pc.10071: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10072
	
	.p2align 4
	.L__pc.10072: Dma_PatchDst (.L__pc.10072.ST), (.L__movme_cp.63), (.L__pc.10072.ST)
	.L__pc.10072.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10073
	
	.L__pc.10073: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10074
	
	.p2align 4
	.L__pc.10074: Dma_PatchDst (.L__pc.10074.ST), (.L__movme_cp.24), (.L__pc.10074.ST)
	.L__pc.10074.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10075
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10075: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10076
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10076: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10077
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10077: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10078
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10078: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10079
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.10079: Dma_PatchSrc (.L__pc.10079.LD), (.L__movme_cp.66), (.L__pc.10079.LD)
	.p2align 4
	.L__pc.10079.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10080
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10080: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10081
	.L__pc.10081: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10082
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10082: Dma_PatchSrc (.L__pc.10082.LD), (.L__movme_cp.24), (.L__pc.10082.LD)
	.p2align 4
	.L__pc.10082.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10083
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10083: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10084
	.L__pc.10084: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10085
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10085: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10086: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10087: Dma_PatchSrc (.L__pc.10087.LD), (.L__movme_tmp.1), (.L__pc.10087.LD)
	.p2align 4
	.L__pc.10087.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10088
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10088: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10089
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10089: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10090: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10091: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10092: Dma_PatchSrc (.L__pc.10092.LD), (.L__movme_tmp.1), (.L__pc.10092.LD)
	.p2align 4
	.L__pc.10092.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10093
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10093: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10094
	
	.L__pc.10094: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10095
	
	.p2align 4
	.L__pc.10095: Dma_PatchDst (.L__pc.10095.ST), (.L__movme_cp.66), (.L__pc.10095.ST)
	.L__pc.10095.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10096
	
	.L__pc.10096: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10097
	
	.p2align 4
	.L__pc.10097: Dma_PatchDst (.L__pc.10097.ST), (.L__movme_cp.24), (.L__pc.10097.ST)
	.L__pc.10097.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10098
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10098: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10099
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10099: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10100
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10100: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10101
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10101: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10102
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.10102: Dma_PatchSrc (.L__pc.10102.LD), (.L__movme_cp.67), (.L__pc.10102.LD)
	.p2align 4
	.L__pc.10102.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10103
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10103: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10104
	.L__pc.10104: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10105
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10105: Dma_PatchSrc (.L__pc.10105.LD), (.L__movme_cp.24), (.L__pc.10105.LD)
	.p2align 4
	.L__pc.10105.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10106
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10106: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10107
	.L__pc.10107: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10108
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10108: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10109: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10110: Dma_PatchSrc (.L__pc.10110.LD), (.L__movme_tmp.1), (.L__pc.10110.LD)
	.p2align 4
	.L__pc.10110.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10111
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10111: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10112
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10112: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10113: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10114: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10115: Dma_PatchSrc (.L__pc.10115.LD), (.L__movme_tmp.1), (.L__pc.10115.LD)
	.p2align 4
	.L__pc.10115.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10116
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10116: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10117
	
	.L__pc.10117: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10118
	
	.p2align 4
	.L__pc.10118: Dma_PatchDst (.L__pc.10118.ST), (.L__movme_cp.67), (.L__pc.10118.ST)
	.L__pc.10118.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10119
	
	.L__pc.10119: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10120
	
	.p2align 4
	.L__pc.10120: Dma_PatchDst (.L__pc.10120.ST), (.L__movme_cp.24), (.L__pc.10120.ST)
	.L__pc.10120.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10121
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10121: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10122
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10122: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10123
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10123: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10124
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10124: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10125
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.10125: Dma_PatchSrc (.L__pc.10125.LD), (.L__movme_cp.68), (.L__pc.10125.LD)
	.p2align 4
	.L__pc.10125.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10126
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10126: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10127
	.L__pc.10127: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10128
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10128: Dma_PatchSrc (.L__pc.10128.LD), (.L__movme_cp.24), (.L__pc.10128.LD)
	.p2align 4
	.L__pc.10128.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10129
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10129: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10130
	.L__pc.10130: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10131
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10131: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10132: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10133: Dma_PatchSrc (.L__pc.10133.LD), (.L__movme_tmp.1), (.L__pc.10133.LD)
	.p2align 4
	.L__pc.10133.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10134
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10134: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10135
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10135: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10136: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10137: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10138: Dma_PatchSrc (.L__pc.10138.LD), (.L__movme_tmp.1), (.L__pc.10138.LD)
	.p2align 4
	.L__pc.10138.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10139
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10139: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10140
	
	.L__pc.10140: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10141
	
	.p2align 4
	.L__pc.10141: Dma_PatchDst (.L__pc.10141.ST), (.L__movme_cp.68), (.L__pc.10141.ST)
	.L__pc.10141.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10142
	
	.L__pc.10142: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10143
	
	.p2align 4
	.L__pc.10143: Dma_PatchDst (.L__pc.10143.ST), (.L__movme_cp.24), (.L__pc.10143.ST)
	.L__pc.10143.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10144
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10144: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10145
	
	.p2align 4
	.L__pc.10145: Dma_PatchDst (.L__pc.10145.ST), (.L__movme_cp.24), (.L__pc.10145.ST)
	.L__pc.10145.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10146
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.10146: Dma_PatchSrc (.L__pc.10146.LD), (.L__movme_cp.60), (.L__pc.10146.LD)
	.p2align 4
	.L__pc.10146.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10147
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10147: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10148
	
	.L__pc.10148: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10149
	
	.p2align 4
	.L__pc.10149: Dma_PatchDst (.L__pc.10149.ST), (.L__movme_cp.21), (.L__pc.10149.ST)
	.L__pc.10149.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10150
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.10150: Dma_PatchSrc (.L__pc.10150.LD), (.L__movme_cp.58), (.L__pc.10150.LD)
	.p2align 4
	.L__pc.10150.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10151
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10151: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10152
	
	.L__pc.10152: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10153
	
	.p2align 4
	.L__pc.10153: Dma_PatchDst (.L__pc.10153.ST), (.L__movme_cp.22), (.L__pc.10153.ST)
	.L__pc.10153.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10154
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10154: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10155
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10155: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10156
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10156: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10157
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10157: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10158
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.10158: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.10159
	
	.p2align 4
	.L__pc.10159: Dma_PatchDst (.L__pc.10159.ST), (.L__movme_cp.24), (.L__pc.10159.ST)
	.L__pc.10159.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10160
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.10160: Dma_PatchSrc (.L__pc.10160.LD), (.L__movme_cp.25), (.L__pc.10160.LD)
	.p2align 4
	.L__pc.10160.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10161
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10161: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10162
	.L__pc.10162: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10163
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.10163: Dma_PatchSrc (.L__pc.10163.LD), (.L__movme_cp.26), (.L__pc.10163.LD)
	.p2align 4
	.L__pc.10163.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10164
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10164: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10165
	.L__pc.10165: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10166
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10166: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10167: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10168: Dma_PatchSrc (.L__pc.10168.LD), (.L__movme_tmp.1), (.L__pc.10168.LD)
	.p2align 4
	.L__pc.10168.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10169
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10169: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10170
	.L__pc.10170: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10171
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10171: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10172: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10173: Dma_PatchSrc (.L__pc.10173.LD), (.L__movme_tmp.1), (.L__pc.10173.LD)
	.p2align 4
	.L__pc.10173.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10174
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10174: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10175
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10175: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10176: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10177: Dma_PatchSrc (.L__pc.10177.LD), (.L__movme_tmp.1), (.L__pc.10177.LD)
	.p2align 4
	.L__pc.10177.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10178
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10178: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10179
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10179: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10180: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10181: Dma_PatchSrc (.L__pc.10181.LD), (.L__movme_tmp.1), (.L__pc.10181.LD)
	.p2align 4
	.L__pc.10181.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10182
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10182: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10183
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10183: Dma_PatchSrc (.L__pc.10183.LD), (.L__movme_cp.24), (.L__pc.10183.LD)
	.p2align 4
	.L__pc.10183.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10184
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10184: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10185
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10185: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10186: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10187: Dma_PatchSrc (.L__pc.10187.LD), (.L__movme_tmp.1), (.L__pc.10187.LD)
	.p2align 4
	.L__pc.10187.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10188
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10188: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10189
	
	.L__pc.10189: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10190
	
	.p2align 4
	.L__pc.10190: Dma_PatchDst (.L__pc.10190.ST), (.L__movme_cp.69), (.L__pc.10190.ST)
	.L__pc.10190.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10191
	
	.L__pc.10191: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10192
	
	.p2align 4
	.L__pc.10192: Dma_PatchDst (.L__pc.10192.ST), (.L__movme_cp.54), (.L__pc.10192.ST)
	.L__pc.10192.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10193
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.10193: Dma_PatchSrc (.L__pc.10193.LD), (.L__movme_cp.30), (.L__pc.10193.LD)
	.p2align 4
	.L__pc.10193.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10194
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10194: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10195
	.L__pc.10195: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10196
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.10196: Dma_PatchSrc (.L__pc.10196.LD), (.L__movme_cp.31), (.L__pc.10196.LD)
	.p2align 4
	.L__pc.10196.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10197
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10197: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10198
	.L__pc.10198: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10199
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10199: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10200: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10201: Dma_PatchSrc (.L__pc.10201.LD), (.L__movme_tmp.1), (.L__pc.10201.LD)
	.p2align 4
	.L__pc.10201.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10202
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10202: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10203
	.L__pc.10203: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10204
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10204: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10205: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10206: Dma_PatchSrc (.L__pc.10206.LD), (.L__movme_tmp.1), (.L__pc.10206.LD)
	.p2align 4
	.L__pc.10206.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10207
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10207: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10208
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10208: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10209: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10210: Dma_PatchSrc (.L__pc.10210.LD), (.L__movme_tmp.1), (.L__pc.10210.LD)
	.p2align 4
	.L__pc.10210.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10211
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10211: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10212
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10212: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10213: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10214: Dma_PatchSrc (.L__pc.10214.LD), (.L__movme_tmp.1), (.L__pc.10214.LD)
	.p2align 4
	.L__pc.10214.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10215
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10215: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10216
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10216: Dma_PatchSrc (.L__pc.10216.LD), (.L__movme_cp.24), (.L__pc.10216.LD)
	.p2align 4
	.L__pc.10216.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10217
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10217: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10218
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10218: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10219: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10220: Dma_PatchSrc (.L__pc.10220.LD), (.L__movme_tmp.1), (.L__pc.10220.LD)
	.p2align 4
	.L__pc.10220.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10221
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10221: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10222
	
	.L__pc.10222: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10223
	
	.p2align 4
	.L__pc.10223: Dma_PatchDst (.L__pc.10223.ST), (.L__movme_cp.70), (.L__pc.10223.ST)
	.L__pc.10223.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10224
	
	.L__pc.10224: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10225
	
	.p2align 4
	.L__pc.10225: Dma_PatchDst (.L__pc.10225.ST), (.L__movme_cp.54), (.L__pc.10225.ST)
	.L__pc.10225.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10226
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10226: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10227
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10227: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10228
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10228: Dma_PatchSrc (.L__pc.10228.LD), (.L__movme_cp.24), (.L__pc.10228.LD)
	.p2align 4
	.L__pc.10228.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10229
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10229: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10230
	.L__pc.10230: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10231
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.10231: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10232: Dma_PatchSrc (.L__pc.10232.LD), (.L__movme_tmp.1), (.L__pc.10232.LD)
	.p2align 4
	.L__pc.10232.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10233
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10233: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10234
	.L__pc.10234: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10235
	
	.L__pc.10235: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10236
	
	.p2align 4
	.L__pc.10236: Dma_PatchDst (.L__pc.10236.ST), (.L__movme_cp.72), (.L__pc.10236.ST)
	.L__pc.10236.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10237
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.10237: Dma_PatchSrc (.L__pc.10237.LD), (.L__movme_cp.72), (.L__pc.10237.LD)
	.p2align 4
	.L__pc.10237.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10238
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10238: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10239
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10239: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10240: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10241: Dma_PatchSrc (.L__pc.10241.LD), (.L__movme_tmp.1), (.L__pc.10241.LD)
	.p2align 4
	.L__pc.10241.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10242
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10242: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10243
	
	.L__pc.10243: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10244
	
	.p2align 4
	.L__pc.10244: Dma_PatchDst (.L__pc.10244.ST), (.L__movme_cp.74), (.L__pc.10244.ST)
	.L__pc.10244.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10245
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10245: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10246: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10247: Dma_PatchSrc (.L__pc.10247.LD), (.L__movme_tmp.1), (.L__pc.10247.LD)
	.p2align 4
	.L__pc.10247.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10248
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10248: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10249
	
	.L__pc.10249: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10250
	
	.p2align 4
	.L__pc.10250: Dma_PatchDst (.L__pc.10250.ST), (.L__movme_cp.76), (.L__pc.10250.ST)
	.L__pc.10250.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10251
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.10251: Dma_PatchSrc (.L__pc.10251.LD), (.L__movme_cp.74), (.L__pc.10251.LD)
	.p2align 4
	.L__pc.10251.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10252
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10252: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10253
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.10253: Dma_PatchSrc (.L__pc.10253.LD), ((.L__movme.reg.eax+0)), (.L__pc.10253.LD)
	.p2align 4
	.L__pc.10253.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10254
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10254: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10255
	
	.L__pc.10255: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10256
	
	.p2align 4
	.L__pc.10256: Dma_PatchDst (.L__pc.10256.ST), (.L__movme_cp.77), (.L__pc.10256.ST)
	.L__pc.10256.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10257
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.10257: Dma_PatchSrc (.L__pc.10257.LD), (.L__movme_cp.77), (.L__pc.10257.LD)
	.p2align 4
	.L__pc.10257.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10258
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10258: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10259
	
	.L__pc.10259: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10260
	
	.p2align 4
	.L__pc.10260: Dma_PatchDst (.L__pc.10260.ST), (.L__movme_cp.21), (.L__pc.10260.ST)
	.L__pc.10260.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10261
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.10261: Dma_PatchSrc (.L__pc.10261.LD), (.L__movme_cp.58), (.L__pc.10261.LD)
	.p2align 4
	.L__pc.10261.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10262
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10262: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10263
	
	.L__pc.10263: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10264
	
	.p2align 4
	.L__pc.10264: Dma_PatchDst (.L__pc.10264.ST), (.L__movme_cp.22), (.L__pc.10264.ST)
	.L__pc.10264.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10265
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10265: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10266
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10266: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10267
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10267: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10268
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10268: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10269
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.10269: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.10270
	
	.p2align 4
	.L__pc.10270: Dma_PatchDst (.L__pc.10270.ST), (.L__movme_cp.24), (.L__pc.10270.ST)
	.L__pc.10270.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10271
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.10271: Dma_PatchSrc (.L__pc.10271.LD), (.L__movme_cp.25), (.L__pc.10271.LD)
	.p2align 4
	.L__pc.10271.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10272
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10272: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10273
	.L__pc.10273: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10274
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.10274: Dma_PatchSrc (.L__pc.10274.LD), (.L__movme_cp.26), (.L__pc.10274.LD)
	.p2align 4
	.L__pc.10274.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10275
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10275: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10276
	.L__pc.10276: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10277
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10277: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10278: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10279: Dma_PatchSrc (.L__pc.10279.LD), (.L__movme_tmp.1), (.L__pc.10279.LD)
	.p2align 4
	.L__pc.10279.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10280
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10280: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10281
	.L__pc.10281: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10282
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10282: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10283: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10284: Dma_PatchSrc (.L__pc.10284.LD), (.L__movme_tmp.1), (.L__pc.10284.LD)
	.p2align 4
	.L__pc.10284.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10285
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10285: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10286
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10286: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10287: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10288: Dma_PatchSrc (.L__pc.10288.LD), (.L__movme_tmp.1), (.L__pc.10288.LD)
	.p2align 4
	.L__pc.10288.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10289
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10289: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10290
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10290: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10291: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10292: Dma_PatchSrc (.L__pc.10292.LD), (.L__movme_tmp.1), (.L__pc.10292.LD)
	.p2align 4
	.L__pc.10292.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10293
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10293: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10294
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10294: Dma_PatchSrc (.L__pc.10294.LD), (.L__movme_cp.24), (.L__pc.10294.LD)
	.p2align 4
	.L__pc.10294.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10295
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10295: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10296
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10296: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10297: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10298: Dma_PatchSrc (.L__pc.10298.LD), (.L__movme_tmp.1), (.L__pc.10298.LD)
	.p2align 4
	.L__pc.10298.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10299
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10299: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10300
	
	.L__pc.10300: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10301
	
	.p2align 4
	.L__pc.10301: Dma_PatchDst (.L__pc.10301.ST), (.L__movme_cp.78), (.L__pc.10301.ST)
	.L__pc.10301.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10302
	
	.L__pc.10302: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10303
	
	.p2align 4
	.L__pc.10303: Dma_PatchDst (.L__pc.10303.ST), (.L__movme_cp.54), (.L__pc.10303.ST)
	.L__pc.10303.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10304
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.10304: Dma_PatchSrc (.L__pc.10304.LD), (.L__movme_cp.30), (.L__pc.10304.LD)
	.p2align 4
	.L__pc.10304.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10305
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10305: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10306
	.L__pc.10306: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10307
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.10307: Dma_PatchSrc (.L__pc.10307.LD), (.L__movme_cp.31), (.L__pc.10307.LD)
	.p2align 4
	.L__pc.10307.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10308
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10308: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10309
	.L__pc.10309: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10310
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10310: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10311: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10312: Dma_PatchSrc (.L__pc.10312.LD), (.L__movme_tmp.1), (.L__pc.10312.LD)
	.p2align 4
	.L__pc.10312.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10313
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10313: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10314
	.L__pc.10314: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10315
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10315: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10316: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10317: Dma_PatchSrc (.L__pc.10317.LD), (.L__movme_tmp.1), (.L__pc.10317.LD)
	.p2align 4
	.L__pc.10317.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10318
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10318: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10319
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10319: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10320: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10321: Dma_PatchSrc (.L__pc.10321.LD), (.L__movme_tmp.1), (.L__pc.10321.LD)
	.p2align 4
	.L__pc.10321.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10322
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10322: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10323
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10323: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10324: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10325: Dma_PatchSrc (.L__pc.10325.LD), (.L__movme_tmp.1), (.L__pc.10325.LD)
	.p2align 4
	.L__pc.10325.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10326
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10326: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10327
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10327: Dma_PatchSrc (.L__pc.10327.LD), (.L__movme_cp.24), (.L__pc.10327.LD)
	.p2align 4
	.L__pc.10327.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10328
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10328: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10329
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10329: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10330: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10331: Dma_PatchSrc (.L__pc.10331.LD), (.L__movme_tmp.1), (.L__pc.10331.LD)
	.p2align 4
	.L__pc.10331.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10332
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10332: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10333
	
	.L__pc.10333: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10334
	
	.p2align 4
	.L__pc.10334: Dma_PatchDst (.L__pc.10334.ST), (.L__movme_cp.79), (.L__pc.10334.ST)
	.L__pc.10334.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10335
	
	.L__pc.10335: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10336
	
	.p2align 4
	.L__pc.10336: Dma_PatchDst (.L__pc.10336.ST), (.L__movme_cp.54), (.L__pc.10336.ST)
	.L__pc.10336.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10337
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.10337: Dma_PatchSrc (.L__pc.10337.LD), (.L__movme_cp.74), (.L__pc.10337.LD)
	.p2align 4
	.L__pc.10337.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10338
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10338: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10339
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.10339: Dma_PatchSrc (.L__pc.10339.LD), (.L__movme_cp.77), (.L__pc.10339.LD)
	.p2align 4
	.L__pc.10339.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10340
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10340: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10341
	
	.L__pc.10341: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10342
	
	.p2align 4
	.L__pc.10342: Dma_PatchDst (.L__pc.10342.ST), ((.L__movme.reg.eax+0)), (.L__pc.10342.ST)
	.L__pc.10342.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10343
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.10343: Dma_PatchSrc (.L__pc.10343.LD), (.L__movme_cp.76), (.L__pc.10343.LD)
	.p2align 4
	.L__pc.10343.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10344
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10344: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10345
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.10345: Dma_PatchSrc (.L__pc.10345.LD), ((.L__movme.reg.eax+0)), (.L__pc.10345.LD)
	.p2align 4
	.L__pc.10345.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10346
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10346: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10347
	
	.L__pc.10347: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10348
	
	.p2align 4
	.L__pc.10348: Dma_PatchDst (.L__pc.10348.ST), (.L__movme_cp.80), (.L__pc.10348.ST)
	.L__pc.10348.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10349
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10349: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10350
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10350: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10351
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.10351: Dma_PatchSrc (.L__pc.10351.LD), (.L__movme_cp.102), (.L__pc.10351.LD)
	.p2align 4
	.L__pc.10351.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10352
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10352: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10353
	.L__pc.10353: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10354
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.84 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.10354: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10355: Dma_PatchSrc (.L__pc.10355.LD), (.L__movme_tmp.1), (.L__pc.10355.LD)
	.p2align 4
	.L__pc.10355.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10356
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10356: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10357
	.L__pc.10357: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10358
	
	.L__pc.10358: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10359
	
	.p2align 4
	.L__pc.10359: Dma_PatchDst (.L__pc.10359.ST), (.L__movme_cp.102), (.L__pc.10359.ST)
	.L__pc.10359.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10360
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.10360: Dma_PatchSrc (.L__pc.10360.LD), (.L__movme_cp.76), (.L__pc.10360.LD)
	.p2align 4
	.L__pc.10360.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10361
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10361: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10362
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.10362: Dma_PatchSrc (.L__pc.10362.LD), (.L__movme_cp.80), (.L__pc.10362.LD)
	.p2align 4
	.L__pc.10362.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10363
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10363: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10364
	
	.L__pc.10364: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10365
	
	.p2align 4
	.L__pc.10365: Dma_PatchDst (.L__pc.10365.ST), ((.L__movme.reg.eax+0)), (.L__pc.10365.ST)
	.L__pc.10365.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10366
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10366: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10367
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10367: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10368
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.10368: Dma_PatchSrc (.L__pc.10368.LD), (.L__movme_cp.101), (.L__pc.10368.LD)
	.p2align 4
	.L__pc.10368.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10369
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10369: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10370
	.L__pc.10370: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10371
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10371: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.85 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10372: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10373: Dma_PatchSrc (.L__pc.10373.LD), (.L__movme_tmp.1), (.L__pc.10373.LD)
	.p2align 4
	.L__pc.10373.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10374
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10374: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10375
	
	.L__pc.10375: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10376
	
	.p2align 4
	.L__pc.10376: Dma_PatchDst (.L__pc.10376.ST), (.L__movme_cp.24), (.L__pc.10376.ST)
	.L__pc.10376.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10377
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10377: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10378
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10378: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10379
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10379: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10380
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10380: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10381
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.10381: Dma_PatchSrc (.L__pc.10381.LD), (.L__movme_cp.63), (.L__pc.10381.LD)
	.p2align 4
	.L__pc.10381.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10382
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10382: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10383
	.L__pc.10383: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10384
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10384: Dma_PatchSrc (.L__pc.10384.LD), (.L__movme_cp.24), (.L__pc.10384.LD)
	.p2align 4
	.L__pc.10384.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10385
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10385: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10386
	.L__pc.10386: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10387
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10387: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10388: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10389: Dma_PatchSrc (.L__pc.10389.LD), (.L__movme_tmp.1), (.L__pc.10389.LD)
	.p2align 4
	.L__pc.10389.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10390
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10390: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10391
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10391: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10392: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10393: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10394: Dma_PatchSrc (.L__pc.10394.LD), (.L__movme_tmp.1), (.L__pc.10394.LD)
	.p2align 4
	.L__pc.10394.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10395
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10395: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10396
	
	.L__pc.10396: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10397
	
	.p2align 4
	.L__pc.10397: Dma_PatchDst (.L__pc.10397.ST), (.L__movme_cp.63), (.L__pc.10397.ST)
	.L__pc.10397.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10398
	
	.L__pc.10398: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10399
	
	.p2align 4
	.L__pc.10399: Dma_PatchDst (.L__pc.10399.ST), (.L__movme_cp.24), (.L__pc.10399.ST)
	.L__pc.10399.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10400
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10400: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10401
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10401: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10402
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10402: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10403
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10403: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10404
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.10404: Dma_PatchSrc (.L__pc.10404.LD), (.L__movme_cp.66), (.L__pc.10404.LD)
	.p2align 4
	.L__pc.10404.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10405
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10405: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10406
	.L__pc.10406: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10407
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10407: Dma_PatchSrc (.L__pc.10407.LD), (.L__movme_cp.24), (.L__pc.10407.LD)
	.p2align 4
	.L__pc.10407.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10408
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10408: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10409
	.L__pc.10409: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10410
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10410: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10411: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10412: Dma_PatchSrc (.L__pc.10412.LD), (.L__movme_tmp.1), (.L__pc.10412.LD)
	.p2align 4
	.L__pc.10412.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10413
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10413: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10414
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10414: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10415: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10416: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10417: Dma_PatchSrc (.L__pc.10417.LD), (.L__movme_tmp.1), (.L__pc.10417.LD)
	.p2align 4
	.L__pc.10417.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10418
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10418: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10419
	
	.L__pc.10419: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10420
	
	.p2align 4
	.L__pc.10420: Dma_PatchDst (.L__pc.10420.ST), (.L__movme_cp.66), (.L__pc.10420.ST)
	.L__pc.10420.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10421
	
	.L__pc.10421: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10422
	
	.p2align 4
	.L__pc.10422: Dma_PatchDst (.L__pc.10422.ST), (.L__movme_cp.24), (.L__pc.10422.ST)
	.L__pc.10422.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10423
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10423: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10424
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10424: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10425
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10425: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10426
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10426: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10427
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.10427: Dma_PatchSrc (.L__pc.10427.LD), (.L__movme_cp.67), (.L__pc.10427.LD)
	.p2align 4
	.L__pc.10427.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10428
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10428: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10429
	.L__pc.10429: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10430
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10430: Dma_PatchSrc (.L__pc.10430.LD), (.L__movme_cp.24), (.L__pc.10430.LD)
	.p2align 4
	.L__pc.10430.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10431
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10431: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10432
	.L__pc.10432: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10433
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10433: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10434: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10435: Dma_PatchSrc (.L__pc.10435.LD), (.L__movme_tmp.1), (.L__pc.10435.LD)
	.p2align 4
	.L__pc.10435.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10436
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10436: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10437
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10437: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10438: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10439: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10440: Dma_PatchSrc (.L__pc.10440.LD), (.L__movme_tmp.1), (.L__pc.10440.LD)
	.p2align 4
	.L__pc.10440.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10441
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10441: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10442
	
	.L__pc.10442: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10443
	
	.p2align 4
	.L__pc.10443: Dma_PatchDst (.L__pc.10443.ST), (.L__movme_cp.67), (.L__pc.10443.ST)
	.L__pc.10443.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10444
	
	.L__pc.10444: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10445
	
	.p2align 4
	.L__pc.10445: Dma_PatchDst (.L__pc.10445.ST), (.L__movme_cp.24), (.L__pc.10445.ST)
	.L__pc.10445.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10446
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10446: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10447
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10447: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10448
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10448: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10449
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10449: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10450
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.10450: Dma_PatchSrc (.L__pc.10450.LD), (.L__movme_cp.68), (.L__pc.10450.LD)
	.p2align 4
	.L__pc.10450.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10451
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10451: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10452
	.L__pc.10452: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10453
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10453: Dma_PatchSrc (.L__pc.10453.LD), (.L__movme_cp.24), (.L__pc.10453.LD)
	.p2align 4
	.L__pc.10453.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10454
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10454: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10455
	.L__pc.10455: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10456
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10456: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10457: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10458: Dma_PatchSrc (.L__pc.10458.LD), (.L__movme_tmp.1), (.L__pc.10458.LD)
	.p2align 4
	.L__pc.10458.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10459
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10459: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10460
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10460: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10461: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10462: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10463: Dma_PatchSrc (.L__pc.10463.LD), (.L__movme_tmp.1), (.L__pc.10463.LD)
	.p2align 4
	.L__pc.10463.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10464
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10464: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10465
	
	.L__pc.10465: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10466
	
	.p2align 4
	.L__pc.10466: Dma_PatchDst (.L__pc.10466.ST), (.L__movme_cp.68), (.L__pc.10466.ST)
	.L__pc.10466.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10467
	
	.L__pc.10467: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10468
	
	.p2align 4
	.L__pc.10468: Dma_PatchDst (.L__pc.10468.ST), (.L__movme_cp.24), (.L__pc.10468.ST)
	.L__pc.10468.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10469
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10469: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10470
	
	.p2align 4
	.L__pc.10470: Dma_PatchDst (.L__pc.10470.ST), (.L__movme_cp.24), (.L__pc.10470.ST)
	.L__pc.10470.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10471
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.10471: Dma_PatchSrc (.L__pc.10471.LD), (.L__movme_cp.60), (.L__pc.10471.LD)
	.p2align 4
	.L__pc.10471.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10472
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10472: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10473
	
	.L__pc.10473: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10474
	
	.p2align 4
	.L__pc.10474: Dma_PatchDst (.L__pc.10474.ST), (.L__movme_cp.21), (.L__pc.10474.ST)
	.L__pc.10474.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10475
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.10475: Dma_PatchSrc (.L__pc.10475.LD), (.L__movme_cp.58), (.L__pc.10475.LD)
	.p2align 4
	.L__pc.10475.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10476
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10476: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10477
	
	.L__pc.10477: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10478
	
	.p2align 4
	.L__pc.10478: Dma_PatchDst (.L__pc.10478.ST), (.L__movme_cp.22), (.L__pc.10478.ST)
	.L__pc.10478.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10479
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10479: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10480
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10480: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10481
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10481: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10482
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10482: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10483
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.10483: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.10484
	
	.p2align 4
	.L__pc.10484: Dma_PatchDst (.L__pc.10484.ST), (.L__movme_cp.24), (.L__pc.10484.ST)
	.L__pc.10484.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10485
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.10485: Dma_PatchSrc (.L__pc.10485.LD), (.L__movme_cp.25), (.L__pc.10485.LD)
	.p2align 4
	.L__pc.10485.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10486
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10486: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10487
	.L__pc.10487: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10488
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.10488: Dma_PatchSrc (.L__pc.10488.LD), (.L__movme_cp.26), (.L__pc.10488.LD)
	.p2align 4
	.L__pc.10488.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10489
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10489: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10490
	.L__pc.10490: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10491
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10491: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10492: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10493: Dma_PatchSrc (.L__pc.10493.LD), (.L__movme_tmp.1), (.L__pc.10493.LD)
	.p2align 4
	.L__pc.10493.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10494
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10494: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10495
	.L__pc.10495: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10496
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10496: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10497: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10498: Dma_PatchSrc (.L__pc.10498.LD), (.L__movme_tmp.1), (.L__pc.10498.LD)
	.p2align 4
	.L__pc.10498.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10499
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10499: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10500
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10500: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10501: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10502: Dma_PatchSrc (.L__pc.10502.LD), (.L__movme_tmp.1), (.L__pc.10502.LD)
	.p2align 4
	.L__pc.10502.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10503
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10503: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10504
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10504: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10505: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10506: Dma_PatchSrc (.L__pc.10506.LD), (.L__movme_tmp.1), (.L__pc.10506.LD)
	.p2align 4
	.L__pc.10506.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10507
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10507: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10508
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10508: Dma_PatchSrc (.L__pc.10508.LD), (.L__movme_cp.24), (.L__pc.10508.LD)
	.p2align 4
	.L__pc.10508.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10509
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10509: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10510
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10510: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10511: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10512: Dma_PatchSrc (.L__pc.10512.LD), (.L__movme_tmp.1), (.L__pc.10512.LD)
	.p2align 4
	.L__pc.10512.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10513
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10513: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10514
	
	.L__pc.10514: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10515
	
	.p2align 4
	.L__pc.10515: Dma_PatchDst (.L__pc.10515.ST), (.L__movme_cp.69), (.L__pc.10515.ST)
	.L__pc.10515.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10516
	
	.L__pc.10516: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10517
	
	.p2align 4
	.L__pc.10517: Dma_PatchDst (.L__pc.10517.ST), (.L__movme_cp.54), (.L__pc.10517.ST)
	.L__pc.10517.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10518
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.10518: Dma_PatchSrc (.L__pc.10518.LD), (.L__movme_cp.30), (.L__pc.10518.LD)
	.p2align 4
	.L__pc.10518.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10519
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10519: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10520
	.L__pc.10520: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10521
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.10521: Dma_PatchSrc (.L__pc.10521.LD), (.L__movme_cp.31), (.L__pc.10521.LD)
	.p2align 4
	.L__pc.10521.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10522
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10522: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10523
	.L__pc.10523: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10524
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10524: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10525: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10526: Dma_PatchSrc (.L__pc.10526.LD), (.L__movme_tmp.1), (.L__pc.10526.LD)
	.p2align 4
	.L__pc.10526.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10527
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10527: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10528
	.L__pc.10528: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10529
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10529: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10530: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10531: Dma_PatchSrc (.L__pc.10531.LD), (.L__movme_tmp.1), (.L__pc.10531.LD)
	.p2align 4
	.L__pc.10531.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10532
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10532: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10533
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10533: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10534: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10535: Dma_PatchSrc (.L__pc.10535.LD), (.L__movme_tmp.1), (.L__pc.10535.LD)
	.p2align 4
	.L__pc.10535.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10536
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10536: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10537
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10537: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10538: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10539: Dma_PatchSrc (.L__pc.10539.LD), (.L__movme_tmp.1), (.L__pc.10539.LD)
	.p2align 4
	.L__pc.10539.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10540
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10540: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10541
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10541: Dma_PatchSrc (.L__pc.10541.LD), (.L__movme_cp.24), (.L__pc.10541.LD)
	.p2align 4
	.L__pc.10541.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10542
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10542: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10543
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10543: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10544: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10545: Dma_PatchSrc (.L__pc.10545.LD), (.L__movme_tmp.1), (.L__pc.10545.LD)
	.p2align 4
	.L__pc.10545.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10546
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10546: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10547
	
	.L__pc.10547: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10548
	
	.p2align 4
	.L__pc.10548: Dma_PatchDst (.L__pc.10548.ST), (.L__movme_cp.70), (.L__pc.10548.ST)
	.L__pc.10548.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10549
	
	.L__pc.10549: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10550
	
	.p2align 4
	.L__pc.10550: Dma_PatchDst (.L__pc.10550.ST), (.L__movme_cp.54), (.L__pc.10550.ST)
	.L__pc.10550.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10551
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10551: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10552
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10552: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10553
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10553: Dma_PatchSrc (.L__pc.10553.LD), (.L__movme_cp.24), (.L__pc.10553.LD)
	.p2align 4
	.L__pc.10553.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10554
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10554: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10555
	.L__pc.10555: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10556
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.10556: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10557: Dma_PatchSrc (.L__pc.10557.LD), (.L__movme_tmp.1), (.L__pc.10557.LD)
	.p2align 4
	.L__pc.10557.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10558
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10558: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10559
	.L__pc.10559: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10560
	
	.L__pc.10560: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10561
	
	.p2align 4
	.L__pc.10561: Dma_PatchDst (.L__pc.10561.ST), (.L__movme_cp.72), (.L__pc.10561.ST)
	.L__pc.10561.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10562
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.10562: Dma_PatchSrc (.L__pc.10562.LD), (.L__movme_cp.72), (.L__pc.10562.LD)
	.p2align 4
	.L__pc.10562.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10563
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10563: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10564
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10564: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10565: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10566: Dma_PatchSrc (.L__pc.10566.LD), (.L__movme_tmp.1), (.L__pc.10566.LD)
	.p2align 4
	.L__pc.10566.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10567
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10567: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10568
	
	.L__pc.10568: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10569
	
	.p2align 4
	.L__pc.10569: Dma_PatchDst (.L__pc.10569.ST), (.L__movme_cp.74), (.L__pc.10569.ST)
	.L__pc.10569.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10570
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10570: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10571: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10572: Dma_PatchSrc (.L__pc.10572.LD), (.L__movme_tmp.1), (.L__pc.10572.LD)
	.p2align 4
	.L__pc.10572.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10573
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10573: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10574
	
	.L__pc.10574: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10575
	
	.p2align 4
	.L__pc.10575: Dma_PatchDst (.L__pc.10575.ST), (.L__movme_cp.76), (.L__pc.10575.ST)
	.L__pc.10575.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10576
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.10576: Dma_PatchSrc (.L__pc.10576.LD), (.L__movme_cp.74), (.L__pc.10576.LD)
	.p2align 4
	.L__pc.10576.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10577
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10577: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10578
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.10578: Dma_PatchSrc (.L__pc.10578.LD), ((.L__movme.reg.eax+0)), (.L__pc.10578.LD)
	.p2align 4
	.L__pc.10578.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10579
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10579: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10580
	
	.L__pc.10580: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10581
	
	.p2align 4
	.L__pc.10581: Dma_PatchDst (.L__pc.10581.ST), (.L__movme_cp.77), (.L__pc.10581.ST)
	.L__pc.10581.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10582
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.10582: Dma_PatchSrc (.L__pc.10582.LD), (.L__movme_cp.77), (.L__pc.10582.LD)
	.p2align 4
	.L__pc.10582.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10583
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10583: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10584
	
	.L__pc.10584: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10585
	
	.p2align 4
	.L__pc.10585: Dma_PatchDst (.L__pc.10585.ST), (.L__movme_cp.21), (.L__pc.10585.ST)
	.L__pc.10585.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10586
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.10586: Dma_PatchSrc (.L__pc.10586.LD), (.L__movme_cp.58), (.L__pc.10586.LD)
	.p2align 4
	.L__pc.10586.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10587
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10587: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10588
	
	.L__pc.10588: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10589
	
	.p2align 4
	.L__pc.10589: Dma_PatchDst (.L__pc.10589.ST), (.L__movme_cp.22), (.L__pc.10589.ST)
	.L__pc.10589.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10590
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10590: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10591
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10591: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10592
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10592: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10593
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10593: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10594
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.10594: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.10595
	
	.p2align 4
	.L__pc.10595: Dma_PatchDst (.L__pc.10595.ST), (.L__movme_cp.24), (.L__pc.10595.ST)
	.L__pc.10595.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10596
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.10596: Dma_PatchSrc (.L__pc.10596.LD), (.L__movme_cp.25), (.L__pc.10596.LD)
	.p2align 4
	.L__pc.10596.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10597
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10597: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10598
	.L__pc.10598: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10599
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.10599: Dma_PatchSrc (.L__pc.10599.LD), (.L__movme_cp.26), (.L__pc.10599.LD)
	.p2align 4
	.L__pc.10599.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10600
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10600: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10601
	.L__pc.10601: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10602
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10602: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10603: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10604: Dma_PatchSrc (.L__pc.10604.LD), (.L__movme_tmp.1), (.L__pc.10604.LD)
	.p2align 4
	.L__pc.10604.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10605
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10605: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10606
	.L__pc.10606: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10607
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10607: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10608: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10609: Dma_PatchSrc (.L__pc.10609.LD), (.L__movme_tmp.1), (.L__pc.10609.LD)
	.p2align 4
	.L__pc.10609.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10610
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10610: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10611
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10611: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10612: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10613: Dma_PatchSrc (.L__pc.10613.LD), (.L__movme_tmp.1), (.L__pc.10613.LD)
	.p2align 4
	.L__pc.10613.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10614
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10614: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10615
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10615: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10616: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10617: Dma_PatchSrc (.L__pc.10617.LD), (.L__movme_tmp.1), (.L__pc.10617.LD)
	.p2align 4
	.L__pc.10617.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10618
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10618: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10619
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10619: Dma_PatchSrc (.L__pc.10619.LD), (.L__movme_cp.24), (.L__pc.10619.LD)
	.p2align 4
	.L__pc.10619.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10620
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10620: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10621
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10621: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10622: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10623: Dma_PatchSrc (.L__pc.10623.LD), (.L__movme_tmp.1), (.L__pc.10623.LD)
	.p2align 4
	.L__pc.10623.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10624
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10624: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10625
	
	.L__pc.10625: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10626
	
	.p2align 4
	.L__pc.10626: Dma_PatchDst (.L__pc.10626.ST), (.L__movme_cp.78), (.L__pc.10626.ST)
	.L__pc.10626.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10627
	
	.L__pc.10627: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10628
	
	.p2align 4
	.L__pc.10628: Dma_PatchDst (.L__pc.10628.ST), (.L__movme_cp.54), (.L__pc.10628.ST)
	.L__pc.10628.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10629
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.10629: Dma_PatchSrc (.L__pc.10629.LD), (.L__movme_cp.30), (.L__pc.10629.LD)
	.p2align 4
	.L__pc.10629.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10630
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10630: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10631
	.L__pc.10631: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10632
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.10632: Dma_PatchSrc (.L__pc.10632.LD), (.L__movme_cp.31), (.L__pc.10632.LD)
	.p2align 4
	.L__pc.10632.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10633
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10633: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10634
	.L__pc.10634: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10635
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10635: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10636: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10637: Dma_PatchSrc (.L__pc.10637.LD), (.L__movme_tmp.1), (.L__pc.10637.LD)
	.p2align 4
	.L__pc.10637.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10638
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10638: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10639
	.L__pc.10639: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10640
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10640: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10641: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10642: Dma_PatchSrc (.L__pc.10642.LD), (.L__movme_tmp.1), (.L__pc.10642.LD)
	.p2align 4
	.L__pc.10642.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10643
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10643: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10644
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10644: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10645: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10646: Dma_PatchSrc (.L__pc.10646.LD), (.L__movme_tmp.1), (.L__pc.10646.LD)
	.p2align 4
	.L__pc.10646.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10647
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10647: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10648
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10648: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10649: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10650: Dma_PatchSrc (.L__pc.10650.LD), (.L__movme_tmp.1), (.L__pc.10650.LD)
	.p2align 4
	.L__pc.10650.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10651
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10651: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10652
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10652: Dma_PatchSrc (.L__pc.10652.LD), (.L__movme_cp.24), (.L__pc.10652.LD)
	.p2align 4
	.L__pc.10652.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10653
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10653: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10654
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10654: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10655: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10656: Dma_PatchSrc (.L__pc.10656.LD), (.L__movme_tmp.1), (.L__pc.10656.LD)
	.p2align 4
	.L__pc.10656.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10657
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10657: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10658
	
	.L__pc.10658: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10659
	
	.p2align 4
	.L__pc.10659: Dma_PatchDst (.L__pc.10659.ST), (.L__movme_cp.79), (.L__pc.10659.ST)
	.L__pc.10659.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10660
	
	.L__pc.10660: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10661
	
	.p2align 4
	.L__pc.10661: Dma_PatchDst (.L__pc.10661.ST), (.L__movme_cp.54), (.L__pc.10661.ST)
	.L__pc.10661.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10662
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.10662: Dma_PatchSrc (.L__pc.10662.LD), (.L__movme_cp.74), (.L__pc.10662.LD)
	.p2align 4
	.L__pc.10662.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10663
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10663: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10664
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.10664: Dma_PatchSrc (.L__pc.10664.LD), (.L__movme_cp.77), (.L__pc.10664.LD)
	.p2align 4
	.L__pc.10664.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10665
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10665: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10666
	
	.L__pc.10666: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10667
	
	.p2align 4
	.L__pc.10667: Dma_PatchDst (.L__pc.10667.ST), ((.L__movme.reg.eax+0)), (.L__pc.10667.ST)
	.L__pc.10667.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10668
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.10668: Dma_PatchSrc (.L__pc.10668.LD), (.L__movme_cp.76), (.L__pc.10668.LD)
	.p2align 4
	.L__pc.10668.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10669
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10669: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10670
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.10670: Dma_PatchSrc (.L__pc.10670.LD), ((.L__movme.reg.eax+0)), (.L__pc.10670.LD)
	.p2align 4
	.L__pc.10670.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10671
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10671: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10672
	
	.L__pc.10672: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10673
	
	.p2align 4
	.L__pc.10673: Dma_PatchDst (.L__pc.10673.ST), (.L__movme_cp.80), (.L__pc.10673.ST)
	.L__pc.10673.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10674
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10674: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10675
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10675: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10676
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.10676: Dma_PatchSrc (.L__pc.10676.LD), (.L__movme_cp.102), (.L__pc.10676.LD)
	.p2align 4
	.L__pc.10676.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10677
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10677: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10678
	.L__pc.10678: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10679
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.86 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.10679: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10680: Dma_PatchSrc (.L__pc.10680.LD), (.L__movme_tmp.1), (.L__pc.10680.LD)
	.p2align 4
	.L__pc.10680.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10681
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10681: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10682
	.L__pc.10682: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10683
	
	.L__pc.10683: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10684
	
	.p2align 4
	.L__pc.10684: Dma_PatchDst (.L__pc.10684.ST), (.L__movme_cp.102), (.L__pc.10684.ST)
	.L__pc.10684.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10685
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.10685: Dma_PatchSrc (.L__pc.10685.LD), (.L__movme_cp.76), (.L__pc.10685.LD)
	.p2align 4
	.L__pc.10685.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10686
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10686: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10687
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.10687: Dma_PatchSrc (.L__pc.10687.LD), (.L__movme_cp.80), (.L__pc.10687.LD)
	.p2align 4
	.L__pc.10687.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10688
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10688: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10689
	
	.L__pc.10689: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10690
	
	.p2align 4
	.L__pc.10690: Dma_PatchDst (.L__pc.10690.ST), ((.L__movme.reg.eax+0)), (.L__pc.10690.ST)
	.L__pc.10690.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10691
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10691: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10692
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10692: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10693
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.10693: Dma_PatchSrc (.L__pc.10693.LD), (.L__movme_cp.101), (.L__pc.10693.LD)
	.p2align 4
	.L__pc.10693.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10694
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10694: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10695
	.L__pc.10695: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10696
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10696: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.87 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10697: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10698: Dma_PatchSrc (.L__pc.10698.LD), (.L__movme_tmp.1), (.L__pc.10698.LD)
	.p2align 4
	.L__pc.10698.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10699
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10699: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10700
	
	.L__pc.10700: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10701
	
	.p2align 4
	.L__pc.10701: Dma_PatchDst (.L__pc.10701.ST), (.L__movme_cp.24), (.L__pc.10701.ST)
	.L__pc.10701.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10702
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10702: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10703
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10703: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10704
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10704: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10705
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10705: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10706
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.10706: Dma_PatchSrc (.L__pc.10706.LD), (.L__movme_cp.63), (.L__pc.10706.LD)
	.p2align 4
	.L__pc.10706.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10707
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10707: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10708
	.L__pc.10708: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10709
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10709: Dma_PatchSrc (.L__pc.10709.LD), (.L__movme_cp.24), (.L__pc.10709.LD)
	.p2align 4
	.L__pc.10709.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10710
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10710: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10711
	.L__pc.10711: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10712
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10712: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10713: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10714: Dma_PatchSrc (.L__pc.10714.LD), (.L__movme_tmp.1), (.L__pc.10714.LD)
	.p2align 4
	.L__pc.10714.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10715
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10715: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10716
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10716: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10717: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10718: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10719: Dma_PatchSrc (.L__pc.10719.LD), (.L__movme_tmp.1), (.L__pc.10719.LD)
	.p2align 4
	.L__pc.10719.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10720
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10720: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10721
	
	.L__pc.10721: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10722
	
	.p2align 4
	.L__pc.10722: Dma_PatchDst (.L__pc.10722.ST), (.L__movme_cp.63), (.L__pc.10722.ST)
	.L__pc.10722.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10723
	
	.L__pc.10723: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10724
	
	.p2align 4
	.L__pc.10724: Dma_PatchDst (.L__pc.10724.ST), (.L__movme_cp.24), (.L__pc.10724.ST)
	.L__pc.10724.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10725
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10725: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10726
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10726: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10727
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10727: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10728
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10728: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10729
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.10729: Dma_PatchSrc (.L__pc.10729.LD), (.L__movme_cp.66), (.L__pc.10729.LD)
	.p2align 4
	.L__pc.10729.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10730
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10730: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10731
	.L__pc.10731: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10732
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10732: Dma_PatchSrc (.L__pc.10732.LD), (.L__movme_cp.24), (.L__pc.10732.LD)
	.p2align 4
	.L__pc.10732.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10733
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10733: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10734
	.L__pc.10734: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10735
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10735: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10736: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10737: Dma_PatchSrc (.L__pc.10737.LD), (.L__movme_tmp.1), (.L__pc.10737.LD)
	.p2align 4
	.L__pc.10737.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10738
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10738: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10739
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10739: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10740: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10741: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10742: Dma_PatchSrc (.L__pc.10742.LD), (.L__movme_tmp.1), (.L__pc.10742.LD)
	.p2align 4
	.L__pc.10742.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10743
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10743: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10744
	
	.L__pc.10744: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10745
	
	.p2align 4
	.L__pc.10745: Dma_PatchDst (.L__pc.10745.ST), (.L__movme_cp.66), (.L__pc.10745.ST)
	.L__pc.10745.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10746
	
	.L__pc.10746: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10747
	
	.p2align 4
	.L__pc.10747: Dma_PatchDst (.L__pc.10747.ST), (.L__movme_cp.24), (.L__pc.10747.ST)
	.L__pc.10747.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10748
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10748: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10749
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10749: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10750
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10750: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10751
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10751: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10752
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.10752: Dma_PatchSrc (.L__pc.10752.LD), (.L__movme_cp.67), (.L__pc.10752.LD)
	.p2align 4
	.L__pc.10752.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10753
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10753: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10754
	.L__pc.10754: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10755
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10755: Dma_PatchSrc (.L__pc.10755.LD), (.L__movme_cp.24), (.L__pc.10755.LD)
	.p2align 4
	.L__pc.10755.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10756
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10756: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10757
	.L__pc.10757: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10758
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10758: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10759: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10760: Dma_PatchSrc (.L__pc.10760.LD), (.L__movme_tmp.1), (.L__pc.10760.LD)
	.p2align 4
	.L__pc.10760.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10761
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10761: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10762
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10762: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10763: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10764: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10765: Dma_PatchSrc (.L__pc.10765.LD), (.L__movme_tmp.1), (.L__pc.10765.LD)
	.p2align 4
	.L__pc.10765.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10766
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10766: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10767
	
	.L__pc.10767: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10768
	
	.p2align 4
	.L__pc.10768: Dma_PatchDst (.L__pc.10768.ST), (.L__movme_cp.67), (.L__pc.10768.ST)
	.L__pc.10768.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10769
	
	.L__pc.10769: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10770
	
	.p2align 4
	.L__pc.10770: Dma_PatchDst (.L__pc.10770.ST), (.L__movme_cp.24), (.L__pc.10770.ST)
	.L__pc.10770.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10771
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10771: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10772
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10772: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10773
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10773: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10774
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10774: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10775
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.10775: Dma_PatchSrc (.L__pc.10775.LD), (.L__movme_cp.68), (.L__pc.10775.LD)
	.p2align 4
	.L__pc.10775.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10776
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10776: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10777
	.L__pc.10777: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10778
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10778: Dma_PatchSrc (.L__pc.10778.LD), (.L__movme_cp.24), (.L__pc.10778.LD)
	.p2align 4
	.L__pc.10778.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10779
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10779: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.10780
	.L__pc.10780: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.10781
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10781: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10782: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10783: Dma_PatchSrc (.L__pc.10783.LD), (.L__movme_tmp.1), (.L__pc.10783.LD)
	.p2align 4
	.L__pc.10783.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10784
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10784: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10785
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.10785: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.10786: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.10787: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10788: Dma_PatchSrc (.L__pc.10788.LD), (.L__movme_tmp.1), (.L__pc.10788.LD)
	.p2align 4
	.L__pc.10788.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10789
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10789: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10790
	
	.L__pc.10790: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.10791
	
	.p2align 4
	.L__pc.10791: Dma_PatchDst (.L__pc.10791.ST), (.L__movme_cp.68), (.L__pc.10791.ST)
	.L__pc.10791.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10792
	
	.L__pc.10792: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.10793
	
	.p2align 4
	.L__pc.10793: Dma_PatchDst (.L__pc.10793.ST), (.L__movme_cp.24), (.L__pc.10793.ST)
	.L__pc.10793.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10794
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10794: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10795
	
	.p2align 4
	.L__pc.10795: Dma_PatchDst (.L__pc.10795.ST), (.L__movme_cp.24), (.L__pc.10795.ST)
	.L__pc.10795.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10796
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.10796: Dma_PatchSrc (.L__pc.10796.LD), (.L__movme_cp.60), (.L__pc.10796.LD)
	.p2align 4
	.L__pc.10796.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10797
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10797: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10798
	
	.L__pc.10798: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10799
	
	.p2align 4
	.L__pc.10799: Dma_PatchDst (.L__pc.10799.ST), (.L__movme_cp.21), (.L__pc.10799.ST)
	.L__pc.10799.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10800
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.10800: Dma_PatchSrc (.L__pc.10800.LD), (.L__movme_cp.58), (.L__pc.10800.LD)
	.p2align 4
	.L__pc.10800.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10801
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10801: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10802
	
	.L__pc.10802: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10803
	
	.p2align 4
	.L__pc.10803: Dma_PatchDst (.L__pc.10803.ST), (.L__movme_cp.22), (.L__pc.10803.ST)
	.L__pc.10803.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10804
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10804: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10805
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10805: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10806
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10806: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10807
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10807: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10808
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.10808: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.10809
	
	.p2align 4
	.L__pc.10809: Dma_PatchDst (.L__pc.10809.ST), (.L__movme_cp.24), (.L__pc.10809.ST)
	.L__pc.10809.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10810
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.10810: Dma_PatchSrc (.L__pc.10810.LD), (.L__movme_cp.25), (.L__pc.10810.LD)
	.p2align 4
	.L__pc.10810.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10811
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10811: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10812
	.L__pc.10812: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10813
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.10813: Dma_PatchSrc (.L__pc.10813.LD), (.L__movme_cp.26), (.L__pc.10813.LD)
	.p2align 4
	.L__pc.10813.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10814
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10814: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10815
	.L__pc.10815: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10816
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10816: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10817: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10818: Dma_PatchSrc (.L__pc.10818.LD), (.L__movme_tmp.1), (.L__pc.10818.LD)
	.p2align 4
	.L__pc.10818.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10819
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10819: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10820
	.L__pc.10820: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10821
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10821: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10822: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10823: Dma_PatchSrc (.L__pc.10823.LD), (.L__movme_tmp.1), (.L__pc.10823.LD)
	.p2align 4
	.L__pc.10823.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10824
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10824: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10825
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10825: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10826: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10827: Dma_PatchSrc (.L__pc.10827.LD), (.L__movme_tmp.1), (.L__pc.10827.LD)
	.p2align 4
	.L__pc.10827.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10828
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10828: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10829
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10829: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10830: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10831: Dma_PatchSrc (.L__pc.10831.LD), (.L__movme_tmp.1), (.L__pc.10831.LD)
	.p2align 4
	.L__pc.10831.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10832
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10832: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10833
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10833: Dma_PatchSrc (.L__pc.10833.LD), (.L__movme_cp.24), (.L__pc.10833.LD)
	.p2align 4
	.L__pc.10833.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10834
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10834: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10835
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10835: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10836: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10837: Dma_PatchSrc (.L__pc.10837.LD), (.L__movme_tmp.1), (.L__pc.10837.LD)
	.p2align 4
	.L__pc.10837.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10838
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10838: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10839
	
	.L__pc.10839: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10840
	
	.p2align 4
	.L__pc.10840: Dma_PatchDst (.L__pc.10840.ST), (.L__movme_cp.69), (.L__pc.10840.ST)
	.L__pc.10840.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10841
	
	.L__pc.10841: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10842
	
	.p2align 4
	.L__pc.10842: Dma_PatchDst (.L__pc.10842.ST), (.L__movme_cp.54), (.L__pc.10842.ST)
	.L__pc.10842.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10843
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.10843: Dma_PatchSrc (.L__pc.10843.LD), (.L__movme_cp.30), (.L__pc.10843.LD)
	.p2align 4
	.L__pc.10843.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10844
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10844: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10845
	.L__pc.10845: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10846
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.10846: Dma_PatchSrc (.L__pc.10846.LD), (.L__movme_cp.31), (.L__pc.10846.LD)
	.p2align 4
	.L__pc.10846.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10847
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10847: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10848
	.L__pc.10848: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10849
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10849: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10850: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10851: Dma_PatchSrc (.L__pc.10851.LD), (.L__movme_tmp.1), (.L__pc.10851.LD)
	.p2align 4
	.L__pc.10851.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10852
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10852: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10853
	.L__pc.10853: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10854
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10854: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10855: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10856: Dma_PatchSrc (.L__pc.10856.LD), (.L__movme_tmp.1), (.L__pc.10856.LD)
	.p2align 4
	.L__pc.10856.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10857
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10857: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10858
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10858: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10859: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10860: Dma_PatchSrc (.L__pc.10860.LD), (.L__movme_tmp.1), (.L__pc.10860.LD)
	.p2align 4
	.L__pc.10860.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10861
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10861: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10862
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10862: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10863: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10864: Dma_PatchSrc (.L__pc.10864.LD), (.L__movme_tmp.1), (.L__pc.10864.LD)
	.p2align 4
	.L__pc.10864.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10865
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10865: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10866
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10866: Dma_PatchSrc (.L__pc.10866.LD), (.L__movme_cp.24), (.L__pc.10866.LD)
	.p2align 4
	.L__pc.10866.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10867
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10867: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10868
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10868: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10869: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10870: Dma_PatchSrc (.L__pc.10870.LD), (.L__movme_tmp.1), (.L__pc.10870.LD)
	.p2align 4
	.L__pc.10870.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10871
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10871: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10872
	
	.L__pc.10872: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10873
	
	.p2align 4
	.L__pc.10873: Dma_PatchDst (.L__pc.10873.ST), (.L__movme_cp.70), (.L__pc.10873.ST)
	.L__pc.10873.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10874
	
	.L__pc.10874: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10875
	
	.p2align 4
	.L__pc.10875: Dma_PatchDst (.L__pc.10875.ST), (.L__movme_cp.54), (.L__pc.10875.ST)
	.L__pc.10875.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10876
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10876: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10877
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10877: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10878
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10878: Dma_PatchSrc (.L__pc.10878.LD), (.L__movme_cp.24), (.L__pc.10878.LD)
	.p2align 4
	.L__pc.10878.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10879
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10879: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10880
	.L__pc.10880: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10881
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.10881: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10882: Dma_PatchSrc (.L__pc.10882.LD), (.L__movme_tmp.1), (.L__pc.10882.LD)
	.p2align 4
	.L__pc.10882.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10883
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10883: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.10884
	.L__pc.10884: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.10885
	
	.L__pc.10885: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10886
	
	.p2align 4
	.L__pc.10886: Dma_PatchDst (.L__pc.10886.ST), (.L__movme_cp.72), (.L__pc.10886.ST)
	.L__pc.10886.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10887
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.10887: Dma_PatchSrc (.L__pc.10887.LD), (.L__movme_cp.72), (.L__pc.10887.LD)
	.p2align 4
	.L__pc.10887.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10888
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10888: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10889
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10889: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10890: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10891: Dma_PatchSrc (.L__pc.10891.LD), (.L__movme_tmp.1), (.L__pc.10891.LD)
	.p2align 4
	.L__pc.10891.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10892
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10892: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10893
	
	.L__pc.10893: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10894
	
	.p2align 4
	.L__pc.10894: Dma_PatchDst (.L__pc.10894.ST), (.L__movme_cp.74), (.L__pc.10894.ST)
	.L__pc.10894.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10895
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10895: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10896: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10897: Dma_PatchSrc (.L__pc.10897.LD), (.L__movme_tmp.1), (.L__pc.10897.LD)
	.p2align 4
	.L__pc.10897.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10898
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10898: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10899
	
	.L__pc.10899: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10900
	
	.p2align 4
	.L__pc.10900: Dma_PatchDst (.L__pc.10900.ST), (.L__movme_cp.76), (.L__pc.10900.ST)
	.L__pc.10900.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10901
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.10901: Dma_PatchSrc (.L__pc.10901.LD), (.L__movme_cp.74), (.L__pc.10901.LD)
	.p2align 4
	.L__pc.10901.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10902
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10902: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10903
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.10903: Dma_PatchSrc (.L__pc.10903.LD), ((.L__movme.reg.eax+0)), (.L__pc.10903.LD)
	.p2align 4
	.L__pc.10903.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10904
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10904: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10905
	
	.L__pc.10905: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10906
	
	.p2align 4
	.L__pc.10906: Dma_PatchDst (.L__pc.10906.ST), (.L__movme_cp.77), (.L__pc.10906.ST)
	.L__pc.10906.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10907
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.10907: Dma_PatchSrc (.L__pc.10907.LD), (.L__movme_cp.77), (.L__pc.10907.LD)
	.p2align 4
	.L__pc.10907.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10908
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10908: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10909
	
	.L__pc.10909: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10910
	
	.p2align 4
	.L__pc.10910: Dma_PatchDst (.L__pc.10910.ST), (.L__movme_cp.21), (.L__pc.10910.ST)
	.L__pc.10910.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10911
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.10911: Dma_PatchSrc (.L__pc.10911.LD), (.L__movme_cp.58), (.L__pc.10911.LD)
	.p2align 4
	.L__pc.10911.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10912
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10912: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10913
	
	.L__pc.10913: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10914
	
	.p2align 4
	.L__pc.10914: Dma_PatchDst (.L__pc.10914.ST), (.L__movme_cp.22), (.L__pc.10914.ST)
	.L__pc.10914.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10915
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10915: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10916
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10916: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10917
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10917: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.10918
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10918: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10919
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.10919: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.10920
	
	.p2align 4
	.L__pc.10920: Dma_PatchDst (.L__pc.10920.ST), (.L__movme_cp.24), (.L__pc.10920.ST)
	.L__pc.10920.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10921
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.10921: Dma_PatchSrc (.L__pc.10921.LD), (.L__movme_cp.25), (.L__pc.10921.LD)
	.p2align 4
	.L__pc.10921.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10922
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10922: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10923
	.L__pc.10923: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10924
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.10924: Dma_PatchSrc (.L__pc.10924.LD), (.L__movme_cp.26), (.L__pc.10924.LD)
	.p2align 4
	.L__pc.10924.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10925
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10925: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10926
	.L__pc.10926: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10927
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10927: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10928: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10929: Dma_PatchSrc (.L__pc.10929.LD), (.L__movme_tmp.1), (.L__pc.10929.LD)
	.p2align 4
	.L__pc.10929.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10930
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10930: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10931
	.L__pc.10931: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10932
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10932: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10933: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10934: Dma_PatchSrc (.L__pc.10934.LD), (.L__movme_tmp.1), (.L__pc.10934.LD)
	.p2align 4
	.L__pc.10934.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10935
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10935: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10936
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10936: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10937: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10938: Dma_PatchSrc (.L__pc.10938.LD), (.L__movme_tmp.1), (.L__pc.10938.LD)
	.p2align 4
	.L__pc.10938.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10939
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10939: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10940
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10940: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10941: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10942: Dma_PatchSrc (.L__pc.10942.LD), (.L__movme_tmp.1), (.L__pc.10942.LD)
	.p2align 4
	.L__pc.10942.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10943
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10943: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10944
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10944: Dma_PatchSrc (.L__pc.10944.LD), (.L__movme_cp.24), (.L__pc.10944.LD)
	.p2align 4
	.L__pc.10944.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10945
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10945: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10946
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10946: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10947: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10948: Dma_PatchSrc (.L__pc.10948.LD), (.L__movme_tmp.1), (.L__pc.10948.LD)
	.p2align 4
	.L__pc.10948.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10949
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10949: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10950
	
	.L__pc.10950: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10951
	
	.p2align 4
	.L__pc.10951: Dma_PatchDst (.L__pc.10951.ST), (.L__movme_cp.78), (.L__pc.10951.ST)
	.L__pc.10951.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10952
	
	.L__pc.10952: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10953
	
	.p2align 4
	.L__pc.10953: Dma_PatchDst (.L__pc.10953.ST), (.L__movme_cp.54), (.L__pc.10953.ST)
	.L__pc.10953.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10954
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.10954: Dma_PatchSrc (.L__pc.10954.LD), (.L__movme_cp.30), (.L__pc.10954.LD)
	.p2align 4
	.L__pc.10954.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10955
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10955: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.10956
	.L__pc.10956: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.10957
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.10957: Dma_PatchSrc (.L__pc.10957.LD), (.L__movme_cp.31), (.L__pc.10957.LD)
	.p2align 4
	.L__pc.10957.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10958
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10958: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10959
	.L__pc.10959: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10960
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.10960: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10961: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10962: Dma_PatchSrc (.L__pc.10962.LD), (.L__movme_tmp.1), (.L__pc.10962.LD)
	.p2align 4
	.L__pc.10962.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10963
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10963: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.10964
	.L__pc.10964: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.10965
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.10965: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10966: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10967: Dma_PatchSrc (.L__pc.10967.LD), (.L__movme_tmp.1), (.L__pc.10967.LD)
	.p2align 4
	.L__pc.10967.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10968
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10968: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10969
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10969: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10970: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10971: Dma_PatchSrc (.L__pc.10971.LD), (.L__movme_tmp.1), (.L__pc.10971.LD)
	.p2align 4
	.L__pc.10971.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10972
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10972: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10973
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.10973: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10974: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10975: Dma_PatchSrc (.L__pc.10975.LD), (.L__movme_tmp.1), (.L__pc.10975.LD)
	.p2align 4
	.L__pc.10975.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10976
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10976: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10977
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.10977: Dma_PatchSrc (.L__pc.10977.LD), (.L__movme_cp.24), (.L__pc.10977.LD)
	.p2align 4
	.L__pc.10977.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10978
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.10978: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.10979
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.10979: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.10980: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.10981: Dma_PatchSrc (.L__pc.10981.LD), (.L__movme_tmp.1), (.L__pc.10981.LD)
	.p2align 4
	.L__pc.10981.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10982
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10982: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10983
	
	.L__pc.10983: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.10984
	
	.p2align 4
	.L__pc.10984: Dma_PatchDst (.L__pc.10984.ST), (.L__movme_cp.79), (.L__pc.10984.ST)
	.L__pc.10984.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10985
	
	.L__pc.10985: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10986
	
	.p2align 4
	.L__pc.10986: Dma_PatchDst (.L__pc.10986.ST), (.L__movme_cp.54), (.L__pc.10986.ST)
	.L__pc.10986.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10987
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.10987: Dma_PatchSrc (.L__pc.10987.LD), (.L__movme_cp.74), (.L__pc.10987.LD)
	.p2align 4
	.L__pc.10987.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10988
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10988: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10989
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.10989: Dma_PatchSrc (.L__pc.10989.LD), (.L__movme_cp.77), (.L__pc.10989.LD)
	.p2align 4
	.L__pc.10989.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10990
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.10990: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.10991
	
	.L__pc.10991: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.10992
	
	.p2align 4
	.L__pc.10992: Dma_PatchDst (.L__pc.10992.ST), ((.L__movme.reg.eax+0)), (.L__pc.10992.ST)
	.L__pc.10992.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10993
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.10993: Dma_PatchSrc (.L__pc.10993.LD), (.L__movme_cp.76), (.L__pc.10993.LD)
	.p2align 4
	.L__pc.10993.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10994
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10994: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10995
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.10995: Dma_PatchSrc (.L__pc.10995.LD), ((.L__movme.reg.eax+0)), (.L__pc.10995.LD)
	.p2align 4
	.L__pc.10995.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.10996
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.10996: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.10997
	
	.L__pc.10997: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.10998
	
	.p2align 4
	.L__pc.10998: Dma_PatchDst (.L__pc.10998.ST), (.L__movme_cp.80), (.L__pc.10998.ST)
	.L__pc.10998.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.10999
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.10999: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11000
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11000: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11001
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.11001: Dma_PatchSrc (.L__pc.11001.LD), (.L__movme_cp.102), (.L__pc.11001.LD)
	.p2align 4
	.L__pc.11001.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11002
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11002: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11003
	.L__pc.11003: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11004
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.88 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.11004: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11005: Dma_PatchSrc (.L__pc.11005.LD), (.L__movme_tmp.1), (.L__pc.11005.LD)
	.p2align 4
	.L__pc.11005.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11006
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11006: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11007
	.L__pc.11007: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11008
	
	.L__pc.11008: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11009
	
	.p2align 4
	.L__pc.11009: Dma_PatchDst (.L__pc.11009.ST), (.L__movme_cp.102), (.L__pc.11009.ST)
	.L__pc.11009.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11010
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.11010: Dma_PatchSrc (.L__pc.11010.LD), (.L__movme_cp.76), (.L__pc.11010.LD)
	.p2align 4
	.L__pc.11010.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11011
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11011: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11012
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.11012: Dma_PatchSrc (.L__pc.11012.LD), (.L__movme_cp.80), (.L__pc.11012.LD)
	.p2align 4
	.L__pc.11012.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11013
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11013: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11014
	
	.L__pc.11014: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11015
	
	.p2align 4
	.L__pc.11015: Dma_PatchDst (.L__pc.11015.ST), ((.L__movme.reg.eax+0)), (.L__pc.11015.ST)
	.L__pc.11015.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11016
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11016: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11017
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11017: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11018
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.11018: Dma_PatchSrc (.L__pc.11018.LD), (.L__movme_cp.101), (.L__pc.11018.LD)
	.p2align 4
	.L__pc.11018.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11019
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11019: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11020
	.L__pc.11020: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11021
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11021: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.89 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11022: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11023: Dma_PatchSrc (.L__pc.11023.LD), (.L__movme_tmp.1), (.L__pc.11023.LD)
	.p2align 4
	.L__pc.11023.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11024
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11024: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11025
	
	.L__pc.11025: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11026
	
	.p2align 4
	.L__pc.11026: Dma_PatchDst (.L__pc.11026.ST), (.L__movme_cp.24), (.L__pc.11026.ST)
	.L__pc.11026.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11027
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11027: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11028
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11028: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11029
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11029: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11030
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11030: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11031
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.11031: Dma_PatchSrc (.L__pc.11031.LD), (.L__movme_cp.63), (.L__pc.11031.LD)
	.p2align 4
	.L__pc.11031.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11032
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11032: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11033
	.L__pc.11033: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11034
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11034: Dma_PatchSrc (.L__pc.11034.LD), (.L__movme_cp.24), (.L__pc.11034.LD)
	.p2align 4
	.L__pc.11034.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11035
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11035: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11036
	.L__pc.11036: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11037
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11037: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11038: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11039: Dma_PatchSrc (.L__pc.11039.LD), (.L__movme_tmp.1), (.L__pc.11039.LD)
	.p2align 4
	.L__pc.11039.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11040
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11040: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11041
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11041: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11042: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11043: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11044: Dma_PatchSrc (.L__pc.11044.LD), (.L__movme_tmp.1), (.L__pc.11044.LD)
	.p2align 4
	.L__pc.11044.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11045
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11045: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11046
	
	.L__pc.11046: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11047
	
	.p2align 4
	.L__pc.11047: Dma_PatchDst (.L__pc.11047.ST), (.L__movme_cp.63), (.L__pc.11047.ST)
	.L__pc.11047.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11048
	
	.L__pc.11048: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11049
	
	.p2align 4
	.L__pc.11049: Dma_PatchDst (.L__pc.11049.ST), (.L__movme_cp.24), (.L__pc.11049.ST)
	.L__pc.11049.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11050
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11050: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11051
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11051: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11052
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11052: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11053
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11053: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11054
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.11054: Dma_PatchSrc (.L__pc.11054.LD), (.L__movme_cp.66), (.L__pc.11054.LD)
	.p2align 4
	.L__pc.11054.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11055
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11055: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11056
	.L__pc.11056: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11057
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11057: Dma_PatchSrc (.L__pc.11057.LD), (.L__movme_cp.24), (.L__pc.11057.LD)
	.p2align 4
	.L__pc.11057.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11058
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11058: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11059
	.L__pc.11059: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11060
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11060: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11061: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11062: Dma_PatchSrc (.L__pc.11062.LD), (.L__movme_tmp.1), (.L__pc.11062.LD)
	.p2align 4
	.L__pc.11062.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11063
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11063: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11064
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11064: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11065: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11066: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11067: Dma_PatchSrc (.L__pc.11067.LD), (.L__movme_tmp.1), (.L__pc.11067.LD)
	.p2align 4
	.L__pc.11067.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11068
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11068: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11069
	
	.L__pc.11069: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11070
	
	.p2align 4
	.L__pc.11070: Dma_PatchDst (.L__pc.11070.ST), (.L__movme_cp.66), (.L__pc.11070.ST)
	.L__pc.11070.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11071
	
	.L__pc.11071: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11072
	
	.p2align 4
	.L__pc.11072: Dma_PatchDst (.L__pc.11072.ST), (.L__movme_cp.24), (.L__pc.11072.ST)
	.L__pc.11072.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11073
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11073: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11074
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11074: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11075
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11075: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11076
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11076: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11077
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.11077: Dma_PatchSrc (.L__pc.11077.LD), (.L__movme_cp.67), (.L__pc.11077.LD)
	.p2align 4
	.L__pc.11077.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11078
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11078: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11079
	.L__pc.11079: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11080
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11080: Dma_PatchSrc (.L__pc.11080.LD), (.L__movme_cp.24), (.L__pc.11080.LD)
	.p2align 4
	.L__pc.11080.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11081
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11081: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11082
	.L__pc.11082: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11083
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11083: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11084: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11085: Dma_PatchSrc (.L__pc.11085.LD), (.L__movme_tmp.1), (.L__pc.11085.LD)
	.p2align 4
	.L__pc.11085.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11086
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11086: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11087
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11087: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11088: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11089: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11090: Dma_PatchSrc (.L__pc.11090.LD), (.L__movme_tmp.1), (.L__pc.11090.LD)
	.p2align 4
	.L__pc.11090.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11091
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11091: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11092
	
	.L__pc.11092: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11093
	
	.p2align 4
	.L__pc.11093: Dma_PatchDst (.L__pc.11093.ST), (.L__movme_cp.67), (.L__pc.11093.ST)
	.L__pc.11093.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11094
	
	.L__pc.11094: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11095
	
	.p2align 4
	.L__pc.11095: Dma_PatchDst (.L__pc.11095.ST), (.L__movme_cp.24), (.L__pc.11095.ST)
	.L__pc.11095.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11096
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11096: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11097
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11097: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11098
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11098: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11099
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11099: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11100
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.11100: Dma_PatchSrc (.L__pc.11100.LD), (.L__movme_cp.68), (.L__pc.11100.LD)
	.p2align 4
	.L__pc.11100.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11101
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11101: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11102
	.L__pc.11102: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11103
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11103: Dma_PatchSrc (.L__pc.11103.LD), (.L__movme_cp.24), (.L__pc.11103.LD)
	.p2align 4
	.L__pc.11103.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11104
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11104: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11105
	.L__pc.11105: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11106
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11106: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11107: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11108: Dma_PatchSrc (.L__pc.11108.LD), (.L__movme_tmp.1), (.L__pc.11108.LD)
	.p2align 4
	.L__pc.11108.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11109
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11109: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11110
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11110: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11111: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11112: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11113: Dma_PatchSrc (.L__pc.11113.LD), (.L__movme_tmp.1), (.L__pc.11113.LD)
	.p2align 4
	.L__pc.11113.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11114
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11114: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11115
	
	.L__pc.11115: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11116
	
	.p2align 4
	.L__pc.11116: Dma_PatchDst (.L__pc.11116.ST), (.L__movme_cp.68), (.L__pc.11116.ST)
	.L__pc.11116.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11117
	
	.L__pc.11117: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11118
	
	.p2align 4
	.L__pc.11118: Dma_PatchDst (.L__pc.11118.ST), (.L__movme_cp.24), (.L__pc.11118.ST)
	.L__pc.11118.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11119
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11119: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11120
	
	.p2align 4
	.L__pc.11120: Dma_PatchDst (.L__pc.11120.ST), (.L__movme_cp.24), (.L__pc.11120.ST)
	.L__pc.11120.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11121
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.11121: Dma_PatchSrc (.L__pc.11121.LD), (.L__movme_cp.60), (.L__pc.11121.LD)
	.p2align 4
	.L__pc.11121.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11122
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11122: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11123
	
	.L__pc.11123: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11124
	
	.p2align 4
	.L__pc.11124: Dma_PatchDst (.L__pc.11124.ST), (.L__movme_cp.21), (.L__pc.11124.ST)
	.L__pc.11124.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11125
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.11125: Dma_PatchSrc (.L__pc.11125.LD), (.L__movme_cp.58), (.L__pc.11125.LD)
	.p2align 4
	.L__pc.11125.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11126
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11126: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11127
	
	.L__pc.11127: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11128
	
	.p2align 4
	.L__pc.11128: Dma_PatchDst (.L__pc.11128.ST), (.L__movme_cp.22), (.L__pc.11128.ST)
	.L__pc.11128.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11129
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11129: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11130
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11130: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11131
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11131: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11132
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11132: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11133
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.11133: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.11134
	
	.p2align 4
	.L__pc.11134: Dma_PatchDst (.L__pc.11134.ST), (.L__movme_cp.24), (.L__pc.11134.ST)
	.L__pc.11134.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11135
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.11135: Dma_PatchSrc (.L__pc.11135.LD), (.L__movme_cp.25), (.L__pc.11135.LD)
	.p2align 4
	.L__pc.11135.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11136
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11136: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11137
	.L__pc.11137: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11138
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.11138: Dma_PatchSrc (.L__pc.11138.LD), (.L__movme_cp.26), (.L__pc.11138.LD)
	.p2align 4
	.L__pc.11138.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11139
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11139: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11140
	.L__pc.11140: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11141
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11141: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11142: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11143: Dma_PatchSrc (.L__pc.11143.LD), (.L__movme_tmp.1), (.L__pc.11143.LD)
	.p2align 4
	.L__pc.11143.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11144
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11144: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11145
	.L__pc.11145: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11146
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11146: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11147: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11148: Dma_PatchSrc (.L__pc.11148.LD), (.L__movme_tmp.1), (.L__pc.11148.LD)
	.p2align 4
	.L__pc.11148.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11149
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11149: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11150
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11150: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11151: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11152: Dma_PatchSrc (.L__pc.11152.LD), (.L__movme_tmp.1), (.L__pc.11152.LD)
	.p2align 4
	.L__pc.11152.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11153
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11153: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11154
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11154: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11155: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11156: Dma_PatchSrc (.L__pc.11156.LD), (.L__movme_tmp.1), (.L__pc.11156.LD)
	.p2align 4
	.L__pc.11156.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11157
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11157: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11158
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11158: Dma_PatchSrc (.L__pc.11158.LD), (.L__movme_cp.24), (.L__pc.11158.LD)
	.p2align 4
	.L__pc.11158.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11159
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11159: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11160
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11160: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11161: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11162: Dma_PatchSrc (.L__pc.11162.LD), (.L__movme_tmp.1), (.L__pc.11162.LD)
	.p2align 4
	.L__pc.11162.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11163
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11163: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11164
	
	.L__pc.11164: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11165
	
	.p2align 4
	.L__pc.11165: Dma_PatchDst (.L__pc.11165.ST), (.L__movme_cp.69), (.L__pc.11165.ST)
	.L__pc.11165.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11166
	
	.L__pc.11166: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11167
	
	.p2align 4
	.L__pc.11167: Dma_PatchDst (.L__pc.11167.ST), (.L__movme_cp.54), (.L__pc.11167.ST)
	.L__pc.11167.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11168
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.11168: Dma_PatchSrc (.L__pc.11168.LD), (.L__movme_cp.30), (.L__pc.11168.LD)
	.p2align 4
	.L__pc.11168.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11169
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11169: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11170
	.L__pc.11170: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11171
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.11171: Dma_PatchSrc (.L__pc.11171.LD), (.L__movme_cp.31), (.L__pc.11171.LD)
	.p2align 4
	.L__pc.11171.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11172
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11172: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11173
	.L__pc.11173: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11174
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11174: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11175: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11176: Dma_PatchSrc (.L__pc.11176.LD), (.L__movme_tmp.1), (.L__pc.11176.LD)
	.p2align 4
	.L__pc.11176.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11177
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11177: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11178
	.L__pc.11178: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11179
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11179: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11180: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11181: Dma_PatchSrc (.L__pc.11181.LD), (.L__movme_tmp.1), (.L__pc.11181.LD)
	.p2align 4
	.L__pc.11181.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11182
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11182: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11183
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11183: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11184: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11185: Dma_PatchSrc (.L__pc.11185.LD), (.L__movme_tmp.1), (.L__pc.11185.LD)
	.p2align 4
	.L__pc.11185.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11186
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11186: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11187
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11187: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11188: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11189: Dma_PatchSrc (.L__pc.11189.LD), (.L__movme_tmp.1), (.L__pc.11189.LD)
	.p2align 4
	.L__pc.11189.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11190
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11190: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11191
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11191: Dma_PatchSrc (.L__pc.11191.LD), (.L__movme_cp.24), (.L__pc.11191.LD)
	.p2align 4
	.L__pc.11191.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11192
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11192: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11193
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11193: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11194: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11195: Dma_PatchSrc (.L__pc.11195.LD), (.L__movme_tmp.1), (.L__pc.11195.LD)
	.p2align 4
	.L__pc.11195.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11196
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11196: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11197
	
	.L__pc.11197: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11198
	
	.p2align 4
	.L__pc.11198: Dma_PatchDst (.L__pc.11198.ST), (.L__movme_cp.70), (.L__pc.11198.ST)
	.L__pc.11198.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11199
	
	.L__pc.11199: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11200
	
	.p2align 4
	.L__pc.11200: Dma_PatchDst (.L__pc.11200.ST), (.L__movme_cp.54), (.L__pc.11200.ST)
	.L__pc.11200.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11201
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11201: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11202
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11202: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11203
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11203: Dma_PatchSrc (.L__pc.11203.LD), (.L__movme_cp.24), (.L__pc.11203.LD)
	.p2align 4
	.L__pc.11203.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11204
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11204: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11205
	.L__pc.11205: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11206
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.11206: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11207: Dma_PatchSrc (.L__pc.11207.LD), (.L__movme_tmp.1), (.L__pc.11207.LD)
	.p2align 4
	.L__pc.11207.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11208
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11208: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11209
	.L__pc.11209: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11210
	
	.L__pc.11210: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11211
	
	.p2align 4
	.L__pc.11211: Dma_PatchDst (.L__pc.11211.ST), (.L__movme_cp.72), (.L__pc.11211.ST)
	.L__pc.11211.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11212
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.11212: Dma_PatchSrc (.L__pc.11212.LD), (.L__movme_cp.72), (.L__pc.11212.LD)
	.p2align 4
	.L__pc.11212.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11213
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11213: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11214
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11214: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11215: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11216: Dma_PatchSrc (.L__pc.11216.LD), (.L__movme_tmp.1), (.L__pc.11216.LD)
	.p2align 4
	.L__pc.11216.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11217
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11217: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11218
	
	.L__pc.11218: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11219
	
	.p2align 4
	.L__pc.11219: Dma_PatchDst (.L__pc.11219.ST), (.L__movme_cp.74), (.L__pc.11219.ST)
	.L__pc.11219.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11220
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11220: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11221: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11222: Dma_PatchSrc (.L__pc.11222.LD), (.L__movme_tmp.1), (.L__pc.11222.LD)
	.p2align 4
	.L__pc.11222.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11223
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11223: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11224
	
	.L__pc.11224: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11225
	
	.p2align 4
	.L__pc.11225: Dma_PatchDst (.L__pc.11225.ST), (.L__movme_cp.76), (.L__pc.11225.ST)
	.L__pc.11225.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11226
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.11226: Dma_PatchSrc (.L__pc.11226.LD), (.L__movme_cp.74), (.L__pc.11226.LD)
	.p2align 4
	.L__pc.11226.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11227
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11227: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11228
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.11228: Dma_PatchSrc (.L__pc.11228.LD), ((.L__movme.reg.eax+0)), (.L__pc.11228.LD)
	.p2align 4
	.L__pc.11228.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11229
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11229: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11230
	
	.L__pc.11230: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11231
	
	.p2align 4
	.L__pc.11231: Dma_PatchDst (.L__pc.11231.ST), (.L__movme_cp.77), (.L__pc.11231.ST)
	.L__pc.11231.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11232
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.11232: Dma_PatchSrc (.L__pc.11232.LD), (.L__movme_cp.77), (.L__pc.11232.LD)
	.p2align 4
	.L__pc.11232.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11233
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11233: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11234
	
	.L__pc.11234: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11235
	
	.p2align 4
	.L__pc.11235: Dma_PatchDst (.L__pc.11235.ST), (.L__movme_cp.21), (.L__pc.11235.ST)
	.L__pc.11235.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11236
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.11236: Dma_PatchSrc (.L__pc.11236.LD), (.L__movme_cp.58), (.L__pc.11236.LD)
	.p2align 4
	.L__pc.11236.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11237
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11237: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11238
	
	.L__pc.11238: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11239
	
	.p2align 4
	.L__pc.11239: Dma_PatchDst (.L__pc.11239.ST), (.L__movme_cp.22), (.L__pc.11239.ST)
	.L__pc.11239.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11240
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11240: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11241
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11241: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11242
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11242: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11243
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11243: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11244
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.11244: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.11245
	
	.p2align 4
	.L__pc.11245: Dma_PatchDst (.L__pc.11245.ST), (.L__movme_cp.24), (.L__pc.11245.ST)
	.L__pc.11245.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11246
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.11246: Dma_PatchSrc (.L__pc.11246.LD), (.L__movme_cp.25), (.L__pc.11246.LD)
	.p2align 4
	.L__pc.11246.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11247
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11247: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11248
	.L__pc.11248: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11249
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.11249: Dma_PatchSrc (.L__pc.11249.LD), (.L__movme_cp.26), (.L__pc.11249.LD)
	.p2align 4
	.L__pc.11249.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11250
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11250: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11251
	.L__pc.11251: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11252
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11252: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11253: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11254: Dma_PatchSrc (.L__pc.11254.LD), (.L__movme_tmp.1), (.L__pc.11254.LD)
	.p2align 4
	.L__pc.11254.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11255
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11255: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11256
	.L__pc.11256: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11257
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11257: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11258: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11259: Dma_PatchSrc (.L__pc.11259.LD), (.L__movme_tmp.1), (.L__pc.11259.LD)
	.p2align 4
	.L__pc.11259.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11260
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11260: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11261
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11261: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11262: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11263: Dma_PatchSrc (.L__pc.11263.LD), (.L__movme_tmp.1), (.L__pc.11263.LD)
	.p2align 4
	.L__pc.11263.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11264
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11264: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11265
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11265: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11266: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11267: Dma_PatchSrc (.L__pc.11267.LD), (.L__movme_tmp.1), (.L__pc.11267.LD)
	.p2align 4
	.L__pc.11267.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11268
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11268: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11269
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11269: Dma_PatchSrc (.L__pc.11269.LD), (.L__movme_cp.24), (.L__pc.11269.LD)
	.p2align 4
	.L__pc.11269.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11270
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11270: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11271
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11271: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11272: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11273: Dma_PatchSrc (.L__pc.11273.LD), (.L__movme_tmp.1), (.L__pc.11273.LD)
	.p2align 4
	.L__pc.11273.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11274
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11274: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11275
	
	.L__pc.11275: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11276
	
	.p2align 4
	.L__pc.11276: Dma_PatchDst (.L__pc.11276.ST), (.L__movme_cp.78), (.L__pc.11276.ST)
	.L__pc.11276.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11277
	
	.L__pc.11277: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11278
	
	.p2align 4
	.L__pc.11278: Dma_PatchDst (.L__pc.11278.ST), (.L__movme_cp.54), (.L__pc.11278.ST)
	.L__pc.11278.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11279
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.11279: Dma_PatchSrc (.L__pc.11279.LD), (.L__movme_cp.30), (.L__pc.11279.LD)
	.p2align 4
	.L__pc.11279.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11280
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11280: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11281
	.L__pc.11281: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11282
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.11282: Dma_PatchSrc (.L__pc.11282.LD), (.L__movme_cp.31), (.L__pc.11282.LD)
	.p2align 4
	.L__pc.11282.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11283
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11283: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11284
	.L__pc.11284: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11285
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11285: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11286: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11287: Dma_PatchSrc (.L__pc.11287.LD), (.L__movme_tmp.1), (.L__pc.11287.LD)
	.p2align 4
	.L__pc.11287.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11288
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11288: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11289
	.L__pc.11289: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11290
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11290: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11291: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11292: Dma_PatchSrc (.L__pc.11292.LD), (.L__movme_tmp.1), (.L__pc.11292.LD)
	.p2align 4
	.L__pc.11292.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11293
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11293: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11294
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11294: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11295: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11296: Dma_PatchSrc (.L__pc.11296.LD), (.L__movme_tmp.1), (.L__pc.11296.LD)
	.p2align 4
	.L__pc.11296.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11297
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11297: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11298
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11298: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11299: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11300: Dma_PatchSrc (.L__pc.11300.LD), (.L__movme_tmp.1), (.L__pc.11300.LD)
	.p2align 4
	.L__pc.11300.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11301
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11301: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11302
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11302: Dma_PatchSrc (.L__pc.11302.LD), (.L__movme_cp.24), (.L__pc.11302.LD)
	.p2align 4
	.L__pc.11302.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11303
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11303: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11304
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11304: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11305: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11306: Dma_PatchSrc (.L__pc.11306.LD), (.L__movme_tmp.1), (.L__pc.11306.LD)
	.p2align 4
	.L__pc.11306.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11307
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11307: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11308
	
	.L__pc.11308: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11309
	
	.p2align 4
	.L__pc.11309: Dma_PatchDst (.L__pc.11309.ST), (.L__movme_cp.79), (.L__pc.11309.ST)
	.L__pc.11309.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11310
	
	.L__pc.11310: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11311
	
	.p2align 4
	.L__pc.11311: Dma_PatchDst (.L__pc.11311.ST), (.L__movme_cp.54), (.L__pc.11311.ST)
	.L__pc.11311.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11312
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.11312: Dma_PatchSrc (.L__pc.11312.LD), (.L__movme_cp.74), (.L__pc.11312.LD)
	.p2align 4
	.L__pc.11312.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11313
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11313: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11314
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.11314: Dma_PatchSrc (.L__pc.11314.LD), (.L__movme_cp.77), (.L__pc.11314.LD)
	.p2align 4
	.L__pc.11314.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11315
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11315: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11316
	
	.L__pc.11316: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11317
	
	.p2align 4
	.L__pc.11317: Dma_PatchDst (.L__pc.11317.ST), ((.L__movme.reg.eax+0)), (.L__pc.11317.ST)
	.L__pc.11317.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11318
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.11318: Dma_PatchSrc (.L__pc.11318.LD), (.L__movme_cp.76), (.L__pc.11318.LD)
	.p2align 4
	.L__pc.11318.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11319
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11319: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11320
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.11320: Dma_PatchSrc (.L__pc.11320.LD), ((.L__movme.reg.eax+0)), (.L__pc.11320.LD)
	.p2align 4
	.L__pc.11320.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11321
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11321: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11322
	
	.L__pc.11322: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11323
	
	.p2align 4
	.L__pc.11323: Dma_PatchDst (.L__pc.11323.ST), (.L__movme_cp.80), (.L__pc.11323.ST)
	.L__pc.11323.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11324
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11324: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11325
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11325: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11326
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.11326: Dma_PatchSrc (.L__pc.11326.LD), (.L__movme_cp.102), (.L__pc.11326.LD)
	.p2align 4
	.L__pc.11326.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11327
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11327: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11328
	.L__pc.11328: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11329
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.90 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.11329: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11330: Dma_PatchSrc (.L__pc.11330.LD), (.L__movme_tmp.1), (.L__pc.11330.LD)
	.p2align 4
	.L__pc.11330.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11331
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11331: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11332
	.L__pc.11332: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11333
	
	.L__pc.11333: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11334
	
	.p2align 4
	.L__pc.11334: Dma_PatchDst (.L__pc.11334.ST), (.L__movme_cp.102), (.L__pc.11334.ST)
	.L__pc.11334.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11335
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.11335: Dma_PatchSrc (.L__pc.11335.LD), (.L__movme_cp.76), (.L__pc.11335.LD)
	.p2align 4
	.L__pc.11335.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11336
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11336: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11337
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.11337: Dma_PatchSrc (.L__pc.11337.LD), (.L__movme_cp.80), (.L__pc.11337.LD)
	.p2align 4
	.L__pc.11337.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11338
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11338: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11339
	
	.L__pc.11339: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11340
	
	.p2align 4
	.L__pc.11340: Dma_PatchDst (.L__pc.11340.ST), ((.L__movme.reg.eax+0)), (.L__pc.11340.ST)
	.L__pc.11340.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11341
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11341: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11342
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11342: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11343
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.11343: Dma_PatchSrc (.L__pc.11343.LD), (.L__movme_cp.101), (.L__pc.11343.LD)
	.p2align 4
	.L__pc.11343.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11344
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11344: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11345
	.L__pc.11345: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11346
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11346: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.91 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11347: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11348: Dma_PatchSrc (.L__pc.11348.LD), (.L__movme_tmp.1), (.L__pc.11348.LD)
	.p2align 4
	.L__pc.11348.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11349
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11349: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11350
	
	.L__pc.11350: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11351
	
	.p2align 4
	.L__pc.11351: Dma_PatchDst (.L__pc.11351.ST), (.L__movme_cp.24), (.L__pc.11351.ST)
	.L__pc.11351.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11352
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11352: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11353
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11353: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11354
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11354: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11355
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11355: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11356
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.11356: Dma_PatchSrc (.L__pc.11356.LD), (.L__movme_cp.63), (.L__pc.11356.LD)
	.p2align 4
	.L__pc.11356.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11357
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11357: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11358
	.L__pc.11358: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11359
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11359: Dma_PatchSrc (.L__pc.11359.LD), (.L__movme_cp.24), (.L__pc.11359.LD)
	.p2align 4
	.L__pc.11359.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11360
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11360: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11361
	.L__pc.11361: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11362
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11362: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11363: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11364: Dma_PatchSrc (.L__pc.11364.LD), (.L__movme_tmp.1), (.L__pc.11364.LD)
	.p2align 4
	.L__pc.11364.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11365
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11365: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11366
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11366: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11367: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11368: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11369: Dma_PatchSrc (.L__pc.11369.LD), (.L__movme_tmp.1), (.L__pc.11369.LD)
	.p2align 4
	.L__pc.11369.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11370
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11370: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11371
	
	.L__pc.11371: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11372
	
	.p2align 4
	.L__pc.11372: Dma_PatchDst (.L__pc.11372.ST), (.L__movme_cp.63), (.L__pc.11372.ST)
	.L__pc.11372.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11373
	
	.L__pc.11373: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11374
	
	.p2align 4
	.L__pc.11374: Dma_PatchDst (.L__pc.11374.ST), (.L__movme_cp.24), (.L__pc.11374.ST)
	.L__pc.11374.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11375
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11375: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11376
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11376: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11377
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11377: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11378
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11378: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11379
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.11379: Dma_PatchSrc (.L__pc.11379.LD), (.L__movme_cp.66), (.L__pc.11379.LD)
	.p2align 4
	.L__pc.11379.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11380
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11380: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11381
	.L__pc.11381: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11382
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11382: Dma_PatchSrc (.L__pc.11382.LD), (.L__movme_cp.24), (.L__pc.11382.LD)
	.p2align 4
	.L__pc.11382.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11383
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11383: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11384
	.L__pc.11384: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11385
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11385: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11386: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11387: Dma_PatchSrc (.L__pc.11387.LD), (.L__movme_tmp.1), (.L__pc.11387.LD)
	.p2align 4
	.L__pc.11387.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11388
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11388: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11389
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11389: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11390: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11391: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11392: Dma_PatchSrc (.L__pc.11392.LD), (.L__movme_tmp.1), (.L__pc.11392.LD)
	.p2align 4
	.L__pc.11392.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11393
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11393: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11394
	
	.L__pc.11394: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11395
	
	.p2align 4
	.L__pc.11395: Dma_PatchDst (.L__pc.11395.ST), (.L__movme_cp.66), (.L__pc.11395.ST)
	.L__pc.11395.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11396
	
	.L__pc.11396: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11397
	
	.p2align 4
	.L__pc.11397: Dma_PatchDst (.L__pc.11397.ST), (.L__movme_cp.24), (.L__pc.11397.ST)
	.L__pc.11397.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11398
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11398: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11399
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11399: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11400
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11400: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11401
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11401: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11402
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.11402: Dma_PatchSrc (.L__pc.11402.LD), (.L__movme_cp.67), (.L__pc.11402.LD)
	.p2align 4
	.L__pc.11402.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11403
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11403: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11404
	.L__pc.11404: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11405
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11405: Dma_PatchSrc (.L__pc.11405.LD), (.L__movme_cp.24), (.L__pc.11405.LD)
	.p2align 4
	.L__pc.11405.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11406
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11406: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11407
	.L__pc.11407: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11408
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11408: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11409: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11410: Dma_PatchSrc (.L__pc.11410.LD), (.L__movme_tmp.1), (.L__pc.11410.LD)
	.p2align 4
	.L__pc.11410.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11411
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11411: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11412
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11412: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11413: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11414: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11415: Dma_PatchSrc (.L__pc.11415.LD), (.L__movme_tmp.1), (.L__pc.11415.LD)
	.p2align 4
	.L__pc.11415.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11416
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11416: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11417
	
	.L__pc.11417: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11418
	
	.p2align 4
	.L__pc.11418: Dma_PatchDst (.L__pc.11418.ST), (.L__movme_cp.67), (.L__pc.11418.ST)
	.L__pc.11418.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11419
	
	.L__pc.11419: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11420
	
	.p2align 4
	.L__pc.11420: Dma_PatchDst (.L__pc.11420.ST), (.L__movme_cp.24), (.L__pc.11420.ST)
	.L__pc.11420.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11421
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11421: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11422
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11422: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11423
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11423: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11424
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11424: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11425
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.11425: Dma_PatchSrc (.L__pc.11425.LD), (.L__movme_cp.68), (.L__pc.11425.LD)
	.p2align 4
	.L__pc.11425.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11426
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11426: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11427
	.L__pc.11427: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11428
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11428: Dma_PatchSrc (.L__pc.11428.LD), (.L__movme_cp.24), (.L__pc.11428.LD)
	.p2align 4
	.L__pc.11428.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11429
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11429: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11430
	.L__pc.11430: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11431
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11431: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11432: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11433: Dma_PatchSrc (.L__pc.11433.LD), (.L__movme_tmp.1), (.L__pc.11433.LD)
	.p2align 4
	.L__pc.11433.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11434
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11434: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11435
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11435: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11436: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11437: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11438: Dma_PatchSrc (.L__pc.11438.LD), (.L__movme_tmp.1), (.L__pc.11438.LD)
	.p2align 4
	.L__pc.11438.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11439
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11439: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11440
	
	.L__pc.11440: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11441
	
	.p2align 4
	.L__pc.11441: Dma_PatchDst (.L__pc.11441.ST), (.L__movme_cp.68), (.L__pc.11441.ST)
	.L__pc.11441.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11442
	
	.L__pc.11442: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11443
	
	.p2align 4
	.L__pc.11443: Dma_PatchDst (.L__pc.11443.ST), (.L__movme_cp.24), (.L__pc.11443.ST)
	.L__pc.11443.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11444
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11444: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11445
	
	.p2align 4
	.L__pc.11445: Dma_PatchDst (.L__pc.11445.ST), (.L__movme_cp.24), (.L__pc.11445.ST)
	.L__pc.11445.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11446
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.11446: Dma_PatchSrc (.L__pc.11446.LD), (.L__movme_cp.60), (.L__pc.11446.LD)
	.p2align 4
	.L__pc.11446.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11447
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11447: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11448
	
	.L__pc.11448: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11449
	
	.p2align 4
	.L__pc.11449: Dma_PatchDst (.L__pc.11449.ST), (.L__movme_cp.21), (.L__pc.11449.ST)
	.L__pc.11449.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11450
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.11450: Dma_PatchSrc (.L__pc.11450.LD), (.L__movme_cp.58), (.L__pc.11450.LD)
	.p2align 4
	.L__pc.11450.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11451
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11451: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11452
	
	.L__pc.11452: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11453
	
	.p2align 4
	.L__pc.11453: Dma_PatchDst (.L__pc.11453.ST), (.L__movme_cp.22), (.L__pc.11453.ST)
	.L__pc.11453.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11454
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11454: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11455
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11455: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11456
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11456: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11457
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11457: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11458
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.11458: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.11459
	
	.p2align 4
	.L__pc.11459: Dma_PatchDst (.L__pc.11459.ST), (.L__movme_cp.24), (.L__pc.11459.ST)
	.L__pc.11459.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11460
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.11460: Dma_PatchSrc (.L__pc.11460.LD), (.L__movme_cp.25), (.L__pc.11460.LD)
	.p2align 4
	.L__pc.11460.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11461
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11461: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11462
	.L__pc.11462: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11463
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.11463: Dma_PatchSrc (.L__pc.11463.LD), (.L__movme_cp.26), (.L__pc.11463.LD)
	.p2align 4
	.L__pc.11463.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11464
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11464: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11465
	.L__pc.11465: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11466
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11466: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11467: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11468: Dma_PatchSrc (.L__pc.11468.LD), (.L__movme_tmp.1), (.L__pc.11468.LD)
	.p2align 4
	.L__pc.11468.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11469
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11469: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11470
	.L__pc.11470: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11471
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11471: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11472: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11473: Dma_PatchSrc (.L__pc.11473.LD), (.L__movme_tmp.1), (.L__pc.11473.LD)
	.p2align 4
	.L__pc.11473.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11474
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11474: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11475
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11475: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11476: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11477: Dma_PatchSrc (.L__pc.11477.LD), (.L__movme_tmp.1), (.L__pc.11477.LD)
	.p2align 4
	.L__pc.11477.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11478
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11478: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11479
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11479: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11480: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11481: Dma_PatchSrc (.L__pc.11481.LD), (.L__movme_tmp.1), (.L__pc.11481.LD)
	.p2align 4
	.L__pc.11481.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11482
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11482: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11483
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11483: Dma_PatchSrc (.L__pc.11483.LD), (.L__movme_cp.24), (.L__pc.11483.LD)
	.p2align 4
	.L__pc.11483.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11484
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11484: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11485
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11485: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11486: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11487: Dma_PatchSrc (.L__pc.11487.LD), (.L__movme_tmp.1), (.L__pc.11487.LD)
	.p2align 4
	.L__pc.11487.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11488
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11488: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11489
	
	.L__pc.11489: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11490
	
	.p2align 4
	.L__pc.11490: Dma_PatchDst (.L__pc.11490.ST), (.L__movme_cp.69), (.L__pc.11490.ST)
	.L__pc.11490.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11491
	
	.L__pc.11491: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11492
	
	.p2align 4
	.L__pc.11492: Dma_PatchDst (.L__pc.11492.ST), (.L__movme_cp.54), (.L__pc.11492.ST)
	.L__pc.11492.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11493
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.11493: Dma_PatchSrc (.L__pc.11493.LD), (.L__movme_cp.30), (.L__pc.11493.LD)
	.p2align 4
	.L__pc.11493.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11494
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11494: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11495
	.L__pc.11495: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11496
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.11496: Dma_PatchSrc (.L__pc.11496.LD), (.L__movme_cp.31), (.L__pc.11496.LD)
	.p2align 4
	.L__pc.11496.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11497
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11497: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11498
	.L__pc.11498: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11499
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11499: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11500: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11501: Dma_PatchSrc (.L__pc.11501.LD), (.L__movme_tmp.1), (.L__pc.11501.LD)
	.p2align 4
	.L__pc.11501.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11502
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11502: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11503
	.L__pc.11503: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11504
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11504: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11505: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11506: Dma_PatchSrc (.L__pc.11506.LD), (.L__movme_tmp.1), (.L__pc.11506.LD)
	.p2align 4
	.L__pc.11506.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11507
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11507: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11508
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11508: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11509: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11510: Dma_PatchSrc (.L__pc.11510.LD), (.L__movme_tmp.1), (.L__pc.11510.LD)
	.p2align 4
	.L__pc.11510.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11511
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11511: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11512
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11512: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11513: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11514: Dma_PatchSrc (.L__pc.11514.LD), (.L__movme_tmp.1), (.L__pc.11514.LD)
	.p2align 4
	.L__pc.11514.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11515
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11515: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11516
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11516: Dma_PatchSrc (.L__pc.11516.LD), (.L__movme_cp.24), (.L__pc.11516.LD)
	.p2align 4
	.L__pc.11516.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11517
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11517: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11518
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11518: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11519: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11520: Dma_PatchSrc (.L__pc.11520.LD), (.L__movme_tmp.1), (.L__pc.11520.LD)
	.p2align 4
	.L__pc.11520.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11521
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11521: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11522
	
	.L__pc.11522: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11523
	
	.p2align 4
	.L__pc.11523: Dma_PatchDst (.L__pc.11523.ST), (.L__movme_cp.70), (.L__pc.11523.ST)
	.L__pc.11523.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11524
	
	.L__pc.11524: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11525
	
	.p2align 4
	.L__pc.11525: Dma_PatchDst (.L__pc.11525.ST), (.L__movme_cp.54), (.L__pc.11525.ST)
	.L__pc.11525.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11526
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11526: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11527
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11527: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11528
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11528: Dma_PatchSrc (.L__pc.11528.LD), (.L__movme_cp.24), (.L__pc.11528.LD)
	.p2align 4
	.L__pc.11528.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11529
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11529: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11530
	.L__pc.11530: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11531
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.11531: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11532: Dma_PatchSrc (.L__pc.11532.LD), (.L__movme_tmp.1), (.L__pc.11532.LD)
	.p2align 4
	.L__pc.11532.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11533
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11533: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11534
	.L__pc.11534: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11535
	
	.L__pc.11535: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11536
	
	.p2align 4
	.L__pc.11536: Dma_PatchDst (.L__pc.11536.ST), (.L__movme_cp.72), (.L__pc.11536.ST)
	.L__pc.11536.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11537
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.11537: Dma_PatchSrc (.L__pc.11537.LD), (.L__movme_cp.72), (.L__pc.11537.LD)
	.p2align 4
	.L__pc.11537.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11538
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11538: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11539
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11539: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11540: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11541: Dma_PatchSrc (.L__pc.11541.LD), (.L__movme_tmp.1), (.L__pc.11541.LD)
	.p2align 4
	.L__pc.11541.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11542
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11542: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11543
	
	.L__pc.11543: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11544
	
	.p2align 4
	.L__pc.11544: Dma_PatchDst (.L__pc.11544.ST), (.L__movme_cp.74), (.L__pc.11544.ST)
	.L__pc.11544.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11545
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11545: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11546: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11547: Dma_PatchSrc (.L__pc.11547.LD), (.L__movme_tmp.1), (.L__pc.11547.LD)
	.p2align 4
	.L__pc.11547.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11548
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11548: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11549
	
	.L__pc.11549: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11550
	
	.p2align 4
	.L__pc.11550: Dma_PatchDst (.L__pc.11550.ST), (.L__movme_cp.76), (.L__pc.11550.ST)
	.L__pc.11550.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11551
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.11551: Dma_PatchSrc (.L__pc.11551.LD), (.L__movme_cp.74), (.L__pc.11551.LD)
	.p2align 4
	.L__pc.11551.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11552
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11552: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11553
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.11553: Dma_PatchSrc (.L__pc.11553.LD), ((.L__movme.reg.eax+0)), (.L__pc.11553.LD)
	.p2align 4
	.L__pc.11553.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11554
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11554: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11555
	
	.L__pc.11555: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11556
	
	.p2align 4
	.L__pc.11556: Dma_PatchDst (.L__pc.11556.ST), (.L__movme_cp.77), (.L__pc.11556.ST)
	.L__pc.11556.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11557
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.11557: Dma_PatchSrc (.L__pc.11557.LD), (.L__movme_cp.77), (.L__pc.11557.LD)
	.p2align 4
	.L__pc.11557.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11558
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11558: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11559
	
	.L__pc.11559: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11560
	
	.p2align 4
	.L__pc.11560: Dma_PatchDst (.L__pc.11560.ST), (.L__movme_cp.21), (.L__pc.11560.ST)
	.L__pc.11560.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11561
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.11561: Dma_PatchSrc (.L__pc.11561.LD), (.L__movme_cp.58), (.L__pc.11561.LD)
	.p2align 4
	.L__pc.11561.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11562
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11562: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11563
	
	.L__pc.11563: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11564
	
	.p2align 4
	.L__pc.11564: Dma_PatchDst (.L__pc.11564.ST), (.L__movme_cp.22), (.L__pc.11564.ST)
	.L__pc.11564.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11565
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11565: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11566
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11566: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11567
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11567: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11568
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11568: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11569
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.11569: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.11570
	
	.p2align 4
	.L__pc.11570: Dma_PatchDst (.L__pc.11570.ST), (.L__movme_cp.24), (.L__pc.11570.ST)
	.L__pc.11570.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11571
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.11571: Dma_PatchSrc (.L__pc.11571.LD), (.L__movme_cp.25), (.L__pc.11571.LD)
	.p2align 4
	.L__pc.11571.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11572
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11572: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11573
	.L__pc.11573: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11574
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.11574: Dma_PatchSrc (.L__pc.11574.LD), (.L__movme_cp.26), (.L__pc.11574.LD)
	.p2align 4
	.L__pc.11574.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11575
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11575: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11576
	.L__pc.11576: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11577
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11577: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11578: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11579: Dma_PatchSrc (.L__pc.11579.LD), (.L__movme_tmp.1), (.L__pc.11579.LD)
	.p2align 4
	.L__pc.11579.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11580
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11580: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11581
	.L__pc.11581: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11582
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11582: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11583: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11584: Dma_PatchSrc (.L__pc.11584.LD), (.L__movme_tmp.1), (.L__pc.11584.LD)
	.p2align 4
	.L__pc.11584.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11585
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11585: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11586
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11586: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11587: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11588: Dma_PatchSrc (.L__pc.11588.LD), (.L__movme_tmp.1), (.L__pc.11588.LD)
	.p2align 4
	.L__pc.11588.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11589
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11589: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11590
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11590: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11591: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11592: Dma_PatchSrc (.L__pc.11592.LD), (.L__movme_tmp.1), (.L__pc.11592.LD)
	.p2align 4
	.L__pc.11592.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11593
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11593: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11594
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11594: Dma_PatchSrc (.L__pc.11594.LD), (.L__movme_cp.24), (.L__pc.11594.LD)
	.p2align 4
	.L__pc.11594.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11595
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11595: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11596
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11596: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11597: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11598: Dma_PatchSrc (.L__pc.11598.LD), (.L__movme_tmp.1), (.L__pc.11598.LD)
	.p2align 4
	.L__pc.11598.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11599
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11599: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11600
	
	.L__pc.11600: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11601
	
	.p2align 4
	.L__pc.11601: Dma_PatchDst (.L__pc.11601.ST), (.L__movme_cp.78), (.L__pc.11601.ST)
	.L__pc.11601.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11602
	
	.L__pc.11602: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11603
	
	.p2align 4
	.L__pc.11603: Dma_PatchDst (.L__pc.11603.ST), (.L__movme_cp.54), (.L__pc.11603.ST)
	.L__pc.11603.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11604
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.11604: Dma_PatchSrc (.L__pc.11604.LD), (.L__movme_cp.30), (.L__pc.11604.LD)
	.p2align 4
	.L__pc.11604.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11605
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11605: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11606
	.L__pc.11606: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11607
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.11607: Dma_PatchSrc (.L__pc.11607.LD), (.L__movme_cp.31), (.L__pc.11607.LD)
	.p2align 4
	.L__pc.11607.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11608
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11608: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11609
	.L__pc.11609: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11610
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11610: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11611: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11612: Dma_PatchSrc (.L__pc.11612.LD), (.L__movme_tmp.1), (.L__pc.11612.LD)
	.p2align 4
	.L__pc.11612.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11613
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11613: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11614
	.L__pc.11614: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11615
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11615: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11616: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11617: Dma_PatchSrc (.L__pc.11617.LD), (.L__movme_tmp.1), (.L__pc.11617.LD)
	.p2align 4
	.L__pc.11617.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11618
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11618: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11619
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11619: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11620: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11621: Dma_PatchSrc (.L__pc.11621.LD), (.L__movme_tmp.1), (.L__pc.11621.LD)
	.p2align 4
	.L__pc.11621.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11622
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11622: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11623
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11623: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11624: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11625: Dma_PatchSrc (.L__pc.11625.LD), (.L__movme_tmp.1), (.L__pc.11625.LD)
	.p2align 4
	.L__pc.11625.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11626
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11626: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11627
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11627: Dma_PatchSrc (.L__pc.11627.LD), (.L__movme_cp.24), (.L__pc.11627.LD)
	.p2align 4
	.L__pc.11627.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11628
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11628: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11629
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11629: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11630: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11631: Dma_PatchSrc (.L__pc.11631.LD), (.L__movme_tmp.1), (.L__pc.11631.LD)
	.p2align 4
	.L__pc.11631.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11632
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11632: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11633
	
	.L__pc.11633: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11634
	
	.p2align 4
	.L__pc.11634: Dma_PatchDst (.L__pc.11634.ST), (.L__movme_cp.79), (.L__pc.11634.ST)
	.L__pc.11634.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11635
	
	.L__pc.11635: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11636
	
	.p2align 4
	.L__pc.11636: Dma_PatchDst (.L__pc.11636.ST), (.L__movme_cp.54), (.L__pc.11636.ST)
	.L__pc.11636.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11637
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.11637: Dma_PatchSrc (.L__pc.11637.LD), (.L__movme_cp.74), (.L__pc.11637.LD)
	.p2align 4
	.L__pc.11637.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11638
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11638: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11639
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.11639: Dma_PatchSrc (.L__pc.11639.LD), (.L__movme_cp.77), (.L__pc.11639.LD)
	.p2align 4
	.L__pc.11639.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11640
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11640: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11641
	
	.L__pc.11641: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11642
	
	.p2align 4
	.L__pc.11642: Dma_PatchDst (.L__pc.11642.ST), ((.L__movme.reg.eax+0)), (.L__pc.11642.ST)
	.L__pc.11642.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11643
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.11643: Dma_PatchSrc (.L__pc.11643.LD), (.L__movme_cp.76), (.L__pc.11643.LD)
	.p2align 4
	.L__pc.11643.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11644
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11644: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11645
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.11645: Dma_PatchSrc (.L__pc.11645.LD), ((.L__movme.reg.eax+0)), (.L__pc.11645.LD)
	.p2align 4
	.L__pc.11645.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11646
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11646: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11647
	
	.L__pc.11647: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11648
	
	.p2align 4
	.L__pc.11648: Dma_PatchDst (.L__pc.11648.ST), (.L__movme_cp.80), (.L__pc.11648.ST)
	.L__pc.11648.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11649
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11649: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11650
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11650: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11651
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.11651: Dma_PatchSrc (.L__pc.11651.LD), (.L__movme_cp.102), (.L__pc.11651.LD)
	.p2align 4
	.L__pc.11651.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11652
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11652: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11653
	.L__pc.11653: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11654
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.92 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.11654: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11655: Dma_PatchSrc (.L__pc.11655.LD), (.L__movme_tmp.1), (.L__pc.11655.LD)
	.p2align 4
	.L__pc.11655.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11656
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11656: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11657
	.L__pc.11657: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11658
	
	.L__pc.11658: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11659
	
	.p2align 4
	.L__pc.11659: Dma_PatchDst (.L__pc.11659.ST), (.L__movme_cp.102), (.L__pc.11659.ST)
	.L__pc.11659.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11660
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.11660: Dma_PatchSrc (.L__pc.11660.LD), (.L__movme_cp.76), (.L__pc.11660.LD)
	.p2align 4
	.L__pc.11660.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11661
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11661: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11662
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.11662: Dma_PatchSrc (.L__pc.11662.LD), (.L__movme_cp.80), (.L__pc.11662.LD)
	.p2align 4
	.L__pc.11662.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11663
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11663: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11664
	
	.L__pc.11664: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11665
	
	.p2align 4
	.L__pc.11665: Dma_PatchDst (.L__pc.11665.ST), ((.L__movme.reg.eax+0)), (.L__pc.11665.ST)
	.L__pc.11665.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11666
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11666: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11667
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11667: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11668
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.11668: Dma_PatchSrc (.L__pc.11668.LD), (.L__movme_cp.101), (.L__pc.11668.LD)
	.p2align 4
	.L__pc.11668.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11669
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11669: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11670
	.L__pc.11670: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11671
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11671: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.93 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11672: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11673: Dma_PatchSrc (.L__pc.11673.LD), (.L__movme_tmp.1), (.L__pc.11673.LD)
	.p2align 4
	.L__pc.11673.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11674
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11674: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11675
	
	.L__pc.11675: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11676
	
	.p2align 4
	.L__pc.11676: Dma_PatchDst (.L__pc.11676.ST), (.L__movme_cp.24), (.L__pc.11676.ST)
	.L__pc.11676.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11677
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11677: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11678
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11678: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11679
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11679: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11680
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11680: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11681
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.11681: Dma_PatchSrc (.L__pc.11681.LD), (.L__movme_cp.63), (.L__pc.11681.LD)
	.p2align 4
	.L__pc.11681.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11682
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11682: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11683
	.L__pc.11683: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11684
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11684: Dma_PatchSrc (.L__pc.11684.LD), (.L__movme_cp.24), (.L__pc.11684.LD)
	.p2align 4
	.L__pc.11684.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11685
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11685: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11686
	.L__pc.11686: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11687
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11687: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11688: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11689: Dma_PatchSrc (.L__pc.11689.LD), (.L__movme_tmp.1), (.L__pc.11689.LD)
	.p2align 4
	.L__pc.11689.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11690
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11690: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11691
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11691: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11692: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11693: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11694: Dma_PatchSrc (.L__pc.11694.LD), (.L__movme_tmp.1), (.L__pc.11694.LD)
	.p2align 4
	.L__pc.11694.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11695
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11695: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11696
	
	.L__pc.11696: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11697
	
	.p2align 4
	.L__pc.11697: Dma_PatchDst (.L__pc.11697.ST), (.L__movme_cp.63), (.L__pc.11697.ST)
	.L__pc.11697.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11698
	
	.L__pc.11698: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11699
	
	.p2align 4
	.L__pc.11699: Dma_PatchDst (.L__pc.11699.ST), (.L__movme_cp.24), (.L__pc.11699.ST)
	.L__pc.11699.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11700
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11700: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11701
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11701: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11702
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11702: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11703
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11703: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11704
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.11704: Dma_PatchSrc (.L__pc.11704.LD), (.L__movme_cp.66), (.L__pc.11704.LD)
	.p2align 4
	.L__pc.11704.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11705
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11705: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11706
	.L__pc.11706: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11707
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11707: Dma_PatchSrc (.L__pc.11707.LD), (.L__movme_cp.24), (.L__pc.11707.LD)
	.p2align 4
	.L__pc.11707.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11708
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11708: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11709
	.L__pc.11709: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11710
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11710: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11711: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11712: Dma_PatchSrc (.L__pc.11712.LD), (.L__movme_tmp.1), (.L__pc.11712.LD)
	.p2align 4
	.L__pc.11712.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11713
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11713: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11714
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11714: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11715: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11716: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11717: Dma_PatchSrc (.L__pc.11717.LD), (.L__movme_tmp.1), (.L__pc.11717.LD)
	.p2align 4
	.L__pc.11717.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11718
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11718: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11719
	
	.L__pc.11719: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11720
	
	.p2align 4
	.L__pc.11720: Dma_PatchDst (.L__pc.11720.ST), (.L__movme_cp.66), (.L__pc.11720.ST)
	.L__pc.11720.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11721
	
	.L__pc.11721: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11722
	
	.p2align 4
	.L__pc.11722: Dma_PatchDst (.L__pc.11722.ST), (.L__movme_cp.24), (.L__pc.11722.ST)
	.L__pc.11722.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11723
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11723: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11724
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11724: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11725
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11725: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11726
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11726: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11727
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.11727: Dma_PatchSrc (.L__pc.11727.LD), (.L__movme_cp.67), (.L__pc.11727.LD)
	.p2align 4
	.L__pc.11727.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11728
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11728: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11729
	.L__pc.11729: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11730
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11730: Dma_PatchSrc (.L__pc.11730.LD), (.L__movme_cp.24), (.L__pc.11730.LD)
	.p2align 4
	.L__pc.11730.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11731
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11731: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11732
	.L__pc.11732: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11733
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11733: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11734: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11735: Dma_PatchSrc (.L__pc.11735.LD), (.L__movme_tmp.1), (.L__pc.11735.LD)
	.p2align 4
	.L__pc.11735.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11736
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11736: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11737
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11737: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11738: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11739: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11740: Dma_PatchSrc (.L__pc.11740.LD), (.L__movme_tmp.1), (.L__pc.11740.LD)
	.p2align 4
	.L__pc.11740.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11741
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11741: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11742
	
	.L__pc.11742: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11743
	
	.p2align 4
	.L__pc.11743: Dma_PatchDst (.L__pc.11743.ST), (.L__movme_cp.67), (.L__pc.11743.ST)
	.L__pc.11743.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11744
	
	.L__pc.11744: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11745
	
	.p2align 4
	.L__pc.11745: Dma_PatchDst (.L__pc.11745.ST), (.L__movme_cp.24), (.L__pc.11745.ST)
	.L__pc.11745.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11746
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11746: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11747
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11747: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11748
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11748: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11749
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11749: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11750
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.11750: Dma_PatchSrc (.L__pc.11750.LD), (.L__movme_cp.68), (.L__pc.11750.LD)
	.p2align 4
	.L__pc.11750.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11751
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11751: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11752
	.L__pc.11752: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11753
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11753: Dma_PatchSrc (.L__pc.11753.LD), (.L__movme_cp.24), (.L__pc.11753.LD)
	.p2align 4
	.L__pc.11753.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11754
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11754: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11755
	.L__pc.11755: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11756
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11756: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11757: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11758: Dma_PatchSrc (.L__pc.11758.LD), (.L__movme_tmp.1), (.L__pc.11758.LD)
	.p2align 4
	.L__pc.11758.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11759
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11759: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11760
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.11760: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.11761: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.11762: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11763: Dma_PatchSrc (.L__pc.11763.LD), (.L__movme_tmp.1), (.L__pc.11763.LD)
	.p2align 4
	.L__pc.11763.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11764
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11764: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11765
	
	.L__pc.11765: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11766
	
	.p2align 4
	.L__pc.11766: Dma_PatchDst (.L__pc.11766.ST), (.L__movme_cp.68), (.L__pc.11766.ST)
	.L__pc.11766.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11767
	
	.L__pc.11767: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.11768
	
	.p2align 4
	.L__pc.11768: Dma_PatchDst (.L__pc.11768.ST), (.L__movme_cp.24), (.L__pc.11768.ST)
	.L__pc.11768.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11769
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11769: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11770
	
	.p2align 4
	.L__pc.11770: Dma_PatchDst (.L__pc.11770.ST), (.L__movme_cp.24), (.L__pc.11770.ST)
	.L__pc.11770.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11771
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.11771: Dma_PatchSrc (.L__pc.11771.LD), (.L__movme_cp.60), (.L__pc.11771.LD)
	.p2align 4
	.L__pc.11771.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11772
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11772: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11773
	
	.L__pc.11773: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11774
	
	.p2align 4
	.L__pc.11774: Dma_PatchDst (.L__pc.11774.ST), (.L__movme_cp.21), (.L__pc.11774.ST)
	.L__pc.11774.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11775
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.11775: Dma_PatchSrc (.L__pc.11775.LD), (.L__movme_cp.58), (.L__pc.11775.LD)
	.p2align 4
	.L__pc.11775.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11776
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11776: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11777
	
	.L__pc.11777: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11778
	
	.p2align 4
	.L__pc.11778: Dma_PatchDst (.L__pc.11778.ST), (.L__movme_cp.22), (.L__pc.11778.ST)
	.L__pc.11778.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11779
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11779: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11780
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11780: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11781
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11781: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11782
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11782: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11783
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.11783: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.11784
	
	.p2align 4
	.L__pc.11784: Dma_PatchDst (.L__pc.11784.ST), (.L__movme_cp.24), (.L__pc.11784.ST)
	.L__pc.11784.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11785
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.11785: Dma_PatchSrc (.L__pc.11785.LD), (.L__movme_cp.25), (.L__pc.11785.LD)
	.p2align 4
	.L__pc.11785.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11786
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11786: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11787
	.L__pc.11787: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11788
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.11788: Dma_PatchSrc (.L__pc.11788.LD), (.L__movme_cp.26), (.L__pc.11788.LD)
	.p2align 4
	.L__pc.11788.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11789
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11789: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11790
	.L__pc.11790: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11791
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11791: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11792: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11793: Dma_PatchSrc (.L__pc.11793.LD), (.L__movme_tmp.1), (.L__pc.11793.LD)
	.p2align 4
	.L__pc.11793.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11794
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11794: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11795
	.L__pc.11795: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11796
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11796: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11797: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11798: Dma_PatchSrc (.L__pc.11798.LD), (.L__movme_tmp.1), (.L__pc.11798.LD)
	.p2align 4
	.L__pc.11798.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11799
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11799: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11800
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11800: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11801: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11802: Dma_PatchSrc (.L__pc.11802.LD), (.L__movme_tmp.1), (.L__pc.11802.LD)
	.p2align 4
	.L__pc.11802.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11803
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11803: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11804
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11804: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11805: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11806: Dma_PatchSrc (.L__pc.11806.LD), (.L__movme_tmp.1), (.L__pc.11806.LD)
	.p2align 4
	.L__pc.11806.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11807
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11807: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11808
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11808: Dma_PatchSrc (.L__pc.11808.LD), (.L__movme_cp.24), (.L__pc.11808.LD)
	.p2align 4
	.L__pc.11808.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11809
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11809: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11810
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11810: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11811: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11812: Dma_PatchSrc (.L__pc.11812.LD), (.L__movme_tmp.1), (.L__pc.11812.LD)
	.p2align 4
	.L__pc.11812.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11813
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11813: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11814
	
	.L__pc.11814: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11815
	
	.p2align 4
	.L__pc.11815: Dma_PatchDst (.L__pc.11815.ST), (.L__movme_cp.69), (.L__pc.11815.ST)
	.L__pc.11815.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11816
	
	.L__pc.11816: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11817
	
	.p2align 4
	.L__pc.11817: Dma_PatchDst (.L__pc.11817.ST), (.L__movme_cp.54), (.L__pc.11817.ST)
	.L__pc.11817.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11818
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.11818: Dma_PatchSrc (.L__pc.11818.LD), (.L__movme_cp.30), (.L__pc.11818.LD)
	.p2align 4
	.L__pc.11818.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11819
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11819: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11820
	.L__pc.11820: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11821
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.11821: Dma_PatchSrc (.L__pc.11821.LD), (.L__movme_cp.31), (.L__pc.11821.LD)
	.p2align 4
	.L__pc.11821.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11822
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11822: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11823
	.L__pc.11823: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11824
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11824: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11825: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11826: Dma_PatchSrc (.L__pc.11826.LD), (.L__movme_tmp.1), (.L__pc.11826.LD)
	.p2align 4
	.L__pc.11826.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11827
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11827: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11828
	.L__pc.11828: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11829
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11829: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11830: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11831: Dma_PatchSrc (.L__pc.11831.LD), (.L__movme_tmp.1), (.L__pc.11831.LD)
	.p2align 4
	.L__pc.11831.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11832
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11832: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11833
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11833: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11834: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11835: Dma_PatchSrc (.L__pc.11835.LD), (.L__movme_tmp.1), (.L__pc.11835.LD)
	.p2align 4
	.L__pc.11835.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11836
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11836: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11837
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11837: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11838: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11839: Dma_PatchSrc (.L__pc.11839.LD), (.L__movme_tmp.1), (.L__pc.11839.LD)
	.p2align 4
	.L__pc.11839.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11840
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11840: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11841
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11841: Dma_PatchSrc (.L__pc.11841.LD), (.L__movme_cp.24), (.L__pc.11841.LD)
	.p2align 4
	.L__pc.11841.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11842
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11842: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11843
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11843: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11844: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11845: Dma_PatchSrc (.L__pc.11845.LD), (.L__movme_tmp.1), (.L__pc.11845.LD)
	.p2align 4
	.L__pc.11845.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11846
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11846: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11847
	
	.L__pc.11847: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11848
	
	.p2align 4
	.L__pc.11848: Dma_PatchDst (.L__pc.11848.ST), (.L__movme_cp.70), (.L__pc.11848.ST)
	.L__pc.11848.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11849
	
	.L__pc.11849: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11850
	
	.p2align 4
	.L__pc.11850: Dma_PatchDst (.L__pc.11850.ST), (.L__movme_cp.54), (.L__pc.11850.ST)
	.L__pc.11850.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11851
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11851: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11852
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11852: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11853
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11853: Dma_PatchSrc (.L__pc.11853.LD), (.L__movme_cp.24), (.L__pc.11853.LD)
	.p2align 4
	.L__pc.11853.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11854
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11854: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11855
	.L__pc.11855: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11856
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.11856: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11857: Dma_PatchSrc (.L__pc.11857.LD), (.L__movme_tmp.1), (.L__pc.11857.LD)
	.p2align 4
	.L__pc.11857.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11858
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11858: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11859
	.L__pc.11859: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11860
	
	.L__pc.11860: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11861
	
	.p2align 4
	.L__pc.11861: Dma_PatchDst (.L__pc.11861.ST), (.L__movme_cp.72), (.L__pc.11861.ST)
	.L__pc.11861.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11862
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.11862: Dma_PatchSrc (.L__pc.11862.LD), (.L__movme_cp.72), (.L__pc.11862.LD)
	.p2align 4
	.L__pc.11862.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11863
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11863: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11864
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11864: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11865: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11866: Dma_PatchSrc (.L__pc.11866.LD), (.L__movme_tmp.1), (.L__pc.11866.LD)
	.p2align 4
	.L__pc.11866.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11867
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11867: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11868
	
	.L__pc.11868: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11869
	
	.p2align 4
	.L__pc.11869: Dma_PatchDst (.L__pc.11869.ST), (.L__movme_cp.74), (.L__pc.11869.ST)
	.L__pc.11869.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11870
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11870: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11871: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11872: Dma_PatchSrc (.L__pc.11872.LD), (.L__movme_tmp.1), (.L__pc.11872.LD)
	.p2align 4
	.L__pc.11872.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11873
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11873: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11874
	
	.L__pc.11874: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11875
	
	.p2align 4
	.L__pc.11875: Dma_PatchDst (.L__pc.11875.ST), (.L__movme_cp.76), (.L__pc.11875.ST)
	.L__pc.11875.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11876
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.11876: Dma_PatchSrc (.L__pc.11876.LD), (.L__movme_cp.74), (.L__pc.11876.LD)
	.p2align 4
	.L__pc.11876.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11877
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11877: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11878
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.11878: Dma_PatchSrc (.L__pc.11878.LD), ((.L__movme.reg.eax+0)), (.L__pc.11878.LD)
	.p2align 4
	.L__pc.11878.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11879
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11879: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11880
	
	.L__pc.11880: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11881
	
	.p2align 4
	.L__pc.11881: Dma_PatchDst (.L__pc.11881.ST), (.L__movme_cp.77), (.L__pc.11881.ST)
	.L__pc.11881.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11882
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.11882: Dma_PatchSrc (.L__pc.11882.LD), (.L__movme_cp.77), (.L__pc.11882.LD)
	.p2align 4
	.L__pc.11882.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11883
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11883: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11884
	
	.L__pc.11884: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11885
	
	.p2align 4
	.L__pc.11885: Dma_PatchDst (.L__pc.11885.ST), (.L__movme_cp.21), (.L__pc.11885.ST)
	.L__pc.11885.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11886
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.11886: Dma_PatchSrc (.L__pc.11886.LD), (.L__movme_cp.58), (.L__pc.11886.LD)
	.p2align 4
	.L__pc.11886.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11887
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11887: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11888
	
	.L__pc.11888: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11889
	
	.p2align 4
	.L__pc.11889: Dma_PatchDst (.L__pc.11889.ST), (.L__movme_cp.22), (.L__pc.11889.ST)
	.L__pc.11889.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11890
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11890: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11891
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11891: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11892
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11892: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11893
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11893: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11894
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.11894: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.11895
	
	.p2align 4
	.L__pc.11895: Dma_PatchDst (.L__pc.11895.ST), (.L__movme_cp.24), (.L__pc.11895.ST)
	.L__pc.11895.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11896
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.11896: Dma_PatchSrc (.L__pc.11896.LD), (.L__movme_cp.25), (.L__pc.11896.LD)
	.p2align 4
	.L__pc.11896.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11897
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11897: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11898
	.L__pc.11898: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11899
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.11899: Dma_PatchSrc (.L__pc.11899.LD), (.L__movme_cp.26), (.L__pc.11899.LD)
	.p2align 4
	.L__pc.11899.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11900
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11900: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11901
	.L__pc.11901: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11902
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11902: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11903: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11904: Dma_PatchSrc (.L__pc.11904.LD), (.L__movme_tmp.1), (.L__pc.11904.LD)
	.p2align 4
	.L__pc.11904.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11905
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11905: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11906
	.L__pc.11906: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11907
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11907: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11908: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11909: Dma_PatchSrc (.L__pc.11909.LD), (.L__movme_tmp.1), (.L__pc.11909.LD)
	.p2align 4
	.L__pc.11909.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11910
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11910: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11911
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11911: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11912: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11913: Dma_PatchSrc (.L__pc.11913.LD), (.L__movme_tmp.1), (.L__pc.11913.LD)
	.p2align 4
	.L__pc.11913.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11914
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11914: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11915
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11915: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11916: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11917: Dma_PatchSrc (.L__pc.11917.LD), (.L__movme_tmp.1), (.L__pc.11917.LD)
	.p2align 4
	.L__pc.11917.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11918
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11918: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11919
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11919: Dma_PatchSrc (.L__pc.11919.LD), (.L__movme_cp.24), (.L__pc.11919.LD)
	.p2align 4
	.L__pc.11919.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11920
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11920: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11921
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11921: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11922: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11923: Dma_PatchSrc (.L__pc.11923.LD), (.L__movme_tmp.1), (.L__pc.11923.LD)
	.p2align 4
	.L__pc.11923.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11924
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11924: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11925
	
	.L__pc.11925: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11926
	
	.p2align 4
	.L__pc.11926: Dma_PatchDst (.L__pc.11926.ST), (.L__movme_cp.78), (.L__pc.11926.ST)
	.L__pc.11926.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11927
	
	.L__pc.11927: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11928
	
	.p2align 4
	.L__pc.11928: Dma_PatchDst (.L__pc.11928.ST), (.L__movme_cp.54), (.L__pc.11928.ST)
	.L__pc.11928.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11929
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.11929: Dma_PatchSrc (.L__pc.11929.LD), (.L__movme_cp.30), (.L__pc.11929.LD)
	.p2align 4
	.L__pc.11929.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11930
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11930: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.11931
	.L__pc.11931: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.11932
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.11932: Dma_PatchSrc (.L__pc.11932.LD), (.L__movme_cp.31), (.L__pc.11932.LD)
	.p2align 4
	.L__pc.11932.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11933
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11933: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11934
	.L__pc.11934: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11935
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.11935: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11936: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11937: Dma_PatchSrc (.L__pc.11937.LD), (.L__movme_tmp.1), (.L__pc.11937.LD)
	.p2align 4
	.L__pc.11937.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11938
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11938: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.11939
	.L__pc.11939: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.11940
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.11940: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11941: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11942: Dma_PatchSrc (.L__pc.11942.LD), (.L__movme_tmp.1), (.L__pc.11942.LD)
	.p2align 4
	.L__pc.11942.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11943
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11943: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11944
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11944: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11945: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11946: Dma_PatchSrc (.L__pc.11946.LD), (.L__movme_tmp.1), (.L__pc.11946.LD)
	.p2align 4
	.L__pc.11946.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11947
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11947: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11948
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11948: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11949: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11950: Dma_PatchSrc (.L__pc.11950.LD), (.L__movme_tmp.1), (.L__pc.11950.LD)
	.p2align 4
	.L__pc.11950.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11951
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11951: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11952
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.11952: Dma_PatchSrc (.L__pc.11952.LD), (.L__movme_cp.24), (.L__pc.11952.LD)
	.p2align 4
	.L__pc.11952.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11953
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.11953: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.11954
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.11954: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11955: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11956: Dma_PatchSrc (.L__pc.11956.LD), (.L__movme_tmp.1), (.L__pc.11956.LD)
	.p2align 4
	.L__pc.11956.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11957
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11957: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11958
	
	.L__pc.11958: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.11959
	
	.p2align 4
	.L__pc.11959: Dma_PatchDst (.L__pc.11959.ST), (.L__movme_cp.79), (.L__pc.11959.ST)
	.L__pc.11959.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11960
	
	.L__pc.11960: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11961
	
	.p2align 4
	.L__pc.11961: Dma_PatchDst (.L__pc.11961.ST), (.L__movme_cp.54), (.L__pc.11961.ST)
	.L__pc.11961.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11962
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.11962: Dma_PatchSrc (.L__pc.11962.LD), (.L__movme_cp.74), (.L__pc.11962.LD)
	.p2align 4
	.L__pc.11962.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11963
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11963: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11964
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.11964: Dma_PatchSrc (.L__pc.11964.LD), (.L__movme_cp.77), (.L__pc.11964.LD)
	.p2align 4
	.L__pc.11964.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11965
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11965: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11966
	
	.L__pc.11966: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11967
	
	.p2align 4
	.L__pc.11967: Dma_PatchDst (.L__pc.11967.ST), ((.L__movme.reg.eax+0)), (.L__pc.11967.ST)
	.L__pc.11967.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11968
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.11968: Dma_PatchSrc (.L__pc.11968.LD), (.L__movme_cp.76), (.L__pc.11968.LD)
	.p2align 4
	.L__pc.11968.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11969
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11969: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11970
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.11970: Dma_PatchSrc (.L__pc.11970.LD), ((.L__movme.reg.eax+0)), (.L__pc.11970.LD)
	.p2align 4
	.L__pc.11970.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11971
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11971: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11972
	
	.L__pc.11972: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.11973
	
	.p2align 4
	.L__pc.11973: Dma_PatchDst (.L__pc.11973.ST), (.L__movme_cp.80), (.L__pc.11973.ST)
	.L__pc.11973.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11974
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11974: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11975
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11975: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11976
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.11976: Dma_PatchSrc (.L__pc.11976.LD), (.L__movme_cp.102), (.L__pc.11976.LD)
	.p2align 4
	.L__pc.11976.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11977
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11977: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11978
	.L__pc.11978: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11979
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.94 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.11979: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11980: Dma_PatchSrc (.L__pc.11980.LD), (.L__movme_tmp.1), (.L__pc.11980.LD)
	.p2align 4
	.L__pc.11980.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11981
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11981: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.11982
	.L__pc.11982: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.11983
	
	.L__pc.11983: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.11984
	
	.p2align 4
	.L__pc.11984: Dma_PatchDst (.L__pc.11984.ST), (.L__movme_cp.102), (.L__pc.11984.ST)
	.L__pc.11984.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11985
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.11985: Dma_PatchSrc (.L__pc.11985.LD), (.L__movme_cp.76), (.L__pc.11985.LD)
	.p2align 4
	.L__pc.11985.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11986
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11986: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.11987
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.11987: Dma_PatchSrc (.L__pc.11987.LD), (.L__movme_cp.80), (.L__pc.11987.LD)
	.p2align 4
	.L__pc.11987.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11988
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11988: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11989
	
	.L__pc.11989: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.11990
	
	.p2align 4
	.L__pc.11990: Dma_PatchDst (.L__pc.11990.ST), ((.L__movme.reg.eax+0)), (.L__pc.11990.ST)
	.L__pc.11990.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.11991
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.11991: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.11992
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11992: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.11993
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.11993: Dma_PatchSrc (.L__pc.11993.LD), (.L__movme_cp.101), (.L__pc.11993.LD)
	.p2align 4
	.L__pc.11993.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11994
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.11994: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.11995
	.L__pc.11995: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.11996
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.11996: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.95 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.11997: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.11998: Dma_PatchSrc (.L__pc.11998.LD), (.L__movme_tmp.1), (.L__pc.11998.LD)
	.p2align 4
	.L__pc.11998.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.11999
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.11999: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12000
	
	.L__pc.12000: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12001
	
	.p2align 4
	.L__pc.12001: Dma_PatchDst (.L__pc.12001.ST), (.L__movme_cp.24), (.L__pc.12001.ST)
	.L__pc.12001.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12002
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12002: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12003
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12003: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12004
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12004: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12005
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12005: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12006
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.12006: Dma_PatchSrc (.L__pc.12006.LD), (.L__movme_cp.63), (.L__pc.12006.LD)
	.p2align 4
	.L__pc.12006.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12007
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12007: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12008
	.L__pc.12008: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12009
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12009: Dma_PatchSrc (.L__pc.12009.LD), (.L__movme_cp.24), (.L__pc.12009.LD)
	.p2align 4
	.L__pc.12009.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12010
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12010: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.12011
	.L__pc.12011: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.12012
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12012: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12013: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12014: Dma_PatchSrc (.L__pc.12014.LD), (.L__movme_tmp.1), (.L__pc.12014.LD)
	.p2align 4
	.L__pc.12014.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12015
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12015: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12016
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.12016: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.12017: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.12018: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12019: Dma_PatchSrc (.L__pc.12019.LD), (.L__movme_tmp.1), (.L__pc.12019.LD)
	.p2align 4
	.L__pc.12019.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12020
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12020: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12021
	
	.L__pc.12021: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.12022
	
	.p2align 4
	.L__pc.12022: Dma_PatchDst (.L__pc.12022.ST), (.L__movme_cp.63), (.L__pc.12022.ST)
	.L__pc.12022.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12023
	
	.L__pc.12023: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.12024
	
	.p2align 4
	.L__pc.12024: Dma_PatchDst (.L__pc.12024.ST), (.L__movme_cp.24), (.L__pc.12024.ST)
	.L__pc.12024.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12025
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12025: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12026
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12026: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12027
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12027: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12028
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12028: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12029
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.12029: Dma_PatchSrc (.L__pc.12029.LD), (.L__movme_cp.66), (.L__pc.12029.LD)
	.p2align 4
	.L__pc.12029.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12030
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12030: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12031
	.L__pc.12031: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12032
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12032: Dma_PatchSrc (.L__pc.12032.LD), (.L__movme_cp.24), (.L__pc.12032.LD)
	.p2align 4
	.L__pc.12032.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12033
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12033: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.12034
	.L__pc.12034: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.12035
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12035: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12036: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12037: Dma_PatchSrc (.L__pc.12037.LD), (.L__movme_tmp.1), (.L__pc.12037.LD)
	.p2align 4
	.L__pc.12037.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12038
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12038: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12039
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.12039: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.12040: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.12041: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12042: Dma_PatchSrc (.L__pc.12042.LD), (.L__movme_tmp.1), (.L__pc.12042.LD)
	.p2align 4
	.L__pc.12042.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12043
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12043: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12044
	
	.L__pc.12044: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.12045
	
	.p2align 4
	.L__pc.12045: Dma_PatchDst (.L__pc.12045.ST), (.L__movme_cp.66), (.L__pc.12045.ST)
	.L__pc.12045.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12046
	
	.L__pc.12046: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.12047
	
	.p2align 4
	.L__pc.12047: Dma_PatchDst (.L__pc.12047.ST), (.L__movme_cp.24), (.L__pc.12047.ST)
	.L__pc.12047.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12048
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12048: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12049
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12049: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12050
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12050: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12051
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12051: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12052
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.12052: Dma_PatchSrc (.L__pc.12052.LD), (.L__movme_cp.67), (.L__pc.12052.LD)
	.p2align 4
	.L__pc.12052.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12053
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12053: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12054
	.L__pc.12054: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12055
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12055: Dma_PatchSrc (.L__pc.12055.LD), (.L__movme_cp.24), (.L__pc.12055.LD)
	.p2align 4
	.L__pc.12055.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12056
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12056: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.12057
	.L__pc.12057: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.12058
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12058: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12059: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12060: Dma_PatchSrc (.L__pc.12060.LD), (.L__movme_tmp.1), (.L__pc.12060.LD)
	.p2align 4
	.L__pc.12060.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12061
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12061: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12062
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.12062: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.12063: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.12064: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12065: Dma_PatchSrc (.L__pc.12065.LD), (.L__movme_tmp.1), (.L__pc.12065.LD)
	.p2align 4
	.L__pc.12065.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12066
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12066: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12067
	
	.L__pc.12067: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.12068
	
	.p2align 4
	.L__pc.12068: Dma_PatchDst (.L__pc.12068.ST), (.L__movme_cp.67), (.L__pc.12068.ST)
	.L__pc.12068.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12069
	
	.L__pc.12069: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.12070
	
	.p2align 4
	.L__pc.12070: Dma_PatchDst (.L__pc.12070.ST), (.L__movme_cp.24), (.L__pc.12070.ST)
	.L__pc.12070.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12071
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12071: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12072
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12072: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12073
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12073: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12074
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12074: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12075
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.12075: Dma_PatchSrc (.L__pc.12075.LD), (.L__movme_cp.68), (.L__pc.12075.LD)
	.p2align 4
	.L__pc.12075.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12076
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12076: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12077
	.L__pc.12077: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12078
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12078: Dma_PatchSrc (.L__pc.12078.LD), (.L__movme_cp.24), (.L__pc.12078.LD)
	.p2align 4
	.L__pc.12078.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12079
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12079: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.12080
	.L__pc.12080: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.12081
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12081: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12082: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12083: Dma_PatchSrc (.L__pc.12083.LD), (.L__movme_tmp.1), (.L__pc.12083.LD)
	.p2align 4
	.L__pc.12083.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12084
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12084: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12085
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.12085: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.12086: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.12087: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12088: Dma_PatchSrc (.L__pc.12088.LD), (.L__movme_tmp.1), (.L__pc.12088.LD)
	.p2align 4
	.L__pc.12088.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12089
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12089: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12090
	
	.L__pc.12090: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.12091
	
	.p2align 4
	.L__pc.12091: Dma_PatchDst (.L__pc.12091.ST), (.L__movme_cp.68), (.L__pc.12091.ST)
	.L__pc.12091.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12092
	
	.L__pc.12092: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.12093
	
	.p2align 4
	.L__pc.12093: Dma_PatchDst (.L__pc.12093.ST), (.L__movme_cp.24), (.L__pc.12093.ST)
	.L__pc.12093.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12094
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12094: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12095
	
	.p2align 4
	.L__pc.12095: Dma_PatchDst (.L__pc.12095.ST), (.L__movme_cp.24), (.L__pc.12095.ST)
	.L__pc.12095.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12096
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.12096: Dma_PatchSrc (.L__pc.12096.LD), (.L__movme_cp.60), (.L__pc.12096.LD)
	.p2align 4
	.L__pc.12096.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12097
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12097: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12098
	
	.L__pc.12098: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12099
	
	.p2align 4
	.L__pc.12099: Dma_PatchDst (.L__pc.12099.ST), (.L__movme_cp.21), (.L__pc.12099.ST)
	.L__pc.12099.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12100
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.12100: Dma_PatchSrc (.L__pc.12100.LD), (.L__movme_cp.58), (.L__pc.12100.LD)
	.p2align 4
	.L__pc.12100.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12101
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12101: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12102
	
	.L__pc.12102: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12103
	
	.p2align 4
	.L__pc.12103: Dma_PatchDst (.L__pc.12103.ST), (.L__movme_cp.22), (.L__pc.12103.ST)
	.L__pc.12103.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12104
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12104: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12105
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12105: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12106
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12106: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12107
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12107: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12108
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.12108: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.12109
	
	.p2align 4
	.L__pc.12109: Dma_PatchDst (.L__pc.12109.ST), (.L__movme_cp.24), (.L__pc.12109.ST)
	.L__pc.12109.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12110
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.12110: Dma_PatchSrc (.L__pc.12110.LD), (.L__movme_cp.25), (.L__pc.12110.LD)
	.p2align 4
	.L__pc.12110.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12111
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12111: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12112
	.L__pc.12112: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12113
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.12113: Dma_PatchSrc (.L__pc.12113.LD), (.L__movme_cp.26), (.L__pc.12113.LD)
	.p2align 4
	.L__pc.12113.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12114
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12114: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12115
	.L__pc.12115: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12116
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.12116: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12117: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12118: Dma_PatchSrc (.L__pc.12118.LD), (.L__movme_tmp.1), (.L__pc.12118.LD)
	.p2align 4
	.L__pc.12118.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12119
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12119: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12120
	.L__pc.12120: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12121
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12121: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12122: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12123: Dma_PatchSrc (.L__pc.12123.LD), (.L__movme_tmp.1), (.L__pc.12123.LD)
	.p2align 4
	.L__pc.12123.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12124
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12124: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12125
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12125: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12126: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12127: Dma_PatchSrc (.L__pc.12127.LD), (.L__movme_tmp.1), (.L__pc.12127.LD)
	.p2align 4
	.L__pc.12127.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12128
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12128: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12129
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12129: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12130: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12131: Dma_PatchSrc (.L__pc.12131.LD), (.L__movme_tmp.1), (.L__pc.12131.LD)
	.p2align 4
	.L__pc.12131.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12132
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12132: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12133
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12133: Dma_PatchSrc (.L__pc.12133.LD), (.L__movme_cp.24), (.L__pc.12133.LD)
	.p2align 4
	.L__pc.12133.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12134
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12134: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12135
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12135: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12136: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12137: Dma_PatchSrc (.L__pc.12137.LD), (.L__movme_tmp.1), (.L__pc.12137.LD)
	.p2align 4
	.L__pc.12137.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12138
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12138: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12139
	
	.L__pc.12139: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12140
	
	.p2align 4
	.L__pc.12140: Dma_PatchDst (.L__pc.12140.ST), (.L__movme_cp.69), (.L__pc.12140.ST)
	.L__pc.12140.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12141
	
	.L__pc.12141: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12142
	
	.p2align 4
	.L__pc.12142: Dma_PatchDst (.L__pc.12142.ST), (.L__movme_cp.54), (.L__pc.12142.ST)
	.L__pc.12142.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12143
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.12143: Dma_PatchSrc (.L__pc.12143.LD), (.L__movme_cp.30), (.L__pc.12143.LD)
	.p2align 4
	.L__pc.12143.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12144
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12144: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12145
	.L__pc.12145: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12146
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.12146: Dma_PatchSrc (.L__pc.12146.LD), (.L__movme_cp.31), (.L__pc.12146.LD)
	.p2align 4
	.L__pc.12146.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12147
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12147: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12148
	.L__pc.12148: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12149
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.12149: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12150: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12151: Dma_PatchSrc (.L__pc.12151.LD), (.L__movme_tmp.1), (.L__pc.12151.LD)
	.p2align 4
	.L__pc.12151.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12152
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12152: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12153
	.L__pc.12153: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12154
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12154: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12155: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12156: Dma_PatchSrc (.L__pc.12156.LD), (.L__movme_tmp.1), (.L__pc.12156.LD)
	.p2align 4
	.L__pc.12156.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12157
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12157: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12158
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12158: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12159: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12160: Dma_PatchSrc (.L__pc.12160.LD), (.L__movme_tmp.1), (.L__pc.12160.LD)
	.p2align 4
	.L__pc.12160.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12161
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12161: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12162
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12162: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12163: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12164: Dma_PatchSrc (.L__pc.12164.LD), (.L__movme_tmp.1), (.L__pc.12164.LD)
	.p2align 4
	.L__pc.12164.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12165
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12165: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12166
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12166: Dma_PatchSrc (.L__pc.12166.LD), (.L__movme_cp.24), (.L__pc.12166.LD)
	.p2align 4
	.L__pc.12166.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12167
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12167: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12168
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12168: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12169: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12170: Dma_PatchSrc (.L__pc.12170.LD), (.L__movme_tmp.1), (.L__pc.12170.LD)
	.p2align 4
	.L__pc.12170.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12171
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12171: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12172
	
	.L__pc.12172: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12173
	
	.p2align 4
	.L__pc.12173: Dma_PatchDst (.L__pc.12173.ST), (.L__movme_cp.70), (.L__pc.12173.ST)
	.L__pc.12173.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12174
	
	.L__pc.12174: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12175
	
	.p2align 4
	.L__pc.12175: Dma_PatchDst (.L__pc.12175.ST), (.L__movme_cp.54), (.L__pc.12175.ST)
	.L__pc.12175.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12176
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12176: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12177
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12177: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12178
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12178: Dma_PatchSrc (.L__pc.12178.LD), (.L__movme_cp.24), (.L__pc.12178.LD)
	.p2align 4
	.L__pc.12178.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12179
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12179: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12180
	.L__pc.12180: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12181
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.12181: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12182: Dma_PatchSrc (.L__pc.12182.LD), (.L__movme_tmp.1), (.L__pc.12182.LD)
	.p2align 4
	.L__pc.12182.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12183
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12183: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12184
	.L__pc.12184: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12185
	
	.L__pc.12185: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12186
	
	.p2align 4
	.L__pc.12186: Dma_PatchDst (.L__pc.12186.ST), (.L__movme_cp.72), (.L__pc.12186.ST)
	.L__pc.12186.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12187
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.12187: Dma_PatchSrc (.L__pc.12187.LD), (.L__movme_cp.72), (.L__pc.12187.LD)
	.p2align 4
	.L__pc.12187.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12188
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12188: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12189
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12189: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12190: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12191: Dma_PatchSrc (.L__pc.12191.LD), (.L__movme_tmp.1), (.L__pc.12191.LD)
	.p2align 4
	.L__pc.12191.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12192
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12192: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12193
	
	.L__pc.12193: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12194
	
	.p2align 4
	.L__pc.12194: Dma_PatchDst (.L__pc.12194.ST), (.L__movme_cp.74), (.L__pc.12194.ST)
	.L__pc.12194.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12195
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12195: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12196: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12197: Dma_PatchSrc (.L__pc.12197.LD), (.L__movme_tmp.1), (.L__pc.12197.LD)
	.p2align 4
	.L__pc.12197.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12198
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12198: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12199
	
	.L__pc.12199: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12200
	
	.p2align 4
	.L__pc.12200: Dma_PatchDst (.L__pc.12200.ST), (.L__movme_cp.76), (.L__pc.12200.ST)
	.L__pc.12200.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12201
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.12201: Dma_PatchSrc (.L__pc.12201.LD), (.L__movme_cp.74), (.L__pc.12201.LD)
	.p2align 4
	.L__pc.12201.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12202
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12202: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12203
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.12203: Dma_PatchSrc (.L__pc.12203.LD), ((.L__movme.reg.eax+0)), (.L__pc.12203.LD)
	.p2align 4
	.L__pc.12203.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12204
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12204: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12205
	
	.L__pc.12205: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12206
	
	.p2align 4
	.L__pc.12206: Dma_PatchDst (.L__pc.12206.ST), (.L__movme_cp.77), (.L__pc.12206.ST)
	.L__pc.12206.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12207
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.12207: Dma_PatchSrc (.L__pc.12207.LD), (.L__movme_cp.77), (.L__pc.12207.LD)
	.p2align 4
	.L__pc.12207.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12208
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12208: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12209
	
	.L__pc.12209: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12210
	
	.p2align 4
	.L__pc.12210: Dma_PatchDst (.L__pc.12210.ST), (.L__movme_cp.21), (.L__pc.12210.ST)
	.L__pc.12210.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12211
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.12211: Dma_PatchSrc (.L__pc.12211.LD), (.L__movme_cp.58), (.L__pc.12211.LD)
	.p2align 4
	.L__pc.12211.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12212
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12212: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12213
	
	.L__pc.12213: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12214
	
	.p2align 4
	.L__pc.12214: Dma_PatchDst (.L__pc.12214.ST), (.L__movme_cp.22), (.L__pc.12214.ST)
	.L__pc.12214.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12215
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12215: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12216
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12216: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12217
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12217: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12218
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12218: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12219
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.12219: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.12220
	
	.p2align 4
	.L__pc.12220: Dma_PatchDst (.L__pc.12220.ST), (.L__movme_cp.24), (.L__pc.12220.ST)
	.L__pc.12220.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12221
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.12221: Dma_PatchSrc (.L__pc.12221.LD), (.L__movme_cp.25), (.L__pc.12221.LD)
	.p2align 4
	.L__pc.12221.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12222
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12222: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12223
	.L__pc.12223: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12224
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.12224: Dma_PatchSrc (.L__pc.12224.LD), (.L__movme_cp.26), (.L__pc.12224.LD)
	.p2align 4
	.L__pc.12224.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12225
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12225: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12226
	.L__pc.12226: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12227
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.12227: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12228: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12229: Dma_PatchSrc (.L__pc.12229.LD), (.L__movme_tmp.1), (.L__pc.12229.LD)
	.p2align 4
	.L__pc.12229.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12230
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12230: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12231
	.L__pc.12231: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12232
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12232: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12233: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12234: Dma_PatchSrc (.L__pc.12234.LD), (.L__movme_tmp.1), (.L__pc.12234.LD)
	.p2align 4
	.L__pc.12234.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12235
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12235: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12236
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12236: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12237: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12238: Dma_PatchSrc (.L__pc.12238.LD), (.L__movme_tmp.1), (.L__pc.12238.LD)
	.p2align 4
	.L__pc.12238.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12239
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12239: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12240
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12240: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12241: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12242: Dma_PatchSrc (.L__pc.12242.LD), (.L__movme_tmp.1), (.L__pc.12242.LD)
	.p2align 4
	.L__pc.12242.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12243
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12243: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12244
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12244: Dma_PatchSrc (.L__pc.12244.LD), (.L__movme_cp.24), (.L__pc.12244.LD)
	.p2align 4
	.L__pc.12244.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12245
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12245: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12246
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12246: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12247: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12248: Dma_PatchSrc (.L__pc.12248.LD), (.L__movme_tmp.1), (.L__pc.12248.LD)
	.p2align 4
	.L__pc.12248.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12249
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12249: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12250
	
	.L__pc.12250: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12251
	
	.p2align 4
	.L__pc.12251: Dma_PatchDst (.L__pc.12251.ST), (.L__movme_cp.78), (.L__pc.12251.ST)
	.L__pc.12251.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12252
	
	.L__pc.12252: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12253
	
	.p2align 4
	.L__pc.12253: Dma_PatchDst (.L__pc.12253.ST), (.L__movme_cp.54), (.L__pc.12253.ST)
	.L__pc.12253.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12254
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.12254: Dma_PatchSrc (.L__pc.12254.LD), (.L__movme_cp.30), (.L__pc.12254.LD)
	.p2align 4
	.L__pc.12254.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12255
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12255: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12256
	.L__pc.12256: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12257
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.12257: Dma_PatchSrc (.L__pc.12257.LD), (.L__movme_cp.31), (.L__pc.12257.LD)
	.p2align 4
	.L__pc.12257.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12258
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12258: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12259
	.L__pc.12259: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12260
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.12260: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12261: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12262: Dma_PatchSrc (.L__pc.12262.LD), (.L__movme_tmp.1), (.L__pc.12262.LD)
	.p2align 4
	.L__pc.12262.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12263
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12263: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12264
	.L__pc.12264: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12265
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12265: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12266: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12267: Dma_PatchSrc (.L__pc.12267.LD), (.L__movme_tmp.1), (.L__pc.12267.LD)
	.p2align 4
	.L__pc.12267.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12268
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12268: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12269
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12269: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12270: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12271: Dma_PatchSrc (.L__pc.12271.LD), (.L__movme_tmp.1), (.L__pc.12271.LD)
	.p2align 4
	.L__pc.12271.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12272
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12272: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12273
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12273: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12274: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12275: Dma_PatchSrc (.L__pc.12275.LD), (.L__movme_tmp.1), (.L__pc.12275.LD)
	.p2align 4
	.L__pc.12275.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12276
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12276: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12277
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12277: Dma_PatchSrc (.L__pc.12277.LD), (.L__movme_cp.24), (.L__pc.12277.LD)
	.p2align 4
	.L__pc.12277.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12278
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12278: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12279
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12279: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12280: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12281: Dma_PatchSrc (.L__pc.12281.LD), (.L__movme_tmp.1), (.L__pc.12281.LD)
	.p2align 4
	.L__pc.12281.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12282
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12282: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12283
	
	.L__pc.12283: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12284
	
	.p2align 4
	.L__pc.12284: Dma_PatchDst (.L__pc.12284.ST), (.L__movme_cp.79), (.L__pc.12284.ST)
	.L__pc.12284.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12285
	
	.L__pc.12285: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12286
	
	.p2align 4
	.L__pc.12286: Dma_PatchDst (.L__pc.12286.ST), (.L__movme_cp.54), (.L__pc.12286.ST)
	.L__pc.12286.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12287
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.12287: Dma_PatchSrc (.L__pc.12287.LD), (.L__movme_cp.74), (.L__pc.12287.LD)
	.p2align 4
	.L__pc.12287.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12288
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12288: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12289
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.12289: Dma_PatchSrc (.L__pc.12289.LD), (.L__movme_cp.77), (.L__pc.12289.LD)
	.p2align 4
	.L__pc.12289.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12290
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12290: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12291
	
	.L__pc.12291: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12292
	
	.p2align 4
	.L__pc.12292: Dma_PatchDst (.L__pc.12292.ST), ((.L__movme.reg.eax+0)), (.L__pc.12292.ST)
	.L__pc.12292.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12293
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.12293: Dma_PatchSrc (.L__pc.12293.LD), (.L__movme_cp.76), (.L__pc.12293.LD)
	.p2align 4
	.L__pc.12293.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12294
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12294: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12295
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.12295: Dma_PatchSrc (.L__pc.12295.LD), ((.L__movme.reg.eax+0)), (.L__pc.12295.LD)
	.p2align 4
	.L__pc.12295.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12296
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12296: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12297
	
	.L__pc.12297: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12298
	
	.p2align 4
	.L__pc.12298: Dma_PatchDst (.L__pc.12298.ST), (.L__movme_cp.80), (.L__pc.12298.ST)
	.L__pc.12298.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12299
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12299: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12300
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12300: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12301
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.12301: Dma_PatchSrc (.L__pc.12301.LD), (.L__movme_cp.102), (.L__pc.12301.LD)
	.p2align 4
	.L__pc.12301.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12302
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12302: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12303
	.L__pc.12303: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12304
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.96 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.12304: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12305: Dma_PatchSrc (.L__pc.12305.LD), (.L__movme_tmp.1), (.L__pc.12305.LD)
	.p2align 4
	.L__pc.12305.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12306
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12306: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12307
	.L__pc.12307: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12308
	
	.L__pc.12308: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.12309
	
	.p2align 4
	.L__pc.12309: Dma_PatchDst (.L__pc.12309.ST), (.L__movme_cp.102), (.L__pc.12309.ST)
	.L__pc.12309.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12310
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.12310: Dma_PatchSrc (.L__pc.12310.LD), (.L__movme_cp.76), (.L__pc.12310.LD)
	.p2align 4
	.L__pc.12310.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12311
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12311: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12312
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.12312: Dma_PatchSrc (.L__pc.12312.LD), (.L__movme_cp.80), (.L__pc.12312.LD)
	.p2align 4
	.L__pc.12312.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12313
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12313: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12314
	
	.L__pc.12314: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12315
	
	.p2align 4
	.L__pc.12315: Dma_PatchDst (.L__pc.12315.ST), ((.L__movme.reg.eax+0)), (.L__pc.12315.ST)
	.L__pc.12315.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12316
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.12316: Dma_PatchSrc (.L__pc.12316.LD), (.L__movme_cp.60), (.L__pc.12316.LD)
	.p2align 4
	.L__pc.12316.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12317
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12317: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12318
	
	.L__pc.12318: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12319
	
	.p2align 4
	.L__pc.12319: Dma_PatchDst (.L__pc.12319.ST), (.L__movme_cp.8), (.L__pc.12319.ST)
	.L__pc.12319.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12320
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.12320: Dma_PatchSrc (.L__pc.12320.LD), (.L__movme_cp.8), (.L__pc.12320.LD)
	.p2align 4
	.L__pc.12320.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12321
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12321: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12322
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.12322: Dma_PatchSrc (.L__pc.12322.LD), (.L__movme_cp.9), (.L__pc.12322.LD)
	.p2align 4
	.L__pc.12322.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12323
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12323: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12324
	
	.L__pc.12324: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12325
	
	.p2align 4
	.L__pc.12325: Dma_PatchDst (.L__pc.12325.ST), (.L__movme_cp.21), (.L__pc.12325.ST)
	.L__pc.12325.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12326
	
	.L__pc.12326: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12327
	
	.p2align 4
	.L__pc.12327: Dma_PatchDst (.L__pc.12327.ST), (.L__movme_cp.22), (.L__pc.12327.ST)
	.L__pc.12327.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12328
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12328: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12329
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12329: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12330
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12330: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12331
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12331: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12332
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12332: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12333
	
	.p2align 4
	.L__pc.12333: Dma_PatchDst (.L__pc.12333.ST), (.L__movme_cp.24), (.L__pc.12333.ST)
	.L__pc.12333.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12334
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.12334: Dma_PatchSrc (.L__pc.12334.LD), (.L__movme_cp.25), (.L__pc.12334.LD)
	.p2align 4
	.L__pc.12334.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12335
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12335: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12336
	.L__pc.12336: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12337
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.12337: Dma_PatchSrc (.L__pc.12337.LD), (.L__movme_cp.26), (.L__pc.12337.LD)
	.p2align 4
	.L__pc.12337.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12338
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12338: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12339
	.L__pc.12339: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12340
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12340: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12341: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12342: Dma_PatchSrc (.L__pc.12342.LD), (.L__movme_tmp.1), (.L__pc.12342.LD)
	.p2align 4
	.L__pc.12342.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12343
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12343: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12344
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12344: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12345: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12346: Dma_PatchSrc (.L__pc.12346.LD), (.L__movme_tmp.1), (.L__pc.12346.LD)
	.p2align 4
	.L__pc.12346.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12347
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12347: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12348
	
	// CG.LOAD4 [.L__movme_cp.28} => .L__movme_tmp.0
	.L__pc.12348: Dma_PatchSrc (.L__pc.12348.LD), (.L__movme_cp.28), (.L__pc.12348.LD)
	.p2align 4
	.L__pc.12348.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12349
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12349: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12350
	.L__pc.12350: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12351
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12351: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12352: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12353: Dma_PatchSrc (.L__pc.12353.LD), (.L__movme_tmp.1), (.L__pc.12353.LD)
	.p2align 4
	.L__pc.12353.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12354
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12354: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12355
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12355: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12356: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12357: Dma_PatchSrc (.L__pc.12357.LD), (.L__movme_tmp.1), (.L__pc.12357.LD)
	.p2align 4
	.L__pc.12357.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12358
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12358: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12359
	
	.L__pc.12359: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12360
	
	.p2align 4
	.L__pc.12360: Dma_PatchDst (.L__pc.12360.ST), (.L__movme_cp.29), (.L__pc.12360.ST)
	.L__pc.12360.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12361
	
	.L__pc.12361: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12362
	
	.p2align 4
	.L__pc.12362: Dma_PatchDst (.L__pc.12362.ST), (.L__movme_cp.24), (.L__pc.12362.ST)
	.L__pc.12362.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12363
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.12363: Dma_PatchSrc (.L__pc.12363.LD), (.L__movme_cp.30), (.L__pc.12363.LD)
	.p2align 4
	.L__pc.12363.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12364
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12364: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12365
	.L__pc.12365: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12366
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.12366: Dma_PatchSrc (.L__pc.12366.LD), (.L__movme_cp.31), (.L__pc.12366.LD)
	.p2align 4
	.L__pc.12366.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12367
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12367: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12368
	.L__pc.12368: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12369
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12369: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12370: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12371: Dma_PatchSrc (.L__pc.12371.LD), (.L__movme_tmp.1), (.L__pc.12371.LD)
	.p2align 4
	.L__pc.12371.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12372
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12372: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12373
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12373: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12374: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12375: Dma_PatchSrc (.L__pc.12375.LD), (.L__movme_tmp.1), (.L__pc.12375.LD)
	.p2align 4
	.L__pc.12375.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12376
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12376: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12377
	
	// CG.LOAD4 [.L__movme_cp.28} => .L__movme_tmp.0
	.L__pc.12377: Dma_PatchSrc (.L__pc.12377.LD), (.L__movme_cp.28), (.L__pc.12377.LD)
	.p2align 4
	.L__pc.12377.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12378
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12378: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12379
	.L__pc.12379: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12380
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12380: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12381: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12382: Dma_PatchSrc (.L__pc.12382.LD), (.L__movme_tmp.1), (.L__pc.12382.LD)
	.p2align 4
	.L__pc.12382.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12383
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12383: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12384
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12384: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12385: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12386: Dma_PatchSrc (.L__pc.12386.LD), (.L__movme_tmp.1), (.L__pc.12386.LD)
	.p2align 4
	.L__pc.12386.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12387
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12387: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12388
	
	.L__pc.12388: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12389
	
	.p2align 4
	.L__pc.12389: Dma_PatchDst (.L__pc.12389.ST), (.L__movme_cp.32), (.L__pc.12389.ST)
	.L__pc.12389.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12390
	
	.L__pc.12390: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12391
	
	.p2align 4
	.L__pc.12391: Dma_PatchDst (.L__pc.12391.ST), (.L__movme_cp.24), (.L__pc.12391.ST)
	.L__pc.12391.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12392
	
	// CG.LOAD4 [.L__movme_cp.33} => .L__movme_tmp.0
	.L__pc.12392: Dma_PatchSrc (.L__pc.12392.LD), (.L__movme_cp.33), (.L__pc.12392.LD)
	.p2align 4
	.L__pc.12392.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12393
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12393: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12394
	
	.L__pc.12394: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12395
	
	.p2align 4
	.L__pc.12395: Dma_PatchDst (.L__pc.12395.ST), (.L__movme_cp.9), (.L__pc.12395.ST)
	.L__pc.12395.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12396
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.12396: Dma_PatchSrc (.L__pc.12396.LD), (.L__movme_cp.0), (.L__pc.12396.LD)
	.p2align 4
	.L__pc.12396.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12397
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12397: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12398
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.12398: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12399: Dma_PatchSrc (.L__pc.12399.LD), (.L__movme_tmp.1), (.L__pc.12399.LD)
	.p2align 4
	.L__pc.12399.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12400
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12400: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12401
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.12401: Dma_PatchSrc (.L__pc.12401.LD), (.L__movme_cp.3), (.L__pc.12401.LD)
	.p2align 4
	.L__pc.12401.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12402
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12402: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12403
	
	.L__pc.12403: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12404
	
	.p2align 4
	.L__pc.12404: Dma_PatchDst (.L__pc.12404.ST), (.L__movme_cp.4), (.L__pc.12404.ST)
	.L__pc.12404.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12405
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12405: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12406: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12407: Dma_PatchSrc (.L__pc.12407.LD), (.L__movme_tmp.1), (.L__pc.12407.LD)
	.p2align 4
	.L__pc.12407.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12408
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12408: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12409
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.12409: Dma_PatchSrc (.L__pc.12409.LD), (.L__movme_cp.9), (.L__pc.12409.LD)
	.p2align 4
	.L__pc.12409.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12410
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12410: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12411
	
	.L__pc.12411: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12412
	
	.p2align 4
	.L__pc.12412: Dma_PatchDst (.L__pc.12412.ST), ((.L__movme.reg.eax+0)), (.L__pc.12412.ST)
	.L__pc.12412.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12413
	
	// JMP imm.4(.LCI15)
	.L__pc.12413: Dma_PatchLink (.L__pc.12413.J), (.L__movme_cp.103), (.L__pc.12413.J)
	.p2align 4
	.L__pc.12413.J: Dma_ByteCopy  (.L__movme_tmp.0), (.L__movme_tmp.0), 1, .L__pc.12414
	
	// LABEL .LCI14
	.LCI14:
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.12414: Dma_PatchSrc (.L__pc.12414.LD), (.L__movme_cp.0), (.L__pc.12414.LD)
	.p2align 4
	.L__pc.12414.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12415
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12415: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12416
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.12416: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12417: Dma_PatchSrc (.L__pc.12417.LD), (.L__movme_tmp.1), (.L__pc.12417.LD)
	.p2align 4
	.L__pc.12417.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12418
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12418: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12419
	
	.L__pc.12419: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12420
	
	.p2align 4
	.L__pc.12420: Dma_PatchDst (.L__pc.12420.ST), (.L__movme_cp.9), (.L__pc.12420.ST)
	.L__pc.12420.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12421
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.12421: Dma_PatchSrc (.L__pc.12421.LD), (.L__movme_cp.9), (.L__pc.12421.LD)
	.p2align 4
	.L__pc.12421.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12422
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12422: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12423
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.12423: Dma_PatchSrc (.L__pc.12423.LD), (.L__movme_cp.3), (.L__pc.12423.LD)
	.p2align 4
	.L__pc.12423.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12424
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12424: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12425
	
	.L__pc.12425: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12426
	
	.p2align 4
	.L__pc.12426: Dma_PatchDst (.L__pc.12426.ST), (.L__movme_cp.4), (.L__pc.12426.ST)
	.L__pc.12426.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12427
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12427: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12428: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12429: Dma_PatchSrc (.L__pc.12429.LD), (.L__movme_tmp.1), (.L__pc.12429.LD)
	.p2align 4
	.L__pc.12429.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12430
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12430: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12431
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.12431: Dma_PatchSrc (.L__pc.12431.LD), ((.L__movme.reg.eax+0)), (.L__pc.12431.LD)
	.p2align 4
	.L__pc.12431.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12432
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12432: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12433
	
	.L__pc.12433: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12434
	
	.p2align 4
	.L__pc.12434: Dma_PatchDst (.L__pc.12434.ST), (.L__movme_cp.9), (.L__pc.12434.ST)
	.L__pc.12434.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12435
	
	// CG.COPY4 .L__movme_cp.104 => .L__movme_tmp.0
	.L__pc.12435: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.104), 4, .L__pc.12436
	
	.p2align 4
	.L__pc.12436: Dma_PatchDst (.L__pc.12436.ST), (.L__movme_cp.8), (.L__pc.12436.ST)
	.L__pc.12436.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12437
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.12437: Dma_PatchSrc (.L__pc.12437.LD), (.L__movme_cp.9), (.L__pc.12437.LD)
	.p2align 4
	.L__pc.12437.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12438
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12438: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12439
	
	// CG.UNIMPLEMENTED: CMP.4 mem.4(imm.4(R2)) ?= reg.4(eax)
	.L__pc.12439: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: COND JMP jb TO imm.4(.LCI16)
	.L__pc.12440: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.COPY4 .L__movme_cp.105 => .L__movme_tmp.0
	.L__pc.12441: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.105), 4, .L__pc.12442
	
	.p2align 4
	.L__pc.12442: Dma_PatchDst (.L__pc.12442.ST), (.L__movme_cp.8), (.L__pc.12442.ST)
	.L__pc.12442.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12443
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.12443: Dma_PatchSrc (.L__pc.12443.LD), (.L__movme_cp.9), (.L__pc.12443.LD)
	.p2align 4
	.L__pc.12443.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12444
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12444: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12445
	
	// CG.UNIMPLEMENTED: CMP.4 mem.4(imm.4(R2)) ?= reg.4(eax)
	.L__pc.12445: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: COND JMP ja TO imm.4(.LCI16)
	.L__pc.12446: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.COPY4 .L__movme_cp.104 => .L__movme_tmp.0
	.L__pc.12447: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.104), 4, .L__pc.12448
	
	.p2align 4
	.L__pc.12448: Dma_PatchDst (.L__pc.12448.ST), (.L__movme_cp.9), (.L__pc.12448.ST)
	.L__pc.12448.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12449
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.12449: Dma_PatchSrc (.L__pc.12449.LD), (.L__movme_cp.0), (.L__pc.12449.LD)
	.p2align 4
	.L__pc.12449.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12450
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12450: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12451
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.12451: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12452: Dma_PatchSrc (.L__pc.12452.LD), (.L__movme_tmp.1), (.L__pc.12452.LD)
	.p2align 4
	.L__pc.12452.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12453
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12453: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12454
	
	.L__pc.12454: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12455
	
	.p2align 4
	.L__pc.12455: Dma_PatchDst (.L__pc.12455.ST), (.L__movme_cp.8), (.L__pc.12455.ST)
	.L__pc.12455.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12456
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.12456: Dma_PatchSrc (.L__pc.12456.LD), (.L__movme_cp.8), (.L__pc.12456.LD)
	.p2align 4
	.L__pc.12456.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12457
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12457: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12458
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.12458: Dma_PatchSrc (.L__pc.12458.LD), (.L__movme_cp.3), (.L__pc.12458.LD)
	.p2align 4
	.L__pc.12458.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12459
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12459: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12460
	
	.L__pc.12460: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12461
	
	.p2align 4
	.L__pc.12461: Dma_PatchDst (.L__pc.12461.ST), (.L__movme_cp.4), (.L__pc.12461.ST)
	.L__pc.12461.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12462
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12462: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12463: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12464: Dma_PatchSrc (.L__pc.12464.LD), (.L__movme_tmp.1), (.L__pc.12464.LD)
	.p2align 4
	.L__pc.12464.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12465
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12465: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12466
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.12466: Dma_PatchSrc (.L__pc.12466.LD), ((.L__movme.reg.eax+0)), (.L__pc.12466.LD)
	.p2align 4
	.L__pc.12466.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12467
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12467: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12468
	
	.L__pc.12468: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12469
	
	.p2align 4
	.L__pc.12469: Dma_PatchDst (.L__pc.12469.ST), (.L__movme_cp.8), (.L__pc.12469.ST)
	.L__pc.12469.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12470
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.12470: Dma_PatchSrc (.L__pc.12470.LD), (.L__movme_cp.8), (.L__pc.12470.LD)
	.p2align 4
	.L__pc.12470.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12471
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12471: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12472
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.12472: Dma_PatchSrc (.L__pc.12472.LD), (.L__movme_cp.9), (.L__pc.12472.LD)
	.p2align 4
	.L__pc.12472.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12473
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12473: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12474
	
	.L__pc.12474: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12475
	
	.p2align 4
	.L__pc.12475: Dma_PatchDst (.L__pc.12475.ST), (.L__movme_cp.21), (.L__pc.12475.ST)
	.L__pc.12475.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12476
	
	.L__pc.12476: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12477
	
	.p2align 4
	.L__pc.12477: Dma_PatchDst (.L__pc.12477.ST), (.L__movme_cp.22), (.L__pc.12477.ST)
	.L__pc.12477.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12478
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12478: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12479
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12479: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12480
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12480: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12481
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12481: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12482
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.12482: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.12483
	
	.p2align 4
	.L__pc.12483: Dma_PatchDst (.L__pc.12483.ST), (.L__movme_cp.24), (.L__pc.12483.ST)
	.L__pc.12483.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12484
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.12484: Dma_PatchSrc (.L__pc.12484.LD), (.L__movme_cp.25), (.L__pc.12484.LD)
	.p2align 4
	.L__pc.12484.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12485
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12485: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12486
	.L__pc.12486: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12487
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.12487: Dma_PatchSrc (.L__pc.12487.LD), (.L__movme_cp.26), (.L__pc.12487.LD)
	.p2align 4
	.L__pc.12487.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12488
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12488: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12489
	.L__pc.12489: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12490
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.12490: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12491: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12492: Dma_PatchSrc (.L__pc.12492.LD), (.L__movme_tmp.1), (.L__pc.12492.LD)
	.p2align 4
	.L__pc.12492.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12493
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12493: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12494
	.L__pc.12494: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12495
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12495: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12496: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12497: Dma_PatchSrc (.L__pc.12497.LD), (.L__movme_tmp.1), (.L__pc.12497.LD)
	.p2align 4
	.L__pc.12497.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12498
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12498: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12499
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12499: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12500: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12501: Dma_PatchSrc (.L__pc.12501.LD), (.L__movme_tmp.1), (.L__pc.12501.LD)
	.p2align 4
	.L__pc.12501.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12502
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12502: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12503
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12503: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12504: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12505: Dma_PatchSrc (.L__pc.12505.LD), (.L__movme_tmp.1), (.L__pc.12505.LD)
	.p2align 4
	.L__pc.12505.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12506
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12506: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12507
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12507: Dma_PatchSrc (.L__pc.12507.LD), (.L__movme_cp.24), (.L__pc.12507.LD)
	.p2align 4
	.L__pc.12507.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12508
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12508: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12509
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12509: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12510: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12511: Dma_PatchSrc (.L__pc.12511.LD), (.L__movme_tmp.1), (.L__pc.12511.LD)
	.p2align 4
	.L__pc.12511.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12512
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12512: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12513
	
	.L__pc.12513: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12514
	
	.p2align 4
	.L__pc.12514: Dma_PatchDst (.L__pc.12514.ST), (.L__movme_cp.29), (.L__pc.12514.ST)
	.L__pc.12514.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12515
	
	.L__pc.12515: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12516
	
	.p2align 4
	.L__pc.12516: Dma_PatchDst (.L__pc.12516.ST), (.L__movme_cp.54), (.L__pc.12516.ST)
	.L__pc.12516.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12517
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.12517: Dma_PatchSrc (.L__pc.12517.LD), (.L__movme_cp.30), (.L__pc.12517.LD)
	.p2align 4
	.L__pc.12517.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12518
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12518: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12519
	.L__pc.12519: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12520
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.12520: Dma_PatchSrc (.L__pc.12520.LD), (.L__movme_cp.31), (.L__pc.12520.LD)
	.p2align 4
	.L__pc.12520.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12521
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12521: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12522
	.L__pc.12522: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12523
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.12523: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12524: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12525: Dma_PatchSrc (.L__pc.12525.LD), (.L__movme_tmp.1), (.L__pc.12525.LD)
	.p2align 4
	.L__pc.12525.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12526
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12526: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12527
	.L__pc.12527: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12528
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12528: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12529: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12530: Dma_PatchSrc (.L__pc.12530.LD), (.L__movme_tmp.1), (.L__pc.12530.LD)
	.p2align 4
	.L__pc.12530.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12531
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12531: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12532
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12532: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12533: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12534: Dma_PatchSrc (.L__pc.12534.LD), (.L__movme_tmp.1), (.L__pc.12534.LD)
	.p2align 4
	.L__pc.12534.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12535
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12535: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12536
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12536: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12537: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12538: Dma_PatchSrc (.L__pc.12538.LD), (.L__movme_tmp.1), (.L__pc.12538.LD)
	.p2align 4
	.L__pc.12538.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12539
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12539: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12540
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12540: Dma_PatchSrc (.L__pc.12540.LD), (.L__movme_cp.24), (.L__pc.12540.LD)
	.p2align 4
	.L__pc.12540.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12541
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12541: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12542
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12542: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12543: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12544: Dma_PatchSrc (.L__pc.12544.LD), (.L__movme_tmp.1), (.L__pc.12544.LD)
	.p2align 4
	.L__pc.12544.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12545
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12545: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12546
	
	.L__pc.12546: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12547
	
	.p2align 4
	.L__pc.12547: Dma_PatchDst (.L__pc.12547.ST), (.L__movme_cp.32), (.L__pc.12547.ST)
	.L__pc.12547.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12548
	
	.L__pc.12548: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12549
	
	.p2align 4
	.L__pc.12549: Dma_PatchDst (.L__pc.12549.ST), (.L__movme_cp.54), (.L__pc.12549.ST)
	.L__pc.12549.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12550
	
	// CG.LOAD4 [.L__movme_cp.33} => .L__movme_tmp.0
	.L__pc.12550: Dma_PatchSrc (.L__pc.12550.LD), (.L__movme_cp.33), (.L__pc.12550.LD)
	.p2align 4
	.L__pc.12550.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12551
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12551: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12552
	
	.L__pc.12552: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12553
	
	.p2align 4
	.L__pc.12553: Dma_PatchDst (.L__pc.12553.ST), (.L__movme_cp.8), (.L__pc.12553.ST)
	.L__pc.12553.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12554
	
	// CG.COPY4 .L__movme_cp.55 => .L__movme_tmp.0
	.L__pc.12554: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.55), 4, .L__pc.12555
	
	.p2align 4
	.L__pc.12555: Dma_PatchDst (.L__pc.12555.ST), (.L__movme_cp.7), (.L__pc.12555.ST)
	.L__pc.12555.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12556
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.12556: Dma_PatchSrc (.L__pc.12556.LD), (.L__movme_cp.8), (.L__pc.12556.LD)
	.p2align 4
	.L__pc.12556.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12557
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12557: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12558
	
	// CG.LOAD4 [.L__movme_cp.7} => .L__movme_tmp.0
	.L__pc.12558: Dma_PatchSrc (.L__pc.12558.LD), (.L__movme_cp.7), (.L__pc.12558.LD)
	.p2align 4
	.L__pc.12558.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12559
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12559: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12560
	
	.L__pc.12560: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12561
	
	.p2align 4
	.L__pc.12561: Dma_PatchDst (.L__pc.12561.ST), (.L__movme_cp.21), (.L__pc.12561.ST)
	.L__pc.12561.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12562
	
	.L__pc.12562: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12563
	
	.p2align 4
	.L__pc.12563: Dma_PatchDst (.L__pc.12563.ST), (.L__movme_cp.22), (.L__pc.12563.ST)
	.L__pc.12563.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12564
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12564: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12565
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12565: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12566
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12566: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12567
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12567: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12568
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12568: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12569
	
	.p2align 4
	.L__pc.12569: Dma_PatchDst (.L__pc.12569.ST), (.L__movme_cp.24), (.L__pc.12569.ST)
	.L__pc.12569.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12570
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.12570: Dma_PatchSrc (.L__pc.12570.LD), (.L__movme_cp.25), (.L__pc.12570.LD)
	.p2align 4
	.L__pc.12570.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12571
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12571: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12572
	.L__pc.12572: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12573
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.12573: Dma_PatchSrc (.L__pc.12573.LD), (.L__movme_cp.26), (.L__pc.12573.LD)
	.p2align 4
	.L__pc.12573.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12574
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12574: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12575
	.L__pc.12575: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12576
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12576: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12577: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12578: Dma_PatchSrc (.L__pc.12578.LD), (.L__movme_tmp.1), (.L__pc.12578.LD)
	.p2align 4
	.L__pc.12578.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12579
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12579: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12580
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12580: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12581: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12582: Dma_PatchSrc (.L__pc.12582.LD), (.L__movme_tmp.1), (.L__pc.12582.LD)
	.p2align 4
	.L__pc.12582.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12583
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12583: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12584
	
	// CG.LOAD4 [.L__movme_cp.28} => .L__movme_tmp.0
	.L__pc.12584: Dma_PatchSrc (.L__pc.12584.LD), (.L__movme_cp.28), (.L__pc.12584.LD)
	.p2align 4
	.L__pc.12584.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12585
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12585: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12586
	.L__pc.12586: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12587
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12587: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12588: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12589: Dma_PatchSrc (.L__pc.12589.LD), (.L__movme_tmp.1), (.L__pc.12589.LD)
	.p2align 4
	.L__pc.12589.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12590
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12590: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12591
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12591: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12592: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12593: Dma_PatchSrc (.L__pc.12593.LD), (.L__movme_tmp.1), (.L__pc.12593.LD)
	.p2align 4
	.L__pc.12593.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12594
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12594: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12595
	
	.L__pc.12595: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12596
	
	.p2align 4
	.L__pc.12596: Dma_PatchDst (.L__pc.12596.ST), (.L__movme_cp.29), (.L__pc.12596.ST)
	.L__pc.12596.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12597
	
	.L__pc.12597: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12598
	
	.p2align 4
	.L__pc.12598: Dma_PatchDst (.L__pc.12598.ST), (.L__movme_cp.24), (.L__pc.12598.ST)
	.L__pc.12598.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12599
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.12599: Dma_PatchSrc (.L__pc.12599.LD), (.L__movme_cp.30), (.L__pc.12599.LD)
	.p2align 4
	.L__pc.12599.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12600
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12600: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12601
	.L__pc.12601: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12602
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.12602: Dma_PatchSrc (.L__pc.12602.LD), (.L__movme_cp.31), (.L__pc.12602.LD)
	.p2align 4
	.L__pc.12602.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12603
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12603: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12604
	.L__pc.12604: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12605
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12605: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12606: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12607: Dma_PatchSrc (.L__pc.12607.LD), (.L__movme_tmp.1), (.L__pc.12607.LD)
	.p2align 4
	.L__pc.12607.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12608
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12608: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12609
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12609: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12610: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12611: Dma_PatchSrc (.L__pc.12611.LD), (.L__movme_tmp.1), (.L__pc.12611.LD)
	.p2align 4
	.L__pc.12611.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12612
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12612: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12613
	
	// CG.LOAD4 [.L__movme_cp.28} => .L__movme_tmp.0
	.L__pc.12613: Dma_PatchSrc (.L__pc.12613.LD), (.L__movme_cp.28), (.L__pc.12613.LD)
	.p2align 4
	.L__pc.12613.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12614
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12614: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12615
	.L__pc.12615: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12616
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12616: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12617: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12618: Dma_PatchSrc (.L__pc.12618.LD), (.L__movme_tmp.1), (.L__pc.12618.LD)
	.p2align 4
	.L__pc.12618.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12619
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12619: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12620
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12620: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12621: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12622: Dma_PatchSrc (.L__pc.12622.LD), (.L__movme_tmp.1), (.L__pc.12622.LD)
	.p2align 4
	.L__pc.12622.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12623
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12623: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12624
	
	.L__pc.12624: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12625
	
	.p2align 4
	.L__pc.12625: Dma_PatchDst (.L__pc.12625.ST), (.L__movme_cp.32), (.L__pc.12625.ST)
	.L__pc.12625.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12626
	
	.L__pc.12626: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12627
	
	.p2align 4
	.L__pc.12627: Dma_PatchDst (.L__pc.12627.ST), (.L__movme_cp.24), (.L__pc.12627.ST)
	.L__pc.12627.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12628
	
	// CG.LOAD4 [.L__movme_cp.33} => .L__movme_tmp.0
	.L__pc.12628: Dma_PatchSrc (.L__pc.12628.LD), (.L__movme_cp.33), (.L__pc.12628.LD)
	.p2align 4
	.L__pc.12628.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12629
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12629: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12630
	
	.L__pc.12630: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12631
	
	.p2align 4
	.L__pc.12631: Dma_PatchDst (.L__pc.12631.ST), (.L__movme_cp.8), (.L__pc.12631.ST)
	.L__pc.12631.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12632
	
	// CG.COPY4 .L__movme_cp.56 => .L__movme_tmp.0
	.L__pc.12632: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.56), 4, .L__pc.12633
	
	.p2align 4
	.L__pc.12633: Dma_PatchDst (.L__pc.12633.ST), (.L__movme_cp.7), (.L__pc.12633.ST)
	.L__pc.12633.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12634
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.12634: Dma_PatchSrc (.L__pc.12634.LD), (.L__movme_cp.8), (.L__pc.12634.LD)
	.p2align 4
	.L__pc.12634.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12635
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12635: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12636
	
	// CG.LOAD4 [.L__movme_cp.7} => .L__movme_tmp.0
	.L__pc.12636: Dma_PatchSrc (.L__pc.12636.LD), (.L__movme_cp.7), (.L__pc.12636.LD)
	.p2align 4
	.L__pc.12636.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12637
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12637: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12638
	
	.L__pc.12638: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12639
	
	.p2align 4
	.L__pc.12639: Dma_PatchDst (.L__pc.12639.ST), (.L__movme_cp.57), (.L__pc.12639.ST)
	.L__pc.12639.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12640
	
	.L__pc.12640: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12641
	
	.p2align 4
	.L__pc.12641: Dma_PatchDst (.L__pc.12641.ST), (.L__movme_cp.58), (.L__pc.12641.ST)
	.L__pc.12641.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12642
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12642: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12643
	
	.p2align 4
	.L__pc.12643: Dma_PatchDst (.L__pc.12643.ST), (.L__movme_cp.59), (.L__pc.12643.ST)
	.L__pc.12643.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12644
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12644: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12645
	
	.p2align 4
	.L__pc.12645: Dma_PatchDst (.L__pc.12645.ST), (.L__movme_cp.60), (.L__pc.12645.ST)
	.L__pc.12645.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12646
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12646: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12647
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12647: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12648
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.12648: Dma_PatchSrc (.L__pc.12648.LD), (.L__movme_cp.61), (.L__pc.12648.LD)
	.p2align 4
	.L__pc.12648.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12649
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12649: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.12650
	.L__pc.12650: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.12651
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12651: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.62 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12652: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12653: Dma_PatchSrc (.L__pc.12653.LD), (.L__movme_tmp.1), (.L__pc.12653.LD)
	.p2align 4
	.L__pc.12653.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12654
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12654: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12655
	
	.L__pc.12655: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12656
	
	.p2align 4
	.L__pc.12656: Dma_PatchDst (.L__pc.12656.ST), (.L__movme_cp.24), (.L__pc.12656.ST)
	.L__pc.12656.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12657
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12657: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12658
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12658: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12659
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12659: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12660
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12660: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12661
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.12661: Dma_PatchSrc (.L__pc.12661.LD), (.L__movme_cp.63), (.L__pc.12661.LD)
	.p2align 4
	.L__pc.12661.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12662
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12662: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12663
	.L__pc.12663: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12664
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12664: Dma_PatchSrc (.L__pc.12664.LD), (.L__movme_cp.24), (.L__pc.12664.LD)
	.p2align 4
	.L__pc.12664.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12665
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12665: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.12666
	.L__pc.12666: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.12667
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12667: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12668: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12669: Dma_PatchSrc (.L__pc.12669.LD), (.L__movme_tmp.1), (.L__pc.12669.LD)
	.p2align 4
	.L__pc.12669.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12670
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12670: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12671
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.12671: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.12672: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.12673: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12674: Dma_PatchSrc (.L__pc.12674.LD), (.L__movme_tmp.1), (.L__pc.12674.LD)
	.p2align 4
	.L__pc.12674.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12675
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12675: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12676
	
	.L__pc.12676: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.12677
	
	.p2align 4
	.L__pc.12677: Dma_PatchDst (.L__pc.12677.ST), (.L__movme_cp.63), (.L__pc.12677.ST)
	.L__pc.12677.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12678
	
	.L__pc.12678: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.12679
	
	.p2align 4
	.L__pc.12679: Dma_PatchDst (.L__pc.12679.ST), (.L__movme_cp.24), (.L__pc.12679.ST)
	.L__pc.12679.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12680
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12680: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12681
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12681: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12682
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12682: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12683
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12683: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12684
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.12684: Dma_PatchSrc (.L__pc.12684.LD), (.L__movme_cp.66), (.L__pc.12684.LD)
	.p2align 4
	.L__pc.12684.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12685
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12685: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12686
	.L__pc.12686: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12687
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12687: Dma_PatchSrc (.L__pc.12687.LD), (.L__movme_cp.24), (.L__pc.12687.LD)
	.p2align 4
	.L__pc.12687.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12688
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12688: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.12689
	.L__pc.12689: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.12690
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12690: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12691: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12692: Dma_PatchSrc (.L__pc.12692.LD), (.L__movme_tmp.1), (.L__pc.12692.LD)
	.p2align 4
	.L__pc.12692.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12693
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12693: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12694
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.12694: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.12695: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.12696: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12697: Dma_PatchSrc (.L__pc.12697.LD), (.L__movme_tmp.1), (.L__pc.12697.LD)
	.p2align 4
	.L__pc.12697.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12698
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12698: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12699
	
	.L__pc.12699: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.12700
	
	.p2align 4
	.L__pc.12700: Dma_PatchDst (.L__pc.12700.ST), (.L__movme_cp.66), (.L__pc.12700.ST)
	.L__pc.12700.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12701
	
	.L__pc.12701: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.12702
	
	.p2align 4
	.L__pc.12702: Dma_PatchDst (.L__pc.12702.ST), (.L__movme_cp.24), (.L__pc.12702.ST)
	.L__pc.12702.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12703
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12703: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12704
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12704: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12705
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12705: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12706
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12706: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12707
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.12707: Dma_PatchSrc (.L__pc.12707.LD), (.L__movme_cp.67), (.L__pc.12707.LD)
	.p2align 4
	.L__pc.12707.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12708
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12708: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12709
	.L__pc.12709: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12710
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12710: Dma_PatchSrc (.L__pc.12710.LD), (.L__movme_cp.24), (.L__pc.12710.LD)
	.p2align 4
	.L__pc.12710.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12711
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12711: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.12712
	.L__pc.12712: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.12713
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12713: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12714: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12715: Dma_PatchSrc (.L__pc.12715.LD), (.L__movme_tmp.1), (.L__pc.12715.LD)
	.p2align 4
	.L__pc.12715.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12716
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12716: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12717
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.12717: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.12718: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.12719: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12720: Dma_PatchSrc (.L__pc.12720.LD), (.L__movme_tmp.1), (.L__pc.12720.LD)
	.p2align 4
	.L__pc.12720.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12721
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12721: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12722
	
	.L__pc.12722: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.12723
	
	.p2align 4
	.L__pc.12723: Dma_PatchDst (.L__pc.12723.ST), (.L__movme_cp.67), (.L__pc.12723.ST)
	.L__pc.12723.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12724
	
	.L__pc.12724: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.12725
	
	.p2align 4
	.L__pc.12725: Dma_PatchDst (.L__pc.12725.ST), (.L__movme_cp.24), (.L__pc.12725.ST)
	.L__pc.12725.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12726
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12726: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12727
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12727: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12728
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12728: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12729
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12729: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12730
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.12730: Dma_PatchSrc (.L__pc.12730.LD), (.L__movme_cp.68), (.L__pc.12730.LD)
	.p2align 4
	.L__pc.12730.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12731
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12731: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12732
	.L__pc.12732: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12733
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12733: Dma_PatchSrc (.L__pc.12733.LD), (.L__movme_cp.24), (.L__pc.12733.LD)
	.p2align 4
	.L__pc.12733.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12734
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12734: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.12735
	.L__pc.12735: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.12736
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12736: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12737: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12738: Dma_PatchSrc (.L__pc.12738.LD), (.L__movme_tmp.1), (.L__pc.12738.LD)
	.p2align 4
	.L__pc.12738.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12739
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12739: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12740
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.12740: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.12741: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.12742: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12743: Dma_PatchSrc (.L__pc.12743.LD), (.L__movme_tmp.1), (.L__pc.12743.LD)
	.p2align 4
	.L__pc.12743.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12744
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12744: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12745
	
	.L__pc.12745: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.12746
	
	.p2align 4
	.L__pc.12746: Dma_PatchDst (.L__pc.12746.ST), (.L__movme_cp.68), (.L__pc.12746.ST)
	.L__pc.12746.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12747
	
	.L__pc.12747: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.12748
	
	.p2align 4
	.L__pc.12748: Dma_PatchDst (.L__pc.12748.ST), (.L__movme_cp.24), (.L__pc.12748.ST)
	.L__pc.12748.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12749
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12749: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12750
	
	.p2align 4
	.L__pc.12750: Dma_PatchDst (.L__pc.12750.ST), (.L__movme_cp.24), (.L__pc.12750.ST)
	.L__pc.12750.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12751
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.12751: Dma_PatchSrc (.L__pc.12751.LD), (.L__movme_cp.60), (.L__pc.12751.LD)
	.p2align 4
	.L__pc.12751.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12752
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12752: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12753
	
	.L__pc.12753: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12754
	
	.p2align 4
	.L__pc.12754: Dma_PatchDst (.L__pc.12754.ST), (.L__movme_cp.21), (.L__pc.12754.ST)
	.L__pc.12754.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12755
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.12755: Dma_PatchSrc (.L__pc.12755.LD), (.L__movme_cp.58), (.L__pc.12755.LD)
	.p2align 4
	.L__pc.12755.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12756
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12756: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12757
	
	.L__pc.12757: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12758
	
	.p2align 4
	.L__pc.12758: Dma_PatchDst (.L__pc.12758.ST), (.L__movme_cp.22), (.L__pc.12758.ST)
	.L__pc.12758.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12759
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12759: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12760
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12760: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12761
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12761: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12762
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12762: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12763
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.12763: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.12764
	
	.p2align 4
	.L__pc.12764: Dma_PatchDst (.L__pc.12764.ST), (.L__movme_cp.24), (.L__pc.12764.ST)
	.L__pc.12764.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12765
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.12765: Dma_PatchSrc (.L__pc.12765.LD), (.L__movme_cp.25), (.L__pc.12765.LD)
	.p2align 4
	.L__pc.12765.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12766
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12766: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12767
	.L__pc.12767: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12768
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.12768: Dma_PatchSrc (.L__pc.12768.LD), (.L__movme_cp.26), (.L__pc.12768.LD)
	.p2align 4
	.L__pc.12768.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12769
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12769: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12770
	.L__pc.12770: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12771
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.12771: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12772: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12773: Dma_PatchSrc (.L__pc.12773.LD), (.L__movme_tmp.1), (.L__pc.12773.LD)
	.p2align 4
	.L__pc.12773.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12774
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12774: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12775
	.L__pc.12775: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12776
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12776: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12777: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12778: Dma_PatchSrc (.L__pc.12778.LD), (.L__movme_tmp.1), (.L__pc.12778.LD)
	.p2align 4
	.L__pc.12778.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12779
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12779: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12780
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12780: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12781: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12782: Dma_PatchSrc (.L__pc.12782.LD), (.L__movme_tmp.1), (.L__pc.12782.LD)
	.p2align 4
	.L__pc.12782.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12783
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12783: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12784
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12784: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12785: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12786: Dma_PatchSrc (.L__pc.12786.LD), (.L__movme_tmp.1), (.L__pc.12786.LD)
	.p2align 4
	.L__pc.12786.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12787
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12787: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12788
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12788: Dma_PatchSrc (.L__pc.12788.LD), (.L__movme_cp.24), (.L__pc.12788.LD)
	.p2align 4
	.L__pc.12788.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12789
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12789: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12790
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12790: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12791: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12792: Dma_PatchSrc (.L__pc.12792.LD), (.L__movme_tmp.1), (.L__pc.12792.LD)
	.p2align 4
	.L__pc.12792.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12793
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12793: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12794
	
	.L__pc.12794: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12795
	
	.p2align 4
	.L__pc.12795: Dma_PatchDst (.L__pc.12795.ST), (.L__movme_cp.69), (.L__pc.12795.ST)
	.L__pc.12795.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12796
	
	.L__pc.12796: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12797
	
	.p2align 4
	.L__pc.12797: Dma_PatchDst (.L__pc.12797.ST), (.L__movme_cp.54), (.L__pc.12797.ST)
	.L__pc.12797.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12798
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.12798: Dma_PatchSrc (.L__pc.12798.LD), (.L__movme_cp.30), (.L__pc.12798.LD)
	.p2align 4
	.L__pc.12798.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12799
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12799: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12800
	.L__pc.12800: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12801
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.12801: Dma_PatchSrc (.L__pc.12801.LD), (.L__movme_cp.31), (.L__pc.12801.LD)
	.p2align 4
	.L__pc.12801.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12802
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12802: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12803
	.L__pc.12803: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12804
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.12804: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12805: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12806: Dma_PatchSrc (.L__pc.12806.LD), (.L__movme_tmp.1), (.L__pc.12806.LD)
	.p2align 4
	.L__pc.12806.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12807
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12807: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12808
	.L__pc.12808: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12809
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12809: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12810: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12811: Dma_PatchSrc (.L__pc.12811.LD), (.L__movme_tmp.1), (.L__pc.12811.LD)
	.p2align 4
	.L__pc.12811.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12812
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12812: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12813
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12813: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12814: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12815: Dma_PatchSrc (.L__pc.12815.LD), (.L__movme_tmp.1), (.L__pc.12815.LD)
	.p2align 4
	.L__pc.12815.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12816
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12816: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12817
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12817: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12818: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12819: Dma_PatchSrc (.L__pc.12819.LD), (.L__movme_tmp.1), (.L__pc.12819.LD)
	.p2align 4
	.L__pc.12819.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12820
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12820: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12821
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12821: Dma_PatchSrc (.L__pc.12821.LD), (.L__movme_cp.24), (.L__pc.12821.LD)
	.p2align 4
	.L__pc.12821.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12822
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12822: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12823
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12823: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12824: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12825: Dma_PatchSrc (.L__pc.12825.LD), (.L__movme_tmp.1), (.L__pc.12825.LD)
	.p2align 4
	.L__pc.12825.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12826
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12826: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12827
	
	.L__pc.12827: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12828
	
	.p2align 4
	.L__pc.12828: Dma_PatchDst (.L__pc.12828.ST), (.L__movme_cp.70), (.L__pc.12828.ST)
	.L__pc.12828.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12829
	
	.L__pc.12829: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12830
	
	.p2align 4
	.L__pc.12830: Dma_PatchDst (.L__pc.12830.ST), (.L__movme_cp.54), (.L__pc.12830.ST)
	.L__pc.12830.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12831
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12831: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12832
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12832: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12833
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12833: Dma_PatchSrc (.L__pc.12833.LD), (.L__movme_cp.24), (.L__pc.12833.LD)
	.p2align 4
	.L__pc.12833.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12834
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12834: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12835
	.L__pc.12835: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12836
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.12836: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12837: Dma_PatchSrc (.L__pc.12837.LD), (.L__movme_tmp.1), (.L__pc.12837.LD)
	.p2align 4
	.L__pc.12837.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12838
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12838: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12839
	.L__pc.12839: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12840
	
	.L__pc.12840: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12841
	
	.p2align 4
	.L__pc.12841: Dma_PatchDst (.L__pc.12841.ST), (.L__movme_cp.72), (.L__pc.12841.ST)
	.L__pc.12841.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12842
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.12842: Dma_PatchSrc (.L__pc.12842.LD), (.L__movme_cp.72), (.L__pc.12842.LD)
	.p2align 4
	.L__pc.12842.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12843
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12843: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12844
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12844: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12845: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12846: Dma_PatchSrc (.L__pc.12846.LD), (.L__movme_tmp.1), (.L__pc.12846.LD)
	.p2align 4
	.L__pc.12846.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12847
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12847: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12848
	
	.L__pc.12848: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12849
	
	.p2align 4
	.L__pc.12849: Dma_PatchDst (.L__pc.12849.ST), (.L__movme_cp.74), (.L__pc.12849.ST)
	.L__pc.12849.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12850
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12850: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12851: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12852: Dma_PatchSrc (.L__pc.12852.LD), (.L__movme_tmp.1), (.L__pc.12852.LD)
	.p2align 4
	.L__pc.12852.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12853
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12853: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12854
	
	.L__pc.12854: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12855
	
	.p2align 4
	.L__pc.12855: Dma_PatchDst (.L__pc.12855.ST), (.L__movme_cp.76), (.L__pc.12855.ST)
	.L__pc.12855.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12856
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.12856: Dma_PatchSrc (.L__pc.12856.LD), (.L__movme_cp.74), (.L__pc.12856.LD)
	.p2align 4
	.L__pc.12856.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12857
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12857: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12858
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.12858: Dma_PatchSrc (.L__pc.12858.LD), ((.L__movme.reg.eax+0)), (.L__pc.12858.LD)
	.p2align 4
	.L__pc.12858.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12859
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12859: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12860
	
	.L__pc.12860: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12861
	
	.p2align 4
	.L__pc.12861: Dma_PatchDst (.L__pc.12861.ST), (.L__movme_cp.77), (.L__pc.12861.ST)
	.L__pc.12861.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12862
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.12862: Dma_PatchSrc (.L__pc.12862.LD), (.L__movme_cp.77), (.L__pc.12862.LD)
	.p2align 4
	.L__pc.12862.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12863
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12863: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12864
	
	.L__pc.12864: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12865
	
	.p2align 4
	.L__pc.12865: Dma_PatchDst (.L__pc.12865.ST), (.L__movme_cp.21), (.L__pc.12865.ST)
	.L__pc.12865.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12866
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.12866: Dma_PatchSrc (.L__pc.12866.LD), (.L__movme_cp.58), (.L__pc.12866.LD)
	.p2align 4
	.L__pc.12866.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12867
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12867: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12868
	
	.L__pc.12868: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12869
	
	.p2align 4
	.L__pc.12869: Dma_PatchDst (.L__pc.12869.ST), (.L__movme_cp.22), (.L__pc.12869.ST)
	.L__pc.12869.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12870
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12870: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12871
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12871: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12872
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12872: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12873
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12873: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12874
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.12874: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.12875
	
	.p2align 4
	.L__pc.12875: Dma_PatchDst (.L__pc.12875.ST), (.L__movme_cp.24), (.L__pc.12875.ST)
	.L__pc.12875.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12876
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.12876: Dma_PatchSrc (.L__pc.12876.LD), (.L__movme_cp.25), (.L__pc.12876.LD)
	.p2align 4
	.L__pc.12876.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12877
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12877: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12878
	.L__pc.12878: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12879
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.12879: Dma_PatchSrc (.L__pc.12879.LD), (.L__movme_cp.26), (.L__pc.12879.LD)
	.p2align 4
	.L__pc.12879.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12880
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12880: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12881
	.L__pc.12881: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12882
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.12882: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12883: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12884: Dma_PatchSrc (.L__pc.12884.LD), (.L__movme_tmp.1), (.L__pc.12884.LD)
	.p2align 4
	.L__pc.12884.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12885
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12885: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12886
	.L__pc.12886: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12887
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12887: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12888: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12889: Dma_PatchSrc (.L__pc.12889.LD), (.L__movme_tmp.1), (.L__pc.12889.LD)
	.p2align 4
	.L__pc.12889.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12890
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12890: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12891
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12891: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12892: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12893: Dma_PatchSrc (.L__pc.12893.LD), (.L__movme_tmp.1), (.L__pc.12893.LD)
	.p2align 4
	.L__pc.12893.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12894
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12894: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12895
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12895: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12896: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12897: Dma_PatchSrc (.L__pc.12897.LD), (.L__movme_tmp.1), (.L__pc.12897.LD)
	.p2align 4
	.L__pc.12897.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12898
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12898: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12899
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12899: Dma_PatchSrc (.L__pc.12899.LD), (.L__movme_cp.24), (.L__pc.12899.LD)
	.p2align 4
	.L__pc.12899.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12900
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12900: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12901
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12901: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12902: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12903: Dma_PatchSrc (.L__pc.12903.LD), (.L__movme_tmp.1), (.L__pc.12903.LD)
	.p2align 4
	.L__pc.12903.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12904
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12904: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12905
	
	.L__pc.12905: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12906
	
	.p2align 4
	.L__pc.12906: Dma_PatchDst (.L__pc.12906.ST), (.L__movme_cp.78), (.L__pc.12906.ST)
	.L__pc.12906.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12907
	
	.L__pc.12907: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12908
	
	.p2align 4
	.L__pc.12908: Dma_PatchDst (.L__pc.12908.ST), (.L__movme_cp.54), (.L__pc.12908.ST)
	.L__pc.12908.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12909
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.12909: Dma_PatchSrc (.L__pc.12909.LD), (.L__movme_cp.30), (.L__pc.12909.LD)
	.p2align 4
	.L__pc.12909.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12910
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12910: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.12911
	.L__pc.12911: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.12912
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.12912: Dma_PatchSrc (.L__pc.12912.LD), (.L__movme_cp.31), (.L__pc.12912.LD)
	.p2align 4
	.L__pc.12912.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12913
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12913: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12914
	.L__pc.12914: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12915
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.12915: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12916: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12917: Dma_PatchSrc (.L__pc.12917.LD), (.L__movme_tmp.1), (.L__pc.12917.LD)
	.p2align 4
	.L__pc.12917.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12918
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12918: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.12919
	.L__pc.12919: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.12920
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12920: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12921: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12922: Dma_PatchSrc (.L__pc.12922.LD), (.L__movme_tmp.1), (.L__pc.12922.LD)
	.p2align 4
	.L__pc.12922.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12923
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12923: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12924
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12924: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12925: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12926: Dma_PatchSrc (.L__pc.12926.LD), (.L__movme_tmp.1), (.L__pc.12926.LD)
	.p2align 4
	.L__pc.12926.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12927
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12927: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12928
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12928: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12929: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12930: Dma_PatchSrc (.L__pc.12930.LD), (.L__movme_tmp.1), (.L__pc.12930.LD)
	.p2align 4
	.L__pc.12930.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12931
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12931: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12932
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12932: Dma_PatchSrc (.L__pc.12932.LD), (.L__movme_cp.24), (.L__pc.12932.LD)
	.p2align 4
	.L__pc.12932.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12933
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.12933: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.12934
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.12934: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12935: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12936: Dma_PatchSrc (.L__pc.12936.LD), (.L__movme_tmp.1), (.L__pc.12936.LD)
	.p2align 4
	.L__pc.12936.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12937
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12937: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12938
	
	.L__pc.12938: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.12939
	
	.p2align 4
	.L__pc.12939: Dma_PatchDst (.L__pc.12939.ST), (.L__movme_cp.79), (.L__pc.12939.ST)
	.L__pc.12939.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12940
	
	.L__pc.12940: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12941
	
	.p2align 4
	.L__pc.12941: Dma_PatchDst (.L__pc.12941.ST), (.L__movme_cp.54), (.L__pc.12941.ST)
	.L__pc.12941.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12942
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.12942: Dma_PatchSrc (.L__pc.12942.LD), (.L__movme_cp.74), (.L__pc.12942.LD)
	.p2align 4
	.L__pc.12942.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12943
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12943: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12944
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.12944: Dma_PatchSrc (.L__pc.12944.LD), (.L__movme_cp.77), (.L__pc.12944.LD)
	.p2align 4
	.L__pc.12944.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12945
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12945: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12946
	
	.L__pc.12946: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12947
	
	.p2align 4
	.L__pc.12947: Dma_PatchDst (.L__pc.12947.ST), ((.L__movme.reg.eax+0)), (.L__pc.12947.ST)
	.L__pc.12947.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12948
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.12948: Dma_PatchSrc (.L__pc.12948.LD), (.L__movme_cp.76), (.L__pc.12948.LD)
	.p2align 4
	.L__pc.12948.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12949
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12949: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12950
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.12950: Dma_PatchSrc (.L__pc.12950.LD), ((.L__movme.reg.eax+0)), (.L__pc.12950.LD)
	.p2align 4
	.L__pc.12950.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12951
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12951: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12952
	
	.L__pc.12952: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12953
	
	.p2align 4
	.L__pc.12953: Dma_PatchDst (.L__pc.12953.ST), (.L__movme_cp.80), (.L__pc.12953.ST)
	.L__pc.12953.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12954
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12954: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12955
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12955: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12956
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.12956: Dma_PatchSrc (.L__pc.12956.LD), (.L__movme_cp.81), (.L__pc.12956.LD)
	.p2align 4
	.L__pc.12956.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12957
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12957: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12958
	.L__pc.12958: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12959
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.82 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.12959: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12960: Dma_PatchSrc (.L__pc.12960.LD), (.L__movme_tmp.1), (.L__pc.12960.LD)
	.p2align 4
	.L__pc.12960.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12961
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12961: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12962
	.L__pc.12962: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12963
	
	.L__pc.12963: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.12964
	
	.p2align 4
	.L__pc.12964: Dma_PatchDst (.L__pc.12964.ST), (.L__movme_cp.81), (.L__pc.12964.ST)
	.L__pc.12964.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12965
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.12965: Dma_PatchSrc (.L__pc.12965.LD), (.L__movme_cp.76), (.L__pc.12965.LD)
	.p2align 4
	.L__pc.12965.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12966
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12966: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12967
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.12967: Dma_PatchSrc (.L__pc.12967.LD), (.L__movme_cp.80), (.L__pc.12967.LD)
	.p2align 4
	.L__pc.12967.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12968
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12968: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12969
	
	.L__pc.12969: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.12970
	
	.p2align 4
	.L__pc.12970: Dma_PatchDst (.L__pc.12970.ST), ((.L__movme.reg.eax+0)), (.L__pc.12970.ST)
	.L__pc.12970.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12971
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12971: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12972
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12972: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12973
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.12973: Dma_PatchSrc (.L__pc.12973.LD), (.L__movme_cp.61), (.L__pc.12973.LD)
	.p2align 4
	.L__pc.12973.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12974
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12974: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.12975
	.L__pc.12975: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.12976
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.12976: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.83 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12977: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12978: Dma_PatchSrc (.L__pc.12978.LD), (.L__movme_tmp.1), (.L__pc.12978.LD)
	.p2align 4
	.L__pc.12978.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12979
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12979: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12980
	
	.L__pc.12980: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.12981
	
	.p2align 4
	.L__pc.12981: Dma_PatchDst (.L__pc.12981.ST), (.L__movme_cp.24), (.L__pc.12981.ST)
	.L__pc.12981.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.12982
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12982: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12983
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12983: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12984
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.12984: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.12985
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12985: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.12986
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.12986: Dma_PatchSrc (.L__pc.12986.LD), (.L__movme_cp.63), (.L__pc.12986.LD)
	.p2align 4
	.L__pc.12986.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12987
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12987: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.12988
	.L__pc.12988: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.12989
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.12989: Dma_PatchSrc (.L__pc.12989.LD), (.L__movme_cp.24), (.L__pc.12989.LD)
	.p2align 4
	.L__pc.12989.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12990
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.12990: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.12991
	.L__pc.12991: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.12992
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.12992: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.12993: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12994: Dma_PatchSrc (.L__pc.12994.LD), (.L__movme_tmp.1), (.L__pc.12994.LD)
	.p2align 4
	.L__pc.12994.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.12995
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.12995: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.12996
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.12996: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.12997: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.12998: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.12999: Dma_PatchSrc (.L__pc.12999.LD), (.L__movme_tmp.1), (.L__pc.12999.LD)
	.p2align 4
	.L__pc.12999.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13000
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13000: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13001
	
	.L__pc.13001: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13002
	
	.p2align 4
	.L__pc.13002: Dma_PatchDst (.L__pc.13002.ST), (.L__movme_cp.63), (.L__pc.13002.ST)
	.L__pc.13002.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13003
	
	.L__pc.13003: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13004
	
	.p2align 4
	.L__pc.13004: Dma_PatchDst (.L__pc.13004.ST), (.L__movme_cp.24), (.L__pc.13004.ST)
	.L__pc.13004.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13005
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13005: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13006
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13006: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13007
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13007: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13008
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13008: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13009
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.13009: Dma_PatchSrc (.L__pc.13009.LD), (.L__movme_cp.66), (.L__pc.13009.LD)
	.p2align 4
	.L__pc.13009.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13010
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13010: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13011
	.L__pc.13011: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13012
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13012: Dma_PatchSrc (.L__pc.13012.LD), (.L__movme_cp.24), (.L__pc.13012.LD)
	.p2align 4
	.L__pc.13012.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13013
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13013: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13014
	.L__pc.13014: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13015
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13015: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13016: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13017: Dma_PatchSrc (.L__pc.13017.LD), (.L__movme_tmp.1), (.L__pc.13017.LD)
	.p2align 4
	.L__pc.13017.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13018
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13018: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13019
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13019: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13020: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13021: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13022: Dma_PatchSrc (.L__pc.13022.LD), (.L__movme_tmp.1), (.L__pc.13022.LD)
	.p2align 4
	.L__pc.13022.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13023
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13023: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13024
	
	.L__pc.13024: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13025
	
	.p2align 4
	.L__pc.13025: Dma_PatchDst (.L__pc.13025.ST), (.L__movme_cp.66), (.L__pc.13025.ST)
	.L__pc.13025.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13026
	
	.L__pc.13026: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13027
	
	.p2align 4
	.L__pc.13027: Dma_PatchDst (.L__pc.13027.ST), (.L__movme_cp.24), (.L__pc.13027.ST)
	.L__pc.13027.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13028
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13028: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13029
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13029: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13030
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13030: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13031
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13031: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13032
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.13032: Dma_PatchSrc (.L__pc.13032.LD), (.L__movme_cp.67), (.L__pc.13032.LD)
	.p2align 4
	.L__pc.13032.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13033
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13033: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13034
	.L__pc.13034: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13035
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13035: Dma_PatchSrc (.L__pc.13035.LD), (.L__movme_cp.24), (.L__pc.13035.LD)
	.p2align 4
	.L__pc.13035.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13036
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13036: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13037
	.L__pc.13037: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13038
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13038: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13039: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13040: Dma_PatchSrc (.L__pc.13040.LD), (.L__movme_tmp.1), (.L__pc.13040.LD)
	.p2align 4
	.L__pc.13040.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13041
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13041: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13042
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13042: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13043: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13044: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13045: Dma_PatchSrc (.L__pc.13045.LD), (.L__movme_tmp.1), (.L__pc.13045.LD)
	.p2align 4
	.L__pc.13045.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13046
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13046: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13047
	
	.L__pc.13047: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13048
	
	.p2align 4
	.L__pc.13048: Dma_PatchDst (.L__pc.13048.ST), (.L__movme_cp.67), (.L__pc.13048.ST)
	.L__pc.13048.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13049
	
	.L__pc.13049: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13050
	
	.p2align 4
	.L__pc.13050: Dma_PatchDst (.L__pc.13050.ST), (.L__movme_cp.24), (.L__pc.13050.ST)
	.L__pc.13050.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13051
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13051: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13052
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13052: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13053
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13053: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13054
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13054: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13055
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.13055: Dma_PatchSrc (.L__pc.13055.LD), (.L__movme_cp.68), (.L__pc.13055.LD)
	.p2align 4
	.L__pc.13055.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13056
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13056: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13057
	.L__pc.13057: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13058
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13058: Dma_PatchSrc (.L__pc.13058.LD), (.L__movme_cp.24), (.L__pc.13058.LD)
	.p2align 4
	.L__pc.13058.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13059
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13059: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13060
	.L__pc.13060: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13061
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13061: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13062: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13063: Dma_PatchSrc (.L__pc.13063.LD), (.L__movme_tmp.1), (.L__pc.13063.LD)
	.p2align 4
	.L__pc.13063.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13064
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13064: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13065
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13065: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13066: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13067: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13068: Dma_PatchSrc (.L__pc.13068.LD), (.L__movme_tmp.1), (.L__pc.13068.LD)
	.p2align 4
	.L__pc.13068.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13069
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13069: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13070
	
	.L__pc.13070: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13071
	
	.p2align 4
	.L__pc.13071: Dma_PatchDst (.L__pc.13071.ST), (.L__movme_cp.68), (.L__pc.13071.ST)
	.L__pc.13071.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13072
	
	.L__pc.13072: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13073
	
	.p2align 4
	.L__pc.13073: Dma_PatchDst (.L__pc.13073.ST), (.L__movme_cp.24), (.L__pc.13073.ST)
	.L__pc.13073.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13074
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13074: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13075
	
	.p2align 4
	.L__pc.13075: Dma_PatchDst (.L__pc.13075.ST), (.L__movme_cp.24), (.L__pc.13075.ST)
	.L__pc.13075.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13076
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.13076: Dma_PatchSrc (.L__pc.13076.LD), (.L__movme_cp.60), (.L__pc.13076.LD)
	.p2align 4
	.L__pc.13076.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13077
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13077: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13078
	
	.L__pc.13078: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13079
	
	.p2align 4
	.L__pc.13079: Dma_PatchDst (.L__pc.13079.ST), (.L__movme_cp.21), (.L__pc.13079.ST)
	.L__pc.13079.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13080
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.13080: Dma_PatchSrc (.L__pc.13080.LD), (.L__movme_cp.58), (.L__pc.13080.LD)
	.p2align 4
	.L__pc.13080.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13081
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13081: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13082
	
	.L__pc.13082: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13083
	
	.p2align 4
	.L__pc.13083: Dma_PatchDst (.L__pc.13083.ST), (.L__movme_cp.22), (.L__pc.13083.ST)
	.L__pc.13083.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13084
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13084: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13085
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13085: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13086
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13086: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13087
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13087: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13088
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.13088: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.13089
	
	.p2align 4
	.L__pc.13089: Dma_PatchDst (.L__pc.13089.ST), (.L__movme_cp.24), (.L__pc.13089.ST)
	.L__pc.13089.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13090
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.13090: Dma_PatchSrc (.L__pc.13090.LD), (.L__movme_cp.25), (.L__pc.13090.LD)
	.p2align 4
	.L__pc.13090.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13091
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13091: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13092
	.L__pc.13092: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13093
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.13093: Dma_PatchSrc (.L__pc.13093.LD), (.L__movme_cp.26), (.L__pc.13093.LD)
	.p2align 4
	.L__pc.13093.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13094
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13094: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13095
	.L__pc.13095: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13096
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13096: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13097: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13098: Dma_PatchSrc (.L__pc.13098.LD), (.L__movme_tmp.1), (.L__pc.13098.LD)
	.p2align 4
	.L__pc.13098.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13099
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13099: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13100
	.L__pc.13100: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13101
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13101: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13102: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13103: Dma_PatchSrc (.L__pc.13103.LD), (.L__movme_tmp.1), (.L__pc.13103.LD)
	.p2align 4
	.L__pc.13103.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13104
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13104: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13105
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13105: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13106: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13107: Dma_PatchSrc (.L__pc.13107.LD), (.L__movme_tmp.1), (.L__pc.13107.LD)
	.p2align 4
	.L__pc.13107.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13108
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13108: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13109
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13109: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13110: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13111: Dma_PatchSrc (.L__pc.13111.LD), (.L__movme_tmp.1), (.L__pc.13111.LD)
	.p2align 4
	.L__pc.13111.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13112
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13112: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13113
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13113: Dma_PatchSrc (.L__pc.13113.LD), (.L__movme_cp.24), (.L__pc.13113.LD)
	.p2align 4
	.L__pc.13113.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13114
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13114: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13115
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13115: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13116: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13117: Dma_PatchSrc (.L__pc.13117.LD), (.L__movme_tmp.1), (.L__pc.13117.LD)
	.p2align 4
	.L__pc.13117.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13118
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13118: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13119
	
	.L__pc.13119: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13120
	
	.p2align 4
	.L__pc.13120: Dma_PatchDst (.L__pc.13120.ST), (.L__movme_cp.69), (.L__pc.13120.ST)
	.L__pc.13120.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13121
	
	.L__pc.13121: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13122
	
	.p2align 4
	.L__pc.13122: Dma_PatchDst (.L__pc.13122.ST), (.L__movme_cp.54), (.L__pc.13122.ST)
	.L__pc.13122.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13123
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.13123: Dma_PatchSrc (.L__pc.13123.LD), (.L__movme_cp.30), (.L__pc.13123.LD)
	.p2align 4
	.L__pc.13123.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13124
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13124: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13125
	.L__pc.13125: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13126
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.13126: Dma_PatchSrc (.L__pc.13126.LD), (.L__movme_cp.31), (.L__pc.13126.LD)
	.p2align 4
	.L__pc.13126.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13127
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13127: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13128
	.L__pc.13128: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13129
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13129: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13130: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13131: Dma_PatchSrc (.L__pc.13131.LD), (.L__movme_tmp.1), (.L__pc.13131.LD)
	.p2align 4
	.L__pc.13131.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13132
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13132: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13133
	.L__pc.13133: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13134
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13134: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13135: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13136: Dma_PatchSrc (.L__pc.13136.LD), (.L__movme_tmp.1), (.L__pc.13136.LD)
	.p2align 4
	.L__pc.13136.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13137
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13137: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13138
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13138: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13139: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13140: Dma_PatchSrc (.L__pc.13140.LD), (.L__movme_tmp.1), (.L__pc.13140.LD)
	.p2align 4
	.L__pc.13140.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13141
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13141: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13142
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13142: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13143: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13144: Dma_PatchSrc (.L__pc.13144.LD), (.L__movme_tmp.1), (.L__pc.13144.LD)
	.p2align 4
	.L__pc.13144.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13145
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13145: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13146
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13146: Dma_PatchSrc (.L__pc.13146.LD), (.L__movme_cp.24), (.L__pc.13146.LD)
	.p2align 4
	.L__pc.13146.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13147
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13147: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13148
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13148: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13149: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13150: Dma_PatchSrc (.L__pc.13150.LD), (.L__movme_tmp.1), (.L__pc.13150.LD)
	.p2align 4
	.L__pc.13150.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13151
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13151: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13152
	
	.L__pc.13152: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13153
	
	.p2align 4
	.L__pc.13153: Dma_PatchDst (.L__pc.13153.ST), (.L__movme_cp.70), (.L__pc.13153.ST)
	.L__pc.13153.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13154
	
	.L__pc.13154: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13155
	
	.p2align 4
	.L__pc.13155: Dma_PatchDst (.L__pc.13155.ST), (.L__movme_cp.54), (.L__pc.13155.ST)
	.L__pc.13155.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13156
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13156: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13157
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13157: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13158
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13158: Dma_PatchSrc (.L__pc.13158.LD), (.L__movme_cp.24), (.L__pc.13158.LD)
	.p2align 4
	.L__pc.13158.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13159
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13159: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13160
	.L__pc.13160: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13161
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.13161: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13162: Dma_PatchSrc (.L__pc.13162.LD), (.L__movme_tmp.1), (.L__pc.13162.LD)
	.p2align 4
	.L__pc.13162.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13163
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13163: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13164
	.L__pc.13164: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13165
	
	.L__pc.13165: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13166
	
	.p2align 4
	.L__pc.13166: Dma_PatchDst (.L__pc.13166.ST), (.L__movme_cp.72), (.L__pc.13166.ST)
	.L__pc.13166.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13167
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.13167: Dma_PatchSrc (.L__pc.13167.LD), (.L__movme_cp.72), (.L__pc.13167.LD)
	.p2align 4
	.L__pc.13167.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13168
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13168: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13169
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13169: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13170: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13171: Dma_PatchSrc (.L__pc.13171.LD), (.L__movme_tmp.1), (.L__pc.13171.LD)
	.p2align 4
	.L__pc.13171.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13172
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13172: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13173
	
	.L__pc.13173: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13174
	
	.p2align 4
	.L__pc.13174: Dma_PatchDst (.L__pc.13174.ST), (.L__movme_cp.74), (.L__pc.13174.ST)
	.L__pc.13174.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13175
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13175: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13176: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13177: Dma_PatchSrc (.L__pc.13177.LD), (.L__movme_tmp.1), (.L__pc.13177.LD)
	.p2align 4
	.L__pc.13177.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13178
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13178: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13179
	
	.L__pc.13179: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13180
	
	.p2align 4
	.L__pc.13180: Dma_PatchDst (.L__pc.13180.ST), (.L__movme_cp.76), (.L__pc.13180.ST)
	.L__pc.13180.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13181
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.13181: Dma_PatchSrc (.L__pc.13181.LD), (.L__movme_cp.74), (.L__pc.13181.LD)
	.p2align 4
	.L__pc.13181.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13182
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13182: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13183
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.13183: Dma_PatchSrc (.L__pc.13183.LD), ((.L__movme.reg.eax+0)), (.L__pc.13183.LD)
	.p2align 4
	.L__pc.13183.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13184
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13184: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13185
	
	.L__pc.13185: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13186
	
	.p2align 4
	.L__pc.13186: Dma_PatchDst (.L__pc.13186.ST), (.L__movme_cp.77), (.L__pc.13186.ST)
	.L__pc.13186.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13187
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.13187: Dma_PatchSrc (.L__pc.13187.LD), (.L__movme_cp.77), (.L__pc.13187.LD)
	.p2align 4
	.L__pc.13187.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13188
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13188: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13189
	
	.L__pc.13189: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13190
	
	.p2align 4
	.L__pc.13190: Dma_PatchDst (.L__pc.13190.ST), (.L__movme_cp.21), (.L__pc.13190.ST)
	.L__pc.13190.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13191
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.13191: Dma_PatchSrc (.L__pc.13191.LD), (.L__movme_cp.58), (.L__pc.13191.LD)
	.p2align 4
	.L__pc.13191.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13192
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13192: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13193
	
	.L__pc.13193: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13194
	
	.p2align 4
	.L__pc.13194: Dma_PatchDst (.L__pc.13194.ST), (.L__movme_cp.22), (.L__pc.13194.ST)
	.L__pc.13194.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13195
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13195: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13196
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13196: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13197
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13197: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13198
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13198: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13199
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.13199: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.13200
	
	.p2align 4
	.L__pc.13200: Dma_PatchDst (.L__pc.13200.ST), (.L__movme_cp.24), (.L__pc.13200.ST)
	.L__pc.13200.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13201
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.13201: Dma_PatchSrc (.L__pc.13201.LD), (.L__movme_cp.25), (.L__pc.13201.LD)
	.p2align 4
	.L__pc.13201.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13202
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13202: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13203
	.L__pc.13203: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13204
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.13204: Dma_PatchSrc (.L__pc.13204.LD), (.L__movme_cp.26), (.L__pc.13204.LD)
	.p2align 4
	.L__pc.13204.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13205
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13205: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13206
	.L__pc.13206: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13207
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13207: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13208: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13209: Dma_PatchSrc (.L__pc.13209.LD), (.L__movme_tmp.1), (.L__pc.13209.LD)
	.p2align 4
	.L__pc.13209.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13210
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13210: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13211
	.L__pc.13211: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13212
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13212: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13213: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13214: Dma_PatchSrc (.L__pc.13214.LD), (.L__movme_tmp.1), (.L__pc.13214.LD)
	.p2align 4
	.L__pc.13214.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13215
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13215: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13216
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13216: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13217: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13218: Dma_PatchSrc (.L__pc.13218.LD), (.L__movme_tmp.1), (.L__pc.13218.LD)
	.p2align 4
	.L__pc.13218.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13219
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13219: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13220
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13220: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13221: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13222: Dma_PatchSrc (.L__pc.13222.LD), (.L__movme_tmp.1), (.L__pc.13222.LD)
	.p2align 4
	.L__pc.13222.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13223
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13223: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13224
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13224: Dma_PatchSrc (.L__pc.13224.LD), (.L__movme_cp.24), (.L__pc.13224.LD)
	.p2align 4
	.L__pc.13224.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13225
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13225: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13226
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13226: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13227: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13228: Dma_PatchSrc (.L__pc.13228.LD), (.L__movme_tmp.1), (.L__pc.13228.LD)
	.p2align 4
	.L__pc.13228.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13229
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13229: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13230
	
	.L__pc.13230: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13231
	
	.p2align 4
	.L__pc.13231: Dma_PatchDst (.L__pc.13231.ST), (.L__movme_cp.78), (.L__pc.13231.ST)
	.L__pc.13231.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13232
	
	.L__pc.13232: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13233
	
	.p2align 4
	.L__pc.13233: Dma_PatchDst (.L__pc.13233.ST), (.L__movme_cp.54), (.L__pc.13233.ST)
	.L__pc.13233.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13234
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.13234: Dma_PatchSrc (.L__pc.13234.LD), (.L__movme_cp.30), (.L__pc.13234.LD)
	.p2align 4
	.L__pc.13234.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13235
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13235: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13236
	.L__pc.13236: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13237
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.13237: Dma_PatchSrc (.L__pc.13237.LD), (.L__movme_cp.31), (.L__pc.13237.LD)
	.p2align 4
	.L__pc.13237.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13238
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13238: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13239
	.L__pc.13239: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13240
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13240: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13241: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13242: Dma_PatchSrc (.L__pc.13242.LD), (.L__movme_tmp.1), (.L__pc.13242.LD)
	.p2align 4
	.L__pc.13242.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13243
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13243: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13244
	.L__pc.13244: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13245
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13245: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13246: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13247: Dma_PatchSrc (.L__pc.13247.LD), (.L__movme_tmp.1), (.L__pc.13247.LD)
	.p2align 4
	.L__pc.13247.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13248
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13248: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13249
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13249: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13250: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13251: Dma_PatchSrc (.L__pc.13251.LD), (.L__movme_tmp.1), (.L__pc.13251.LD)
	.p2align 4
	.L__pc.13251.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13252
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13252: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13253
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13253: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13254: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13255: Dma_PatchSrc (.L__pc.13255.LD), (.L__movme_tmp.1), (.L__pc.13255.LD)
	.p2align 4
	.L__pc.13255.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13256
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13256: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13257
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13257: Dma_PatchSrc (.L__pc.13257.LD), (.L__movme_cp.24), (.L__pc.13257.LD)
	.p2align 4
	.L__pc.13257.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13258
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13258: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13259
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13259: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13260: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13261: Dma_PatchSrc (.L__pc.13261.LD), (.L__movme_tmp.1), (.L__pc.13261.LD)
	.p2align 4
	.L__pc.13261.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13262
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13262: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13263
	
	.L__pc.13263: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13264
	
	.p2align 4
	.L__pc.13264: Dma_PatchDst (.L__pc.13264.ST), (.L__movme_cp.79), (.L__pc.13264.ST)
	.L__pc.13264.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13265
	
	.L__pc.13265: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13266
	
	.p2align 4
	.L__pc.13266: Dma_PatchDst (.L__pc.13266.ST), (.L__movme_cp.54), (.L__pc.13266.ST)
	.L__pc.13266.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13267
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.13267: Dma_PatchSrc (.L__pc.13267.LD), (.L__movme_cp.74), (.L__pc.13267.LD)
	.p2align 4
	.L__pc.13267.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13268
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13268: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13269
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.13269: Dma_PatchSrc (.L__pc.13269.LD), (.L__movme_cp.77), (.L__pc.13269.LD)
	.p2align 4
	.L__pc.13269.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13270
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13270: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13271
	
	.L__pc.13271: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13272
	
	.p2align 4
	.L__pc.13272: Dma_PatchDst (.L__pc.13272.ST), ((.L__movme.reg.eax+0)), (.L__pc.13272.ST)
	.L__pc.13272.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13273
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.13273: Dma_PatchSrc (.L__pc.13273.LD), (.L__movme_cp.76), (.L__pc.13273.LD)
	.p2align 4
	.L__pc.13273.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13274
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13274: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13275
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.13275: Dma_PatchSrc (.L__pc.13275.LD), ((.L__movme.reg.eax+0)), (.L__pc.13275.LD)
	.p2align 4
	.L__pc.13275.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13276
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13276: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13277
	
	.L__pc.13277: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13278
	
	.p2align 4
	.L__pc.13278: Dma_PatchDst (.L__pc.13278.ST), (.L__movme_cp.80), (.L__pc.13278.ST)
	.L__pc.13278.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13279
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13279: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13280
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13280: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13281
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.13281: Dma_PatchSrc (.L__pc.13281.LD), (.L__movme_cp.81), (.L__pc.13281.LD)
	.p2align 4
	.L__pc.13281.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13282
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13282: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13283
	.L__pc.13283: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13284
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.84 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.13284: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13285: Dma_PatchSrc (.L__pc.13285.LD), (.L__movme_tmp.1), (.L__pc.13285.LD)
	.p2align 4
	.L__pc.13285.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13286
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13286: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13287
	.L__pc.13287: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13288
	
	.L__pc.13288: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13289
	
	.p2align 4
	.L__pc.13289: Dma_PatchDst (.L__pc.13289.ST), (.L__movme_cp.81), (.L__pc.13289.ST)
	.L__pc.13289.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13290
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.13290: Dma_PatchSrc (.L__pc.13290.LD), (.L__movme_cp.76), (.L__pc.13290.LD)
	.p2align 4
	.L__pc.13290.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13291
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13291: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13292
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.13292: Dma_PatchSrc (.L__pc.13292.LD), (.L__movme_cp.80), (.L__pc.13292.LD)
	.p2align 4
	.L__pc.13292.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13293
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13293: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13294
	
	.L__pc.13294: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13295
	
	.p2align 4
	.L__pc.13295: Dma_PatchDst (.L__pc.13295.ST), ((.L__movme.reg.eax+0)), (.L__pc.13295.ST)
	.L__pc.13295.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13296
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13296: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13297
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13297: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13298
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.13298: Dma_PatchSrc (.L__pc.13298.LD), (.L__movme_cp.61), (.L__pc.13298.LD)
	.p2align 4
	.L__pc.13298.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13299
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13299: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13300
	.L__pc.13300: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13301
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13301: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.85 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13302: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13303: Dma_PatchSrc (.L__pc.13303.LD), (.L__movme_tmp.1), (.L__pc.13303.LD)
	.p2align 4
	.L__pc.13303.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13304
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13304: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13305
	
	.L__pc.13305: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13306
	
	.p2align 4
	.L__pc.13306: Dma_PatchDst (.L__pc.13306.ST), (.L__movme_cp.24), (.L__pc.13306.ST)
	.L__pc.13306.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13307
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13307: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13308
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13308: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13309
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13309: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13310
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13310: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13311
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.13311: Dma_PatchSrc (.L__pc.13311.LD), (.L__movme_cp.63), (.L__pc.13311.LD)
	.p2align 4
	.L__pc.13311.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13312
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13312: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13313
	.L__pc.13313: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13314
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13314: Dma_PatchSrc (.L__pc.13314.LD), (.L__movme_cp.24), (.L__pc.13314.LD)
	.p2align 4
	.L__pc.13314.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13315
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13315: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13316
	.L__pc.13316: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13317
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13317: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13318: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13319: Dma_PatchSrc (.L__pc.13319.LD), (.L__movme_tmp.1), (.L__pc.13319.LD)
	.p2align 4
	.L__pc.13319.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13320
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13320: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13321
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13321: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13322: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13323: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13324: Dma_PatchSrc (.L__pc.13324.LD), (.L__movme_tmp.1), (.L__pc.13324.LD)
	.p2align 4
	.L__pc.13324.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13325
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13325: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13326
	
	.L__pc.13326: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13327
	
	.p2align 4
	.L__pc.13327: Dma_PatchDst (.L__pc.13327.ST), (.L__movme_cp.63), (.L__pc.13327.ST)
	.L__pc.13327.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13328
	
	.L__pc.13328: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13329
	
	.p2align 4
	.L__pc.13329: Dma_PatchDst (.L__pc.13329.ST), (.L__movme_cp.24), (.L__pc.13329.ST)
	.L__pc.13329.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13330
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13330: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13331
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13331: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13332
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13332: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13333
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13333: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13334
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.13334: Dma_PatchSrc (.L__pc.13334.LD), (.L__movme_cp.66), (.L__pc.13334.LD)
	.p2align 4
	.L__pc.13334.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13335
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13335: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13336
	.L__pc.13336: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13337
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13337: Dma_PatchSrc (.L__pc.13337.LD), (.L__movme_cp.24), (.L__pc.13337.LD)
	.p2align 4
	.L__pc.13337.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13338
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13338: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13339
	.L__pc.13339: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13340
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13340: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13341: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13342: Dma_PatchSrc (.L__pc.13342.LD), (.L__movme_tmp.1), (.L__pc.13342.LD)
	.p2align 4
	.L__pc.13342.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13343
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13343: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13344
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13344: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13345: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13346: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13347: Dma_PatchSrc (.L__pc.13347.LD), (.L__movme_tmp.1), (.L__pc.13347.LD)
	.p2align 4
	.L__pc.13347.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13348
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13348: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13349
	
	.L__pc.13349: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13350
	
	.p2align 4
	.L__pc.13350: Dma_PatchDst (.L__pc.13350.ST), (.L__movme_cp.66), (.L__pc.13350.ST)
	.L__pc.13350.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13351
	
	.L__pc.13351: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13352
	
	.p2align 4
	.L__pc.13352: Dma_PatchDst (.L__pc.13352.ST), (.L__movme_cp.24), (.L__pc.13352.ST)
	.L__pc.13352.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13353
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13353: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13354
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13354: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13355
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13355: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13356
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13356: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13357
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.13357: Dma_PatchSrc (.L__pc.13357.LD), (.L__movme_cp.67), (.L__pc.13357.LD)
	.p2align 4
	.L__pc.13357.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13358
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13358: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13359
	.L__pc.13359: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13360
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13360: Dma_PatchSrc (.L__pc.13360.LD), (.L__movme_cp.24), (.L__pc.13360.LD)
	.p2align 4
	.L__pc.13360.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13361
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13361: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13362
	.L__pc.13362: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13363
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13363: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13364: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13365: Dma_PatchSrc (.L__pc.13365.LD), (.L__movme_tmp.1), (.L__pc.13365.LD)
	.p2align 4
	.L__pc.13365.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13366
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13366: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13367
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13367: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13368: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13369: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13370: Dma_PatchSrc (.L__pc.13370.LD), (.L__movme_tmp.1), (.L__pc.13370.LD)
	.p2align 4
	.L__pc.13370.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13371
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13371: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13372
	
	.L__pc.13372: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13373
	
	.p2align 4
	.L__pc.13373: Dma_PatchDst (.L__pc.13373.ST), (.L__movme_cp.67), (.L__pc.13373.ST)
	.L__pc.13373.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13374
	
	.L__pc.13374: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13375
	
	.p2align 4
	.L__pc.13375: Dma_PatchDst (.L__pc.13375.ST), (.L__movme_cp.24), (.L__pc.13375.ST)
	.L__pc.13375.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13376
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13376: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13377
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13377: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13378
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13378: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13379
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13379: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13380
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.13380: Dma_PatchSrc (.L__pc.13380.LD), (.L__movme_cp.68), (.L__pc.13380.LD)
	.p2align 4
	.L__pc.13380.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13381
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13381: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13382
	.L__pc.13382: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13383
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13383: Dma_PatchSrc (.L__pc.13383.LD), (.L__movme_cp.24), (.L__pc.13383.LD)
	.p2align 4
	.L__pc.13383.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13384
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13384: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13385
	.L__pc.13385: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13386
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13386: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13387: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13388: Dma_PatchSrc (.L__pc.13388.LD), (.L__movme_tmp.1), (.L__pc.13388.LD)
	.p2align 4
	.L__pc.13388.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13389
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13389: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13390
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13390: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13391: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13392: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13393: Dma_PatchSrc (.L__pc.13393.LD), (.L__movme_tmp.1), (.L__pc.13393.LD)
	.p2align 4
	.L__pc.13393.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13394
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13394: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13395
	
	.L__pc.13395: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13396
	
	.p2align 4
	.L__pc.13396: Dma_PatchDst (.L__pc.13396.ST), (.L__movme_cp.68), (.L__pc.13396.ST)
	.L__pc.13396.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13397
	
	.L__pc.13397: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13398
	
	.p2align 4
	.L__pc.13398: Dma_PatchDst (.L__pc.13398.ST), (.L__movme_cp.24), (.L__pc.13398.ST)
	.L__pc.13398.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13399
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13399: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13400
	
	.p2align 4
	.L__pc.13400: Dma_PatchDst (.L__pc.13400.ST), (.L__movme_cp.24), (.L__pc.13400.ST)
	.L__pc.13400.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13401
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.13401: Dma_PatchSrc (.L__pc.13401.LD), (.L__movme_cp.60), (.L__pc.13401.LD)
	.p2align 4
	.L__pc.13401.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13402
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13402: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13403
	
	.L__pc.13403: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13404
	
	.p2align 4
	.L__pc.13404: Dma_PatchDst (.L__pc.13404.ST), (.L__movme_cp.21), (.L__pc.13404.ST)
	.L__pc.13404.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13405
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.13405: Dma_PatchSrc (.L__pc.13405.LD), (.L__movme_cp.58), (.L__pc.13405.LD)
	.p2align 4
	.L__pc.13405.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13406
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13406: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13407
	
	.L__pc.13407: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13408
	
	.p2align 4
	.L__pc.13408: Dma_PatchDst (.L__pc.13408.ST), (.L__movme_cp.22), (.L__pc.13408.ST)
	.L__pc.13408.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13409
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13409: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13410
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13410: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13411
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13411: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13412
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13412: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13413
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.13413: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.13414
	
	.p2align 4
	.L__pc.13414: Dma_PatchDst (.L__pc.13414.ST), (.L__movme_cp.24), (.L__pc.13414.ST)
	.L__pc.13414.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13415
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.13415: Dma_PatchSrc (.L__pc.13415.LD), (.L__movme_cp.25), (.L__pc.13415.LD)
	.p2align 4
	.L__pc.13415.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13416
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13416: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13417
	.L__pc.13417: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13418
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.13418: Dma_PatchSrc (.L__pc.13418.LD), (.L__movme_cp.26), (.L__pc.13418.LD)
	.p2align 4
	.L__pc.13418.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13419
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13419: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13420
	.L__pc.13420: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13421
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13421: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13422: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13423: Dma_PatchSrc (.L__pc.13423.LD), (.L__movme_tmp.1), (.L__pc.13423.LD)
	.p2align 4
	.L__pc.13423.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13424
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13424: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13425
	.L__pc.13425: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13426
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13426: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13427: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13428: Dma_PatchSrc (.L__pc.13428.LD), (.L__movme_tmp.1), (.L__pc.13428.LD)
	.p2align 4
	.L__pc.13428.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13429
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13429: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13430
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13430: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13431: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13432: Dma_PatchSrc (.L__pc.13432.LD), (.L__movme_tmp.1), (.L__pc.13432.LD)
	.p2align 4
	.L__pc.13432.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13433
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13433: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13434
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13434: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13435: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13436: Dma_PatchSrc (.L__pc.13436.LD), (.L__movme_tmp.1), (.L__pc.13436.LD)
	.p2align 4
	.L__pc.13436.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13437
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13437: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13438
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13438: Dma_PatchSrc (.L__pc.13438.LD), (.L__movme_cp.24), (.L__pc.13438.LD)
	.p2align 4
	.L__pc.13438.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13439
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13439: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13440
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13440: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13441: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13442: Dma_PatchSrc (.L__pc.13442.LD), (.L__movme_tmp.1), (.L__pc.13442.LD)
	.p2align 4
	.L__pc.13442.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13443
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13443: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13444
	
	.L__pc.13444: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13445
	
	.p2align 4
	.L__pc.13445: Dma_PatchDst (.L__pc.13445.ST), (.L__movme_cp.69), (.L__pc.13445.ST)
	.L__pc.13445.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13446
	
	.L__pc.13446: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13447
	
	.p2align 4
	.L__pc.13447: Dma_PatchDst (.L__pc.13447.ST), (.L__movme_cp.54), (.L__pc.13447.ST)
	.L__pc.13447.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13448
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.13448: Dma_PatchSrc (.L__pc.13448.LD), (.L__movme_cp.30), (.L__pc.13448.LD)
	.p2align 4
	.L__pc.13448.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13449
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13449: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13450
	.L__pc.13450: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13451
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.13451: Dma_PatchSrc (.L__pc.13451.LD), (.L__movme_cp.31), (.L__pc.13451.LD)
	.p2align 4
	.L__pc.13451.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13452
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13452: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13453
	.L__pc.13453: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13454
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13454: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13455: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13456: Dma_PatchSrc (.L__pc.13456.LD), (.L__movme_tmp.1), (.L__pc.13456.LD)
	.p2align 4
	.L__pc.13456.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13457
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13457: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13458
	.L__pc.13458: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13459
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13459: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13460: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13461: Dma_PatchSrc (.L__pc.13461.LD), (.L__movme_tmp.1), (.L__pc.13461.LD)
	.p2align 4
	.L__pc.13461.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13462
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13462: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13463
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13463: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13464: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13465: Dma_PatchSrc (.L__pc.13465.LD), (.L__movme_tmp.1), (.L__pc.13465.LD)
	.p2align 4
	.L__pc.13465.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13466
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13466: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13467
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13467: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13468: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13469: Dma_PatchSrc (.L__pc.13469.LD), (.L__movme_tmp.1), (.L__pc.13469.LD)
	.p2align 4
	.L__pc.13469.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13470
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13470: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13471
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13471: Dma_PatchSrc (.L__pc.13471.LD), (.L__movme_cp.24), (.L__pc.13471.LD)
	.p2align 4
	.L__pc.13471.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13472
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13472: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13473
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13473: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13474: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13475: Dma_PatchSrc (.L__pc.13475.LD), (.L__movme_tmp.1), (.L__pc.13475.LD)
	.p2align 4
	.L__pc.13475.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13476
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13476: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13477
	
	.L__pc.13477: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13478
	
	.p2align 4
	.L__pc.13478: Dma_PatchDst (.L__pc.13478.ST), (.L__movme_cp.70), (.L__pc.13478.ST)
	.L__pc.13478.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13479
	
	.L__pc.13479: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13480
	
	.p2align 4
	.L__pc.13480: Dma_PatchDst (.L__pc.13480.ST), (.L__movme_cp.54), (.L__pc.13480.ST)
	.L__pc.13480.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13481
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13481: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13482
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13482: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13483
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13483: Dma_PatchSrc (.L__pc.13483.LD), (.L__movme_cp.24), (.L__pc.13483.LD)
	.p2align 4
	.L__pc.13483.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13484
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13484: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13485
	.L__pc.13485: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13486
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.13486: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13487: Dma_PatchSrc (.L__pc.13487.LD), (.L__movme_tmp.1), (.L__pc.13487.LD)
	.p2align 4
	.L__pc.13487.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13488
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13488: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13489
	.L__pc.13489: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13490
	
	.L__pc.13490: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13491
	
	.p2align 4
	.L__pc.13491: Dma_PatchDst (.L__pc.13491.ST), (.L__movme_cp.72), (.L__pc.13491.ST)
	.L__pc.13491.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13492
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.13492: Dma_PatchSrc (.L__pc.13492.LD), (.L__movme_cp.72), (.L__pc.13492.LD)
	.p2align 4
	.L__pc.13492.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13493
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13493: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13494
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13494: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13495: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13496: Dma_PatchSrc (.L__pc.13496.LD), (.L__movme_tmp.1), (.L__pc.13496.LD)
	.p2align 4
	.L__pc.13496.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13497
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13497: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13498
	
	.L__pc.13498: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13499
	
	.p2align 4
	.L__pc.13499: Dma_PatchDst (.L__pc.13499.ST), (.L__movme_cp.74), (.L__pc.13499.ST)
	.L__pc.13499.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13500
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13500: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13501: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13502: Dma_PatchSrc (.L__pc.13502.LD), (.L__movme_tmp.1), (.L__pc.13502.LD)
	.p2align 4
	.L__pc.13502.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13503
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13503: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13504
	
	.L__pc.13504: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13505
	
	.p2align 4
	.L__pc.13505: Dma_PatchDst (.L__pc.13505.ST), (.L__movme_cp.76), (.L__pc.13505.ST)
	.L__pc.13505.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13506
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.13506: Dma_PatchSrc (.L__pc.13506.LD), (.L__movme_cp.74), (.L__pc.13506.LD)
	.p2align 4
	.L__pc.13506.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13507
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13507: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13508
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.13508: Dma_PatchSrc (.L__pc.13508.LD), ((.L__movme.reg.eax+0)), (.L__pc.13508.LD)
	.p2align 4
	.L__pc.13508.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13509
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13509: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13510
	
	.L__pc.13510: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13511
	
	.p2align 4
	.L__pc.13511: Dma_PatchDst (.L__pc.13511.ST), (.L__movme_cp.77), (.L__pc.13511.ST)
	.L__pc.13511.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13512
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.13512: Dma_PatchSrc (.L__pc.13512.LD), (.L__movme_cp.77), (.L__pc.13512.LD)
	.p2align 4
	.L__pc.13512.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13513
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13513: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13514
	
	.L__pc.13514: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13515
	
	.p2align 4
	.L__pc.13515: Dma_PatchDst (.L__pc.13515.ST), (.L__movme_cp.21), (.L__pc.13515.ST)
	.L__pc.13515.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13516
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.13516: Dma_PatchSrc (.L__pc.13516.LD), (.L__movme_cp.58), (.L__pc.13516.LD)
	.p2align 4
	.L__pc.13516.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13517
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13517: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13518
	
	.L__pc.13518: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13519
	
	.p2align 4
	.L__pc.13519: Dma_PatchDst (.L__pc.13519.ST), (.L__movme_cp.22), (.L__pc.13519.ST)
	.L__pc.13519.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13520
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13520: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13521
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13521: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13522
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13522: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13523
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13523: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13524
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.13524: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.13525
	
	.p2align 4
	.L__pc.13525: Dma_PatchDst (.L__pc.13525.ST), (.L__movme_cp.24), (.L__pc.13525.ST)
	.L__pc.13525.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13526
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.13526: Dma_PatchSrc (.L__pc.13526.LD), (.L__movme_cp.25), (.L__pc.13526.LD)
	.p2align 4
	.L__pc.13526.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13527
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13527: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13528
	.L__pc.13528: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13529
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.13529: Dma_PatchSrc (.L__pc.13529.LD), (.L__movme_cp.26), (.L__pc.13529.LD)
	.p2align 4
	.L__pc.13529.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13530
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13530: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13531
	.L__pc.13531: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13532
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13532: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13533: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13534: Dma_PatchSrc (.L__pc.13534.LD), (.L__movme_tmp.1), (.L__pc.13534.LD)
	.p2align 4
	.L__pc.13534.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13535
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13535: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13536
	.L__pc.13536: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13537
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13537: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13538: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13539: Dma_PatchSrc (.L__pc.13539.LD), (.L__movme_tmp.1), (.L__pc.13539.LD)
	.p2align 4
	.L__pc.13539.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13540
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13540: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13541
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13541: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13542: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13543: Dma_PatchSrc (.L__pc.13543.LD), (.L__movme_tmp.1), (.L__pc.13543.LD)
	.p2align 4
	.L__pc.13543.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13544
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13544: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13545
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13545: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13546: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13547: Dma_PatchSrc (.L__pc.13547.LD), (.L__movme_tmp.1), (.L__pc.13547.LD)
	.p2align 4
	.L__pc.13547.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13548
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13548: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13549
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13549: Dma_PatchSrc (.L__pc.13549.LD), (.L__movme_cp.24), (.L__pc.13549.LD)
	.p2align 4
	.L__pc.13549.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13550
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13550: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13551
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13551: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13552: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13553: Dma_PatchSrc (.L__pc.13553.LD), (.L__movme_tmp.1), (.L__pc.13553.LD)
	.p2align 4
	.L__pc.13553.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13554
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13554: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13555
	
	.L__pc.13555: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13556
	
	.p2align 4
	.L__pc.13556: Dma_PatchDst (.L__pc.13556.ST), (.L__movme_cp.78), (.L__pc.13556.ST)
	.L__pc.13556.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13557
	
	.L__pc.13557: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13558
	
	.p2align 4
	.L__pc.13558: Dma_PatchDst (.L__pc.13558.ST), (.L__movme_cp.54), (.L__pc.13558.ST)
	.L__pc.13558.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13559
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.13559: Dma_PatchSrc (.L__pc.13559.LD), (.L__movme_cp.30), (.L__pc.13559.LD)
	.p2align 4
	.L__pc.13559.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13560
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13560: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13561
	.L__pc.13561: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13562
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.13562: Dma_PatchSrc (.L__pc.13562.LD), (.L__movme_cp.31), (.L__pc.13562.LD)
	.p2align 4
	.L__pc.13562.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13563
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13563: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13564
	.L__pc.13564: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13565
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13565: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13566: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13567: Dma_PatchSrc (.L__pc.13567.LD), (.L__movme_tmp.1), (.L__pc.13567.LD)
	.p2align 4
	.L__pc.13567.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13568
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13568: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13569
	.L__pc.13569: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13570
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13570: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13571: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13572: Dma_PatchSrc (.L__pc.13572.LD), (.L__movme_tmp.1), (.L__pc.13572.LD)
	.p2align 4
	.L__pc.13572.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13573
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13573: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13574
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13574: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13575: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13576: Dma_PatchSrc (.L__pc.13576.LD), (.L__movme_tmp.1), (.L__pc.13576.LD)
	.p2align 4
	.L__pc.13576.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13577
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13577: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13578
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13578: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13579: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13580: Dma_PatchSrc (.L__pc.13580.LD), (.L__movme_tmp.1), (.L__pc.13580.LD)
	.p2align 4
	.L__pc.13580.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13581
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13581: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13582
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13582: Dma_PatchSrc (.L__pc.13582.LD), (.L__movme_cp.24), (.L__pc.13582.LD)
	.p2align 4
	.L__pc.13582.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13583
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13583: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13584
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13584: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13585: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13586: Dma_PatchSrc (.L__pc.13586.LD), (.L__movme_tmp.1), (.L__pc.13586.LD)
	.p2align 4
	.L__pc.13586.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13587
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13587: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13588
	
	.L__pc.13588: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13589
	
	.p2align 4
	.L__pc.13589: Dma_PatchDst (.L__pc.13589.ST), (.L__movme_cp.79), (.L__pc.13589.ST)
	.L__pc.13589.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13590
	
	.L__pc.13590: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13591
	
	.p2align 4
	.L__pc.13591: Dma_PatchDst (.L__pc.13591.ST), (.L__movme_cp.54), (.L__pc.13591.ST)
	.L__pc.13591.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13592
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.13592: Dma_PatchSrc (.L__pc.13592.LD), (.L__movme_cp.74), (.L__pc.13592.LD)
	.p2align 4
	.L__pc.13592.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13593
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13593: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13594
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.13594: Dma_PatchSrc (.L__pc.13594.LD), (.L__movme_cp.77), (.L__pc.13594.LD)
	.p2align 4
	.L__pc.13594.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13595
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13595: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13596
	
	.L__pc.13596: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13597
	
	.p2align 4
	.L__pc.13597: Dma_PatchDst (.L__pc.13597.ST), ((.L__movme.reg.eax+0)), (.L__pc.13597.ST)
	.L__pc.13597.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13598
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.13598: Dma_PatchSrc (.L__pc.13598.LD), (.L__movme_cp.76), (.L__pc.13598.LD)
	.p2align 4
	.L__pc.13598.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13599
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13599: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13600
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.13600: Dma_PatchSrc (.L__pc.13600.LD), ((.L__movme.reg.eax+0)), (.L__pc.13600.LD)
	.p2align 4
	.L__pc.13600.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13601
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13601: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13602
	
	.L__pc.13602: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13603
	
	.p2align 4
	.L__pc.13603: Dma_PatchDst (.L__pc.13603.ST), (.L__movme_cp.80), (.L__pc.13603.ST)
	.L__pc.13603.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13604
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13604: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13605
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13605: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13606
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.13606: Dma_PatchSrc (.L__pc.13606.LD), (.L__movme_cp.81), (.L__pc.13606.LD)
	.p2align 4
	.L__pc.13606.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13607
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13607: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13608
	.L__pc.13608: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13609
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.86 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.13609: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13610: Dma_PatchSrc (.L__pc.13610.LD), (.L__movme_tmp.1), (.L__pc.13610.LD)
	.p2align 4
	.L__pc.13610.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13611
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13611: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13612
	.L__pc.13612: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13613
	
	.L__pc.13613: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13614
	
	.p2align 4
	.L__pc.13614: Dma_PatchDst (.L__pc.13614.ST), (.L__movme_cp.81), (.L__pc.13614.ST)
	.L__pc.13614.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13615
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.13615: Dma_PatchSrc (.L__pc.13615.LD), (.L__movme_cp.76), (.L__pc.13615.LD)
	.p2align 4
	.L__pc.13615.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13616
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13616: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13617
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.13617: Dma_PatchSrc (.L__pc.13617.LD), (.L__movme_cp.80), (.L__pc.13617.LD)
	.p2align 4
	.L__pc.13617.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13618
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13618: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13619
	
	.L__pc.13619: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13620
	
	.p2align 4
	.L__pc.13620: Dma_PatchDst (.L__pc.13620.ST), ((.L__movme.reg.eax+0)), (.L__pc.13620.ST)
	.L__pc.13620.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13621
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13621: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13622
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13622: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13623
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.13623: Dma_PatchSrc (.L__pc.13623.LD), (.L__movme_cp.61), (.L__pc.13623.LD)
	.p2align 4
	.L__pc.13623.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13624
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13624: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13625
	.L__pc.13625: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13626
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13626: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.87 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13627: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13628: Dma_PatchSrc (.L__pc.13628.LD), (.L__movme_tmp.1), (.L__pc.13628.LD)
	.p2align 4
	.L__pc.13628.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13629
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13629: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13630
	
	.L__pc.13630: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13631
	
	.p2align 4
	.L__pc.13631: Dma_PatchDst (.L__pc.13631.ST), (.L__movme_cp.24), (.L__pc.13631.ST)
	.L__pc.13631.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13632
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13632: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13633
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13633: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13634
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13634: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13635
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13635: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13636
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.13636: Dma_PatchSrc (.L__pc.13636.LD), (.L__movme_cp.63), (.L__pc.13636.LD)
	.p2align 4
	.L__pc.13636.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13637
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13637: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13638
	.L__pc.13638: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13639
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13639: Dma_PatchSrc (.L__pc.13639.LD), (.L__movme_cp.24), (.L__pc.13639.LD)
	.p2align 4
	.L__pc.13639.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13640
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13640: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13641
	.L__pc.13641: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13642
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13642: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13643: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13644: Dma_PatchSrc (.L__pc.13644.LD), (.L__movme_tmp.1), (.L__pc.13644.LD)
	.p2align 4
	.L__pc.13644.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13645
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13645: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13646
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13646: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13647: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13648: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13649: Dma_PatchSrc (.L__pc.13649.LD), (.L__movme_tmp.1), (.L__pc.13649.LD)
	.p2align 4
	.L__pc.13649.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13650
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13650: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13651
	
	.L__pc.13651: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13652
	
	.p2align 4
	.L__pc.13652: Dma_PatchDst (.L__pc.13652.ST), (.L__movme_cp.63), (.L__pc.13652.ST)
	.L__pc.13652.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13653
	
	.L__pc.13653: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13654
	
	.p2align 4
	.L__pc.13654: Dma_PatchDst (.L__pc.13654.ST), (.L__movme_cp.24), (.L__pc.13654.ST)
	.L__pc.13654.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13655
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13655: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13656
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13656: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13657
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13657: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13658
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13658: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13659
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.13659: Dma_PatchSrc (.L__pc.13659.LD), (.L__movme_cp.66), (.L__pc.13659.LD)
	.p2align 4
	.L__pc.13659.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13660
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13660: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13661
	.L__pc.13661: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13662
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13662: Dma_PatchSrc (.L__pc.13662.LD), (.L__movme_cp.24), (.L__pc.13662.LD)
	.p2align 4
	.L__pc.13662.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13663
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13663: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13664
	.L__pc.13664: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13665
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13665: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13666: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13667: Dma_PatchSrc (.L__pc.13667.LD), (.L__movme_tmp.1), (.L__pc.13667.LD)
	.p2align 4
	.L__pc.13667.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13668
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13668: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13669
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13669: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13670: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13671: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13672: Dma_PatchSrc (.L__pc.13672.LD), (.L__movme_tmp.1), (.L__pc.13672.LD)
	.p2align 4
	.L__pc.13672.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13673
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13673: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13674
	
	.L__pc.13674: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13675
	
	.p2align 4
	.L__pc.13675: Dma_PatchDst (.L__pc.13675.ST), (.L__movme_cp.66), (.L__pc.13675.ST)
	.L__pc.13675.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13676
	
	.L__pc.13676: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13677
	
	.p2align 4
	.L__pc.13677: Dma_PatchDst (.L__pc.13677.ST), (.L__movme_cp.24), (.L__pc.13677.ST)
	.L__pc.13677.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13678
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13678: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13679
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13679: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13680
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13680: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13681
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13681: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13682
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.13682: Dma_PatchSrc (.L__pc.13682.LD), (.L__movme_cp.67), (.L__pc.13682.LD)
	.p2align 4
	.L__pc.13682.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13683
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13683: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13684
	.L__pc.13684: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13685
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13685: Dma_PatchSrc (.L__pc.13685.LD), (.L__movme_cp.24), (.L__pc.13685.LD)
	.p2align 4
	.L__pc.13685.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13686
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13686: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13687
	.L__pc.13687: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13688
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13688: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13689: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13690: Dma_PatchSrc (.L__pc.13690.LD), (.L__movme_tmp.1), (.L__pc.13690.LD)
	.p2align 4
	.L__pc.13690.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13691
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13691: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13692
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13692: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13693: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13694: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13695: Dma_PatchSrc (.L__pc.13695.LD), (.L__movme_tmp.1), (.L__pc.13695.LD)
	.p2align 4
	.L__pc.13695.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13696
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13696: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13697
	
	.L__pc.13697: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13698
	
	.p2align 4
	.L__pc.13698: Dma_PatchDst (.L__pc.13698.ST), (.L__movme_cp.67), (.L__pc.13698.ST)
	.L__pc.13698.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13699
	
	.L__pc.13699: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13700
	
	.p2align 4
	.L__pc.13700: Dma_PatchDst (.L__pc.13700.ST), (.L__movme_cp.24), (.L__pc.13700.ST)
	.L__pc.13700.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13701
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13701: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13702
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13702: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13703
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13703: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13704
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13704: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13705
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.13705: Dma_PatchSrc (.L__pc.13705.LD), (.L__movme_cp.68), (.L__pc.13705.LD)
	.p2align 4
	.L__pc.13705.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13706
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13706: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13707
	.L__pc.13707: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13708
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13708: Dma_PatchSrc (.L__pc.13708.LD), (.L__movme_cp.24), (.L__pc.13708.LD)
	.p2align 4
	.L__pc.13708.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13709
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13709: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13710
	.L__pc.13710: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13711
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13711: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13712: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13713: Dma_PatchSrc (.L__pc.13713.LD), (.L__movme_tmp.1), (.L__pc.13713.LD)
	.p2align 4
	.L__pc.13713.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13714
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13714: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13715
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13715: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13716: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13717: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13718: Dma_PatchSrc (.L__pc.13718.LD), (.L__movme_tmp.1), (.L__pc.13718.LD)
	.p2align 4
	.L__pc.13718.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13719
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13719: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13720
	
	.L__pc.13720: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13721
	
	.p2align 4
	.L__pc.13721: Dma_PatchDst (.L__pc.13721.ST), (.L__movme_cp.68), (.L__pc.13721.ST)
	.L__pc.13721.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13722
	
	.L__pc.13722: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13723
	
	.p2align 4
	.L__pc.13723: Dma_PatchDst (.L__pc.13723.ST), (.L__movme_cp.24), (.L__pc.13723.ST)
	.L__pc.13723.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13724
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13724: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13725
	
	.p2align 4
	.L__pc.13725: Dma_PatchDst (.L__pc.13725.ST), (.L__movme_cp.24), (.L__pc.13725.ST)
	.L__pc.13725.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13726
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.13726: Dma_PatchSrc (.L__pc.13726.LD), (.L__movme_cp.60), (.L__pc.13726.LD)
	.p2align 4
	.L__pc.13726.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13727
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13727: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13728
	
	.L__pc.13728: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13729
	
	.p2align 4
	.L__pc.13729: Dma_PatchDst (.L__pc.13729.ST), (.L__movme_cp.21), (.L__pc.13729.ST)
	.L__pc.13729.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13730
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.13730: Dma_PatchSrc (.L__pc.13730.LD), (.L__movme_cp.58), (.L__pc.13730.LD)
	.p2align 4
	.L__pc.13730.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13731
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13731: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13732
	
	.L__pc.13732: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13733
	
	.p2align 4
	.L__pc.13733: Dma_PatchDst (.L__pc.13733.ST), (.L__movme_cp.22), (.L__pc.13733.ST)
	.L__pc.13733.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13734
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13734: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13735
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13735: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13736
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13736: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13737
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13737: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13738
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.13738: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.13739
	
	.p2align 4
	.L__pc.13739: Dma_PatchDst (.L__pc.13739.ST), (.L__movme_cp.24), (.L__pc.13739.ST)
	.L__pc.13739.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13740
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.13740: Dma_PatchSrc (.L__pc.13740.LD), (.L__movme_cp.25), (.L__pc.13740.LD)
	.p2align 4
	.L__pc.13740.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13741
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13741: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13742
	.L__pc.13742: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13743
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.13743: Dma_PatchSrc (.L__pc.13743.LD), (.L__movme_cp.26), (.L__pc.13743.LD)
	.p2align 4
	.L__pc.13743.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13744
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13744: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13745
	.L__pc.13745: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13746
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13746: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13747: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13748: Dma_PatchSrc (.L__pc.13748.LD), (.L__movme_tmp.1), (.L__pc.13748.LD)
	.p2align 4
	.L__pc.13748.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13749
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13749: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13750
	.L__pc.13750: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13751
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13751: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13752: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13753: Dma_PatchSrc (.L__pc.13753.LD), (.L__movme_tmp.1), (.L__pc.13753.LD)
	.p2align 4
	.L__pc.13753.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13754
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13754: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13755
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13755: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13756: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13757: Dma_PatchSrc (.L__pc.13757.LD), (.L__movme_tmp.1), (.L__pc.13757.LD)
	.p2align 4
	.L__pc.13757.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13758
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13758: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13759
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13759: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13760: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13761: Dma_PatchSrc (.L__pc.13761.LD), (.L__movme_tmp.1), (.L__pc.13761.LD)
	.p2align 4
	.L__pc.13761.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13762
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13762: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13763
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13763: Dma_PatchSrc (.L__pc.13763.LD), (.L__movme_cp.24), (.L__pc.13763.LD)
	.p2align 4
	.L__pc.13763.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13764
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13764: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13765
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13765: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13766: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13767: Dma_PatchSrc (.L__pc.13767.LD), (.L__movme_tmp.1), (.L__pc.13767.LD)
	.p2align 4
	.L__pc.13767.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13768
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13768: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13769
	
	.L__pc.13769: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13770
	
	.p2align 4
	.L__pc.13770: Dma_PatchDst (.L__pc.13770.ST), (.L__movme_cp.69), (.L__pc.13770.ST)
	.L__pc.13770.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13771
	
	.L__pc.13771: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13772
	
	.p2align 4
	.L__pc.13772: Dma_PatchDst (.L__pc.13772.ST), (.L__movme_cp.54), (.L__pc.13772.ST)
	.L__pc.13772.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13773
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.13773: Dma_PatchSrc (.L__pc.13773.LD), (.L__movme_cp.30), (.L__pc.13773.LD)
	.p2align 4
	.L__pc.13773.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13774
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13774: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13775
	.L__pc.13775: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13776
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.13776: Dma_PatchSrc (.L__pc.13776.LD), (.L__movme_cp.31), (.L__pc.13776.LD)
	.p2align 4
	.L__pc.13776.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13777
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13777: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13778
	.L__pc.13778: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13779
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13779: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13780: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13781: Dma_PatchSrc (.L__pc.13781.LD), (.L__movme_tmp.1), (.L__pc.13781.LD)
	.p2align 4
	.L__pc.13781.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13782
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13782: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13783
	.L__pc.13783: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13784
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13784: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13785: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13786: Dma_PatchSrc (.L__pc.13786.LD), (.L__movme_tmp.1), (.L__pc.13786.LD)
	.p2align 4
	.L__pc.13786.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13787
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13787: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13788
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13788: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13789: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13790: Dma_PatchSrc (.L__pc.13790.LD), (.L__movme_tmp.1), (.L__pc.13790.LD)
	.p2align 4
	.L__pc.13790.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13791
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13791: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13792
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13792: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13793: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13794: Dma_PatchSrc (.L__pc.13794.LD), (.L__movme_tmp.1), (.L__pc.13794.LD)
	.p2align 4
	.L__pc.13794.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13795
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13795: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13796
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13796: Dma_PatchSrc (.L__pc.13796.LD), (.L__movme_cp.24), (.L__pc.13796.LD)
	.p2align 4
	.L__pc.13796.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13797
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13797: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13798
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13798: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13799: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13800: Dma_PatchSrc (.L__pc.13800.LD), (.L__movme_tmp.1), (.L__pc.13800.LD)
	.p2align 4
	.L__pc.13800.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13801
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13801: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13802
	
	.L__pc.13802: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13803
	
	.p2align 4
	.L__pc.13803: Dma_PatchDst (.L__pc.13803.ST), (.L__movme_cp.70), (.L__pc.13803.ST)
	.L__pc.13803.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13804
	
	.L__pc.13804: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13805
	
	.p2align 4
	.L__pc.13805: Dma_PatchDst (.L__pc.13805.ST), (.L__movme_cp.54), (.L__pc.13805.ST)
	.L__pc.13805.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13806
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13806: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13807
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13807: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13808
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13808: Dma_PatchSrc (.L__pc.13808.LD), (.L__movme_cp.24), (.L__pc.13808.LD)
	.p2align 4
	.L__pc.13808.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13809
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13809: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13810
	.L__pc.13810: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13811
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.13811: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13812: Dma_PatchSrc (.L__pc.13812.LD), (.L__movme_tmp.1), (.L__pc.13812.LD)
	.p2align 4
	.L__pc.13812.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13813
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13813: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13814
	.L__pc.13814: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13815
	
	.L__pc.13815: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13816
	
	.p2align 4
	.L__pc.13816: Dma_PatchDst (.L__pc.13816.ST), (.L__movme_cp.72), (.L__pc.13816.ST)
	.L__pc.13816.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13817
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.13817: Dma_PatchSrc (.L__pc.13817.LD), (.L__movme_cp.72), (.L__pc.13817.LD)
	.p2align 4
	.L__pc.13817.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13818
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13818: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13819
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13819: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13820: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13821: Dma_PatchSrc (.L__pc.13821.LD), (.L__movme_tmp.1), (.L__pc.13821.LD)
	.p2align 4
	.L__pc.13821.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13822
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13822: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13823
	
	.L__pc.13823: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13824
	
	.p2align 4
	.L__pc.13824: Dma_PatchDst (.L__pc.13824.ST), (.L__movme_cp.74), (.L__pc.13824.ST)
	.L__pc.13824.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13825
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13825: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13826: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13827: Dma_PatchSrc (.L__pc.13827.LD), (.L__movme_tmp.1), (.L__pc.13827.LD)
	.p2align 4
	.L__pc.13827.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13828
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13828: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13829
	
	.L__pc.13829: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13830
	
	.p2align 4
	.L__pc.13830: Dma_PatchDst (.L__pc.13830.ST), (.L__movme_cp.76), (.L__pc.13830.ST)
	.L__pc.13830.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13831
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.13831: Dma_PatchSrc (.L__pc.13831.LD), (.L__movme_cp.74), (.L__pc.13831.LD)
	.p2align 4
	.L__pc.13831.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13832
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13832: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13833
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.13833: Dma_PatchSrc (.L__pc.13833.LD), ((.L__movme.reg.eax+0)), (.L__pc.13833.LD)
	.p2align 4
	.L__pc.13833.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13834
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13834: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13835
	
	.L__pc.13835: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13836
	
	.p2align 4
	.L__pc.13836: Dma_PatchDst (.L__pc.13836.ST), (.L__movme_cp.77), (.L__pc.13836.ST)
	.L__pc.13836.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13837
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.13837: Dma_PatchSrc (.L__pc.13837.LD), (.L__movme_cp.77), (.L__pc.13837.LD)
	.p2align 4
	.L__pc.13837.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13838
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13838: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13839
	
	.L__pc.13839: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13840
	
	.p2align 4
	.L__pc.13840: Dma_PatchDst (.L__pc.13840.ST), (.L__movme_cp.21), (.L__pc.13840.ST)
	.L__pc.13840.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13841
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.13841: Dma_PatchSrc (.L__pc.13841.LD), (.L__movme_cp.58), (.L__pc.13841.LD)
	.p2align 4
	.L__pc.13841.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13842
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13842: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13843
	
	.L__pc.13843: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13844
	
	.p2align 4
	.L__pc.13844: Dma_PatchDst (.L__pc.13844.ST), (.L__movme_cp.22), (.L__pc.13844.ST)
	.L__pc.13844.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13845
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13845: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13846
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13846: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13847
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13847: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13848
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13848: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13849
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.13849: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.13850
	
	.p2align 4
	.L__pc.13850: Dma_PatchDst (.L__pc.13850.ST), (.L__movme_cp.24), (.L__pc.13850.ST)
	.L__pc.13850.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13851
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.13851: Dma_PatchSrc (.L__pc.13851.LD), (.L__movme_cp.25), (.L__pc.13851.LD)
	.p2align 4
	.L__pc.13851.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13852
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13852: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13853
	.L__pc.13853: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13854
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.13854: Dma_PatchSrc (.L__pc.13854.LD), (.L__movme_cp.26), (.L__pc.13854.LD)
	.p2align 4
	.L__pc.13854.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13855
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13855: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13856
	.L__pc.13856: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13857
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13857: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13858: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13859: Dma_PatchSrc (.L__pc.13859.LD), (.L__movme_tmp.1), (.L__pc.13859.LD)
	.p2align 4
	.L__pc.13859.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13860
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13860: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13861
	.L__pc.13861: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13862
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13862: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13863: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13864: Dma_PatchSrc (.L__pc.13864.LD), (.L__movme_tmp.1), (.L__pc.13864.LD)
	.p2align 4
	.L__pc.13864.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13865
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13865: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13866
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13866: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13867: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13868: Dma_PatchSrc (.L__pc.13868.LD), (.L__movme_tmp.1), (.L__pc.13868.LD)
	.p2align 4
	.L__pc.13868.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13869
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13869: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13870
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13870: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13871: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13872: Dma_PatchSrc (.L__pc.13872.LD), (.L__movme_tmp.1), (.L__pc.13872.LD)
	.p2align 4
	.L__pc.13872.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13873
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13873: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13874
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13874: Dma_PatchSrc (.L__pc.13874.LD), (.L__movme_cp.24), (.L__pc.13874.LD)
	.p2align 4
	.L__pc.13874.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13875
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13875: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13876
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13876: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13877: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13878: Dma_PatchSrc (.L__pc.13878.LD), (.L__movme_tmp.1), (.L__pc.13878.LD)
	.p2align 4
	.L__pc.13878.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13879
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13879: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13880
	
	.L__pc.13880: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13881
	
	.p2align 4
	.L__pc.13881: Dma_PatchDst (.L__pc.13881.ST), (.L__movme_cp.78), (.L__pc.13881.ST)
	.L__pc.13881.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13882
	
	.L__pc.13882: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13883
	
	.p2align 4
	.L__pc.13883: Dma_PatchDst (.L__pc.13883.ST), (.L__movme_cp.54), (.L__pc.13883.ST)
	.L__pc.13883.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13884
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.13884: Dma_PatchSrc (.L__pc.13884.LD), (.L__movme_cp.30), (.L__pc.13884.LD)
	.p2align 4
	.L__pc.13884.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13885
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13885: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.13886
	.L__pc.13886: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.13887
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.13887: Dma_PatchSrc (.L__pc.13887.LD), (.L__movme_cp.31), (.L__pc.13887.LD)
	.p2align 4
	.L__pc.13887.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13888
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13888: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13889
	.L__pc.13889: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13890
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.13890: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13891: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13892: Dma_PatchSrc (.L__pc.13892.LD), (.L__movme_tmp.1), (.L__pc.13892.LD)
	.p2align 4
	.L__pc.13892.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13893
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13893: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.13894
	.L__pc.13894: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.13895
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13895: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13896: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13897: Dma_PatchSrc (.L__pc.13897.LD), (.L__movme_tmp.1), (.L__pc.13897.LD)
	.p2align 4
	.L__pc.13897.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13898
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13898: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13899
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13899: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13900: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13901: Dma_PatchSrc (.L__pc.13901.LD), (.L__movme_tmp.1), (.L__pc.13901.LD)
	.p2align 4
	.L__pc.13901.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13902
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13902: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13903
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13903: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13904: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13905: Dma_PatchSrc (.L__pc.13905.LD), (.L__movme_tmp.1), (.L__pc.13905.LD)
	.p2align 4
	.L__pc.13905.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13906
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13906: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13907
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13907: Dma_PatchSrc (.L__pc.13907.LD), (.L__movme_cp.24), (.L__pc.13907.LD)
	.p2align 4
	.L__pc.13907.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13908
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.13908: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.13909
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.13909: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13910: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13911: Dma_PatchSrc (.L__pc.13911.LD), (.L__movme_tmp.1), (.L__pc.13911.LD)
	.p2align 4
	.L__pc.13911.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13912
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13912: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13913
	
	.L__pc.13913: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.13914
	
	.p2align 4
	.L__pc.13914: Dma_PatchDst (.L__pc.13914.ST), (.L__movme_cp.79), (.L__pc.13914.ST)
	.L__pc.13914.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13915
	
	.L__pc.13915: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13916
	
	.p2align 4
	.L__pc.13916: Dma_PatchDst (.L__pc.13916.ST), (.L__movme_cp.54), (.L__pc.13916.ST)
	.L__pc.13916.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13917
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.13917: Dma_PatchSrc (.L__pc.13917.LD), (.L__movme_cp.74), (.L__pc.13917.LD)
	.p2align 4
	.L__pc.13917.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13918
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13918: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13919
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.13919: Dma_PatchSrc (.L__pc.13919.LD), (.L__movme_cp.77), (.L__pc.13919.LD)
	.p2align 4
	.L__pc.13919.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13920
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13920: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13921
	
	.L__pc.13921: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13922
	
	.p2align 4
	.L__pc.13922: Dma_PatchDst (.L__pc.13922.ST), ((.L__movme.reg.eax+0)), (.L__pc.13922.ST)
	.L__pc.13922.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13923
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.13923: Dma_PatchSrc (.L__pc.13923.LD), (.L__movme_cp.76), (.L__pc.13923.LD)
	.p2align 4
	.L__pc.13923.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13924
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13924: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13925
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.13925: Dma_PatchSrc (.L__pc.13925.LD), ((.L__movme.reg.eax+0)), (.L__pc.13925.LD)
	.p2align 4
	.L__pc.13925.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13926
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13926: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13927
	
	.L__pc.13927: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13928
	
	.p2align 4
	.L__pc.13928: Dma_PatchDst (.L__pc.13928.ST), (.L__movme_cp.80), (.L__pc.13928.ST)
	.L__pc.13928.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13929
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13929: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13930
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13930: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13931
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.13931: Dma_PatchSrc (.L__pc.13931.LD), (.L__movme_cp.81), (.L__pc.13931.LD)
	.p2align 4
	.L__pc.13931.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13932
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13932: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13933
	.L__pc.13933: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13934
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.88 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.13934: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13935: Dma_PatchSrc (.L__pc.13935.LD), (.L__movme_tmp.1), (.L__pc.13935.LD)
	.p2align 4
	.L__pc.13935.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13936
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13936: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13937
	.L__pc.13937: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13938
	
	.L__pc.13938: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13939
	
	.p2align 4
	.L__pc.13939: Dma_PatchDst (.L__pc.13939.ST), (.L__movme_cp.81), (.L__pc.13939.ST)
	.L__pc.13939.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13940
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.13940: Dma_PatchSrc (.L__pc.13940.LD), (.L__movme_cp.76), (.L__pc.13940.LD)
	.p2align 4
	.L__pc.13940.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13941
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13941: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13942
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.13942: Dma_PatchSrc (.L__pc.13942.LD), (.L__movme_cp.80), (.L__pc.13942.LD)
	.p2align 4
	.L__pc.13942.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13943
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13943: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13944
	
	.L__pc.13944: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.13945
	
	.p2align 4
	.L__pc.13945: Dma_PatchDst (.L__pc.13945.ST), ((.L__movme.reg.eax+0)), (.L__pc.13945.ST)
	.L__pc.13945.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13946
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13946: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13947
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13947: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13948
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.13948: Dma_PatchSrc (.L__pc.13948.LD), (.L__movme_cp.61), (.L__pc.13948.LD)
	.p2align 4
	.L__pc.13948.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13949
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13949: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13950
	.L__pc.13950: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13951
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.13951: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.89 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13952: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13953: Dma_PatchSrc (.L__pc.13953.LD), (.L__movme_tmp.1), (.L__pc.13953.LD)
	.p2align 4
	.L__pc.13953.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13954
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13954: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13955
	
	.L__pc.13955: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.13956
	
	.p2align 4
	.L__pc.13956: Dma_PatchDst (.L__pc.13956.ST), (.L__movme_cp.24), (.L__pc.13956.ST)
	.L__pc.13956.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13957
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13957: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13958
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13958: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13959
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13959: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13960
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13960: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13961
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.13961: Dma_PatchSrc (.L__pc.13961.LD), (.L__movme_cp.63), (.L__pc.13961.LD)
	.p2align 4
	.L__pc.13961.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13962
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13962: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13963
	.L__pc.13963: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13964
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13964: Dma_PatchSrc (.L__pc.13964.LD), (.L__movme_cp.24), (.L__pc.13964.LD)
	.p2align 4
	.L__pc.13964.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13965
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13965: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13966
	.L__pc.13966: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13967
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13967: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13968: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13969: Dma_PatchSrc (.L__pc.13969.LD), (.L__movme_tmp.1), (.L__pc.13969.LD)
	.p2align 4
	.L__pc.13969.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13970
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13970: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13971
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13971: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13972: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13973: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13974: Dma_PatchSrc (.L__pc.13974.LD), (.L__movme_tmp.1), (.L__pc.13974.LD)
	.p2align 4
	.L__pc.13974.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13975
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13975: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13976
	
	.L__pc.13976: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.13977
	
	.p2align 4
	.L__pc.13977: Dma_PatchDst (.L__pc.13977.ST), (.L__movme_cp.63), (.L__pc.13977.ST)
	.L__pc.13977.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13978
	
	.L__pc.13978: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.13979
	
	.p2align 4
	.L__pc.13979: Dma_PatchDst (.L__pc.13979.ST), (.L__movme_cp.24), (.L__pc.13979.ST)
	.L__pc.13979.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.13980
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13980: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13981
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13981: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13982
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.13982: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.13983
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13983: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.13984
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.13984: Dma_PatchSrc (.L__pc.13984.LD), (.L__movme_cp.66), (.L__pc.13984.LD)
	.p2align 4
	.L__pc.13984.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13985
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13985: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.13986
	.L__pc.13986: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.13987
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.13987: Dma_PatchSrc (.L__pc.13987.LD), (.L__movme_cp.24), (.L__pc.13987.LD)
	.p2align 4
	.L__pc.13987.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13988
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.13988: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.13989
	.L__pc.13989: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.13990
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.13990: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.13991: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13992: Dma_PatchSrc (.L__pc.13992.LD), (.L__movme_tmp.1), (.L__pc.13992.LD)
	.p2align 4
	.L__pc.13992.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13993
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13993: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13994
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.13994: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.13995: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.13996: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.13997: Dma_PatchSrc (.L__pc.13997.LD), (.L__movme_tmp.1), (.L__pc.13997.LD)
	.p2align 4
	.L__pc.13997.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.13998
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.13998: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.13999
	
	.L__pc.13999: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14000
	
	.p2align 4
	.L__pc.14000: Dma_PatchDst (.L__pc.14000.ST), (.L__movme_cp.66), (.L__pc.14000.ST)
	.L__pc.14000.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14001
	
	.L__pc.14001: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14002
	
	.p2align 4
	.L__pc.14002: Dma_PatchDst (.L__pc.14002.ST), (.L__movme_cp.24), (.L__pc.14002.ST)
	.L__pc.14002.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14003
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14003: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14004
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14004: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14005
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14005: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14006
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14006: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14007
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.14007: Dma_PatchSrc (.L__pc.14007.LD), (.L__movme_cp.67), (.L__pc.14007.LD)
	.p2align 4
	.L__pc.14007.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14008
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14008: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14009
	.L__pc.14009: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14010
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14010: Dma_PatchSrc (.L__pc.14010.LD), (.L__movme_cp.24), (.L__pc.14010.LD)
	.p2align 4
	.L__pc.14010.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14011
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14011: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14012
	.L__pc.14012: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14013
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14013: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14014: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14015: Dma_PatchSrc (.L__pc.14015.LD), (.L__movme_tmp.1), (.L__pc.14015.LD)
	.p2align 4
	.L__pc.14015.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14016
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14016: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14017
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14017: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14018: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14019: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14020: Dma_PatchSrc (.L__pc.14020.LD), (.L__movme_tmp.1), (.L__pc.14020.LD)
	.p2align 4
	.L__pc.14020.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14021
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14021: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14022
	
	.L__pc.14022: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14023
	
	.p2align 4
	.L__pc.14023: Dma_PatchDst (.L__pc.14023.ST), (.L__movme_cp.67), (.L__pc.14023.ST)
	.L__pc.14023.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14024
	
	.L__pc.14024: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14025
	
	.p2align 4
	.L__pc.14025: Dma_PatchDst (.L__pc.14025.ST), (.L__movme_cp.24), (.L__pc.14025.ST)
	.L__pc.14025.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14026
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14026: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14027
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14027: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14028
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14028: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14029
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14029: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14030
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.14030: Dma_PatchSrc (.L__pc.14030.LD), (.L__movme_cp.68), (.L__pc.14030.LD)
	.p2align 4
	.L__pc.14030.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14031
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14031: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14032
	.L__pc.14032: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14033
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14033: Dma_PatchSrc (.L__pc.14033.LD), (.L__movme_cp.24), (.L__pc.14033.LD)
	.p2align 4
	.L__pc.14033.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14034
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14034: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14035
	.L__pc.14035: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14036
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14036: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14037: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14038: Dma_PatchSrc (.L__pc.14038.LD), (.L__movme_tmp.1), (.L__pc.14038.LD)
	.p2align 4
	.L__pc.14038.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14039
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14039: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14040
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14040: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14041: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14042: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14043: Dma_PatchSrc (.L__pc.14043.LD), (.L__movme_tmp.1), (.L__pc.14043.LD)
	.p2align 4
	.L__pc.14043.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14044
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14044: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14045
	
	.L__pc.14045: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14046
	
	.p2align 4
	.L__pc.14046: Dma_PatchDst (.L__pc.14046.ST), (.L__movme_cp.68), (.L__pc.14046.ST)
	.L__pc.14046.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14047
	
	.L__pc.14047: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14048
	
	.p2align 4
	.L__pc.14048: Dma_PatchDst (.L__pc.14048.ST), (.L__movme_cp.24), (.L__pc.14048.ST)
	.L__pc.14048.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14049
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14049: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14050
	
	.p2align 4
	.L__pc.14050: Dma_PatchDst (.L__pc.14050.ST), (.L__movme_cp.24), (.L__pc.14050.ST)
	.L__pc.14050.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14051
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.14051: Dma_PatchSrc (.L__pc.14051.LD), (.L__movme_cp.60), (.L__pc.14051.LD)
	.p2align 4
	.L__pc.14051.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14052
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14052: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14053
	
	.L__pc.14053: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14054
	
	.p2align 4
	.L__pc.14054: Dma_PatchDst (.L__pc.14054.ST), (.L__movme_cp.21), (.L__pc.14054.ST)
	.L__pc.14054.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14055
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.14055: Dma_PatchSrc (.L__pc.14055.LD), (.L__movme_cp.58), (.L__pc.14055.LD)
	.p2align 4
	.L__pc.14055.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14056
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14056: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14057
	
	.L__pc.14057: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14058
	
	.p2align 4
	.L__pc.14058: Dma_PatchDst (.L__pc.14058.ST), (.L__movme_cp.22), (.L__pc.14058.ST)
	.L__pc.14058.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14059
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14059: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14060
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14060: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14061
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14061: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14062
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14062: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14063
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.14063: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.14064
	
	.p2align 4
	.L__pc.14064: Dma_PatchDst (.L__pc.14064.ST), (.L__movme_cp.24), (.L__pc.14064.ST)
	.L__pc.14064.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14065
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.14065: Dma_PatchSrc (.L__pc.14065.LD), (.L__movme_cp.25), (.L__pc.14065.LD)
	.p2align 4
	.L__pc.14065.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14066
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14066: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14067
	.L__pc.14067: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14068
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.14068: Dma_PatchSrc (.L__pc.14068.LD), (.L__movme_cp.26), (.L__pc.14068.LD)
	.p2align 4
	.L__pc.14068.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14069
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14069: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14070
	.L__pc.14070: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14071
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14071: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14072: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14073: Dma_PatchSrc (.L__pc.14073.LD), (.L__movme_tmp.1), (.L__pc.14073.LD)
	.p2align 4
	.L__pc.14073.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14074
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14074: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14075
	.L__pc.14075: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14076
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14076: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14077: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14078: Dma_PatchSrc (.L__pc.14078.LD), (.L__movme_tmp.1), (.L__pc.14078.LD)
	.p2align 4
	.L__pc.14078.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14079
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14079: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14080
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14080: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14081: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14082: Dma_PatchSrc (.L__pc.14082.LD), (.L__movme_tmp.1), (.L__pc.14082.LD)
	.p2align 4
	.L__pc.14082.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14083
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14083: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14084
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14084: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14085: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14086: Dma_PatchSrc (.L__pc.14086.LD), (.L__movme_tmp.1), (.L__pc.14086.LD)
	.p2align 4
	.L__pc.14086.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14087
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14087: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14088
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14088: Dma_PatchSrc (.L__pc.14088.LD), (.L__movme_cp.24), (.L__pc.14088.LD)
	.p2align 4
	.L__pc.14088.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14089
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14089: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14090
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14090: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14091: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14092: Dma_PatchSrc (.L__pc.14092.LD), (.L__movme_tmp.1), (.L__pc.14092.LD)
	.p2align 4
	.L__pc.14092.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14093
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14093: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14094
	
	.L__pc.14094: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14095
	
	.p2align 4
	.L__pc.14095: Dma_PatchDst (.L__pc.14095.ST), (.L__movme_cp.69), (.L__pc.14095.ST)
	.L__pc.14095.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14096
	
	.L__pc.14096: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14097
	
	.p2align 4
	.L__pc.14097: Dma_PatchDst (.L__pc.14097.ST), (.L__movme_cp.54), (.L__pc.14097.ST)
	.L__pc.14097.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14098
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.14098: Dma_PatchSrc (.L__pc.14098.LD), (.L__movme_cp.30), (.L__pc.14098.LD)
	.p2align 4
	.L__pc.14098.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14099
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14099: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14100
	.L__pc.14100: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14101
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.14101: Dma_PatchSrc (.L__pc.14101.LD), (.L__movme_cp.31), (.L__pc.14101.LD)
	.p2align 4
	.L__pc.14101.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14102
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14102: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14103
	.L__pc.14103: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14104
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14104: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14105: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14106: Dma_PatchSrc (.L__pc.14106.LD), (.L__movme_tmp.1), (.L__pc.14106.LD)
	.p2align 4
	.L__pc.14106.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14107
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14107: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14108
	.L__pc.14108: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14109
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14109: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14110: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14111: Dma_PatchSrc (.L__pc.14111.LD), (.L__movme_tmp.1), (.L__pc.14111.LD)
	.p2align 4
	.L__pc.14111.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14112
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14112: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14113
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14113: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14114: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14115: Dma_PatchSrc (.L__pc.14115.LD), (.L__movme_tmp.1), (.L__pc.14115.LD)
	.p2align 4
	.L__pc.14115.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14116
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14116: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14117
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14117: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14118: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14119: Dma_PatchSrc (.L__pc.14119.LD), (.L__movme_tmp.1), (.L__pc.14119.LD)
	.p2align 4
	.L__pc.14119.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14120
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14120: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14121
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14121: Dma_PatchSrc (.L__pc.14121.LD), (.L__movme_cp.24), (.L__pc.14121.LD)
	.p2align 4
	.L__pc.14121.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14122
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14122: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14123
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14123: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14124: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14125: Dma_PatchSrc (.L__pc.14125.LD), (.L__movme_tmp.1), (.L__pc.14125.LD)
	.p2align 4
	.L__pc.14125.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14126
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14126: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14127
	
	.L__pc.14127: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14128
	
	.p2align 4
	.L__pc.14128: Dma_PatchDst (.L__pc.14128.ST), (.L__movme_cp.70), (.L__pc.14128.ST)
	.L__pc.14128.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14129
	
	.L__pc.14129: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14130
	
	.p2align 4
	.L__pc.14130: Dma_PatchDst (.L__pc.14130.ST), (.L__movme_cp.54), (.L__pc.14130.ST)
	.L__pc.14130.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14131
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14131: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14132
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14132: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14133
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14133: Dma_PatchSrc (.L__pc.14133.LD), (.L__movme_cp.24), (.L__pc.14133.LD)
	.p2align 4
	.L__pc.14133.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14134
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14134: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14135
	.L__pc.14135: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14136
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.14136: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14137: Dma_PatchSrc (.L__pc.14137.LD), (.L__movme_tmp.1), (.L__pc.14137.LD)
	.p2align 4
	.L__pc.14137.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14138
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14138: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14139
	.L__pc.14139: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14140
	
	.L__pc.14140: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14141
	
	.p2align 4
	.L__pc.14141: Dma_PatchDst (.L__pc.14141.ST), (.L__movme_cp.72), (.L__pc.14141.ST)
	.L__pc.14141.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14142
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.14142: Dma_PatchSrc (.L__pc.14142.LD), (.L__movme_cp.72), (.L__pc.14142.LD)
	.p2align 4
	.L__pc.14142.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14143
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14143: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14144
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14144: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14145: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14146: Dma_PatchSrc (.L__pc.14146.LD), (.L__movme_tmp.1), (.L__pc.14146.LD)
	.p2align 4
	.L__pc.14146.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14147
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14147: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14148
	
	.L__pc.14148: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14149
	
	.p2align 4
	.L__pc.14149: Dma_PatchDst (.L__pc.14149.ST), (.L__movme_cp.74), (.L__pc.14149.ST)
	.L__pc.14149.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14150
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14150: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14151: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14152: Dma_PatchSrc (.L__pc.14152.LD), (.L__movme_tmp.1), (.L__pc.14152.LD)
	.p2align 4
	.L__pc.14152.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14153
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14153: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14154
	
	.L__pc.14154: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14155
	
	.p2align 4
	.L__pc.14155: Dma_PatchDst (.L__pc.14155.ST), (.L__movme_cp.76), (.L__pc.14155.ST)
	.L__pc.14155.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14156
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.14156: Dma_PatchSrc (.L__pc.14156.LD), (.L__movme_cp.74), (.L__pc.14156.LD)
	.p2align 4
	.L__pc.14156.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14157
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14157: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14158
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.14158: Dma_PatchSrc (.L__pc.14158.LD), ((.L__movme.reg.eax+0)), (.L__pc.14158.LD)
	.p2align 4
	.L__pc.14158.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14159
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14159: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14160
	
	.L__pc.14160: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14161
	
	.p2align 4
	.L__pc.14161: Dma_PatchDst (.L__pc.14161.ST), (.L__movme_cp.77), (.L__pc.14161.ST)
	.L__pc.14161.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14162
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.14162: Dma_PatchSrc (.L__pc.14162.LD), (.L__movme_cp.77), (.L__pc.14162.LD)
	.p2align 4
	.L__pc.14162.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14163
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14163: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14164
	
	.L__pc.14164: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14165
	
	.p2align 4
	.L__pc.14165: Dma_PatchDst (.L__pc.14165.ST), (.L__movme_cp.21), (.L__pc.14165.ST)
	.L__pc.14165.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14166
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.14166: Dma_PatchSrc (.L__pc.14166.LD), (.L__movme_cp.58), (.L__pc.14166.LD)
	.p2align 4
	.L__pc.14166.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14167
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14167: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14168
	
	.L__pc.14168: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14169
	
	.p2align 4
	.L__pc.14169: Dma_PatchDst (.L__pc.14169.ST), (.L__movme_cp.22), (.L__pc.14169.ST)
	.L__pc.14169.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14170
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14170: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14171
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14171: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14172
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14172: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14173
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14173: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14174
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.14174: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.14175
	
	.p2align 4
	.L__pc.14175: Dma_PatchDst (.L__pc.14175.ST), (.L__movme_cp.24), (.L__pc.14175.ST)
	.L__pc.14175.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14176
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.14176: Dma_PatchSrc (.L__pc.14176.LD), (.L__movme_cp.25), (.L__pc.14176.LD)
	.p2align 4
	.L__pc.14176.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14177
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14177: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14178
	.L__pc.14178: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14179
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.14179: Dma_PatchSrc (.L__pc.14179.LD), (.L__movme_cp.26), (.L__pc.14179.LD)
	.p2align 4
	.L__pc.14179.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14180
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14180: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14181
	.L__pc.14181: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14182
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14182: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14183: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14184: Dma_PatchSrc (.L__pc.14184.LD), (.L__movme_tmp.1), (.L__pc.14184.LD)
	.p2align 4
	.L__pc.14184.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14185
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14185: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14186
	.L__pc.14186: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14187
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14187: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14188: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14189: Dma_PatchSrc (.L__pc.14189.LD), (.L__movme_tmp.1), (.L__pc.14189.LD)
	.p2align 4
	.L__pc.14189.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14190
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14190: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14191
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14191: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14192: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14193: Dma_PatchSrc (.L__pc.14193.LD), (.L__movme_tmp.1), (.L__pc.14193.LD)
	.p2align 4
	.L__pc.14193.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14194
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14194: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14195
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14195: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14196: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14197: Dma_PatchSrc (.L__pc.14197.LD), (.L__movme_tmp.1), (.L__pc.14197.LD)
	.p2align 4
	.L__pc.14197.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14198
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14198: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14199
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14199: Dma_PatchSrc (.L__pc.14199.LD), (.L__movme_cp.24), (.L__pc.14199.LD)
	.p2align 4
	.L__pc.14199.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14200
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14200: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14201
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14201: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14202: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14203: Dma_PatchSrc (.L__pc.14203.LD), (.L__movme_tmp.1), (.L__pc.14203.LD)
	.p2align 4
	.L__pc.14203.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14204
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14204: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14205
	
	.L__pc.14205: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14206
	
	.p2align 4
	.L__pc.14206: Dma_PatchDst (.L__pc.14206.ST), (.L__movme_cp.78), (.L__pc.14206.ST)
	.L__pc.14206.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14207
	
	.L__pc.14207: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14208
	
	.p2align 4
	.L__pc.14208: Dma_PatchDst (.L__pc.14208.ST), (.L__movme_cp.54), (.L__pc.14208.ST)
	.L__pc.14208.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14209
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.14209: Dma_PatchSrc (.L__pc.14209.LD), (.L__movme_cp.30), (.L__pc.14209.LD)
	.p2align 4
	.L__pc.14209.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14210
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14210: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14211
	.L__pc.14211: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14212
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.14212: Dma_PatchSrc (.L__pc.14212.LD), (.L__movme_cp.31), (.L__pc.14212.LD)
	.p2align 4
	.L__pc.14212.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14213
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14213: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14214
	.L__pc.14214: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14215
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14215: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14216: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14217: Dma_PatchSrc (.L__pc.14217.LD), (.L__movme_tmp.1), (.L__pc.14217.LD)
	.p2align 4
	.L__pc.14217.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14218
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14218: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14219
	.L__pc.14219: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14220
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14220: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14221: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14222: Dma_PatchSrc (.L__pc.14222.LD), (.L__movme_tmp.1), (.L__pc.14222.LD)
	.p2align 4
	.L__pc.14222.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14223
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14223: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14224
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14224: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14225: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14226: Dma_PatchSrc (.L__pc.14226.LD), (.L__movme_tmp.1), (.L__pc.14226.LD)
	.p2align 4
	.L__pc.14226.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14227
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14227: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14228
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14228: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14229: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14230: Dma_PatchSrc (.L__pc.14230.LD), (.L__movme_tmp.1), (.L__pc.14230.LD)
	.p2align 4
	.L__pc.14230.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14231
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14231: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14232
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14232: Dma_PatchSrc (.L__pc.14232.LD), (.L__movme_cp.24), (.L__pc.14232.LD)
	.p2align 4
	.L__pc.14232.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14233
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14233: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14234
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14234: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14235: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14236: Dma_PatchSrc (.L__pc.14236.LD), (.L__movme_tmp.1), (.L__pc.14236.LD)
	.p2align 4
	.L__pc.14236.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14237
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14237: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14238
	
	.L__pc.14238: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14239
	
	.p2align 4
	.L__pc.14239: Dma_PatchDst (.L__pc.14239.ST), (.L__movme_cp.79), (.L__pc.14239.ST)
	.L__pc.14239.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14240
	
	.L__pc.14240: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14241
	
	.p2align 4
	.L__pc.14241: Dma_PatchDst (.L__pc.14241.ST), (.L__movme_cp.54), (.L__pc.14241.ST)
	.L__pc.14241.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14242
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.14242: Dma_PatchSrc (.L__pc.14242.LD), (.L__movme_cp.74), (.L__pc.14242.LD)
	.p2align 4
	.L__pc.14242.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14243
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14243: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14244
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.14244: Dma_PatchSrc (.L__pc.14244.LD), (.L__movme_cp.77), (.L__pc.14244.LD)
	.p2align 4
	.L__pc.14244.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14245
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14245: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14246
	
	.L__pc.14246: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14247
	
	.p2align 4
	.L__pc.14247: Dma_PatchDst (.L__pc.14247.ST), ((.L__movme.reg.eax+0)), (.L__pc.14247.ST)
	.L__pc.14247.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14248
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.14248: Dma_PatchSrc (.L__pc.14248.LD), (.L__movme_cp.76), (.L__pc.14248.LD)
	.p2align 4
	.L__pc.14248.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14249
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14249: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14250
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.14250: Dma_PatchSrc (.L__pc.14250.LD), ((.L__movme.reg.eax+0)), (.L__pc.14250.LD)
	.p2align 4
	.L__pc.14250.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14251
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14251: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14252
	
	.L__pc.14252: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14253
	
	.p2align 4
	.L__pc.14253: Dma_PatchDst (.L__pc.14253.ST), (.L__movme_cp.80), (.L__pc.14253.ST)
	.L__pc.14253.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14254
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14254: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14255
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14255: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14256
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.14256: Dma_PatchSrc (.L__pc.14256.LD), (.L__movme_cp.81), (.L__pc.14256.LD)
	.p2align 4
	.L__pc.14256.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14257
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14257: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14258
	.L__pc.14258: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14259
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.90 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.14259: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14260: Dma_PatchSrc (.L__pc.14260.LD), (.L__movme_tmp.1), (.L__pc.14260.LD)
	.p2align 4
	.L__pc.14260.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14261
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14261: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14262
	.L__pc.14262: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14263
	
	.L__pc.14263: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14264
	
	.p2align 4
	.L__pc.14264: Dma_PatchDst (.L__pc.14264.ST), (.L__movme_cp.81), (.L__pc.14264.ST)
	.L__pc.14264.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14265
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.14265: Dma_PatchSrc (.L__pc.14265.LD), (.L__movme_cp.76), (.L__pc.14265.LD)
	.p2align 4
	.L__pc.14265.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14266
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14266: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14267
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.14267: Dma_PatchSrc (.L__pc.14267.LD), (.L__movme_cp.80), (.L__pc.14267.LD)
	.p2align 4
	.L__pc.14267.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14268
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14268: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14269
	
	.L__pc.14269: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14270
	
	.p2align 4
	.L__pc.14270: Dma_PatchDst (.L__pc.14270.ST), ((.L__movme.reg.eax+0)), (.L__pc.14270.ST)
	.L__pc.14270.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14271
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14271: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14272
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14272: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14273
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.14273: Dma_PatchSrc (.L__pc.14273.LD), (.L__movme_cp.61), (.L__pc.14273.LD)
	.p2align 4
	.L__pc.14273.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14274
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14274: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14275
	.L__pc.14275: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14276
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14276: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.91 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14277: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14278: Dma_PatchSrc (.L__pc.14278.LD), (.L__movme_tmp.1), (.L__pc.14278.LD)
	.p2align 4
	.L__pc.14278.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14279
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14279: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14280
	
	.L__pc.14280: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14281
	
	.p2align 4
	.L__pc.14281: Dma_PatchDst (.L__pc.14281.ST), (.L__movme_cp.24), (.L__pc.14281.ST)
	.L__pc.14281.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14282
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14282: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14283
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14283: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14284
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14284: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14285
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14285: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14286
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.14286: Dma_PatchSrc (.L__pc.14286.LD), (.L__movme_cp.63), (.L__pc.14286.LD)
	.p2align 4
	.L__pc.14286.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14287
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14287: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14288
	.L__pc.14288: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14289
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14289: Dma_PatchSrc (.L__pc.14289.LD), (.L__movme_cp.24), (.L__pc.14289.LD)
	.p2align 4
	.L__pc.14289.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14290
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14290: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14291
	.L__pc.14291: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14292
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14292: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14293: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14294: Dma_PatchSrc (.L__pc.14294.LD), (.L__movme_tmp.1), (.L__pc.14294.LD)
	.p2align 4
	.L__pc.14294.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14295
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14295: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14296
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14296: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14297: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14298: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14299: Dma_PatchSrc (.L__pc.14299.LD), (.L__movme_tmp.1), (.L__pc.14299.LD)
	.p2align 4
	.L__pc.14299.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14300
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14300: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14301
	
	.L__pc.14301: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14302
	
	.p2align 4
	.L__pc.14302: Dma_PatchDst (.L__pc.14302.ST), (.L__movme_cp.63), (.L__pc.14302.ST)
	.L__pc.14302.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14303
	
	.L__pc.14303: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14304
	
	.p2align 4
	.L__pc.14304: Dma_PatchDst (.L__pc.14304.ST), (.L__movme_cp.24), (.L__pc.14304.ST)
	.L__pc.14304.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14305
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14305: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14306
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14306: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14307
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14307: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14308
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14308: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14309
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.14309: Dma_PatchSrc (.L__pc.14309.LD), (.L__movme_cp.66), (.L__pc.14309.LD)
	.p2align 4
	.L__pc.14309.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14310
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14310: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14311
	.L__pc.14311: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14312
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14312: Dma_PatchSrc (.L__pc.14312.LD), (.L__movme_cp.24), (.L__pc.14312.LD)
	.p2align 4
	.L__pc.14312.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14313
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14313: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14314
	.L__pc.14314: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14315
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14315: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14316: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14317: Dma_PatchSrc (.L__pc.14317.LD), (.L__movme_tmp.1), (.L__pc.14317.LD)
	.p2align 4
	.L__pc.14317.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14318
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14318: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14319
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14319: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14320: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14321: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14322: Dma_PatchSrc (.L__pc.14322.LD), (.L__movme_tmp.1), (.L__pc.14322.LD)
	.p2align 4
	.L__pc.14322.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14323
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14323: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14324
	
	.L__pc.14324: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14325
	
	.p2align 4
	.L__pc.14325: Dma_PatchDst (.L__pc.14325.ST), (.L__movme_cp.66), (.L__pc.14325.ST)
	.L__pc.14325.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14326
	
	.L__pc.14326: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14327
	
	.p2align 4
	.L__pc.14327: Dma_PatchDst (.L__pc.14327.ST), (.L__movme_cp.24), (.L__pc.14327.ST)
	.L__pc.14327.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14328
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14328: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14329
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14329: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14330
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14330: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14331
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14331: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14332
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.14332: Dma_PatchSrc (.L__pc.14332.LD), (.L__movme_cp.67), (.L__pc.14332.LD)
	.p2align 4
	.L__pc.14332.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14333
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14333: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14334
	.L__pc.14334: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14335
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14335: Dma_PatchSrc (.L__pc.14335.LD), (.L__movme_cp.24), (.L__pc.14335.LD)
	.p2align 4
	.L__pc.14335.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14336
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14336: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14337
	.L__pc.14337: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14338
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14338: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14339: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14340: Dma_PatchSrc (.L__pc.14340.LD), (.L__movme_tmp.1), (.L__pc.14340.LD)
	.p2align 4
	.L__pc.14340.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14341
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14341: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14342
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14342: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14343: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14344: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14345: Dma_PatchSrc (.L__pc.14345.LD), (.L__movme_tmp.1), (.L__pc.14345.LD)
	.p2align 4
	.L__pc.14345.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14346
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14346: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14347
	
	.L__pc.14347: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14348
	
	.p2align 4
	.L__pc.14348: Dma_PatchDst (.L__pc.14348.ST), (.L__movme_cp.67), (.L__pc.14348.ST)
	.L__pc.14348.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14349
	
	.L__pc.14349: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14350
	
	.p2align 4
	.L__pc.14350: Dma_PatchDst (.L__pc.14350.ST), (.L__movme_cp.24), (.L__pc.14350.ST)
	.L__pc.14350.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14351
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14351: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14352
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14352: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14353
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14353: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14354
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14354: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14355
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.14355: Dma_PatchSrc (.L__pc.14355.LD), (.L__movme_cp.68), (.L__pc.14355.LD)
	.p2align 4
	.L__pc.14355.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14356
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14356: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14357
	.L__pc.14357: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14358
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14358: Dma_PatchSrc (.L__pc.14358.LD), (.L__movme_cp.24), (.L__pc.14358.LD)
	.p2align 4
	.L__pc.14358.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14359
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14359: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14360
	.L__pc.14360: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14361
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14361: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14362: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14363: Dma_PatchSrc (.L__pc.14363.LD), (.L__movme_tmp.1), (.L__pc.14363.LD)
	.p2align 4
	.L__pc.14363.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14364
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14364: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14365
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14365: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14366: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14367: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14368: Dma_PatchSrc (.L__pc.14368.LD), (.L__movme_tmp.1), (.L__pc.14368.LD)
	.p2align 4
	.L__pc.14368.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14369
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14369: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14370
	
	.L__pc.14370: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14371
	
	.p2align 4
	.L__pc.14371: Dma_PatchDst (.L__pc.14371.ST), (.L__movme_cp.68), (.L__pc.14371.ST)
	.L__pc.14371.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14372
	
	.L__pc.14372: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14373
	
	.p2align 4
	.L__pc.14373: Dma_PatchDst (.L__pc.14373.ST), (.L__movme_cp.24), (.L__pc.14373.ST)
	.L__pc.14373.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14374
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14374: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14375
	
	.p2align 4
	.L__pc.14375: Dma_PatchDst (.L__pc.14375.ST), (.L__movme_cp.24), (.L__pc.14375.ST)
	.L__pc.14375.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14376
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.14376: Dma_PatchSrc (.L__pc.14376.LD), (.L__movme_cp.60), (.L__pc.14376.LD)
	.p2align 4
	.L__pc.14376.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14377
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14377: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14378
	
	.L__pc.14378: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14379
	
	.p2align 4
	.L__pc.14379: Dma_PatchDst (.L__pc.14379.ST), (.L__movme_cp.21), (.L__pc.14379.ST)
	.L__pc.14379.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14380
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.14380: Dma_PatchSrc (.L__pc.14380.LD), (.L__movme_cp.58), (.L__pc.14380.LD)
	.p2align 4
	.L__pc.14380.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14381
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14381: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14382
	
	.L__pc.14382: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14383
	
	.p2align 4
	.L__pc.14383: Dma_PatchDst (.L__pc.14383.ST), (.L__movme_cp.22), (.L__pc.14383.ST)
	.L__pc.14383.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14384
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14384: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14385
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14385: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14386
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14386: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14387
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14387: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14388
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.14388: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.14389
	
	.p2align 4
	.L__pc.14389: Dma_PatchDst (.L__pc.14389.ST), (.L__movme_cp.24), (.L__pc.14389.ST)
	.L__pc.14389.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14390
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.14390: Dma_PatchSrc (.L__pc.14390.LD), (.L__movme_cp.25), (.L__pc.14390.LD)
	.p2align 4
	.L__pc.14390.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14391
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14391: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14392
	.L__pc.14392: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14393
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.14393: Dma_PatchSrc (.L__pc.14393.LD), (.L__movme_cp.26), (.L__pc.14393.LD)
	.p2align 4
	.L__pc.14393.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14394
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14394: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14395
	.L__pc.14395: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14396
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14396: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14397: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14398: Dma_PatchSrc (.L__pc.14398.LD), (.L__movme_tmp.1), (.L__pc.14398.LD)
	.p2align 4
	.L__pc.14398.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14399
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14399: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14400
	.L__pc.14400: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14401
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14401: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14402: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14403: Dma_PatchSrc (.L__pc.14403.LD), (.L__movme_tmp.1), (.L__pc.14403.LD)
	.p2align 4
	.L__pc.14403.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14404
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14404: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14405
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14405: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14406: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14407: Dma_PatchSrc (.L__pc.14407.LD), (.L__movme_tmp.1), (.L__pc.14407.LD)
	.p2align 4
	.L__pc.14407.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14408
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14408: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14409
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14409: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14410: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14411: Dma_PatchSrc (.L__pc.14411.LD), (.L__movme_tmp.1), (.L__pc.14411.LD)
	.p2align 4
	.L__pc.14411.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14412
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14412: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14413
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14413: Dma_PatchSrc (.L__pc.14413.LD), (.L__movme_cp.24), (.L__pc.14413.LD)
	.p2align 4
	.L__pc.14413.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14414
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14414: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14415
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14415: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14416: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14417: Dma_PatchSrc (.L__pc.14417.LD), (.L__movme_tmp.1), (.L__pc.14417.LD)
	.p2align 4
	.L__pc.14417.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14418
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14418: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14419
	
	.L__pc.14419: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14420
	
	.p2align 4
	.L__pc.14420: Dma_PatchDst (.L__pc.14420.ST), (.L__movme_cp.69), (.L__pc.14420.ST)
	.L__pc.14420.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14421
	
	.L__pc.14421: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14422
	
	.p2align 4
	.L__pc.14422: Dma_PatchDst (.L__pc.14422.ST), (.L__movme_cp.54), (.L__pc.14422.ST)
	.L__pc.14422.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14423
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.14423: Dma_PatchSrc (.L__pc.14423.LD), (.L__movme_cp.30), (.L__pc.14423.LD)
	.p2align 4
	.L__pc.14423.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14424
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14424: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14425
	.L__pc.14425: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14426
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.14426: Dma_PatchSrc (.L__pc.14426.LD), (.L__movme_cp.31), (.L__pc.14426.LD)
	.p2align 4
	.L__pc.14426.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14427
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14427: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14428
	.L__pc.14428: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14429
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14429: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14430: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14431: Dma_PatchSrc (.L__pc.14431.LD), (.L__movme_tmp.1), (.L__pc.14431.LD)
	.p2align 4
	.L__pc.14431.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14432
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14432: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14433
	.L__pc.14433: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14434
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14434: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14435: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14436: Dma_PatchSrc (.L__pc.14436.LD), (.L__movme_tmp.1), (.L__pc.14436.LD)
	.p2align 4
	.L__pc.14436.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14437
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14437: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14438
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14438: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14439: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14440: Dma_PatchSrc (.L__pc.14440.LD), (.L__movme_tmp.1), (.L__pc.14440.LD)
	.p2align 4
	.L__pc.14440.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14441
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14441: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14442
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14442: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14443: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14444: Dma_PatchSrc (.L__pc.14444.LD), (.L__movme_tmp.1), (.L__pc.14444.LD)
	.p2align 4
	.L__pc.14444.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14445
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14445: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14446
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14446: Dma_PatchSrc (.L__pc.14446.LD), (.L__movme_cp.24), (.L__pc.14446.LD)
	.p2align 4
	.L__pc.14446.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14447
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14447: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14448
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14448: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14449: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14450: Dma_PatchSrc (.L__pc.14450.LD), (.L__movme_tmp.1), (.L__pc.14450.LD)
	.p2align 4
	.L__pc.14450.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14451
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14451: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14452
	
	.L__pc.14452: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14453
	
	.p2align 4
	.L__pc.14453: Dma_PatchDst (.L__pc.14453.ST), (.L__movme_cp.70), (.L__pc.14453.ST)
	.L__pc.14453.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14454
	
	.L__pc.14454: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14455
	
	.p2align 4
	.L__pc.14455: Dma_PatchDst (.L__pc.14455.ST), (.L__movme_cp.54), (.L__pc.14455.ST)
	.L__pc.14455.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14456
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14456: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14457
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14457: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14458
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14458: Dma_PatchSrc (.L__pc.14458.LD), (.L__movme_cp.24), (.L__pc.14458.LD)
	.p2align 4
	.L__pc.14458.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14459
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14459: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14460
	.L__pc.14460: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14461
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.14461: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14462: Dma_PatchSrc (.L__pc.14462.LD), (.L__movme_tmp.1), (.L__pc.14462.LD)
	.p2align 4
	.L__pc.14462.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14463
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14463: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14464
	.L__pc.14464: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14465
	
	.L__pc.14465: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14466
	
	.p2align 4
	.L__pc.14466: Dma_PatchDst (.L__pc.14466.ST), (.L__movme_cp.72), (.L__pc.14466.ST)
	.L__pc.14466.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14467
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.14467: Dma_PatchSrc (.L__pc.14467.LD), (.L__movme_cp.72), (.L__pc.14467.LD)
	.p2align 4
	.L__pc.14467.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14468
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14468: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14469
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14469: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14470: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14471: Dma_PatchSrc (.L__pc.14471.LD), (.L__movme_tmp.1), (.L__pc.14471.LD)
	.p2align 4
	.L__pc.14471.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14472
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14472: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14473
	
	.L__pc.14473: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14474
	
	.p2align 4
	.L__pc.14474: Dma_PatchDst (.L__pc.14474.ST), (.L__movme_cp.74), (.L__pc.14474.ST)
	.L__pc.14474.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14475
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14475: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14476: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14477: Dma_PatchSrc (.L__pc.14477.LD), (.L__movme_tmp.1), (.L__pc.14477.LD)
	.p2align 4
	.L__pc.14477.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14478
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14478: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14479
	
	.L__pc.14479: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14480
	
	.p2align 4
	.L__pc.14480: Dma_PatchDst (.L__pc.14480.ST), (.L__movme_cp.76), (.L__pc.14480.ST)
	.L__pc.14480.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14481
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.14481: Dma_PatchSrc (.L__pc.14481.LD), (.L__movme_cp.74), (.L__pc.14481.LD)
	.p2align 4
	.L__pc.14481.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14482
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14482: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14483
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.14483: Dma_PatchSrc (.L__pc.14483.LD), ((.L__movme.reg.eax+0)), (.L__pc.14483.LD)
	.p2align 4
	.L__pc.14483.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14484
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14484: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14485
	
	.L__pc.14485: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14486
	
	.p2align 4
	.L__pc.14486: Dma_PatchDst (.L__pc.14486.ST), (.L__movme_cp.77), (.L__pc.14486.ST)
	.L__pc.14486.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14487
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.14487: Dma_PatchSrc (.L__pc.14487.LD), (.L__movme_cp.77), (.L__pc.14487.LD)
	.p2align 4
	.L__pc.14487.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14488
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14488: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14489
	
	.L__pc.14489: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14490
	
	.p2align 4
	.L__pc.14490: Dma_PatchDst (.L__pc.14490.ST), (.L__movme_cp.21), (.L__pc.14490.ST)
	.L__pc.14490.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14491
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.14491: Dma_PatchSrc (.L__pc.14491.LD), (.L__movme_cp.58), (.L__pc.14491.LD)
	.p2align 4
	.L__pc.14491.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14492
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14492: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14493
	
	.L__pc.14493: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14494
	
	.p2align 4
	.L__pc.14494: Dma_PatchDst (.L__pc.14494.ST), (.L__movme_cp.22), (.L__pc.14494.ST)
	.L__pc.14494.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14495
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14495: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14496
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14496: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14497
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14497: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14498
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14498: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14499
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.14499: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.14500
	
	.p2align 4
	.L__pc.14500: Dma_PatchDst (.L__pc.14500.ST), (.L__movme_cp.24), (.L__pc.14500.ST)
	.L__pc.14500.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14501
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.14501: Dma_PatchSrc (.L__pc.14501.LD), (.L__movme_cp.25), (.L__pc.14501.LD)
	.p2align 4
	.L__pc.14501.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14502
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14502: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14503
	.L__pc.14503: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14504
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.14504: Dma_PatchSrc (.L__pc.14504.LD), (.L__movme_cp.26), (.L__pc.14504.LD)
	.p2align 4
	.L__pc.14504.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14505
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14505: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14506
	.L__pc.14506: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14507
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14507: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14508: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14509: Dma_PatchSrc (.L__pc.14509.LD), (.L__movme_tmp.1), (.L__pc.14509.LD)
	.p2align 4
	.L__pc.14509.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14510
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14510: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14511
	.L__pc.14511: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14512
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14512: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14513: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14514: Dma_PatchSrc (.L__pc.14514.LD), (.L__movme_tmp.1), (.L__pc.14514.LD)
	.p2align 4
	.L__pc.14514.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14515
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14515: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14516
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14516: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14517: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14518: Dma_PatchSrc (.L__pc.14518.LD), (.L__movme_tmp.1), (.L__pc.14518.LD)
	.p2align 4
	.L__pc.14518.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14519
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14519: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14520
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14520: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14521: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14522: Dma_PatchSrc (.L__pc.14522.LD), (.L__movme_tmp.1), (.L__pc.14522.LD)
	.p2align 4
	.L__pc.14522.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14523
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14523: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14524
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14524: Dma_PatchSrc (.L__pc.14524.LD), (.L__movme_cp.24), (.L__pc.14524.LD)
	.p2align 4
	.L__pc.14524.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14525
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14525: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14526
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14526: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14527: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14528: Dma_PatchSrc (.L__pc.14528.LD), (.L__movme_tmp.1), (.L__pc.14528.LD)
	.p2align 4
	.L__pc.14528.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14529
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14529: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14530
	
	.L__pc.14530: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14531
	
	.p2align 4
	.L__pc.14531: Dma_PatchDst (.L__pc.14531.ST), (.L__movme_cp.78), (.L__pc.14531.ST)
	.L__pc.14531.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14532
	
	.L__pc.14532: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14533
	
	.p2align 4
	.L__pc.14533: Dma_PatchDst (.L__pc.14533.ST), (.L__movme_cp.54), (.L__pc.14533.ST)
	.L__pc.14533.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14534
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.14534: Dma_PatchSrc (.L__pc.14534.LD), (.L__movme_cp.30), (.L__pc.14534.LD)
	.p2align 4
	.L__pc.14534.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14535
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14535: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14536
	.L__pc.14536: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14537
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.14537: Dma_PatchSrc (.L__pc.14537.LD), (.L__movme_cp.31), (.L__pc.14537.LD)
	.p2align 4
	.L__pc.14537.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14538
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14538: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14539
	.L__pc.14539: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14540
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14540: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14541: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14542: Dma_PatchSrc (.L__pc.14542.LD), (.L__movme_tmp.1), (.L__pc.14542.LD)
	.p2align 4
	.L__pc.14542.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14543
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14543: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14544
	.L__pc.14544: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14545
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14545: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14546: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14547: Dma_PatchSrc (.L__pc.14547.LD), (.L__movme_tmp.1), (.L__pc.14547.LD)
	.p2align 4
	.L__pc.14547.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14548
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14548: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14549
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14549: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14550: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14551: Dma_PatchSrc (.L__pc.14551.LD), (.L__movme_tmp.1), (.L__pc.14551.LD)
	.p2align 4
	.L__pc.14551.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14552
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14552: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14553
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14553: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14554: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14555: Dma_PatchSrc (.L__pc.14555.LD), (.L__movme_tmp.1), (.L__pc.14555.LD)
	.p2align 4
	.L__pc.14555.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14556
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14556: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14557
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14557: Dma_PatchSrc (.L__pc.14557.LD), (.L__movme_cp.24), (.L__pc.14557.LD)
	.p2align 4
	.L__pc.14557.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14558
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14558: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14559
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14559: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14560: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14561: Dma_PatchSrc (.L__pc.14561.LD), (.L__movme_tmp.1), (.L__pc.14561.LD)
	.p2align 4
	.L__pc.14561.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14562
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14562: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14563
	
	.L__pc.14563: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14564
	
	.p2align 4
	.L__pc.14564: Dma_PatchDst (.L__pc.14564.ST), (.L__movme_cp.79), (.L__pc.14564.ST)
	.L__pc.14564.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14565
	
	.L__pc.14565: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14566
	
	.p2align 4
	.L__pc.14566: Dma_PatchDst (.L__pc.14566.ST), (.L__movme_cp.54), (.L__pc.14566.ST)
	.L__pc.14566.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14567
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.14567: Dma_PatchSrc (.L__pc.14567.LD), (.L__movme_cp.74), (.L__pc.14567.LD)
	.p2align 4
	.L__pc.14567.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14568
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14568: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14569
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.14569: Dma_PatchSrc (.L__pc.14569.LD), (.L__movme_cp.77), (.L__pc.14569.LD)
	.p2align 4
	.L__pc.14569.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14570
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14570: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14571
	
	.L__pc.14571: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14572
	
	.p2align 4
	.L__pc.14572: Dma_PatchDst (.L__pc.14572.ST), ((.L__movme.reg.eax+0)), (.L__pc.14572.ST)
	.L__pc.14572.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14573
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.14573: Dma_PatchSrc (.L__pc.14573.LD), (.L__movme_cp.76), (.L__pc.14573.LD)
	.p2align 4
	.L__pc.14573.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14574
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14574: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14575
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.14575: Dma_PatchSrc (.L__pc.14575.LD), ((.L__movme.reg.eax+0)), (.L__pc.14575.LD)
	.p2align 4
	.L__pc.14575.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14576
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14576: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14577
	
	.L__pc.14577: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14578
	
	.p2align 4
	.L__pc.14578: Dma_PatchDst (.L__pc.14578.ST), (.L__movme_cp.80), (.L__pc.14578.ST)
	.L__pc.14578.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14579
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14579: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14580
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14580: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14581
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.14581: Dma_PatchSrc (.L__pc.14581.LD), (.L__movme_cp.81), (.L__pc.14581.LD)
	.p2align 4
	.L__pc.14581.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14582
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14582: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14583
	.L__pc.14583: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14584
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.92 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.14584: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14585: Dma_PatchSrc (.L__pc.14585.LD), (.L__movme_tmp.1), (.L__pc.14585.LD)
	.p2align 4
	.L__pc.14585.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14586
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14586: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14587
	.L__pc.14587: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14588
	
	.L__pc.14588: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14589
	
	.p2align 4
	.L__pc.14589: Dma_PatchDst (.L__pc.14589.ST), (.L__movme_cp.81), (.L__pc.14589.ST)
	.L__pc.14589.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14590
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.14590: Dma_PatchSrc (.L__pc.14590.LD), (.L__movme_cp.76), (.L__pc.14590.LD)
	.p2align 4
	.L__pc.14590.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14591
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14591: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14592
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.14592: Dma_PatchSrc (.L__pc.14592.LD), (.L__movme_cp.80), (.L__pc.14592.LD)
	.p2align 4
	.L__pc.14592.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14593
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14593: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14594
	
	.L__pc.14594: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14595
	
	.p2align 4
	.L__pc.14595: Dma_PatchDst (.L__pc.14595.ST), ((.L__movme.reg.eax+0)), (.L__pc.14595.ST)
	.L__pc.14595.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14596
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14596: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14597
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14597: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14598
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.14598: Dma_PatchSrc (.L__pc.14598.LD), (.L__movme_cp.61), (.L__pc.14598.LD)
	.p2align 4
	.L__pc.14598.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14599
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14599: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14600
	.L__pc.14600: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14601
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14601: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.93 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14602: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14603: Dma_PatchSrc (.L__pc.14603.LD), (.L__movme_tmp.1), (.L__pc.14603.LD)
	.p2align 4
	.L__pc.14603.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14604
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14604: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14605
	
	.L__pc.14605: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14606
	
	.p2align 4
	.L__pc.14606: Dma_PatchDst (.L__pc.14606.ST), (.L__movme_cp.24), (.L__pc.14606.ST)
	.L__pc.14606.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14607
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14607: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14608
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14608: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14609
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14609: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14610
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14610: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14611
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.14611: Dma_PatchSrc (.L__pc.14611.LD), (.L__movme_cp.63), (.L__pc.14611.LD)
	.p2align 4
	.L__pc.14611.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14612
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14612: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14613
	.L__pc.14613: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14614
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14614: Dma_PatchSrc (.L__pc.14614.LD), (.L__movme_cp.24), (.L__pc.14614.LD)
	.p2align 4
	.L__pc.14614.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14615
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14615: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14616
	.L__pc.14616: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14617
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14617: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14618: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14619: Dma_PatchSrc (.L__pc.14619.LD), (.L__movme_tmp.1), (.L__pc.14619.LD)
	.p2align 4
	.L__pc.14619.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14620
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14620: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14621
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14621: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14622: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14623: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14624: Dma_PatchSrc (.L__pc.14624.LD), (.L__movme_tmp.1), (.L__pc.14624.LD)
	.p2align 4
	.L__pc.14624.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14625
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14625: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14626
	
	.L__pc.14626: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14627
	
	.p2align 4
	.L__pc.14627: Dma_PatchDst (.L__pc.14627.ST), (.L__movme_cp.63), (.L__pc.14627.ST)
	.L__pc.14627.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14628
	
	.L__pc.14628: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14629
	
	.p2align 4
	.L__pc.14629: Dma_PatchDst (.L__pc.14629.ST), (.L__movme_cp.24), (.L__pc.14629.ST)
	.L__pc.14629.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14630
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14630: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14631
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14631: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14632
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14632: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14633
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14633: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14634
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.14634: Dma_PatchSrc (.L__pc.14634.LD), (.L__movme_cp.66), (.L__pc.14634.LD)
	.p2align 4
	.L__pc.14634.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14635
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14635: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14636
	.L__pc.14636: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14637
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14637: Dma_PatchSrc (.L__pc.14637.LD), (.L__movme_cp.24), (.L__pc.14637.LD)
	.p2align 4
	.L__pc.14637.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14638
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14638: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14639
	.L__pc.14639: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14640
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14640: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14641: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14642: Dma_PatchSrc (.L__pc.14642.LD), (.L__movme_tmp.1), (.L__pc.14642.LD)
	.p2align 4
	.L__pc.14642.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14643
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14643: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14644
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14644: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14645: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14646: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14647: Dma_PatchSrc (.L__pc.14647.LD), (.L__movme_tmp.1), (.L__pc.14647.LD)
	.p2align 4
	.L__pc.14647.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14648
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14648: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14649
	
	.L__pc.14649: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14650
	
	.p2align 4
	.L__pc.14650: Dma_PatchDst (.L__pc.14650.ST), (.L__movme_cp.66), (.L__pc.14650.ST)
	.L__pc.14650.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14651
	
	.L__pc.14651: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14652
	
	.p2align 4
	.L__pc.14652: Dma_PatchDst (.L__pc.14652.ST), (.L__movme_cp.24), (.L__pc.14652.ST)
	.L__pc.14652.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14653
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14653: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14654
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14654: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14655
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14655: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14656
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14656: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14657
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.14657: Dma_PatchSrc (.L__pc.14657.LD), (.L__movme_cp.67), (.L__pc.14657.LD)
	.p2align 4
	.L__pc.14657.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14658
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14658: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14659
	.L__pc.14659: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14660
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14660: Dma_PatchSrc (.L__pc.14660.LD), (.L__movme_cp.24), (.L__pc.14660.LD)
	.p2align 4
	.L__pc.14660.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14661
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14661: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14662
	.L__pc.14662: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14663
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14663: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14664: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14665: Dma_PatchSrc (.L__pc.14665.LD), (.L__movme_tmp.1), (.L__pc.14665.LD)
	.p2align 4
	.L__pc.14665.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14666
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14666: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14667
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14667: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14668: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14669: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14670: Dma_PatchSrc (.L__pc.14670.LD), (.L__movme_tmp.1), (.L__pc.14670.LD)
	.p2align 4
	.L__pc.14670.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14671
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14671: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14672
	
	.L__pc.14672: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14673
	
	.p2align 4
	.L__pc.14673: Dma_PatchDst (.L__pc.14673.ST), (.L__movme_cp.67), (.L__pc.14673.ST)
	.L__pc.14673.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14674
	
	.L__pc.14674: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14675
	
	.p2align 4
	.L__pc.14675: Dma_PatchDst (.L__pc.14675.ST), (.L__movme_cp.24), (.L__pc.14675.ST)
	.L__pc.14675.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14676
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14676: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14677
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14677: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14678
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14678: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14679
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14679: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14680
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.14680: Dma_PatchSrc (.L__pc.14680.LD), (.L__movme_cp.68), (.L__pc.14680.LD)
	.p2align 4
	.L__pc.14680.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14681
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14681: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14682
	.L__pc.14682: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14683
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14683: Dma_PatchSrc (.L__pc.14683.LD), (.L__movme_cp.24), (.L__pc.14683.LD)
	.p2align 4
	.L__pc.14683.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14684
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14684: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14685
	.L__pc.14685: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14686
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14686: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14687: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14688: Dma_PatchSrc (.L__pc.14688.LD), (.L__movme_tmp.1), (.L__pc.14688.LD)
	.p2align 4
	.L__pc.14688.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14689
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14689: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14690
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14690: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14691: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14692: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14693: Dma_PatchSrc (.L__pc.14693.LD), (.L__movme_tmp.1), (.L__pc.14693.LD)
	.p2align 4
	.L__pc.14693.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14694
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14694: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14695
	
	.L__pc.14695: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14696
	
	.p2align 4
	.L__pc.14696: Dma_PatchDst (.L__pc.14696.ST), (.L__movme_cp.68), (.L__pc.14696.ST)
	.L__pc.14696.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14697
	
	.L__pc.14697: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14698
	
	.p2align 4
	.L__pc.14698: Dma_PatchDst (.L__pc.14698.ST), (.L__movme_cp.24), (.L__pc.14698.ST)
	.L__pc.14698.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14699
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14699: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14700
	
	.p2align 4
	.L__pc.14700: Dma_PatchDst (.L__pc.14700.ST), (.L__movme_cp.24), (.L__pc.14700.ST)
	.L__pc.14700.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14701
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.14701: Dma_PatchSrc (.L__pc.14701.LD), (.L__movme_cp.60), (.L__pc.14701.LD)
	.p2align 4
	.L__pc.14701.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14702
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14702: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14703
	
	.L__pc.14703: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14704
	
	.p2align 4
	.L__pc.14704: Dma_PatchDst (.L__pc.14704.ST), (.L__movme_cp.21), (.L__pc.14704.ST)
	.L__pc.14704.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14705
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.14705: Dma_PatchSrc (.L__pc.14705.LD), (.L__movme_cp.58), (.L__pc.14705.LD)
	.p2align 4
	.L__pc.14705.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14706
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14706: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14707
	
	.L__pc.14707: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14708
	
	.p2align 4
	.L__pc.14708: Dma_PatchDst (.L__pc.14708.ST), (.L__movme_cp.22), (.L__pc.14708.ST)
	.L__pc.14708.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14709
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14709: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14710
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14710: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14711
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14711: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14712
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14712: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14713
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.14713: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.14714
	
	.p2align 4
	.L__pc.14714: Dma_PatchDst (.L__pc.14714.ST), (.L__movme_cp.24), (.L__pc.14714.ST)
	.L__pc.14714.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14715
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.14715: Dma_PatchSrc (.L__pc.14715.LD), (.L__movme_cp.25), (.L__pc.14715.LD)
	.p2align 4
	.L__pc.14715.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14716
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14716: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14717
	.L__pc.14717: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14718
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.14718: Dma_PatchSrc (.L__pc.14718.LD), (.L__movme_cp.26), (.L__pc.14718.LD)
	.p2align 4
	.L__pc.14718.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14719
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14719: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14720
	.L__pc.14720: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14721
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14721: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14722: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14723: Dma_PatchSrc (.L__pc.14723.LD), (.L__movme_tmp.1), (.L__pc.14723.LD)
	.p2align 4
	.L__pc.14723.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14724
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14724: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14725
	.L__pc.14725: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14726
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14726: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14727: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14728: Dma_PatchSrc (.L__pc.14728.LD), (.L__movme_tmp.1), (.L__pc.14728.LD)
	.p2align 4
	.L__pc.14728.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14729
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14729: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14730
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14730: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14731: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14732: Dma_PatchSrc (.L__pc.14732.LD), (.L__movme_tmp.1), (.L__pc.14732.LD)
	.p2align 4
	.L__pc.14732.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14733
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14733: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14734
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14734: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14735: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14736: Dma_PatchSrc (.L__pc.14736.LD), (.L__movme_tmp.1), (.L__pc.14736.LD)
	.p2align 4
	.L__pc.14736.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14737
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14737: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14738
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14738: Dma_PatchSrc (.L__pc.14738.LD), (.L__movme_cp.24), (.L__pc.14738.LD)
	.p2align 4
	.L__pc.14738.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14739
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14739: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14740
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14740: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14741: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14742: Dma_PatchSrc (.L__pc.14742.LD), (.L__movme_tmp.1), (.L__pc.14742.LD)
	.p2align 4
	.L__pc.14742.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14743
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14743: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14744
	
	.L__pc.14744: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14745
	
	.p2align 4
	.L__pc.14745: Dma_PatchDst (.L__pc.14745.ST), (.L__movme_cp.69), (.L__pc.14745.ST)
	.L__pc.14745.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14746
	
	.L__pc.14746: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14747
	
	.p2align 4
	.L__pc.14747: Dma_PatchDst (.L__pc.14747.ST), (.L__movme_cp.54), (.L__pc.14747.ST)
	.L__pc.14747.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14748
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.14748: Dma_PatchSrc (.L__pc.14748.LD), (.L__movme_cp.30), (.L__pc.14748.LD)
	.p2align 4
	.L__pc.14748.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14749
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14749: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14750
	.L__pc.14750: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14751
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.14751: Dma_PatchSrc (.L__pc.14751.LD), (.L__movme_cp.31), (.L__pc.14751.LD)
	.p2align 4
	.L__pc.14751.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14752
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14752: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14753
	.L__pc.14753: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14754
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14754: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14755: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14756: Dma_PatchSrc (.L__pc.14756.LD), (.L__movme_tmp.1), (.L__pc.14756.LD)
	.p2align 4
	.L__pc.14756.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14757
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14757: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14758
	.L__pc.14758: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14759
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14759: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14760: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14761: Dma_PatchSrc (.L__pc.14761.LD), (.L__movme_tmp.1), (.L__pc.14761.LD)
	.p2align 4
	.L__pc.14761.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14762
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14762: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14763
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14763: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14764: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14765: Dma_PatchSrc (.L__pc.14765.LD), (.L__movme_tmp.1), (.L__pc.14765.LD)
	.p2align 4
	.L__pc.14765.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14766
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14766: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14767
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14767: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14768: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14769: Dma_PatchSrc (.L__pc.14769.LD), (.L__movme_tmp.1), (.L__pc.14769.LD)
	.p2align 4
	.L__pc.14769.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14770
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14770: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14771
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14771: Dma_PatchSrc (.L__pc.14771.LD), (.L__movme_cp.24), (.L__pc.14771.LD)
	.p2align 4
	.L__pc.14771.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14772
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14772: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14773
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14773: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14774: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14775: Dma_PatchSrc (.L__pc.14775.LD), (.L__movme_tmp.1), (.L__pc.14775.LD)
	.p2align 4
	.L__pc.14775.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14776
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14776: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14777
	
	.L__pc.14777: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14778
	
	.p2align 4
	.L__pc.14778: Dma_PatchDst (.L__pc.14778.ST), (.L__movme_cp.70), (.L__pc.14778.ST)
	.L__pc.14778.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14779
	
	.L__pc.14779: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14780
	
	.p2align 4
	.L__pc.14780: Dma_PatchDst (.L__pc.14780.ST), (.L__movme_cp.54), (.L__pc.14780.ST)
	.L__pc.14780.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14781
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14781: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14782
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14782: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14783
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14783: Dma_PatchSrc (.L__pc.14783.LD), (.L__movme_cp.24), (.L__pc.14783.LD)
	.p2align 4
	.L__pc.14783.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14784
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14784: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14785
	.L__pc.14785: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14786
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.14786: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14787: Dma_PatchSrc (.L__pc.14787.LD), (.L__movme_tmp.1), (.L__pc.14787.LD)
	.p2align 4
	.L__pc.14787.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14788
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14788: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14789
	.L__pc.14789: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14790
	
	.L__pc.14790: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14791
	
	.p2align 4
	.L__pc.14791: Dma_PatchDst (.L__pc.14791.ST), (.L__movme_cp.72), (.L__pc.14791.ST)
	.L__pc.14791.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14792
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.14792: Dma_PatchSrc (.L__pc.14792.LD), (.L__movme_cp.72), (.L__pc.14792.LD)
	.p2align 4
	.L__pc.14792.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14793
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14793: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14794
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14794: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14795: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14796: Dma_PatchSrc (.L__pc.14796.LD), (.L__movme_tmp.1), (.L__pc.14796.LD)
	.p2align 4
	.L__pc.14796.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14797
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14797: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14798
	
	.L__pc.14798: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14799
	
	.p2align 4
	.L__pc.14799: Dma_PatchDst (.L__pc.14799.ST), (.L__movme_cp.74), (.L__pc.14799.ST)
	.L__pc.14799.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14800
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14800: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14801: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14802: Dma_PatchSrc (.L__pc.14802.LD), (.L__movme_tmp.1), (.L__pc.14802.LD)
	.p2align 4
	.L__pc.14802.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14803
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14803: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14804
	
	.L__pc.14804: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14805
	
	.p2align 4
	.L__pc.14805: Dma_PatchDst (.L__pc.14805.ST), (.L__movme_cp.76), (.L__pc.14805.ST)
	.L__pc.14805.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14806
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.14806: Dma_PatchSrc (.L__pc.14806.LD), (.L__movme_cp.74), (.L__pc.14806.LD)
	.p2align 4
	.L__pc.14806.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14807
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14807: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14808
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.14808: Dma_PatchSrc (.L__pc.14808.LD), ((.L__movme.reg.eax+0)), (.L__pc.14808.LD)
	.p2align 4
	.L__pc.14808.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14809
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14809: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14810
	
	.L__pc.14810: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14811
	
	.p2align 4
	.L__pc.14811: Dma_PatchDst (.L__pc.14811.ST), (.L__movme_cp.77), (.L__pc.14811.ST)
	.L__pc.14811.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14812
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.14812: Dma_PatchSrc (.L__pc.14812.LD), (.L__movme_cp.77), (.L__pc.14812.LD)
	.p2align 4
	.L__pc.14812.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14813
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14813: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14814
	
	.L__pc.14814: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14815
	
	.p2align 4
	.L__pc.14815: Dma_PatchDst (.L__pc.14815.ST), (.L__movme_cp.21), (.L__pc.14815.ST)
	.L__pc.14815.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14816
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.14816: Dma_PatchSrc (.L__pc.14816.LD), (.L__movme_cp.58), (.L__pc.14816.LD)
	.p2align 4
	.L__pc.14816.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14817
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14817: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14818
	
	.L__pc.14818: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14819
	
	.p2align 4
	.L__pc.14819: Dma_PatchDst (.L__pc.14819.ST), (.L__movme_cp.22), (.L__pc.14819.ST)
	.L__pc.14819.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14820
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14820: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14821
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14821: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14822
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14822: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14823
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14823: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14824
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.14824: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.14825
	
	.p2align 4
	.L__pc.14825: Dma_PatchDst (.L__pc.14825.ST), (.L__movme_cp.24), (.L__pc.14825.ST)
	.L__pc.14825.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14826
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.14826: Dma_PatchSrc (.L__pc.14826.LD), (.L__movme_cp.25), (.L__pc.14826.LD)
	.p2align 4
	.L__pc.14826.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14827
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14827: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14828
	.L__pc.14828: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14829
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.14829: Dma_PatchSrc (.L__pc.14829.LD), (.L__movme_cp.26), (.L__pc.14829.LD)
	.p2align 4
	.L__pc.14829.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14830
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14830: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14831
	.L__pc.14831: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14832
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14832: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14833: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14834: Dma_PatchSrc (.L__pc.14834.LD), (.L__movme_tmp.1), (.L__pc.14834.LD)
	.p2align 4
	.L__pc.14834.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14835
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14835: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14836
	.L__pc.14836: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14837
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14837: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14838: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14839: Dma_PatchSrc (.L__pc.14839.LD), (.L__movme_tmp.1), (.L__pc.14839.LD)
	.p2align 4
	.L__pc.14839.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14840
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14840: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14841
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14841: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14842: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14843: Dma_PatchSrc (.L__pc.14843.LD), (.L__movme_tmp.1), (.L__pc.14843.LD)
	.p2align 4
	.L__pc.14843.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14844
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14844: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14845
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14845: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14846: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14847: Dma_PatchSrc (.L__pc.14847.LD), (.L__movme_tmp.1), (.L__pc.14847.LD)
	.p2align 4
	.L__pc.14847.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14848
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14848: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14849
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14849: Dma_PatchSrc (.L__pc.14849.LD), (.L__movme_cp.24), (.L__pc.14849.LD)
	.p2align 4
	.L__pc.14849.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14850
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14850: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14851
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14851: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14852: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14853: Dma_PatchSrc (.L__pc.14853.LD), (.L__movme_tmp.1), (.L__pc.14853.LD)
	.p2align 4
	.L__pc.14853.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14854
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14854: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14855
	
	.L__pc.14855: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14856
	
	.p2align 4
	.L__pc.14856: Dma_PatchDst (.L__pc.14856.ST), (.L__movme_cp.78), (.L__pc.14856.ST)
	.L__pc.14856.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14857
	
	.L__pc.14857: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14858
	
	.p2align 4
	.L__pc.14858: Dma_PatchDst (.L__pc.14858.ST), (.L__movme_cp.54), (.L__pc.14858.ST)
	.L__pc.14858.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14859
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.14859: Dma_PatchSrc (.L__pc.14859.LD), (.L__movme_cp.30), (.L__pc.14859.LD)
	.p2align 4
	.L__pc.14859.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14860
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14860: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.14861
	.L__pc.14861: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.14862
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.14862: Dma_PatchSrc (.L__pc.14862.LD), (.L__movme_cp.31), (.L__pc.14862.LD)
	.p2align 4
	.L__pc.14862.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14863
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14863: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14864
	.L__pc.14864: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14865
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.14865: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14866: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14867: Dma_PatchSrc (.L__pc.14867.LD), (.L__movme_tmp.1), (.L__pc.14867.LD)
	.p2align 4
	.L__pc.14867.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14868
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14868: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.14869
	.L__pc.14869: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.14870
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14870: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14871: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14872: Dma_PatchSrc (.L__pc.14872.LD), (.L__movme_tmp.1), (.L__pc.14872.LD)
	.p2align 4
	.L__pc.14872.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14873
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14873: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14874
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14874: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14875: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14876: Dma_PatchSrc (.L__pc.14876.LD), (.L__movme_tmp.1), (.L__pc.14876.LD)
	.p2align 4
	.L__pc.14876.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14877
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14877: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14878
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14878: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14879: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14880: Dma_PatchSrc (.L__pc.14880.LD), (.L__movme_tmp.1), (.L__pc.14880.LD)
	.p2align 4
	.L__pc.14880.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14881
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14881: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14882
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14882: Dma_PatchSrc (.L__pc.14882.LD), (.L__movme_cp.24), (.L__pc.14882.LD)
	.p2align 4
	.L__pc.14882.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14883
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.14883: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.14884
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.14884: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14885: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14886: Dma_PatchSrc (.L__pc.14886.LD), (.L__movme_tmp.1), (.L__pc.14886.LD)
	.p2align 4
	.L__pc.14886.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14887
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14887: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14888
	
	.L__pc.14888: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.14889
	
	.p2align 4
	.L__pc.14889: Dma_PatchDst (.L__pc.14889.ST), (.L__movme_cp.79), (.L__pc.14889.ST)
	.L__pc.14889.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14890
	
	.L__pc.14890: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14891
	
	.p2align 4
	.L__pc.14891: Dma_PatchDst (.L__pc.14891.ST), (.L__movme_cp.54), (.L__pc.14891.ST)
	.L__pc.14891.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14892
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.14892: Dma_PatchSrc (.L__pc.14892.LD), (.L__movme_cp.74), (.L__pc.14892.LD)
	.p2align 4
	.L__pc.14892.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14893
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14893: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14894
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.14894: Dma_PatchSrc (.L__pc.14894.LD), (.L__movme_cp.77), (.L__pc.14894.LD)
	.p2align 4
	.L__pc.14894.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14895
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14895: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14896
	
	.L__pc.14896: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14897
	
	.p2align 4
	.L__pc.14897: Dma_PatchDst (.L__pc.14897.ST), ((.L__movme.reg.eax+0)), (.L__pc.14897.ST)
	.L__pc.14897.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14898
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.14898: Dma_PatchSrc (.L__pc.14898.LD), (.L__movme_cp.76), (.L__pc.14898.LD)
	.p2align 4
	.L__pc.14898.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14899
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14899: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14900
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.14900: Dma_PatchSrc (.L__pc.14900.LD), ((.L__movme.reg.eax+0)), (.L__pc.14900.LD)
	.p2align 4
	.L__pc.14900.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14901
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14901: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14902
	
	.L__pc.14902: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14903
	
	.p2align 4
	.L__pc.14903: Dma_PatchDst (.L__pc.14903.ST), (.L__movme_cp.80), (.L__pc.14903.ST)
	.L__pc.14903.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14904
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14904: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14905
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14905: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14906
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.14906: Dma_PatchSrc (.L__pc.14906.LD), (.L__movme_cp.81), (.L__pc.14906.LD)
	.p2align 4
	.L__pc.14906.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14907
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14907: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14908
	.L__pc.14908: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14909
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.94 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.14909: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14910: Dma_PatchSrc (.L__pc.14910.LD), (.L__movme_tmp.1), (.L__pc.14910.LD)
	.p2align 4
	.L__pc.14910.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14911
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14911: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14912
	.L__pc.14912: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14913
	
	.L__pc.14913: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14914
	
	.p2align 4
	.L__pc.14914: Dma_PatchDst (.L__pc.14914.ST), (.L__movme_cp.81), (.L__pc.14914.ST)
	.L__pc.14914.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14915
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.14915: Dma_PatchSrc (.L__pc.14915.LD), (.L__movme_cp.76), (.L__pc.14915.LD)
	.p2align 4
	.L__pc.14915.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14916
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14916: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14917
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.14917: Dma_PatchSrc (.L__pc.14917.LD), (.L__movme_cp.80), (.L__pc.14917.LD)
	.p2align 4
	.L__pc.14917.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14918
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14918: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14919
	
	.L__pc.14919: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.14920
	
	.p2align 4
	.L__pc.14920: Dma_PatchDst (.L__pc.14920.ST), ((.L__movme.reg.eax+0)), (.L__pc.14920.ST)
	.L__pc.14920.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14921
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14921: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14922
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14922: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14923
	
	// CG.LOAD4 [.L__movme_cp.61} => .L__movme_tmp.0
	.L__pc.14923: Dma_PatchSrc (.L__pc.14923.LD), (.L__movme_cp.61), (.L__pc.14923.LD)
	.p2align 4
	.L__pc.14923.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14924
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14924: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14925
	.L__pc.14925: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14926
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.14926: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.95 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14927: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14928: Dma_PatchSrc (.L__pc.14928.LD), (.L__movme_tmp.1), (.L__pc.14928.LD)
	.p2align 4
	.L__pc.14928.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14929
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14929: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14930
	
	.L__pc.14930: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.14931
	
	.p2align 4
	.L__pc.14931: Dma_PatchDst (.L__pc.14931.ST), (.L__movme_cp.24), (.L__pc.14931.ST)
	.L__pc.14931.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14932
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14932: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14933
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14933: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14934
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14934: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14935
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14935: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14936
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.14936: Dma_PatchSrc (.L__pc.14936.LD), (.L__movme_cp.63), (.L__pc.14936.LD)
	.p2align 4
	.L__pc.14936.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14937
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14937: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14938
	.L__pc.14938: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14939
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14939: Dma_PatchSrc (.L__pc.14939.LD), (.L__movme_cp.24), (.L__pc.14939.LD)
	.p2align 4
	.L__pc.14939.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14940
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14940: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14941
	.L__pc.14941: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14942
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14942: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14943: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14944: Dma_PatchSrc (.L__pc.14944.LD), (.L__movme_tmp.1), (.L__pc.14944.LD)
	.p2align 4
	.L__pc.14944.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14945
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14945: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14946
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14946: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14947: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14948: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14949: Dma_PatchSrc (.L__pc.14949.LD), (.L__movme_tmp.1), (.L__pc.14949.LD)
	.p2align 4
	.L__pc.14949.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14950
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14950: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14951
	
	.L__pc.14951: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14952
	
	.p2align 4
	.L__pc.14952: Dma_PatchDst (.L__pc.14952.ST), (.L__movme_cp.63), (.L__pc.14952.ST)
	.L__pc.14952.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14953
	
	.L__pc.14953: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14954
	
	.p2align 4
	.L__pc.14954: Dma_PatchDst (.L__pc.14954.ST), (.L__movme_cp.24), (.L__pc.14954.ST)
	.L__pc.14954.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14955
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14955: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14956
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14956: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14957
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14957: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14958
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14958: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14959
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.14959: Dma_PatchSrc (.L__pc.14959.LD), (.L__movme_cp.66), (.L__pc.14959.LD)
	.p2align 4
	.L__pc.14959.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14960
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14960: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14961
	.L__pc.14961: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14962
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14962: Dma_PatchSrc (.L__pc.14962.LD), (.L__movme_cp.24), (.L__pc.14962.LD)
	.p2align 4
	.L__pc.14962.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14963
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14963: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14964
	.L__pc.14964: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14965
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14965: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14966: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14967: Dma_PatchSrc (.L__pc.14967.LD), (.L__movme_tmp.1), (.L__pc.14967.LD)
	.p2align 4
	.L__pc.14967.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14968
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14968: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14969
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14969: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14970: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14971: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14972: Dma_PatchSrc (.L__pc.14972.LD), (.L__movme_tmp.1), (.L__pc.14972.LD)
	.p2align 4
	.L__pc.14972.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14973
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14973: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14974
	
	.L__pc.14974: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14975
	
	.p2align 4
	.L__pc.14975: Dma_PatchDst (.L__pc.14975.ST), (.L__movme_cp.66), (.L__pc.14975.ST)
	.L__pc.14975.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14976
	
	.L__pc.14976: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.14977
	
	.p2align 4
	.L__pc.14977: Dma_PatchDst (.L__pc.14977.ST), (.L__movme_cp.24), (.L__pc.14977.ST)
	.L__pc.14977.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14978
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14978: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14979
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14979: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14980
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.14980: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.14981
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14981: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.14982
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.14982: Dma_PatchSrc (.L__pc.14982.LD), (.L__movme_cp.67), (.L__pc.14982.LD)
	.p2align 4
	.L__pc.14982.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14983
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14983: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.14984
	.L__pc.14984: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.14985
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.14985: Dma_PatchSrc (.L__pc.14985.LD), (.L__movme_cp.24), (.L__pc.14985.LD)
	.p2align 4
	.L__pc.14985.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14986
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.14986: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.14987
	.L__pc.14987: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.14988
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.14988: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.14989: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14990: Dma_PatchSrc (.L__pc.14990.LD), (.L__movme_tmp.1), (.L__pc.14990.LD)
	.p2align 4
	.L__pc.14990.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14991
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14991: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14992
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.14992: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.14993: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.14994: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.14995: Dma_PatchSrc (.L__pc.14995.LD), (.L__movme_tmp.1), (.L__pc.14995.LD)
	.p2align 4
	.L__pc.14995.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.14996
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.14996: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.14997
	
	.L__pc.14997: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.14998
	
	.p2align 4
	.L__pc.14998: Dma_PatchDst (.L__pc.14998.ST), (.L__movme_cp.67), (.L__pc.14998.ST)
	.L__pc.14998.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.14999
	
	.L__pc.14999: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15000
	
	.p2align 4
	.L__pc.15000: Dma_PatchDst (.L__pc.15000.ST), (.L__movme_cp.24), (.L__pc.15000.ST)
	.L__pc.15000.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15001
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15001: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15002
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15002: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15003
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15003: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15004
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15004: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15005
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.15005: Dma_PatchSrc (.L__pc.15005.LD), (.L__movme_cp.68), (.L__pc.15005.LD)
	.p2align 4
	.L__pc.15005.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15006
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15006: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15007
	.L__pc.15007: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15008
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15008: Dma_PatchSrc (.L__pc.15008.LD), (.L__movme_cp.24), (.L__pc.15008.LD)
	.p2align 4
	.L__pc.15008.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15009
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15009: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15010
	.L__pc.15010: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15011
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15011: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15012: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15013: Dma_PatchSrc (.L__pc.15013.LD), (.L__movme_tmp.1), (.L__pc.15013.LD)
	.p2align 4
	.L__pc.15013.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15014
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15014: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15015
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15015: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15016: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15017: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15018: Dma_PatchSrc (.L__pc.15018.LD), (.L__movme_tmp.1), (.L__pc.15018.LD)
	.p2align 4
	.L__pc.15018.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15019
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15019: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15020
	
	.L__pc.15020: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15021
	
	.p2align 4
	.L__pc.15021: Dma_PatchDst (.L__pc.15021.ST), (.L__movme_cp.68), (.L__pc.15021.ST)
	.L__pc.15021.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15022
	
	.L__pc.15022: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15023
	
	.p2align 4
	.L__pc.15023: Dma_PatchDst (.L__pc.15023.ST), (.L__movme_cp.24), (.L__pc.15023.ST)
	.L__pc.15023.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15024
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15024: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15025
	
	.p2align 4
	.L__pc.15025: Dma_PatchDst (.L__pc.15025.ST), (.L__movme_cp.24), (.L__pc.15025.ST)
	.L__pc.15025.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15026
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.15026: Dma_PatchSrc (.L__pc.15026.LD), (.L__movme_cp.60), (.L__pc.15026.LD)
	.p2align 4
	.L__pc.15026.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15027
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15027: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15028
	
	.L__pc.15028: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15029
	
	.p2align 4
	.L__pc.15029: Dma_PatchDst (.L__pc.15029.ST), (.L__movme_cp.21), (.L__pc.15029.ST)
	.L__pc.15029.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15030
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.15030: Dma_PatchSrc (.L__pc.15030.LD), (.L__movme_cp.58), (.L__pc.15030.LD)
	.p2align 4
	.L__pc.15030.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15031
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15031: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15032
	
	.L__pc.15032: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15033
	
	.p2align 4
	.L__pc.15033: Dma_PatchDst (.L__pc.15033.ST), (.L__movme_cp.22), (.L__pc.15033.ST)
	.L__pc.15033.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15034
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15034: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15035
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15035: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15036
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15036: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15037
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15037: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15038
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.15038: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.15039
	
	.p2align 4
	.L__pc.15039: Dma_PatchDst (.L__pc.15039.ST), (.L__movme_cp.24), (.L__pc.15039.ST)
	.L__pc.15039.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15040
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.15040: Dma_PatchSrc (.L__pc.15040.LD), (.L__movme_cp.25), (.L__pc.15040.LD)
	.p2align 4
	.L__pc.15040.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15041
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15041: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15042
	.L__pc.15042: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15043
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.15043: Dma_PatchSrc (.L__pc.15043.LD), (.L__movme_cp.26), (.L__pc.15043.LD)
	.p2align 4
	.L__pc.15043.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15044
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15044: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15045
	.L__pc.15045: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15046
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15046: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15047: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15048: Dma_PatchSrc (.L__pc.15048.LD), (.L__movme_tmp.1), (.L__pc.15048.LD)
	.p2align 4
	.L__pc.15048.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15049
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15049: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15050
	.L__pc.15050: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15051
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15051: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15052: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15053: Dma_PatchSrc (.L__pc.15053.LD), (.L__movme_tmp.1), (.L__pc.15053.LD)
	.p2align 4
	.L__pc.15053.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15054
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15054: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15055
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15055: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15056: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15057: Dma_PatchSrc (.L__pc.15057.LD), (.L__movme_tmp.1), (.L__pc.15057.LD)
	.p2align 4
	.L__pc.15057.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15058
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15058: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15059
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15059: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15060: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15061: Dma_PatchSrc (.L__pc.15061.LD), (.L__movme_tmp.1), (.L__pc.15061.LD)
	.p2align 4
	.L__pc.15061.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15062
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15062: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15063
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15063: Dma_PatchSrc (.L__pc.15063.LD), (.L__movme_cp.24), (.L__pc.15063.LD)
	.p2align 4
	.L__pc.15063.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15064
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15064: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15065
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15065: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15066: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15067: Dma_PatchSrc (.L__pc.15067.LD), (.L__movme_tmp.1), (.L__pc.15067.LD)
	.p2align 4
	.L__pc.15067.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15068
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15068: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15069
	
	.L__pc.15069: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15070
	
	.p2align 4
	.L__pc.15070: Dma_PatchDst (.L__pc.15070.ST), (.L__movme_cp.69), (.L__pc.15070.ST)
	.L__pc.15070.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15071
	
	.L__pc.15071: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15072
	
	.p2align 4
	.L__pc.15072: Dma_PatchDst (.L__pc.15072.ST), (.L__movme_cp.54), (.L__pc.15072.ST)
	.L__pc.15072.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15073
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.15073: Dma_PatchSrc (.L__pc.15073.LD), (.L__movme_cp.30), (.L__pc.15073.LD)
	.p2align 4
	.L__pc.15073.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15074
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15074: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15075
	.L__pc.15075: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15076
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.15076: Dma_PatchSrc (.L__pc.15076.LD), (.L__movme_cp.31), (.L__pc.15076.LD)
	.p2align 4
	.L__pc.15076.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15077
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15077: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15078
	.L__pc.15078: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15079
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15079: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15080: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15081: Dma_PatchSrc (.L__pc.15081.LD), (.L__movme_tmp.1), (.L__pc.15081.LD)
	.p2align 4
	.L__pc.15081.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15082
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15082: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15083
	.L__pc.15083: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15084
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15084: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15085: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15086: Dma_PatchSrc (.L__pc.15086.LD), (.L__movme_tmp.1), (.L__pc.15086.LD)
	.p2align 4
	.L__pc.15086.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15087
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15087: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15088
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15088: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15089: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15090: Dma_PatchSrc (.L__pc.15090.LD), (.L__movme_tmp.1), (.L__pc.15090.LD)
	.p2align 4
	.L__pc.15090.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15091
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15091: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15092
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15092: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15093: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15094: Dma_PatchSrc (.L__pc.15094.LD), (.L__movme_tmp.1), (.L__pc.15094.LD)
	.p2align 4
	.L__pc.15094.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15095
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15095: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15096
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15096: Dma_PatchSrc (.L__pc.15096.LD), (.L__movme_cp.24), (.L__pc.15096.LD)
	.p2align 4
	.L__pc.15096.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15097
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15097: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15098
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15098: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15099: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15100: Dma_PatchSrc (.L__pc.15100.LD), (.L__movme_tmp.1), (.L__pc.15100.LD)
	.p2align 4
	.L__pc.15100.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15101
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15101: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15102
	
	.L__pc.15102: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15103
	
	.p2align 4
	.L__pc.15103: Dma_PatchDst (.L__pc.15103.ST), (.L__movme_cp.70), (.L__pc.15103.ST)
	.L__pc.15103.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15104
	
	.L__pc.15104: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15105
	
	.p2align 4
	.L__pc.15105: Dma_PatchDst (.L__pc.15105.ST), (.L__movme_cp.54), (.L__pc.15105.ST)
	.L__pc.15105.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15106
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15106: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15107
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15107: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15108
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15108: Dma_PatchSrc (.L__pc.15108.LD), (.L__movme_cp.24), (.L__pc.15108.LD)
	.p2align 4
	.L__pc.15108.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15109
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15109: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15110
	.L__pc.15110: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15111
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.15111: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15112: Dma_PatchSrc (.L__pc.15112.LD), (.L__movme_tmp.1), (.L__pc.15112.LD)
	.p2align 4
	.L__pc.15112.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15113
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15113: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15114
	.L__pc.15114: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15115
	
	.L__pc.15115: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15116
	
	.p2align 4
	.L__pc.15116: Dma_PatchDst (.L__pc.15116.ST), (.L__movme_cp.72), (.L__pc.15116.ST)
	.L__pc.15116.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15117
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.15117: Dma_PatchSrc (.L__pc.15117.LD), (.L__movme_cp.72), (.L__pc.15117.LD)
	.p2align 4
	.L__pc.15117.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15118
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15118: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15119
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15119: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15120: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15121: Dma_PatchSrc (.L__pc.15121.LD), (.L__movme_tmp.1), (.L__pc.15121.LD)
	.p2align 4
	.L__pc.15121.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15122
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15122: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15123
	
	.L__pc.15123: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15124
	
	.p2align 4
	.L__pc.15124: Dma_PatchDst (.L__pc.15124.ST), (.L__movme_cp.74), (.L__pc.15124.ST)
	.L__pc.15124.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15125
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15125: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15126: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15127: Dma_PatchSrc (.L__pc.15127.LD), (.L__movme_tmp.1), (.L__pc.15127.LD)
	.p2align 4
	.L__pc.15127.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15128
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15128: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15129
	
	.L__pc.15129: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15130
	
	.p2align 4
	.L__pc.15130: Dma_PatchDst (.L__pc.15130.ST), (.L__movme_cp.76), (.L__pc.15130.ST)
	.L__pc.15130.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15131
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.15131: Dma_PatchSrc (.L__pc.15131.LD), (.L__movme_cp.74), (.L__pc.15131.LD)
	.p2align 4
	.L__pc.15131.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15132
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15132: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15133
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.15133: Dma_PatchSrc (.L__pc.15133.LD), ((.L__movme.reg.eax+0)), (.L__pc.15133.LD)
	.p2align 4
	.L__pc.15133.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15134
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15134: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15135
	
	.L__pc.15135: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15136
	
	.p2align 4
	.L__pc.15136: Dma_PatchDst (.L__pc.15136.ST), (.L__movme_cp.77), (.L__pc.15136.ST)
	.L__pc.15136.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15137
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.15137: Dma_PatchSrc (.L__pc.15137.LD), (.L__movme_cp.77), (.L__pc.15137.LD)
	.p2align 4
	.L__pc.15137.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15138
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15138: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15139
	
	.L__pc.15139: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15140
	
	.p2align 4
	.L__pc.15140: Dma_PatchDst (.L__pc.15140.ST), (.L__movme_cp.21), (.L__pc.15140.ST)
	.L__pc.15140.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15141
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.15141: Dma_PatchSrc (.L__pc.15141.LD), (.L__movme_cp.58), (.L__pc.15141.LD)
	.p2align 4
	.L__pc.15141.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15142
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15142: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15143
	
	.L__pc.15143: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15144
	
	.p2align 4
	.L__pc.15144: Dma_PatchDst (.L__pc.15144.ST), (.L__movme_cp.22), (.L__pc.15144.ST)
	.L__pc.15144.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15145
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15145: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15146
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15146: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15147
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15147: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15148
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15148: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15149
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.15149: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.15150
	
	.p2align 4
	.L__pc.15150: Dma_PatchDst (.L__pc.15150.ST), (.L__movme_cp.24), (.L__pc.15150.ST)
	.L__pc.15150.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15151
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.15151: Dma_PatchSrc (.L__pc.15151.LD), (.L__movme_cp.25), (.L__pc.15151.LD)
	.p2align 4
	.L__pc.15151.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15152
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15152: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15153
	.L__pc.15153: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15154
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.15154: Dma_PatchSrc (.L__pc.15154.LD), (.L__movme_cp.26), (.L__pc.15154.LD)
	.p2align 4
	.L__pc.15154.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15155
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15155: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15156
	.L__pc.15156: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15157
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15157: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15158: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15159: Dma_PatchSrc (.L__pc.15159.LD), (.L__movme_tmp.1), (.L__pc.15159.LD)
	.p2align 4
	.L__pc.15159.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15160
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15160: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15161
	.L__pc.15161: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15162
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15162: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15163: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15164: Dma_PatchSrc (.L__pc.15164.LD), (.L__movme_tmp.1), (.L__pc.15164.LD)
	.p2align 4
	.L__pc.15164.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15165
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15165: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15166
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15166: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15167: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15168: Dma_PatchSrc (.L__pc.15168.LD), (.L__movme_tmp.1), (.L__pc.15168.LD)
	.p2align 4
	.L__pc.15168.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15169
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15169: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15170
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15170: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15171: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15172: Dma_PatchSrc (.L__pc.15172.LD), (.L__movme_tmp.1), (.L__pc.15172.LD)
	.p2align 4
	.L__pc.15172.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15173
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15173: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15174
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15174: Dma_PatchSrc (.L__pc.15174.LD), (.L__movme_cp.24), (.L__pc.15174.LD)
	.p2align 4
	.L__pc.15174.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15175
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15175: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15176
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15176: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15177: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15178: Dma_PatchSrc (.L__pc.15178.LD), (.L__movme_tmp.1), (.L__pc.15178.LD)
	.p2align 4
	.L__pc.15178.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15179
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15179: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15180
	
	.L__pc.15180: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15181
	
	.p2align 4
	.L__pc.15181: Dma_PatchDst (.L__pc.15181.ST), (.L__movme_cp.78), (.L__pc.15181.ST)
	.L__pc.15181.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15182
	
	.L__pc.15182: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15183
	
	.p2align 4
	.L__pc.15183: Dma_PatchDst (.L__pc.15183.ST), (.L__movme_cp.54), (.L__pc.15183.ST)
	.L__pc.15183.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15184
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.15184: Dma_PatchSrc (.L__pc.15184.LD), (.L__movme_cp.30), (.L__pc.15184.LD)
	.p2align 4
	.L__pc.15184.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15185
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15185: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15186
	.L__pc.15186: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15187
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.15187: Dma_PatchSrc (.L__pc.15187.LD), (.L__movme_cp.31), (.L__pc.15187.LD)
	.p2align 4
	.L__pc.15187.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15188
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15188: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15189
	.L__pc.15189: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15190
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15190: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15191: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15192: Dma_PatchSrc (.L__pc.15192.LD), (.L__movme_tmp.1), (.L__pc.15192.LD)
	.p2align 4
	.L__pc.15192.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15193
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15193: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15194
	.L__pc.15194: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15195
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15195: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15196: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15197: Dma_PatchSrc (.L__pc.15197.LD), (.L__movme_tmp.1), (.L__pc.15197.LD)
	.p2align 4
	.L__pc.15197.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15198
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15198: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15199
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15199: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15200: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15201: Dma_PatchSrc (.L__pc.15201.LD), (.L__movme_tmp.1), (.L__pc.15201.LD)
	.p2align 4
	.L__pc.15201.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15202
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15202: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15203
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15203: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15204: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15205: Dma_PatchSrc (.L__pc.15205.LD), (.L__movme_tmp.1), (.L__pc.15205.LD)
	.p2align 4
	.L__pc.15205.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15206
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15206: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15207
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15207: Dma_PatchSrc (.L__pc.15207.LD), (.L__movme_cp.24), (.L__pc.15207.LD)
	.p2align 4
	.L__pc.15207.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15208
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15208: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15209
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15209: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15210: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15211: Dma_PatchSrc (.L__pc.15211.LD), (.L__movme_tmp.1), (.L__pc.15211.LD)
	.p2align 4
	.L__pc.15211.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15212
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15212: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15213
	
	.L__pc.15213: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15214
	
	.p2align 4
	.L__pc.15214: Dma_PatchDst (.L__pc.15214.ST), (.L__movme_cp.79), (.L__pc.15214.ST)
	.L__pc.15214.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15215
	
	.L__pc.15215: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15216
	
	.p2align 4
	.L__pc.15216: Dma_PatchDst (.L__pc.15216.ST), (.L__movme_cp.54), (.L__pc.15216.ST)
	.L__pc.15216.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15217
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.15217: Dma_PatchSrc (.L__pc.15217.LD), (.L__movme_cp.74), (.L__pc.15217.LD)
	.p2align 4
	.L__pc.15217.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15218
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15218: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15219
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.15219: Dma_PatchSrc (.L__pc.15219.LD), (.L__movme_cp.77), (.L__pc.15219.LD)
	.p2align 4
	.L__pc.15219.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15220
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15220: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15221
	
	.L__pc.15221: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15222
	
	.p2align 4
	.L__pc.15222: Dma_PatchDst (.L__pc.15222.ST), ((.L__movme.reg.eax+0)), (.L__pc.15222.ST)
	.L__pc.15222.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15223
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.15223: Dma_PatchSrc (.L__pc.15223.LD), (.L__movme_cp.76), (.L__pc.15223.LD)
	.p2align 4
	.L__pc.15223.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15224
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15224: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15225
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.15225: Dma_PatchSrc (.L__pc.15225.LD), ((.L__movme.reg.eax+0)), (.L__pc.15225.LD)
	.p2align 4
	.L__pc.15225.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15226
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15226: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15227
	
	.L__pc.15227: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15228
	
	.p2align 4
	.L__pc.15228: Dma_PatchDst (.L__pc.15228.ST), (.L__movme_cp.80), (.L__pc.15228.ST)
	.L__pc.15228.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15229
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15229: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15230
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15230: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15231
	
	// CG.LOAD4 [.L__movme_cp.81} => .L__movme_tmp.0
	.L__pc.15231: Dma_PatchSrc (.L__pc.15231.LD), (.L__movme_cp.81), (.L__pc.15231.LD)
	.p2align 4
	.L__pc.15231.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15232
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15232: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15233
	.L__pc.15233: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15234
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.96 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.15234: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15235: Dma_PatchSrc (.L__pc.15235.LD), (.L__movme_tmp.1), (.L__pc.15235.LD)
	.p2align 4
	.L__pc.15235.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15236
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15236: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15237
	.L__pc.15237: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15238
	
	.L__pc.15238: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15239
	
	.p2align 4
	.L__pc.15239: Dma_PatchDst (.L__pc.15239.ST), (.L__movme_cp.81), (.L__pc.15239.ST)
	.L__pc.15239.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15240
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.15240: Dma_PatchSrc (.L__pc.15240.LD), (.L__movme_cp.76), (.L__pc.15240.LD)
	.p2align 4
	.L__pc.15240.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15241
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15241: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15242
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.15242: Dma_PatchSrc (.L__pc.15242.LD), (.L__movme_cp.80), (.L__pc.15242.LD)
	.p2align 4
	.L__pc.15242.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15243
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15243: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15244
	
	.L__pc.15244: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15245
	
	.p2align 4
	.L__pc.15245: Dma_PatchDst (.L__pc.15245.ST), ((.L__movme.reg.eax+0)), (.L__pc.15245.ST)
	.L__pc.15245.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15246
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15246: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15247
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15247: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15248
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.15248: Dma_PatchSrc (.L__pc.15248.LD), (.L__movme_cp.97), (.L__pc.15248.LD)
	.p2align 4
	.L__pc.15248.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15249
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15249: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15250
	.L__pc.15250: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15251
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15251: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.62 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15252: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15253: Dma_PatchSrc (.L__pc.15253.LD), (.L__movme_tmp.1), (.L__pc.15253.LD)
	.p2align 4
	.L__pc.15253.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15254
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15254: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15255
	
	.L__pc.15255: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15256
	
	.p2align 4
	.L__pc.15256: Dma_PatchDst (.L__pc.15256.ST), (.L__movme_cp.24), (.L__pc.15256.ST)
	.L__pc.15256.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15257
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15257: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15258
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15258: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15259
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15259: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15260
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15260: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15261
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.15261: Dma_PatchSrc (.L__pc.15261.LD), (.L__movme_cp.63), (.L__pc.15261.LD)
	.p2align 4
	.L__pc.15261.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15262
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15262: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15263
	.L__pc.15263: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15264
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15264: Dma_PatchSrc (.L__pc.15264.LD), (.L__movme_cp.24), (.L__pc.15264.LD)
	.p2align 4
	.L__pc.15264.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15265
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15265: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15266
	.L__pc.15266: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15267
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15267: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15268: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15269: Dma_PatchSrc (.L__pc.15269.LD), (.L__movme_tmp.1), (.L__pc.15269.LD)
	.p2align 4
	.L__pc.15269.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15270
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15270: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15271
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15271: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15272: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15273: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15274: Dma_PatchSrc (.L__pc.15274.LD), (.L__movme_tmp.1), (.L__pc.15274.LD)
	.p2align 4
	.L__pc.15274.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15275
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15275: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15276
	
	.L__pc.15276: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15277
	
	.p2align 4
	.L__pc.15277: Dma_PatchDst (.L__pc.15277.ST), (.L__movme_cp.63), (.L__pc.15277.ST)
	.L__pc.15277.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15278
	
	.L__pc.15278: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15279
	
	.p2align 4
	.L__pc.15279: Dma_PatchDst (.L__pc.15279.ST), (.L__movme_cp.24), (.L__pc.15279.ST)
	.L__pc.15279.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15280
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15280: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15281
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15281: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15282
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15282: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15283
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15283: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15284
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.15284: Dma_PatchSrc (.L__pc.15284.LD), (.L__movme_cp.66), (.L__pc.15284.LD)
	.p2align 4
	.L__pc.15284.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15285
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15285: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15286
	.L__pc.15286: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15287
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15287: Dma_PatchSrc (.L__pc.15287.LD), (.L__movme_cp.24), (.L__pc.15287.LD)
	.p2align 4
	.L__pc.15287.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15288
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15288: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15289
	.L__pc.15289: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15290
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15290: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15291: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15292: Dma_PatchSrc (.L__pc.15292.LD), (.L__movme_tmp.1), (.L__pc.15292.LD)
	.p2align 4
	.L__pc.15292.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15293
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15293: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15294
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15294: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15295: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15296: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15297: Dma_PatchSrc (.L__pc.15297.LD), (.L__movme_tmp.1), (.L__pc.15297.LD)
	.p2align 4
	.L__pc.15297.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15298
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15298: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15299
	
	.L__pc.15299: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15300
	
	.p2align 4
	.L__pc.15300: Dma_PatchDst (.L__pc.15300.ST), (.L__movme_cp.66), (.L__pc.15300.ST)
	.L__pc.15300.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15301
	
	.L__pc.15301: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15302
	
	.p2align 4
	.L__pc.15302: Dma_PatchDst (.L__pc.15302.ST), (.L__movme_cp.24), (.L__pc.15302.ST)
	.L__pc.15302.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15303
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15303: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15304
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15304: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15305
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15305: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15306
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15306: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15307
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.15307: Dma_PatchSrc (.L__pc.15307.LD), (.L__movme_cp.67), (.L__pc.15307.LD)
	.p2align 4
	.L__pc.15307.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15308
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15308: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15309
	.L__pc.15309: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15310
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15310: Dma_PatchSrc (.L__pc.15310.LD), (.L__movme_cp.24), (.L__pc.15310.LD)
	.p2align 4
	.L__pc.15310.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15311
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15311: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15312
	.L__pc.15312: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15313
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15313: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15314: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15315: Dma_PatchSrc (.L__pc.15315.LD), (.L__movme_tmp.1), (.L__pc.15315.LD)
	.p2align 4
	.L__pc.15315.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15316
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15316: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15317
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15317: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15318: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15319: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15320: Dma_PatchSrc (.L__pc.15320.LD), (.L__movme_tmp.1), (.L__pc.15320.LD)
	.p2align 4
	.L__pc.15320.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15321
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15321: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15322
	
	.L__pc.15322: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15323
	
	.p2align 4
	.L__pc.15323: Dma_PatchDst (.L__pc.15323.ST), (.L__movme_cp.67), (.L__pc.15323.ST)
	.L__pc.15323.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15324
	
	.L__pc.15324: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15325
	
	.p2align 4
	.L__pc.15325: Dma_PatchDst (.L__pc.15325.ST), (.L__movme_cp.24), (.L__pc.15325.ST)
	.L__pc.15325.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15326
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15326: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15327
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15327: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15328
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15328: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15329
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15329: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15330
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.15330: Dma_PatchSrc (.L__pc.15330.LD), (.L__movme_cp.68), (.L__pc.15330.LD)
	.p2align 4
	.L__pc.15330.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15331
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15331: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15332
	.L__pc.15332: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15333
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15333: Dma_PatchSrc (.L__pc.15333.LD), (.L__movme_cp.24), (.L__pc.15333.LD)
	.p2align 4
	.L__pc.15333.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15334
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15334: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15335
	.L__pc.15335: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15336
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15336: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15337: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15338: Dma_PatchSrc (.L__pc.15338.LD), (.L__movme_tmp.1), (.L__pc.15338.LD)
	.p2align 4
	.L__pc.15338.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15339
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15339: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15340
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15340: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15341: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15342: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15343: Dma_PatchSrc (.L__pc.15343.LD), (.L__movme_tmp.1), (.L__pc.15343.LD)
	.p2align 4
	.L__pc.15343.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15344
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15344: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15345
	
	.L__pc.15345: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15346
	
	.p2align 4
	.L__pc.15346: Dma_PatchDst (.L__pc.15346.ST), (.L__movme_cp.68), (.L__pc.15346.ST)
	.L__pc.15346.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15347
	
	.L__pc.15347: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15348
	
	.p2align 4
	.L__pc.15348: Dma_PatchDst (.L__pc.15348.ST), (.L__movme_cp.24), (.L__pc.15348.ST)
	.L__pc.15348.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15349
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15349: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15350
	
	.p2align 4
	.L__pc.15350: Dma_PatchDst (.L__pc.15350.ST), (.L__movme_cp.24), (.L__pc.15350.ST)
	.L__pc.15350.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15351
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.15351: Dma_PatchSrc (.L__pc.15351.LD), (.L__movme_cp.60), (.L__pc.15351.LD)
	.p2align 4
	.L__pc.15351.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15352
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15352: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15353
	
	.L__pc.15353: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15354
	
	.p2align 4
	.L__pc.15354: Dma_PatchDst (.L__pc.15354.ST), (.L__movme_cp.21), (.L__pc.15354.ST)
	.L__pc.15354.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15355
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.15355: Dma_PatchSrc (.L__pc.15355.LD), (.L__movme_cp.58), (.L__pc.15355.LD)
	.p2align 4
	.L__pc.15355.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15356
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15356: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15357
	
	.L__pc.15357: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15358
	
	.p2align 4
	.L__pc.15358: Dma_PatchDst (.L__pc.15358.ST), (.L__movme_cp.22), (.L__pc.15358.ST)
	.L__pc.15358.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15359
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15359: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15360
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15360: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15361
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15361: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15362
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15362: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15363
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.15363: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.15364
	
	.p2align 4
	.L__pc.15364: Dma_PatchDst (.L__pc.15364.ST), (.L__movme_cp.24), (.L__pc.15364.ST)
	.L__pc.15364.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15365
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.15365: Dma_PatchSrc (.L__pc.15365.LD), (.L__movme_cp.25), (.L__pc.15365.LD)
	.p2align 4
	.L__pc.15365.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15366
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15366: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15367
	.L__pc.15367: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15368
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.15368: Dma_PatchSrc (.L__pc.15368.LD), (.L__movme_cp.26), (.L__pc.15368.LD)
	.p2align 4
	.L__pc.15368.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15369
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15369: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15370
	.L__pc.15370: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15371
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15371: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15372: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15373: Dma_PatchSrc (.L__pc.15373.LD), (.L__movme_tmp.1), (.L__pc.15373.LD)
	.p2align 4
	.L__pc.15373.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15374
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15374: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15375
	.L__pc.15375: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15376
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15376: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15377: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15378: Dma_PatchSrc (.L__pc.15378.LD), (.L__movme_tmp.1), (.L__pc.15378.LD)
	.p2align 4
	.L__pc.15378.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15379
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15379: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15380
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15380: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15381: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15382: Dma_PatchSrc (.L__pc.15382.LD), (.L__movme_tmp.1), (.L__pc.15382.LD)
	.p2align 4
	.L__pc.15382.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15383
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15383: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15384
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15384: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15385: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15386: Dma_PatchSrc (.L__pc.15386.LD), (.L__movme_tmp.1), (.L__pc.15386.LD)
	.p2align 4
	.L__pc.15386.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15387
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15387: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15388
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15388: Dma_PatchSrc (.L__pc.15388.LD), (.L__movme_cp.24), (.L__pc.15388.LD)
	.p2align 4
	.L__pc.15388.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15389
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15389: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15390
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15390: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15391: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15392: Dma_PatchSrc (.L__pc.15392.LD), (.L__movme_tmp.1), (.L__pc.15392.LD)
	.p2align 4
	.L__pc.15392.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15393
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15393: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15394
	
	.L__pc.15394: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15395
	
	.p2align 4
	.L__pc.15395: Dma_PatchDst (.L__pc.15395.ST), (.L__movme_cp.69), (.L__pc.15395.ST)
	.L__pc.15395.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15396
	
	.L__pc.15396: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15397
	
	.p2align 4
	.L__pc.15397: Dma_PatchDst (.L__pc.15397.ST), (.L__movme_cp.54), (.L__pc.15397.ST)
	.L__pc.15397.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15398
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.15398: Dma_PatchSrc (.L__pc.15398.LD), (.L__movme_cp.30), (.L__pc.15398.LD)
	.p2align 4
	.L__pc.15398.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15399
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15399: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15400
	.L__pc.15400: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15401
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.15401: Dma_PatchSrc (.L__pc.15401.LD), (.L__movme_cp.31), (.L__pc.15401.LD)
	.p2align 4
	.L__pc.15401.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15402
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15402: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15403
	.L__pc.15403: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15404
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15404: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15405: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15406: Dma_PatchSrc (.L__pc.15406.LD), (.L__movme_tmp.1), (.L__pc.15406.LD)
	.p2align 4
	.L__pc.15406.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15407
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15407: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15408
	.L__pc.15408: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15409
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15409: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15410: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15411: Dma_PatchSrc (.L__pc.15411.LD), (.L__movme_tmp.1), (.L__pc.15411.LD)
	.p2align 4
	.L__pc.15411.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15412
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15412: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15413
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15413: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15414: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15415: Dma_PatchSrc (.L__pc.15415.LD), (.L__movme_tmp.1), (.L__pc.15415.LD)
	.p2align 4
	.L__pc.15415.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15416
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15416: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15417
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15417: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15418: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15419: Dma_PatchSrc (.L__pc.15419.LD), (.L__movme_tmp.1), (.L__pc.15419.LD)
	.p2align 4
	.L__pc.15419.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15420
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15420: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15421
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15421: Dma_PatchSrc (.L__pc.15421.LD), (.L__movme_cp.24), (.L__pc.15421.LD)
	.p2align 4
	.L__pc.15421.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15422
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15422: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15423
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15423: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15424: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15425: Dma_PatchSrc (.L__pc.15425.LD), (.L__movme_tmp.1), (.L__pc.15425.LD)
	.p2align 4
	.L__pc.15425.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15426
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15426: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15427
	
	.L__pc.15427: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15428
	
	.p2align 4
	.L__pc.15428: Dma_PatchDst (.L__pc.15428.ST), (.L__movme_cp.70), (.L__pc.15428.ST)
	.L__pc.15428.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15429
	
	.L__pc.15429: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15430
	
	.p2align 4
	.L__pc.15430: Dma_PatchDst (.L__pc.15430.ST), (.L__movme_cp.54), (.L__pc.15430.ST)
	.L__pc.15430.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15431
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15431: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15432
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15432: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15433
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15433: Dma_PatchSrc (.L__pc.15433.LD), (.L__movme_cp.24), (.L__pc.15433.LD)
	.p2align 4
	.L__pc.15433.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15434
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15434: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15435
	.L__pc.15435: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15436
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.15436: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15437: Dma_PatchSrc (.L__pc.15437.LD), (.L__movme_tmp.1), (.L__pc.15437.LD)
	.p2align 4
	.L__pc.15437.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15438
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15438: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15439
	.L__pc.15439: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15440
	
	.L__pc.15440: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15441
	
	.p2align 4
	.L__pc.15441: Dma_PatchDst (.L__pc.15441.ST), (.L__movme_cp.72), (.L__pc.15441.ST)
	.L__pc.15441.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15442
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.15442: Dma_PatchSrc (.L__pc.15442.LD), (.L__movme_cp.72), (.L__pc.15442.LD)
	.p2align 4
	.L__pc.15442.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15443
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15443: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15444
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15444: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15445: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15446: Dma_PatchSrc (.L__pc.15446.LD), (.L__movme_tmp.1), (.L__pc.15446.LD)
	.p2align 4
	.L__pc.15446.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15447
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15447: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15448
	
	.L__pc.15448: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15449
	
	.p2align 4
	.L__pc.15449: Dma_PatchDst (.L__pc.15449.ST), (.L__movme_cp.74), (.L__pc.15449.ST)
	.L__pc.15449.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15450
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15450: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15451: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15452: Dma_PatchSrc (.L__pc.15452.LD), (.L__movme_tmp.1), (.L__pc.15452.LD)
	.p2align 4
	.L__pc.15452.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15453
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15453: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15454
	
	.L__pc.15454: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15455
	
	.p2align 4
	.L__pc.15455: Dma_PatchDst (.L__pc.15455.ST), (.L__movme_cp.76), (.L__pc.15455.ST)
	.L__pc.15455.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15456
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.15456: Dma_PatchSrc (.L__pc.15456.LD), (.L__movme_cp.74), (.L__pc.15456.LD)
	.p2align 4
	.L__pc.15456.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15457
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15457: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15458
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.15458: Dma_PatchSrc (.L__pc.15458.LD), ((.L__movme.reg.eax+0)), (.L__pc.15458.LD)
	.p2align 4
	.L__pc.15458.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15459
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15459: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15460
	
	.L__pc.15460: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15461
	
	.p2align 4
	.L__pc.15461: Dma_PatchDst (.L__pc.15461.ST), (.L__movme_cp.77), (.L__pc.15461.ST)
	.L__pc.15461.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15462
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.15462: Dma_PatchSrc (.L__pc.15462.LD), (.L__movme_cp.77), (.L__pc.15462.LD)
	.p2align 4
	.L__pc.15462.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15463
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15463: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15464
	
	.L__pc.15464: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15465
	
	.p2align 4
	.L__pc.15465: Dma_PatchDst (.L__pc.15465.ST), (.L__movme_cp.21), (.L__pc.15465.ST)
	.L__pc.15465.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15466
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.15466: Dma_PatchSrc (.L__pc.15466.LD), (.L__movme_cp.58), (.L__pc.15466.LD)
	.p2align 4
	.L__pc.15466.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15467
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15467: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15468
	
	.L__pc.15468: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15469
	
	.p2align 4
	.L__pc.15469: Dma_PatchDst (.L__pc.15469.ST), (.L__movme_cp.22), (.L__pc.15469.ST)
	.L__pc.15469.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15470
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15470: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15471
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15471: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15472
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15472: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15473
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15473: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15474
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.15474: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.15475
	
	.p2align 4
	.L__pc.15475: Dma_PatchDst (.L__pc.15475.ST), (.L__movme_cp.24), (.L__pc.15475.ST)
	.L__pc.15475.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15476
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.15476: Dma_PatchSrc (.L__pc.15476.LD), (.L__movme_cp.25), (.L__pc.15476.LD)
	.p2align 4
	.L__pc.15476.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15477
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15477: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15478
	.L__pc.15478: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15479
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.15479: Dma_PatchSrc (.L__pc.15479.LD), (.L__movme_cp.26), (.L__pc.15479.LD)
	.p2align 4
	.L__pc.15479.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15480
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15480: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15481
	.L__pc.15481: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15482
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15482: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15483: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15484: Dma_PatchSrc (.L__pc.15484.LD), (.L__movme_tmp.1), (.L__pc.15484.LD)
	.p2align 4
	.L__pc.15484.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15485
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15485: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15486
	.L__pc.15486: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15487
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15487: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15488: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15489: Dma_PatchSrc (.L__pc.15489.LD), (.L__movme_tmp.1), (.L__pc.15489.LD)
	.p2align 4
	.L__pc.15489.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15490
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15490: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15491
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15491: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15492: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15493: Dma_PatchSrc (.L__pc.15493.LD), (.L__movme_tmp.1), (.L__pc.15493.LD)
	.p2align 4
	.L__pc.15493.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15494
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15494: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15495
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15495: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15496: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15497: Dma_PatchSrc (.L__pc.15497.LD), (.L__movme_tmp.1), (.L__pc.15497.LD)
	.p2align 4
	.L__pc.15497.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15498
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15498: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15499
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15499: Dma_PatchSrc (.L__pc.15499.LD), (.L__movme_cp.24), (.L__pc.15499.LD)
	.p2align 4
	.L__pc.15499.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15500
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15500: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15501
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15501: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15502: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15503: Dma_PatchSrc (.L__pc.15503.LD), (.L__movme_tmp.1), (.L__pc.15503.LD)
	.p2align 4
	.L__pc.15503.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15504
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15504: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15505
	
	.L__pc.15505: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15506
	
	.p2align 4
	.L__pc.15506: Dma_PatchDst (.L__pc.15506.ST), (.L__movme_cp.78), (.L__pc.15506.ST)
	.L__pc.15506.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15507
	
	.L__pc.15507: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15508
	
	.p2align 4
	.L__pc.15508: Dma_PatchDst (.L__pc.15508.ST), (.L__movme_cp.54), (.L__pc.15508.ST)
	.L__pc.15508.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15509
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.15509: Dma_PatchSrc (.L__pc.15509.LD), (.L__movme_cp.30), (.L__pc.15509.LD)
	.p2align 4
	.L__pc.15509.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15510
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15510: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15511
	.L__pc.15511: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15512
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.15512: Dma_PatchSrc (.L__pc.15512.LD), (.L__movme_cp.31), (.L__pc.15512.LD)
	.p2align 4
	.L__pc.15512.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15513
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15513: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15514
	.L__pc.15514: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15515
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15515: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15516: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15517: Dma_PatchSrc (.L__pc.15517.LD), (.L__movme_tmp.1), (.L__pc.15517.LD)
	.p2align 4
	.L__pc.15517.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15518
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15518: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15519
	.L__pc.15519: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15520
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15520: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15521: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15522: Dma_PatchSrc (.L__pc.15522.LD), (.L__movme_tmp.1), (.L__pc.15522.LD)
	.p2align 4
	.L__pc.15522.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15523
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15523: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15524
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15524: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15525: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15526: Dma_PatchSrc (.L__pc.15526.LD), (.L__movme_tmp.1), (.L__pc.15526.LD)
	.p2align 4
	.L__pc.15526.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15527
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15527: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15528
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15528: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15529: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15530: Dma_PatchSrc (.L__pc.15530.LD), (.L__movme_tmp.1), (.L__pc.15530.LD)
	.p2align 4
	.L__pc.15530.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15531
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15531: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15532
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15532: Dma_PatchSrc (.L__pc.15532.LD), (.L__movme_cp.24), (.L__pc.15532.LD)
	.p2align 4
	.L__pc.15532.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15533
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15533: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15534
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15534: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15535: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15536: Dma_PatchSrc (.L__pc.15536.LD), (.L__movme_tmp.1), (.L__pc.15536.LD)
	.p2align 4
	.L__pc.15536.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15537
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15537: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15538
	
	.L__pc.15538: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15539
	
	.p2align 4
	.L__pc.15539: Dma_PatchDst (.L__pc.15539.ST), (.L__movme_cp.79), (.L__pc.15539.ST)
	.L__pc.15539.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15540
	
	.L__pc.15540: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15541
	
	.p2align 4
	.L__pc.15541: Dma_PatchDst (.L__pc.15541.ST), (.L__movme_cp.54), (.L__pc.15541.ST)
	.L__pc.15541.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15542
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.15542: Dma_PatchSrc (.L__pc.15542.LD), (.L__movme_cp.74), (.L__pc.15542.LD)
	.p2align 4
	.L__pc.15542.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15543
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15543: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15544
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.15544: Dma_PatchSrc (.L__pc.15544.LD), (.L__movme_cp.77), (.L__pc.15544.LD)
	.p2align 4
	.L__pc.15544.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15545
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15545: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15546
	
	.L__pc.15546: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15547
	
	.p2align 4
	.L__pc.15547: Dma_PatchDst (.L__pc.15547.ST), ((.L__movme.reg.eax+0)), (.L__pc.15547.ST)
	.L__pc.15547.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15548
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.15548: Dma_PatchSrc (.L__pc.15548.LD), (.L__movme_cp.76), (.L__pc.15548.LD)
	.p2align 4
	.L__pc.15548.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15549
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15549: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15550
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.15550: Dma_PatchSrc (.L__pc.15550.LD), ((.L__movme.reg.eax+0)), (.L__pc.15550.LD)
	.p2align 4
	.L__pc.15550.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15551
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15551: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15552
	
	.L__pc.15552: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15553
	
	.p2align 4
	.L__pc.15553: Dma_PatchDst (.L__pc.15553.ST), (.L__movme_cp.80), (.L__pc.15553.ST)
	.L__pc.15553.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15554
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15554: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15555
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15555: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15556
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.15556: Dma_PatchSrc (.L__pc.15556.LD), (.L__movme_cp.98), (.L__pc.15556.LD)
	.p2align 4
	.L__pc.15556.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15557
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15557: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15558
	.L__pc.15558: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15559
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.82 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.15559: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15560: Dma_PatchSrc (.L__pc.15560.LD), (.L__movme_tmp.1), (.L__pc.15560.LD)
	.p2align 4
	.L__pc.15560.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15561
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15561: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15562
	.L__pc.15562: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15563
	
	.L__pc.15563: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15564
	
	.p2align 4
	.L__pc.15564: Dma_PatchDst (.L__pc.15564.ST), (.L__movme_cp.98), (.L__pc.15564.ST)
	.L__pc.15564.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15565
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.15565: Dma_PatchSrc (.L__pc.15565.LD), (.L__movme_cp.76), (.L__pc.15565.LD)
	.p2align 4
	.L__pc.15565.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15566
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15566: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15567
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.15567: Dma_PatchSrc (.L__pc.15567.LD), (.L__movme_cp.80), (.L__pc.15567.LD)
	.p2align 4
	.L__pc.15567.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15568
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15568: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15569
	
	.L__pc.15569: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15570
	
	.p2align 4
	.L__pc.15570: Dma_PatchDst (.L__pc.15570.ST), ((.L__movme.reg.eax+0)), (.L__pc.15570.ST)
	.L__pc.15570.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15571
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15571: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15572
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15572: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15573
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.15573: Dma_PatchSrc (.L__pc.15573.LD), (.L__movme_cp.97), (.L__pc.15573.LD)
	.p2align 4
	.L__pc.15573.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15574
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15574: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15575
	.L__pc.15575: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15576
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15576: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.83 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15577: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15578: Dma_PatchSrc (.L__pc.15578.LD), (.L__movme_tmp.1), (.L__pc.15578.LD)
	.p2align 4
	.L__pc.15578.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15579
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15579: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15580
	
	.L__pc.15580: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15581
	
	.p2align 4
	.L__pc.15581: Dma_PatchDst (.L__pc.15581.ST), (.L__movme_cp.24), (.L__pc.15581.ST)
	.L__pc.15581.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15582
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15582: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15583
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15583: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15584
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15584: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15585
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15585: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15586
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.15586: Dma_PatchSrc (.L__pc.15586.LD), (.L__movme_cp.63), (.L__pc.15586.LD)
	.p2align 4
	.L__pc.15586.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15587
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15587: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15588
	.L__pc.15588: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15589
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15589: Dma_PatchSrc (.L__pc.15589.LD), (.L__movme_cp.24), (.L__pc.15589.LD)
	.p2align 4
	.L__pc.15589.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15590
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15590: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15591
	.L__pc.15591: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15592
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15592: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15593: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15594: Dma_PatchSrc (.L__pc.15594.LD), (.L__movme_tmp.1), (.L__pc.15594.LD)
	.p2align 4
	.L__pc.15594.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15595
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15595: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15596
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15596: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15597: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15598: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15599: Dma_PatchSrc (.L__pc.15599.LD), (.L__movme_tmp.1), (.L__pc.15599.LD)
	.p2align 4
	.L__pc.15599.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15600
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15600: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15601
	
	.L__pc.15601: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15602
	
	.p2align 4
	.L__pc.15602: Dma_PatchDst (.L__pc.15602.ST), (.L__movme_cp.63), (.L__pc.15602.ST)
	.L__pc.15602.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15603
	
	.L__pc.15603: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15604
	
	.p2align 4
	.L__pc.15604: Dma_PatchDst (.L__pc.15604.ST), (.L__movme_cp.24), (.L__pc.15604.ST)
	.L__pc.15604.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15605
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15605: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15606
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15606: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15607
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15607: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15608
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15608: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15609
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.15609: Dma_PatchSrc (.L__pc.15609.LD), (.L__movme_cp.66), (.L__pc.15609.LD)
	.p2align 4
	.L__pc.15609.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15610
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15610: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15611
	.L__pc.15611: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15612
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15612: Dma_PatchSrc (.L__pc.15612.LD), (.L__movme_cp.24), (.L__pc.15612.LD)
	.p2align 4
	.L__pc.15612.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15613
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15613: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15614
	.L__pc.15614: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15615
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15615: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15616: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15617: Dma_PatchSrc (.L__pc.15617.LD), (.L__movme_tmp.1), (.L__pc.15617.LD)
	.p2align 4
	.L__pc.15617.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15618
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15618: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15619
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15619: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15620: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15621: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15622: Dma_PatchSrc (.L__pc.15622.LD), (.L__movme_tmp.1), (.L__pc.15622.LD)
	.p2align 4
	.L__pc.15622.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15623
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15623: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15624
	
	.L__pc.15624: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15625
	
	.p2align 4
	.L__pc.15625: Dma_PatchDst (.L__pc.15625.ST), (.L__movme_cp.66), (.L__pc.15625.ST)
	.L__pc.15625.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15626
	
	.L__pc.15626: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15627
	
	.p2align 4
	.L__pc.15627: Dma_PatchDst (.L__pc.15627.ST), (.L__movme_cp.24), (.L__pc.15627.ST)
	.L__pc.15627.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15628
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15628: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15629
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15629: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15630
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15630: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15631
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15631: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15632
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.15632: Dma_PatchSrc (.L__pc.15632.LD), (.L__movme_cp.67), (.L__pc.15632.LD)
	.p2align 4
	.L__pc.15632.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15633
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15633: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15634
	.L__pc.15634: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15635
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15635: Dma_PatchSrc (.L__pc.15635.LD), (.L__movme_cp.24), (.L__pc.15635.LD)
	.p2align 4
	.L__pc.15635.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15636
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15636: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15637
	.L__pc.15637: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15638
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15638: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15639: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15640: Dma_PatchSrc (.L__pc.15640.LD), (.L__movme_tmp.1), (.L__pc.15640.LD)
	.p2align 4
	.L__pc.15640.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15641
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15641: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15642
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15642: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15643: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15644: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15645: Dma_PatchSrc (.L__pc.15645.LD), (.L__movme_tmp.1), (.L__pc.15645.LD)
	.p2align 4
	.L__pc.15645.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15646
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15646: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15647
	
	.L__pc.15647: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15648
	
	.p2align 4
	.L__pc.15648: Dma_PatchDst (.L__pc.15648.ST), (.L__movme_cp.67), (.L__pc.15648.ST)
	.L__pc.15648.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15649
	
	.L__pc.15649: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15650
	
	.p2align 4
	.L__pc.15650: Dma_PatchDst (.L__pc.15650.ST), (.L__movme_cp.24), (.L__pc.15650.ST)
	.L__pc.15650.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15651
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15651: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15652
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15652: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15653
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15653: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15654
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15654: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15655
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.15655: Dma_PatchSrc (.L__pc.15655.LD), (.L__movme_cp.68), (.L__pc.15655.LD)
	.p2align 4
	.L__pc.15655.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15656
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15656: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15657
	.L__pc.15657: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15658
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15658: Dma_PatchSrc (.L__pc.15658.LD), (.L__movme_cp.24), (.L__pc.15658.LD)
	.p2align 4
	.L__pc.15658.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15659
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15659: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15660
	.L__pc.15660: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15661
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15661: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15662: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15663: Dma_PatchSrc (.L__pc.15663.LD), (.L__movme_tmp.1), (.L__pc.15663.LD)
	.p2align 4
	.L__pc.15663.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15664
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15664: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15665
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15665: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15666: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15667: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15668: Dma_PatchSrc (.L__pc.15668.LD), (.L__movme_tmp.1), (.L__pc.15668.LD)
	.p2align 4
	.L__pc.15668.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15669
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15669: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15670
	
	.L__pc.15670: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15671
	
	.p2align 4
	.L__pc.15671: Dma_PatchDst (.L__pc.15671.ST), (.L__movme_cp.68), (.L__pc.15671.ST)
	.L__pc.15671.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15672
	
	.L__pc.15672: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15673
	
	.p2align 4
	.L__pc.15673: Dma_PatchDst (.L__pc.15673.ST), (.L__movme_cp.24), (.L__pc.15673.ST)
	.L__pc.15673.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15674
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15674: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15675
	
	.p2align 4
	.L__pc.15675: Dma_PatchDst (.L__pc.15675.ST), (.L__movme_cp.24), (.L__pc.15675.ST)
	.L__pc.15675.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15676
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.15676: Dma_PatchSrc (.L__pc.15676.LD), (.L__movme_cp.60), (.L__pc.15676.LD)
	.p2align 4
	.L__pc.15676.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15677
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15677: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15678
	
	.L__pc.15678: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15679
	
	.p2align 4
	.L__pc.15679: Dma_PatchDst (.L__pc.15679.ST), (.L__movme_cp.21), (.L__pc.15679.ST)
	.L__pc.15679.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15680
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.15680: Dma_PatchSrc (.L__pc.15680.LD), (.L__movme_cp.58), (.L__pc.15680.LD)
	.p2align 4
	.L__pc.15680.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15681
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15681: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15682
	
	.L__pc.15682: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15683
	
	.p2align 4
	.L__pc.15683: Dma_PatchDst (.L__pc.15683.ST), (.L__movme_cp.22), (.L__pc.15683.ST)
	.L__pc.15683.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15684
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15684: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15685
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15685: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15686
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15686: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15687
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15687: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15688
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.15688: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.15689
	
	.p2align 4
	.L__pc.15689: Dma_PatchDst (.L__pc.15689.ST), (.L__movme_cp.24), (.L__pc.15689.ST)
	.L__pc.15689.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15690
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.15690: Dma_PatchSrc (.L__pc.15690.LD), (.L__movme_cp.25), (.L__pc.15690.LD)
	.p2align 4
	.L__pc.15690.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15691
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15691: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15692
	.L__pc.15692: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15693
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.15693: Dma_PatchSrc (.L__pc.15693.LD), (.L__movme_cp.26), (.L__pc.15693.LD)
	.p2align 4
	.L__pc.15693.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15694
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15694: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15695
	.L__pc.15695: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15696
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15696: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15697: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15698: Dma_PatchSrc (.L__pc.15698.LD), (.L__movme_tmp.1), (.L__pc.15698.LD)
	.p2align 4
	.L__pc.15698.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15699
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15699: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15700
	.L__pc.15700: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15701
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15701: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15702: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15703: Dma_PatchSrc (.L__pc.15703.LD), (.L__movme_tmp.1), (.L__pc.15703.LD)
	.p2align 4
	.L__pc.15703.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15704
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15704: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15705
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15705: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15706: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15707: Dma_PatchSrc (.L__pc.15707.LD), (.L__movme_tmp.1), (.L__pc.15707.LD)
	.p2align 4
	.L__pc.15707.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15708
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15708: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15709
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15709: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15710: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15711: Dma_PatchSrc (.L__pc.15711.LD), (.L__movme_tmp.1), (.L__pc.15711.LD)
	.p2align 4
	.L__pc.15711.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15712
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15712: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15713
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15713: Dma_PatchSrc (.L__pc.15713.LD), (.L__movme_cp.24), (.L__pc.15713.LD)
	.p2align 4
	.L__pc.15713.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15714
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15714: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15715
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15715: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15716: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15717: Dma_PatchSrc (.L__pc.15717.LD), (.L__movme_tmp.1), (.L__pc.15717.LD)
	.p2align 4
	.L__pc.15717.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15718
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15718: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15719
	
	.L__pc.15719: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15720
	
	.p2align 4
	.L__pc.15720: Dma_PatchDst (.L__pc.15720.ST), (.L__movme_cp.69), (.L__pc.15720.ST)
	.L__pc.15720.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15721
	
	.L__pc.15721: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15722
	
	.p2align 4
	.L__pc.15722: Dma_PatchDst (.L__pc.15722.ST), (.L__movme_cp.54), (.L__pc.15722.ST)
	.L__pc.15722.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15723
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.15723: Dma_PatchSrc (.L__pc.15723.LD), (.L__movme_cp.30), (.L__pc.15723.LD)
	.p2align 4
	.L__pc.15723.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15724
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15724: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15725
	.L__pc.15725: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15726
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.15726: Dma_PatchSrc (.L__pc.15726.LD), (.L__movme_cp.31), (.L__pc.15726.LD)
	.p2align 4
	.L__pc.15726.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15727
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15727: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15728
	.L__pc.15728: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15729
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15729: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15730: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15731: Dma_PatchSrc (.L__pc.15731.LD), (.L__movme_tmp.1), (.L__pc.15731.LD)
	.p2align 4
	.L__pc.15731.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15732
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15732: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15733
	.L__pc.15733: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15734
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15734: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15735: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15736: Dma_PatchSrc (.L__pc.15736.LD), (.L__movme_tmp.1), (.L__pc.15736.LD)
	.p2align 4
	.L__pc.15736.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15737
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15737: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15738
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15738: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15739: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15740: Dma_PatchSrc (.L__pc.15740.LD), (.L__movme_tmp.1), (.L__pc.15740.LD)
	.p2align 4
	.L__pc.15740.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15741
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15741: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15742
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15742: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15743: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15744: Dma_PatchSrc (.L__pc.15744.LD), (.L__movme_tmp.1), (.L__pc.15744.LD)
	.p2align 4
	.L__pc.15744.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15745
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15745: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15746
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15746: Dma_PatchSrc (.L__pc.15746.LD), (.L__movme_cp.24), (.L__pc.15746.LD)
	.p2align 4
	.L__pc.15746.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15747
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15747: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15748
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15748: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15749: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15750: Dma_PatchSrc (.L__pc.15750.LD), (.L__movme_tmp.1), (.L__pc.15750.LD)
	.p2align 4
	.L__pc.15750.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15751
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15751: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15752
	
	.L__pc.15752: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15753
	
	.p2align 4
	.L__pc.15753: Dma_PatchDst (.L__pc.15753.ST), (.L__movme_cp.70), (.L__pc.15753.ST)
	.L__pc.15753.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15754
	
	.L__pc.15754: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15755
	
	.p2align 4
	.L__pc.15755: Dma_PatchDst (.L__pc.15755.ST), (.L__movme_cp.54), (.L__pc.15755.ST)
	.L__pc.15755.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15756
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15756: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15757
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15757: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15758
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15758: Dma_PatchSrc (.L__pc.15758.LD), (.L__movme_cp.24), (.L__pc.15758.LD)
	.p2align 4
	.L__pc.15758.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15759
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15759: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15760
	.L__pc.15760: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15761
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.15761: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15762: Dma_PatchSrc (.L__pc.15762.LD), (.L__movme_tmp.1), (.L__pc.15762.LD)
	.p2align 4
	.L__pc.15762.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15763
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15763: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15764
	.L__pc.15764: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15765
	
	.L__pc.15765: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15766
	
	.p2align 4
	.L__pc.15766: Dma_PatchDst (.L__pc.15766.ST), (.L__movme_cp.72), (.L__pc.15766.ST)
	.L__pc.15766.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15767
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.15767: Dma_PatchSrc (.L__pc.15767.LD), (.L__movme_cp.72), (.L__pc.15767.LD)
	.p2align 4
	.L__pc.15767.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15768
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15768: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15769
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15769: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15770: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15771: Dma_PatchSrc (.L__pc.15771.LD), (.L__movme_tmp.1), (.L__pc.15771.LD)
	.p2align 4
	.L__pc.15771.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15772
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15772: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15773
	
	.L__pc.15773: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15774
	
	.p2align 4
	.L__pc.15774: Dma_PatchDst (.L__pc.15774.ST), (.L__movme_cp.74), (.L__pc.15774.ST)
	.L__pc.15774.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15775
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15775: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15776: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15777: Dma_PatchSrc (.L__pc.15777.LD), (.L__movme_tmp.1), (.L__pc.15777.LD)
	.p2align 4
	.L__pc.15777.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15778
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15778: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15779
	
	.L__pc.15779: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15780
	
	.p2align 4
	.L__pc.15780: Dma_PatchDst (.L__pc.15780.ST), (.L__movme_cp.76), (.L__pc.15780.ST)
	.L__pc.15780.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15781
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.15781: Dma_PatchSrc (.L__pc.15781.LD), (.L__movme_cp.74), (.L__pc.15781.LD)
	.p2align 4
	.L__pc.15781.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15782
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15782: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15783
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.15783: Dma_PatchSrc (.L__pc.15783.LD), ((.L__movme.reg.eax+0)), (.L__pc.15783.LD)
	.p2align 4
	.L__pc.15783.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15784
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15784: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15785
	
	.L__pc.15785: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15786
	
	.p2align 4
	.L__pc.15786: Dma_PatchDst (.L__pc.15786.ST), (.L__movme_cp.77), (.L__pc.15786.ST)
	.L__pc.15786.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15787
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.15787: Dma_PatchSrc (.L__pc.15787.LD), (.L__movme_cp.77), (.L__pc.15787.LD)
	.p2align 4
	.L__pc.15787.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15788
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15788: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15789
	
	.L__pc.15789: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15790
	
	.p2align 4
	.L__pc.15790: Dma_PatchDst (.L__pc.15790.ST), (.L__movme_cp.21), (.L__pc.15790.ST)
	.L__pc.15790.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15791
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.15791: Dma_PatchSrc (.L__pc.15791.LD), (.L__movme_cp.58), (.L__pc.15791.LD)
	.p2align 4
	.L__pc.15791.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15792
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15792: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15793
	
	.L__pc.15793: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15794
	
	.p2align 4
	.L__pc.15794: Dma_PatchDst (.L__pc.15794.ST), (.L__movme_cp.22), (.L__pc.15794.ST)
	.L__pc.15794.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15795
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15795: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15796
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15796: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15797
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15797: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15798
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15798: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15799
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.15799: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.15800
	
	.p2align 4
	.L__pc.15800: Dma_PatchDst (.L__pc.15800.ST), (.L__movme_cp.24), (.L__pc.15800.ST)
	.L__pc.15800.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15801
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.15801: Dma_PatchSrc (.L__pc.15801.LD), (.L__movme_cp.25), (.L__pc.15801.LD)
	.p2align 4
	.L__pc.15801.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15802
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15802: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15803
	.L__pc.15803: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15804
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.15804: Dma_PatchSrc (.L__pc.15804.LD), (.L__movme_cp.26), (.L__pc.15804.LD)
	.p2align 4
	.L__pc.15804.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15805
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15805: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15806
	.L__pc.15806: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15807
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15807: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15808: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15809: Dma_PatchSrc (.L__pc.15809.LD), (.L__movme_tmp.1), (.L__pc.15809.LD)
	.p2align 4
	.L__pc.15809.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15810
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15810: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15811
	.L__pc.15811: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15812
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15812: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15813: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15814: Dma_PatchSrc (.L__pc.15814.LD), (.L__movme_tmp.1), (.L__pc.15814.LD)
	.p2align 4
	.L__pc.15814.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15815
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15815: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15816
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15816: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15817: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15818: Dma_PatchSrc (.L__pc.15818.LD), (.L__movme_tmp.1), (.L__pc.15818.LD)
	.p2align 4
	.L__pc.15818.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15819
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15819: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15820
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15820: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15821: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15822: Dma_PatchSrc (.L__pc.15822.LD), (.L__movme_tmp.1), (.L__pc.15822.LD)
	.p2align 4
	.L__pc.15822.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15823
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15823: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15824
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15824: Dma_PatchSrc (.L__pc.15824.LD), (.L__movme_cp.24), (.L__pc.15824.LD)
	.p2align 4
	.L__pc.15824.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15825
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15825: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15826
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15826: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15827: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15828: Dma_PatchSrc (.L__pc.15828.LD), (.L__movme_tmp.1), (.L__pc.15828.LD)
	.p2align 4
	.L__pc.15828.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15829
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15829: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15830
	
	.L__pc.15830: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15831
	
	.p2align 4
	.L__pc.15831: Dma_PatchDst (.L__pc.15831.ST), (.L__movme_cp.78), (.L__pc.15831.ST)
	.L__pc.15831.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15832
	
	.L__pc.15832: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15833
	
	.p2align 4
	.L__pc.15833: Dma_PatchDst (.L__pc.15833.ST), (.L__movme_cp.54), (.L__pc.15833.ST)
	.L__pc.15833.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15834
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.15834: Dma_PatchSrc (.L__pc.15834.LD), (.L__movme_cp.30), (.L__pc.15834.LD)
	.p2align 4
	.L__pc.15834.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15835
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15835: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.15836
	.L__pc.15836: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.15837
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.15837: Dma_PatchSrc (.L__pc.15837.LD), (.L__movme_cp.31), (.L__pc.15837.LD)
	.p2align 4
	.L__pc.15837.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15838
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15838: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15839
	.L__pc.15839: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15840
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.15840: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15841: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15842: Dma_PatchSrc (.L__pc.15842.LD), (.L__movme_tmp.1), (.L__pc.15842.LD)
	.p2align 4
	.L__pc.15842.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15843
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15843: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.15844
	.L__pc.15844: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.15845
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15845: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15846: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15847: Dma_PatchSrc (.L__pc.15847.LD), (.L__movme_tmp.1), (.L__pc.15847.LD)
	.p2align 4
	.L__pc.15847.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15848
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15848: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15849
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15849: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15850: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15851: Dma_PatchSrc (.L__pc.15851.LD), (.L__movme_tmp.1), (.L__pc.15851.LD)
	.p2align 4
	.L__pc.15851.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15852
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15852: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15853
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15853: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15854: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15855: Dma_PatchSrc (.L__pc.15855.LD), (.L__movme_tmp.1), (.L__pc.15855.LD)
	.p2align 4
	.L__pc.15855.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15856
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15856: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15857
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15857: Dma_PatchSrc (.L__pc.15857.LD), (.L__movme_cp.24), (.L__pc.15857.LD)
	.p2align 4
	.L__pc.15857.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15858
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.15858: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.15859
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.15859: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15860: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15861: Dma_PatchSrc (.L__pc.15861.LD), (.L__movme_tmp.1), (.L__pc.15861.LD)
	.p2align 4
	.L__pc.15861.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15862
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15862: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15863
	
	.L__pc.15863: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.15864
	
	.p2align 4
	.L__pc.15864: Dma_PatchDst (.L__pc.15864.ST), (.L__movme_cp.79), (.L__pc.15864.ST)
	.L__pc.15864.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15865
	
	.L__pc.15865: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15866
	
	.p2align 4
	.L__pc.15866: Dma_PatchDst (.L__pc.15866.ST), (.L__movme_cp.54), (.L__pc.15866.ST)
	.L__pc.15866.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15867
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.15867: Dma_PatchSrc (.L__pc.15867.LD), (.L__movme_cp.74), (.L__pc.15867.LD)
	.p2align 4
	.L__pc.15867.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15868
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15868: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15869
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.15869: Dma_PatchSrc (.L__pc.15869.LD), (.L__movme_cp.77), (.L__pc.15869.LD)
	.p2align 4
	.L__pc.15869.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15870
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15870: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15871
	
	.L__pc.15871: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15872
	
	.p2align 4
	.L__pc.15872: Dma_PatchDst (.L__pc.15872.ST), ((.L__movme.reg.eax+0)), (.L__pc.15872.ST)
	.L__pc.15872.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15873
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.15873: Dma_PatchSrc (.L__pc.15873.LD), (.L__movme_cp.76), (.L__pc.15873.LD)
	.p2align 4
	.L__pc.15873.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15874
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15874: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15875
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.15875: Dma_PatchSrc (.L__pc.15875.LD), ((.L__movme.reg.eax+0)), (.L__pc.15875.LD)
	.p2align 4
	.L__pc.15875.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15876
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15876: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15877
	
	.L__pc.15877: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15878
	
	.p2align 4
	.L__pc.15878: Dma_PatchDst (.L__pc.15878.ST), (.L__movme_cp.80), (.L__pc.15878.ST)
	.L__pc.15878.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15879
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15879: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15880
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15880: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15881
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.15881: Dma_PatchSrc (.L__pc.15881.LD), (.L__movme_cp.98), (.L__pc.15881.LD)
	.p2align 4
	.L__pc.15881.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15882
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15882: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15883
	.L__pc.15883: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15884
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.84 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.15884: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15885: Dma_PatchSrc (.L__pc.15885.LD), (.L__movme_tmp.1), (.L__pc.15885.LD)
	.p2align 4
	.L__pc.15885.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15886
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15886: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15887
	.L__pc.15887: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15888
	
	.L__pc.15888: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15889
	
	.p2align 4
	.L__pc.15889: Dma_PatchDst (.L__pc.15889.ST), (.L__movme_cp.98), (.L__pc.15889.ST)
	.L__pc.15889.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15890
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.15890: Dma_PatchSrc (.L__pc.15890.LD), (.L__movme_cp.76), (.L__pc.15890.LD)
	.p2align 4
	.L__pc.15890.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15891
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15891: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15892
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.15892: Dma_PatchSrc (.L__pc.15892.LD), (.L__movme_cp.80), (.L__pc.15892.LD)
	.p2align 4
	.L__pc.15892.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15893
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15893: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15894
	
	.L__pc.15894: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.15895
	
	.p2align 4
	.L__pc.15895: Dma_PatchDst (.L__pc.15895.ST), ((.L__movme.reg.eax+0)), (.L__pc.15895.ST)
	.L__pc.15895.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15896
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15896: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15897
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15897: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15898
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.15898: Dma_PatchSrc (.L__pc.15898.LD), (.L__movme_cp.97), (.L__pc.15898.LD)
	.p2align 4
	.L__pc.15898.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15899
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15899: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15900
	.L__pc.15900: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15901
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.15901: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.85 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15902: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15903: Dma_PatchSrc (.L__pc.15903.LD), (.L__movme_tmp.1), (.L__pc.15903.LD)
	.p2align 4
	.L__pc.15903.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15904
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15904: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15905
	
	.L__pc.15905: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.15906
	
	.p2align 4
	.L__pc.15906: Dma_PatchDst (.L__pc.15906.ST), (.L__movme_cp.24), (.L__pc.15906.ST)
	.L__pc.15906.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15907
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15907: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15908
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15908: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15909
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15909: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15910
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15910: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15911
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.15911: Dma_PatchSrc (.L__pc.15911.LD), (.L__movme_cp.63), (.L__pc.15911.LD)
	.p2align 4
	.L__pc.15911.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15912
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15912: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15913
	.L__pc.15913: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15914
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15914: Dma_PatchSrc (.L__pc.15914.LD), (.L__movme_cp.24), (.L__pc.15914.LD)
	.p2align 4
	.L__pc.15914.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15915
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15915: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15916
	.L__pc.15916: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15917
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15917: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15918: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15919: Dma_PatchSrc (.L__pc.15919.LD), (.L__movme_tmp.1), (.L__pc.15919.LD)
	.p2align 4
	.L__pc.15919.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15920
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15920: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15921
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15921: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15922: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15923: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15924: Dma_PatchSrc (.L__pc.15924.LD), (.L__movme_tmp.1), (.L__pc.15924.LD)
	.p2align 4
	.L__pc.15924.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15925
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15925: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15926
	
	.L__pc.15926: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15927
	
	.p2align 4
	.L__pc.15927: Dma_PatchDst (.L__pc.15927.ST), (.L__movme_cp.63), (.L__pc.15927.ST)
	.L__pc.15927.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15928
	
	.L__pc.15928: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15929
	
	.p2align 4
	.L__pc.15929: Dma_PatchDst (.L__pc.15929.ST), (.L__movme_cp.24), (.L__pc.15929.ST)
	.L__pc.15929.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15930
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15930: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15931
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15931: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15932
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15932: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15933
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15933: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15934
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.15934: Dma_PatchSrc (.L__pc.15934.LD), (.L__movme_cp.66), (.L__pc.15934.LD)
	.p2align 4
	.L__pc.15934.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15935
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15935: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15936
	.L__pc.15936: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15937
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15937: Dma_PatchSrc (.L__pc.15937.LD), (.L__movme_cp.24), (.L__pc.15937.LD)
	.p2align 4
	.L__pc.15937.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15938
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15938: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15939
	.L__pc.15939: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15940
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15940: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15941: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15942: Dma_PatchSrc (.L__pc.15942.LD), (.L__movme_tmp.1), (.L__pc.15942.LD)
	.p2align 4
	.L__pc.15942.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15943
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15943: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15944
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15944: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15945: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15946: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15947: Dma_PatchSrc (.L__pc.15947.LD), (.L__movme_tmp.1), (.L__pc.15947.LD)
	.p2align 4
	.L__pc.15947.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15948
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15948: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15949
	
	.L__pc.15949: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15950
	
	.p2align 4
	.L__pc.15950: Dma_PatchDst (.L__pc.15950.ST), (.L__movme_cp.66), (.L__pc.15950.ST)
	.L__pc.15950.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15951
	
	.L__pc.15951: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15952
	
	.p2align 4
	.L__pc.15952: Dma_PatchDst (.L__pc.15952.ST), (.L__movme_cp.24), (.L__pc.15952.ST)
	.L__pc.15952.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15953
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15953: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15954
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15954: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15955
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15955: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15956
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15956: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15957
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.15957: Dma_PatchSrc (.L__pc.15957.LD), (.L__movme_cp.67), (.L__pc.15957.LD)
	.p2align 4
	.L__pc.15957.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15958
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15958: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15959
	.L__pc.15959: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15960
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15960: Dma_PatchSrc (.L__pc.15960.LD), (.L__movme_cp.24), (.L__pc.15960.LD)
	.p2align 4
	.L__pc.15960.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15961
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15961: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15962
	.L__pc.15962: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15963
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15963: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15964: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15965: Dma_PatchSrc (.L__pc.15965.LD), (.L__movme_tmp.1), (.L__pc.15965.LD)
	.p2align 4
	.L__pc.15965.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15966
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15966: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15967
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15967: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15968: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15969: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15970: Dma_PatchSrc (.L__pc.15970.LD), (.L__movme_tmp.1), (.L__pc.15970.LD)
	.p2align 4
	.L__pc.15970.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15971
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15971: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15972
	
	.L__pc.15972: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15973
	
	.p2align 4
	.L__pc.15973: Dma_PatchDst (.L__pc.15973.ST), (.L__movme_cp.67), (.L__pc.15973.ST)
	.L__pc.15973.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15974
	
	.L__pc.15974: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15975
	
	.p2align 4
	.L__pc.15975: Dma_PatchDst (.L__pc.15975.ST), (.L__movme_cp.24), (.L__pc.15975.ST)
	.L__pc.15975.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15976
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15976: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15977
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15977: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15978
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15978: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.15979
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15979: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.15980
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.15980: Dma_PatchSrc (.L__pc.15980.LD), (.L__movme_cp.68), (.L__pc.15980.LD)
	.p2align 4
	.L__pc.15980.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15981
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15981: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.15982
	.L__pc.15982: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.15983
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.15983: Dma_PatchSrc (.L__pc.15983.LD), (.L__movme_cp.24), (.L__pc.15983.LD)
	.p2align 4
	.L__pc.15983.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15984
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.15984: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.15985
	.L__pc.15985: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.15986
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.15986: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.15987: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15988: Dma_PatchSrc (.L__pc.15988.LD), (.L__movme_tmp.1), (.L__pc.15988.LD)
	.p2align 4
	.L__pc.15988.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15989
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15989: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15990
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.15990: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.15991: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.15992: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.15993: Dma_PatchSrc (.L__pc.15993.LD), (.L__movme_tmp.1), (.L__pc.15993.LD)
	.p2align 4
	.L__pc.15993.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.15994
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.15994: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.15995
	
	.L__pc.15995: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.15996
	
	.p2align 4
	.L__pc.15996: Dma_PatchDst (.L__pc.15996.ST), (.L__movme_cp.68), (.L__pc.15996.ST)
	.L__pc.15996.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15997
	
	.L__pc.15997: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.15998
	
	.p2align 4
	.L__pc.15998: Dma_PatchDst (.L__pc.15998.ST), (.L__movme_cp.24), (.L__pc.15998.ST)
	.L__pc.15998.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.15999
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.15999: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16000
	
	.p2align 4
	.L__pc.16000: Dma_PatchDst (.L__pc.16000.ST), (.L__movme_cp.24), (.L__pc.16000.ST)
	.L__pc.16000.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16001
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.16001: Dma_PatchSrc (.L__pc.16001.LD), (.L__movme_cp.60), (.L__pc.16001.LD)
	.p2align 4
	.L__pc.16001.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16002
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16002: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16003
	
	.L__pc.16003: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16004
	
	.p2align 4
	.L__pc.16004: Dma_PatchDst (.L__pc.16004.ST), (.L__movme_cp.21), (.L__pc.16004.ST)
	.L__pc.16004.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16005
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.16005: Dma_PatchSrc (.L__pc.16005.LD), (.L__movme_cp.58), (.L__pc.16005.LD)
	.p2align 4
	.L__pc.16005.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16006
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16006: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16007
	
	.L__pc.16007: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16008
	
	.p2align 4
	.L__pc.16008: Dma_PatchDst (.L__pc.16008.ST), (.L__movme_cp.22), (.L__pc.16008.ST)
	.L__pc.16008.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16009
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16009: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16010
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16010: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16011
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16011: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16012
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16012: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16013
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.16013: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.16014
	
	.p2align 4
	.L__pc.16014: Dma_PatchDst (.L__pc.16014.ST), (.L__movme_cp.24), (.L__pc.16014.ST)
	.L__pc.16014.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16015
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.16015: Dma_PatchSrc (.L__pc.16015.LD), (.L__movme_cp.25), (.L__pc.16015.LD)
	.p2align 4
	.L__pc.16015.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16016
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16016: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16017
	.L__pc.16017: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16018
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.16018: Dma_PatchSrc (.L__pc.16018.LD), (.L__movme_cp.26), (.L__pc.16018.LD)
	.p2align 4
	.L__pc.16018.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16019
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16019: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16020
	.L__pc.16020: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16021
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16021: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16022: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16023: Dma_PatchSrc (.L__pc.16023.LD), (.L__movme_tmp.1), (.L__pc.16023.LD)
	.p2align 4
	.L__pc.16023.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16024
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16024: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16025
	.L__pc.16025: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16026
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16026: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16027: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16028: Dma_PatchSrc (.L__pc.16028.LD), (.L__movme_tmp.1), (.L__pc.16028.LD)
	.p2align 4
	.L__pc.16028.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16029
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16029: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16030
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16030: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16031: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16032: Dma_PatchSrc (.L__pc.16032.LD), (.L__movme_tmp.1), (.L__pc.16032.LD)
	.p2align 4
	.L__pc.16032.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16033
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16033: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16034
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16034: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16035: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16036: Dma_PatchSrc (.L__pc.16036.LD), (.L__movme_tmp.1), (.L__pc.16036.LD)
	.p2align 4
	.L__pc.16036.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16037
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16037: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16038
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16038: Dma_PatchSrc (.L__pc.16038.LD), (.L__movme_cp.24), (.L__pc.16038.LD)
	.p2align 4
	.L__pc.16038.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16039
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16039: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16040
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16040: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16041: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16042: Dma_PatchSrc (.L__pc.16042.LD), (.L__movme_tmp.1), (.L__pc.16042.LD)
	.p2align 4
	.L__pc.16042.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16043
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16043: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16044
	
	.L__pc.16044: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16045
	
	.p2align 4
	.L__pc.16045: Dma_PatchDst (.L__pc.16045.ST), (.L__movme_cp.69), (.L__pc.16045.ST)
	.L__pc.16045.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16046
	
	.L__pc.16046: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16047
	
	.p2align 4
	.L__pc.16047: Dma_PatchDst (.L__pc.16047.ST), (.L__movme_cp.54), (.L__pc.16047.ST)
	.L__pc.16047.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16048
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.16048: Dma_PatchSrc (.L__pc.16048.LD), (.L__movme_cp.30), (.L__pc.16048.LD)
	.p2align 4
	.L__pc.16048.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16049
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16049: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16050
	.L__pc.16050: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16051
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.16051: Dma_PatchSrc (.L__pc.16051.LD), (.L__movme_cp.31), (.L__pc.16051.LD)
	.p2align 4
	.L__pc.16051.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16052
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16052: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16053
	.L__pc.16053: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16054
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16054: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16055: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16056: Dma_PatchSrc (.L__pc.16056.LD), (.L__movme_tmp.1), (.L__pc.16056.LD)
	.p2align 4
	.L__pc.16056.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16057
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16057: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16058
	.L__pc.16058: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16059
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16059: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16060: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16061: Dma_PatchSrc (.L__pc.16061.LD), (.L__movme_tmp.1), (.L__pc.16061.LD)
	.p2align 4
	.L__pc.16061.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16062
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16062: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16063
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16063: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16064: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16065: Dma_PatchSrc (.L__pc.16065.LD), (.L__movme_tmp.1), (.L__pc.16065.LD)
	.p2align 4
	.L__pc.16065.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16066
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16066: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16067
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16067: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16068: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16069: Dma_PatchSrc (.L__pc.16069.LD), (.L__movme_tmp.1), (.L__pc.16069.LD)
	.p2align 4
	.L__pc.16069.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16070
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16070: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16071
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16071: Dma_PatchSrc (.L__pc.16071.LD), (.L__movme_cp.24), (.L__pc.16071.LD)
	.p2align 4
	.L__pc.16071.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16072
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16072: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16073
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16073: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16074: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16075: Dma_PatchSrc (.L__pc.16075.LD), (.L__movme_tmp.1), (.L__pc.16075.LD)
	.p2align 4
	.L__pc.16075.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16076
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16076: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16077
	
	.L__pc.16077: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16078
	
	.p2align 4
	.L__pc.16078: Dma_PatchDst (.L__pc.16078.ST), (.L__movme_cp.70), (.L__pc.16078.ST)
	.L__pc.16078.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16079
	
	.L__pc.16079: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16080
	
	.p2align 4
	.L__pc.16080: Dma_PatchDst (.L__pc.16080.ST), (.L__movme_cp.54), (.L__pc.16080.ST)
	.L__pc.16080.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16081
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16081: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16082
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16082: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16083
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16083: Dma_PatchSrc (.L__pc.16083.LD), (.L__movme_cp.24), (.L__pc.16083.LD)
	.p2align 4
	.L__pc.16083.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16084
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16084: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16085
	.L__pc.16085: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16086
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.16086: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16087: Dma_PatchSrc (.L__pc.16087.LD), (.L__movme_tmp.1), (.L__pc.16087.LD)
	.p2align 4
	.L__pc.16087.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16088
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16088: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16089
	.L__pc.16089: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16090
	
	.L__pc.16090: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16091
	
	.p2align 4
	.L__pc.16091: Dma_PatchDst (.L__pc.16091.ST), (.L__movme_cp.72), (.L__pc.16091.ST)
	.L__pc.16091.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16092
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.16092: Dma_PatchSrc (.L__pc.16092.LD), (.L__movme_cp.72), (.L__pc.16092.LD)
	.p2align 4
	.L__pc.16092.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16093
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16093: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16094
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16094: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16095: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16096: Dma_PatchSrc (.L__pc.16096.LD), (.L__movme_tmp.1), (.L__pc.16096.LD)
	.p2align 4
	.L__pc.16096.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16097
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16097: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16098
	
	.L__pc.16098: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16099
	
	.p2align 4
	.L__pc.16099: Dma_PatchDst (.L__pc.16099.ST), (.L__movme_cp.74), (.L__pc.16099.ST)
	.L__pc.16099.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16100
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16100: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16101: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16102: Dma_PatchSrc (.L__pc.16102.LD), (.L__movme_tmp.1), (.L__pc.16102.LD)
	.p2align 4
	.L__pc.16102.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16103
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16103: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16104
	
	.L__pc.16104: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16105
	
	.p2align 4
	.L__pc.16105: Dma_PatchDst (.L__pc.16105.ST), (.L__movme_cp.76), (.L__pc.16105.ST)
	.L__pc.16105.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16106
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.16106: Dma_PatchSrc (.L__pc.16106.LD), (.L__movme_cp.74), (.L__pc.16106.LD)
	.p2align 4
	.L__pc.16106.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16107
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16107: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16108
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.16108: Dma_PatchSrc (.L__pc.16108.LD), ((.L__movme.reg.eax+0)), (.L__pc.16108.LD)
	.p2align 4
	.L__pc.16108.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16109
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16109: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16110
	
	.L__pc.16110: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16111
	
	.p2align 4
	.L__pc.16111: Dma_PatchDst (.L__pc.16111.ST), (.L__movme_cp.77), (.L__pc.16111.ST)
	.L__pc.16111.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16112
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.16112: Dma_PatchSrc (.L__pc.16112.LD), (.L__movme_cp.77), (.L__pc.16112.LD)
	.p2align 4
	.L__pc.16112.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16113
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16113: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16114
	
	.L__pc.16114: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16115
	
	.p2align 4
	.L__pc.16115: Dma_PatchDst (.L__pc.16115.ST), (.L__movme_cp.21), (.L__pc.16115.ST)
	.L__pc.16115.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16116
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.16116: Dma_PatchSrc (.L__pc.16116.LD), (.L__movme_cp.58), (.L__pc.16116.LD)
	.p2align 4
	.L__pc.16116.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16117
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16117: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16118
	
	.L__pc.16118: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16119
	
	.p2align 4
	.L__pc.16119: Dma_PatchDst (.L__pc.16119.ST), (.L__movme_cp.22), (.L__pc.16119.ST)
	.L__pc.16119.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16120
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16120: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16121
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16121: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16122
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16122: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16123
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16123: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16124
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.16124: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.16125
	
	.p2align 4
	.L__pc.16125: Dma_PatchDst (.L__pc.16125.ST), (.L__movme_cp.24), (.L__pc.16125.ST)
	.L__pc.16125.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16126
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.16126: Dma_PatchSrc (.L__pc.16126.LD), (.L__movme_cp.25), (.L__pc.16126.LD)
	.p2align 4
	.L__pc.16126.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16127
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16127: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16128
	.L__pc.16128: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16129
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.16129: Dma_PatchSrc (.L__pc.16129.LD), (.L__movme_cp.26), (.L__pc.16129.LD)
	.p2align 4
	.L__pc.16129.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16130
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16130: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16131
	.L__pc.16131: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16132
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16132: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16133: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16134: Dma_PatchSrc (.L__pc.16134.LD), (.L__movme_tmp.1), (.L__pc.16134.LD)
	.p2align 4
	.L__pc.16134.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16135
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16135: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16136
	.L__pc.16136: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16137
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16137: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16138: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16139: Dma_PatchSrc (.L__pc.16139.LD), (.L__movme_tmp.1), (.L__pc.16139.LD)
	.p2align 4
	.L__pc.16139.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16140
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16140: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16141
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16141: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16142: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16143: Dma_PatchSrc (.L__pc.16143.LD), (.L__movme_tmp.1), (.L__pc.16143.LD)
	.p2align 4
	.L__pc.16143.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16144
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16144: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16145
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16145: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16146: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16147: Dma_PatchSrc (.L__pc.16147.LD), (.L__movme_tmp.1), (.L__pc.16147.LD)
	.p2align 4
	.L__pc.16147.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16148
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16148: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16149
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16149: Dma_PatchSrc (.L__pc.16149.LD), (.L__movme_cp.24), (.L__pc.16149.LD)
	.p2align 4
	.L__pc.16149.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16150
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16150: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16151
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16151: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16152: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16153: Dma_PatchSrc (.L__pc.16153.LD), (.L__movme_tmp.1), (.L__pc.16153.LD)
	.p2align 4
	.L__pc.16153.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16154
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16154: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16155
	
	.L__pc.16155: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16156
	
	.p2align 4
	.L__pc.16156: Dma_PatchDst (.L__pc.16156.ST), (.L__movme_cp.78), (.L__pc.16156.ST)
	.L__pc.16156.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16157
	
	.L__pc.16157: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16158
	
	.p2align 4
	.L__pc.16158: Dma_PatchDst (.L__pc.16158.ST), (.L__movme_cp.54), (.L__pc.16158.ST)
	.L__pc.16158.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16159
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.16159: Dma_PatchSrc (.L__pc.16159.LD), (.L__movme_cp.30), (.L__pc.16159.LD)
	.p2align 4
	.L__pc.16159.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16160
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16160: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16161
	.L__pc.16161: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16162
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.16162: Dma_PatchSrc (.L__pc.16162.LD), (.L__movme_cp.31), (.L__pc.16162.LD)
	.p2align 4
	.L__pc.16162.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16163
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16163: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16164
	.L__pc.16164: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16165
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16165: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16166: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16167: Dma_PatchSrc (.L__pc.16167.LD), (.L__movme_tmp.1), (.L__pc.16167.LD)
	.p2align 4
	.L__pc.16167.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16168
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16168: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16169
	.L__pc.16169: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16170
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16170: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16171: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16172: Dma_PatchSrc (.L__pc.16172.LD), (.L__movme_tmp.1), (.L__pc.16172.LD)
	.p2align 4
	.L__pc.16172.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16173
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16173: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16174
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16174: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16175: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16176: Dma_PatchSrc (.L__pc.16176.LD), (.L__movme_tmp.1), (.L__pc.16176.LD)
	.p2align 4
	.L__pc.16176.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16177
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16177: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16178
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16178: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16179: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16180: Dma_PatchSrc (.L__pc.16180.LD), (.L__movme_tmp.1), (.L__pc.16180.LD)
	.p2align 4
	.L__pc.16180.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16181
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16181: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16182
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16182: Dma_PatchSrc (.L__pc.16182.LD), (.L__movme_cp.24), (.L__pc.16182.LD)
	.p2align 4
	.L__pc.16182.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16183
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16183: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16184
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16184: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16185: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16186: Dma_PatchSrc (.L__pc.16186.LD), (.L__movme_tmp.1), (.L__pc.16186.LD)
	.p2align 4
	.L__pc.16186.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16187
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16187: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16188
	
	.L__pc.16188: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16189
	
	.p2align 4
	.L__pc.16189: Dma_PatchDst (.L__pc.16189.ST), (.L__movme_cp.79), (.L__pc.16189.ST)
	.L__pc.16189.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16190
	
	.L__pc.16190: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16191
	
	.p2align 4
	.L__pc.16191: Dma_PatchDst (.L__pc.16191.ST), (.L__movme_cp.54), (.L__pc.16191.ST)
	.L__pc.16191.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16192
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.16192: Dma_PatchSrc (.L__pc.16192.LD), (.L__movme_cp.74), (.L__pc.16192.LD)
	.p2align 4
	.L__pc.16192.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16193
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16193: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16194
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.16194: Dma_PatchSrc (.L__pc.16194.LD), (.L__movme_cp.77), (.L__pc.16194.LD)
	.p2align 4
	.L__pc.16194.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16195
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16195: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16196
	
	.L__pc.16196: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16197
	
	.p2align 4
	.L__pc.16197: Dma_PatchDst (.L__pc.16197.ST), ((.L__movme.reg.eax+0)), (.L__pc.16197.ST)
	.L__pc.16197.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16198
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.16198: Dma_PatchSrc (.L__pc.16198.LD), (.L__movme_cp.76), (.L__pc.16198.LD)
	.p2align 4
	.L__pc.16198.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16199
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16199: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16200
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.16200: Dma_PatchSrc (.L__pc.16200.LD), ((.L__movme.reg.eax+0)), (.L__pc.16200.LD)
	.p2align 4
	.L__pc.16200.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16201
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16201: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16202
	
	.L__pc.16202: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16203
	
	.p2align 4
	.L__pc.16203: Dma_PatchDst (.L__pc.16203.ST), (.L__movme_cp.80), (.L__pc.16203.ST)
	.L__pc.16203.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16204
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16204: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16205
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16205: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16206
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.16206: Dma_PatchSrc (.L__pc.16206.LD), (.L__movme_cp.98), (.L__pc.16206.LD)
	.p2align 4
	.L__pc.16206.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16207
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16207: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16208
	.L__pc.16208: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16209
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.86 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.16209: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16210: Dma_PatchSrc (.L__pc.16210.LD), (.L__movme_tmp.1), (.L__pc.16210.LD)
	.p2align 4
	.L__pc.16210.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16211
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16211: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16212
	.L__pc.16212: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16213
	
	.L__pc.16213: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16214
	
	.p2align 4
	.L__pc.16214: Dma_PatchDst (.L__pc.16214.ST), (.L__movme_cp.98), (.L__pc.16214.ST)
	.L__pc.16214.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16215
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.16215: Dma_PatchSrc (.L__pc.16215.LD), (.L__movme_cp.76), (.L__pc.16215.LD)
	.p2align 4
	.L__pc.16215.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16216
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16216: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16217
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.16217: Dma_PatchSrc (.L__pc.16217.LD), (.L__movme_cp.80), (.L__pc.16217.LD)
	.p2align 4
	.L__pc.16217.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16218
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16218: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16219
	
	.L__pc.16219: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16220
	
	.p2align 4
	.L__pc.16220: Dma_PatchDst (.L__pc.16220.ST), ((.L__movme.reg.eax+0)), (.L__pc.16220.ST)
	.L__pc.16220.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16221
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16221: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16222
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16222: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16223
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.16223: Dma_PatchSrc (.L__pc.16223.LD), (.L__movme_cp.97), (.L__pc.16223.LD)
	.p2align 4
	.L__pc.16223.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16224
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16224: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16225
	.L__pc.16225: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16226
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16226: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.87 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16227: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16228: Dma_PatchSrc (.L__pc.16228.LD), (.L__movme_tmp.1), (.L__pc.16228.LD)
	.p2align 4
	.L__pc.16228.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16229
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16229: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16230
	
	.L__pc.16230: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16231
	
	.p2align 4
	.L__pc.16231: Dma_PatchDst (.L__pc.16231.ST), (.L__movme_cp.24), (.L__pc.16231.ST)
	.L__pc.16231.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16232
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16232: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16233
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16233: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16234
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16234: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16235
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16235: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16236
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.16236: Dma_PatchSrc (.L__pc.16236.LD), (.L__movme_cp.63), (.L__pc.16236.LD)
	.p2align 4
	.L__pc.16236.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16237
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16237: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16238
	.L__pc.16238: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16239
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16239: Dma_PatchSrc (.L__pc.16239.LD), (.L__movme_cp.24), (.L__pc.16239.LD)
	.p2align 4
	.L__pc.16239.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16240
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16240: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16241
	.L__pc.16241: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16242
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16242: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16243: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16244: Dma_PatchSrc (.L__pc.16244.LD), (.L__movme_tmp.1), (.L__pc.16244.LD)
	.p2align 4
	.L__pc.16244.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16245
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16245: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16246
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16246: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16247: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16248: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16249: Dma_PatchSrc (.L__pc.16249.LD), (.L__movme_tmp.1), (.L__pc.16249.LD)
	.p2align 4
	.L__pc.16249.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16250
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16250: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16251
	
	.L__pc.16251: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16252
	
	.p2align 4
	.L__pc.16252: Dma_PatchDst (.L__pc.16252.ST), (.L__movme_cp.63), (.L__pc.16252.ST)
	.L__pc.16252.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16253
	
	.L__pc.16253: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16254
	
	.p2align 4
	.L__pc.16254: Dma_PatchDst (.L__pc.16254.ST), (.L__movme_cp.24), (.L__pc.16254.ST)
	.L__pc.16254.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16255
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16255: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16256
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16256: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16257
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16257: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16258
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16258: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16259
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.16259: Dma_PatchSrc (.L__pc.16259.LD), (.L__movme_cp.66), (.L__pc.16259.LD)
	.p2align 4
	.L__pc.16259.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16260
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16260: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16261
	.L__pc.16261: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16262
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16262: Dma_PatchSrc (.L__pc.16262.LD), (.L__movme_cp.24), (.L__pc.16262.LD)
	.p2align 4
	.L__pc.16262.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16263
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16263: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16264
	.L__pc.16264: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16265
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16265: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16266: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16267: Dma_PatchSrc (.L__pc.16267.LD), (.L__movme_tmp.1), (.L__pc.16267.LD)
	.p2align 4
	.L__pc.16267.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16268
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16268: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16269
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16269: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16270: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16271: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16272: Dma_PatchSrc (.L__pc.16272.LD), (.L__movme_tmp.1), (.L__pc.16272.LD)
	.p2align 4
	.L__pc.16272.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16273
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16273: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16274
	
	.L__pc.16274: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16275
	
	.p2align 4
	.L__pc.16275: Dma_PatchDst (.L__pc.16275.ST), (.L__movme_cp.66), (.L__pc.16275.ST)
	.L__pc.16275.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16276
	
	.L__pc.16276: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16277
	
	.p2align 4
	.L__pc.16277: Dma_PatchDst (.L__pc.16277.ST), (.L__movme_cp.24), (.L__pc.16277.ST)
	.L__pc.16277.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16278
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16278: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16279
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16279: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16280
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16280: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16281
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16281: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16282
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.16282: Dma_PatchSrc (.L__pc.16282.LD), (.L__movme_cp.67), (.L__pc.16282.LD)
	.p2align 4
	.L__pc.16282.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16283
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16283: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16284
	.L__pc.16284: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16285
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16285: Dma_PatchSrc (.L__pc.16285.LD), (.L__movme_cp.24), (.L__pc.16285.LD)
	.p2align 4
	.L__pc.16285.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16286
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16286: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16287
	.L__pc.16287: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16288
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16288: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16289: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16290: Dma_PatchSrc (.L__pc.16290.LD), (.L__movme_tmp.1), (.L__pc.16290.LD)
	.p2align 4
	.L__pc.16290.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16291
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16291: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16292
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16292: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16293: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16294: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16295: Dma_PatchSrc (.L__pc.16295.LD), (.L__movme_tmp.1), (.L__pc.16295.LD)
	.p2align 4
	.L__pc.16295.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16296
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16296: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16297
	
	.L__pc.16297: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16298
	
	.p2align 4
	.L__pc.16298: Dma_PatchDst (.L__pc.16298.ST), (.L__movme_cp.67), (.L__pc.16298.ST)
	.L__pc.16298.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16299
	
	.L__pc.16299: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16300
	
	.p2align 4
	.L__pc.16300: Dma_PatchDst (.L__pc.16300.ST), (.L__movme_cp.24), (.L__pc.16300.ST)
	.L__pc.16300.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16301
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16301: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16302
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16302: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16303
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16303: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16304
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16304: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16305
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.16305: Dma_PatchSrc (.L__pc.16305.LD), (.L__movme_cp.68), (.L__pc.16305.LD)
	.p2align 4
	.L__pc.16305.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16306
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16306: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16307
	.L__pc.16307: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16308
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16308: Dma_PatchSrc (.L__pc.16308.LD), (.L__movme_cp.24), (.L__pc.16308.LD)
	.p2align 4
	.L__pc.16308.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16309
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16309: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16310
	.L__pc.16310: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16311
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16311: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16312: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16313: Dma_PatchSrc (.L__pc.16313.LD), (.L__movme_tmp.1), (.L__pc.16313.LD)
	.p2align 4
	.L__pc.16313.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16314
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16314: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16315
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16315: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16316: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16317: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16318: Dma_PatchSrc (.L__pc.16318.LD), (.L__movme_tmp.1), (.L__pc.16318.LD)
	.p2align 4
	.L__pc.16318.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16319
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16319: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16320
	
	.L__pc.16320: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16321
	
	.p2align 4
	.L__pc.16321: Dma_PatchDst (.L__pc.16321.ST), (.L__movme_cp.68), (.L__pc.16321.ST)
	.L__pc.16321.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16322
	
	.L__pc.16322: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16323
	
	.p2align 4
	.L__pc.16323: Dma_PatchDst (.L__pc.16323.ST), (.L__movme_cp.24), (.L__pc.16323.ST)
	.L__pc.16323.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16324
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16324: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16325
	
	.p2align 4
	.L__pc.16325: Dma_PatchDst (.L__pc.16325.ST), (.L__movme_cp.24), (.L__pc.16325.ST)
	.L__pc.16325.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16326
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.16326: Dma_PatchSrc (.L__pc.16326.LD), (.L__movme_cp.60), (.L__pc.16326.LD)
	.p2align 4
	.L__pc.16326.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16327
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16327: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16328
	
	.L__pc.16328: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16329
	
	.p2align 4
	.L__pc.16329: Dma_PatchDst (.L__pc.16329.ST), (.L__movme_cp.21), (.L__pc.16329.ST)
	.L__pc.16329.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16330
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.16330: Dma_PatchSrc (.L__pc.16330.LD), (.L__movme_cp.58), (.L__pc.16330.LD)
	.p2align 4
	.L__pc.16330.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16331
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16331: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16332
	
	.L__pc.16332: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16333
	
	.p2align 4
	.L__pc.16333: Dma_PatchDst (.L__pc.16333.ST), (.L__movme_cp.22), (.L__pc.16333.ST)
	.L__pc.16333.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16334
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16334: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16335
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16335: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16336
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16336: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16337
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16337: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16338
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.16338: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.16339
	
	.p2align 4
	.L__pc.16339: Dma_PatchDst (.L__pc.16339.ST), (.L__movme_cp.24), (.L__pc.16339.ST)
	.L__pc.16339.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16340
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.16340: Dma_PatchSrc (.L__pc.16340.LD), (.L__movme_cp.25), (.L__pc.16340.LD)
	.p2align 4
	.L__pc.16340.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16341
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16341: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16342
	.L__pc.16342: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16343
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.16343: Dma_PatchSrc (.L__pc.16343.LD), (.L__movme_cp.26), (.L__pc.16343.LD)
	.p2align 4
	.L__pc.16343.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16344
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16344: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16345
	.L__pc.16345: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16346
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16346: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16347: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16348: Dma_PatchSrc (.L__pc.16348.LD), (.L__movme_tmp.1), (.L__pc.16348.LD)
	.p2align 4
	.L__pc.16348.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16349
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16349: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16350
	.L__pc.16350: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16351
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16351: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16352: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16353: Dma_PatchSrc (.L__pc.16353.LD), (.L__movme_tmp.1), (.L__pc.16353.LD)
	.p2align 4
	.L__pc.16353.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16354
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16354: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16355
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16355: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16356: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16357: Dma_PatchSrc (.L__pc.16357.LD), (.L__movme_tmp.1), (.L__pc.16357.LD)
	.p2align 4
	.L__pc.16357.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16358
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16358: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16359
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16359: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16360: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16361: Dma_PatchSrc (.L__pc.16361.LD), (.L__movme_tmp.1), (.L__pc.16361.LD)
	.p2align 4
	.L__pc.16361.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16362
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16362: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16363
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16363: Dma_PatchSrc (.L__pc.16363.LD), (.L__movme_cp.24), (.L__pc.16363.LD)
	.p2align 4
	.L__pc.16363.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16364
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16364: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16365
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16365: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16366: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16367: Dma_PatchSrc (.L__pc.16367.LD), (.L__movme_tmp.1), (.L__pc.16367.LD)
	.p2align 4
	.L__pc.16367.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16368
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16368: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16369
	
	.L__pc.16369: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16370
	
	.p2align 4
	.L__pc.16370: Dma_PatchDst (.L__pc.16370.ST), (.L__movme_cp.69), (.L__pc.16370.ST)
	.L__pc.16370.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16371
	
	.L__pc.16371: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16372
	
	.p2align 4
	.L__pc.16372: Dma_PatchDst (.L__pc.16372.ST), (.L__movme_cp.54), (.L__pc.16372.ST)
	.L__pc.16372.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16373
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.16373: Dma_PatchSrc (.L__pc.16373.LD), (.L__movme_cp.30), (.L__pc.16373.LD)
	.p2align 4
	.L__pc.16373.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16374
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16374: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16375
	.L__pc.16375: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16376
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.16376: Dma_PatchSrc (.L__pc.16376.LD), (.L__movme_cp.31), (.L__pc.16376.LD)
	.p2align 4
	.L__pc.16376.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16377
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16377: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16378
	.L__pc.16378: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16379
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16379: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16380: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16381: Dma_PatchSrc (.L__pc.16381.LD), (.L__movme_tmp.1), (.L__pc.16381.LD)
	.p2align 4
	.L__pc.16381.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16382
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16382: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16383
	.L__pc.16383: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16384
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16384: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16385: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16386: Dma_PatchSrc (.L__pc.16386.LD), (.L__movme_tmp.1), (.L__pc.16386.LD)
	.p2align 4
	.L__pc.16386.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16387
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16387: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16388
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16388: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16389: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16390: Dma_PatchSrc (.L__pc.16390.LD), (.L__movme_tmp.1), (.L__pc.16390.LD)
	.p2align 4
	.L__pc.16390.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16391
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16391: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16392
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16392: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16393: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16394: Dma_PatchSrc (.L__pc.16394.LD), (.L__movme_tmp.1), (.L__pc.16394.LD)
	.p2align 4
	.L__pc.16394.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16395
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16395: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16396
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16396: Dma_PatchSrc (.L__pc.16396.LD), (.L__movme_cp.24), (.L__pc.16396.LD)
	.p2align 4
	.L__pc.16396.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16397
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16397: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16398
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16398: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16399: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16400: Dma_PatchSrc (.L__pc.16400.LD), (.L__movme_tmp.1), (.L__pc.16400.LD)
	.p2align 4
	.L__pc.16400.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16401
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16401: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16402
	
	.L__pc.16402: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16403
	
	.p2align 4
	.L__pc.16403: Dma_PatchDst (.L__pc.16403.ST), (.L__movme_cp.70), (.L__pc.16403.ST)
	.L__pc.16403.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16404
	
	.L__pc.16404: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16405
	
	.p2align 4
	.L__pc.16405: Dma_PatchDst (.L__pc.16405.ST), (.L__movme_cp.54), (.L__pc.16405.ST)
	.L__pc.16405.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16406
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16406: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16407
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16407: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16408
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16408: Dma_PatchSrc (.L__pc.16408.LD), (.L__movme_cp.24), (.L__pc.16408.LD)
	.p2align 4
	.L__pc.16408.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16409
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16409: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16410
	.L__pc.16410: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16411
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.16411: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16412: Dma_PatchSrc (.L__pc.16412.LD), (.L__movme_tmp.1), (.L__pc.16412.LD)
	.p2align 4
	.L__pc.16412.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16413
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16413: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16414
	.L__pc.16414: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16415
	
	.L__pc.16415: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16416
	
	.p2align 4
	.L__pc.16416: Dma_PatchDst (.L__pc.16416.ST), (.L__movme_cp.72), (.L__pc.16416.ST)
	.L__pc.16416.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16417
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.16417: Dma_PatchSrc (.L__pc.16417.LD), (.L__movme_cp.72), (.L__pc.16417.LD)
	.p2align 4
	.L__pc.16417.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16418
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16418: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16419
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16419: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16420: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16421: Dma_PatchSrc (.L__pc.16421.LD), (.L__movme_tmp.1), (.L__pc.16421.LD)
	.p2align 4
	.L__pc.16421.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16422
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16422: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16423
	
	.L__pc.16423: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16424
	
	.p2align 4
	.L__pc.16424: Dma_PatchDst (.L__pc.16424.ST), (.L__movme_cp.74), (.L__pc.16424.ST)
	.L__pc.16424.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16425
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16425: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16426: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16427: Dma_PatchSrc (.L__pc.16427.LD), (.L__movme_tmp.1), (.L__pc.16427.LD)
	.p2align 4
	.L__pc.16427.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16428
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16428: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16429
	
	.L__pc.16429: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16430
	
	.p2align 4
	.L__pc.16430: Dma_PatchDst (.L__pc.16430.ST), (.L__movme_cp.76), (.L__pc.16430.ST)
	.L__pc.16430.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16431
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.16431: Dma_PatchSrc (.L__pc.16431.LD), (.L__movme_cp.74), (.L__pc.16431.LD)
	.p2align 4
	.L__pc.16431.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16432
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16432: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16433
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.16433: Dma_PatchSrc (.L__pc.16433.LD), ((.L__movme.reg.eax+0)), (.L__pc.16433.LD)
	.p2align 4
	.L__pc.16433.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16434
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16434: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16435
	
	.L__pc.16435: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16436
	
	.p2align 4
	.L__pc.16436: Dma_PatchDst (.L__pc.16436.ST), (.L__movme_cp.77), (.L__pc.16436.ST)
	.L__pc.16436.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16437
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.16437: Dma_PatchSrc (.L__pc.16437.LD), (.L__movme_cp.77), (.L__pc.16437.LD)
	.p2align 4
	.L__pc.16437.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16438
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16438: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16439
	
	.L__pc.16439: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16440
	
	.p2align 4
	.L__pc.16440: Dma_PatchDst (.L__pc.16440.ST), (.L__movme_cp.21), (.L__pc.16440.ST)
	.L__pc.16440.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16441
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.16441: Dma_PatchSrc (.L__pc.16441.LD), (.L__movme_cp.58), (.L__pc.16441.LD)
	.p2align 4
	.L__pc.16441.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16442
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16442: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16443
	
	.L__pc.16443: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16444
	
	.p2align 4
	.L__pc.16444: Dma_PatchDst (.L__pc.16444.ST), (.L__movme_cp.22), (.L__pc.16444.ST)
	.L__pc.16444.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16445
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16445: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16446
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16446: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16447
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16447: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16448
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16448: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16449
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.16449: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.16450
	
	.p2align 4
	.L__pc.16450: Dma_PatchDst (.L__pc.16450.ST), (.L__movme_cp.24), (.L__pc.16450.ST)
	.L__pc.16450.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16451
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.16451: Dma_PatchSrc (.L__pc.16451.LD), (.L__movme_cp.25), (.L__pc.16451.LD)
	.p2align 4
	.L__pc.16451.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16452
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16452: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16453
	.L__pc.16453: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16454
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.16454: Dma_PatchSrc (.L__pc.16454.LD), (.L__movme_cp.26), (.L__pc.16454.LD)
	.p2align 4
	.L__pc.16454.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16455
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16455: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16456
	.L__pc.16456: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16457
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16457: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16458: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16459: Dma_PatchSrc (.L__pc.16459.LD), (.L__movme_tmp.1), (.L__pc.16459.LD)
	.p2align 4
	.L__pc.16459.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16460
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16460: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16461
	.L__pc.16461: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16462
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16462: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16463: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16464: Dma_PatchSrc (.L__pc.16464.LD), (.L__movme_tmp.1), (.L__pc.16464.LD)
	.p2align 4
	.L__pc.16464.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16465
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16465: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16466
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16466: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16467: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16468: Dma_PatchSrc (.L__pc.16468.LD), (.L__movme_tmp.1), (.L__pc.16468.LD)
	.p2align 4
	.L__pc.16468.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16469
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16469: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16470
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16470: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16471: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16472: Dma_PatchSrc (.L__pc.16472.LD), (.L__movme_tmp.1), (.L__pc.16472.LD)
	.p2align 4
	.L__pc.16472.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16473
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16473: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16474
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16474: Dma_PatchSrc (.L__pc.16474.LD), (.L__movme_cp.24), (.L__pc.16474.LD)
	.p2align 4
	.L__pc.16474.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16475
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16475: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16476
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16476: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16477: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16478: Dma_PatchSrc (.L__pc.16478.LD), (.L__movme_tmp.1), (.L__pc.16478.LD)
	.p2align 4
	.L__pc.16478.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16479
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16479: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16480
	
	.L__pc.16480: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16481
	
	.p2align 4
	.L__pc.16481: Dma_PatchDst (.L__pc.16481.ST), (.L__movme_cp.78), (.L__pc.16481.ST)
	.L__pc.16481.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16482
	
	.L__pc.16482: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16483
	
	.p2align 4
	.L__pc.16483: Dma_PatchDst (.L__pc.16483.ST), (.L__movme_cp.54), (.L__pc.16483.ST)
	.L__pc.16483.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16484
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.16484: Dma_PatchSrc (.L__pc.16484.LD), (.L__movme_cp.30), (.L__pc.16484.LD)
	.p2align 4
	.L__pc.16484.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16485
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16485: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16486
	.L__pc.16486: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16487
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.16487: Dma_PatchSrc (.L__pc.16487.LD), (.L__movme_cp.31), (.L__pc.16487.LD)
	.p2align 4
	.L__pc.16487.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16488
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16488: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16489
	.L__pc.16489: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16490
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16490: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16491: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16492: Dma_PatchSrc (.L__pc.16492.LD), (.L__movme_tmp.1), (.L__pc.16492.LD)
	.p2align 4
	.L__pc.16492.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16493
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16493: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16494
	.L__pc.16494: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16495
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16495: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16496: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16497: Dma_PatchSrc (.L__pc.16497.LD), (.L__movme_tmp.1), (.L__pc.16497.LD)
	.p2align 4
	.L__pc.16497.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16498
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16498: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16499
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16499: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16500: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16501: Dma_PatchSrc (.L__pc.16501.LD), (.L__movme_tmp.1), (.L__pc.16501.LD)
	.p2align 4
	.L__pc.16501.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16502
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16502: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16503
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16503: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16504: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16505: Dma_PatchSrc (.L__pc.16505.LD), (.L__movme_tmp.1), (.L__pc.16505.LD)
	.p2align 4
	.L__pc.16505.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16506
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16506: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16507
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16507: Dma_PatchSrc (.L__pc.16507.LD), (.L__movme_cp.24), (.L__pc.16507.LD)
	.p2align 4
	.L__pc.16507.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16508
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16508: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16509
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16509: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16510: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16511: Dma_PatchSrc (.L__pc.16511.LD), (.L__movme_tmp.1), (.L__pc.16511.LD)
	.p2align 4
	.L__pc.16511.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16512
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16512: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16513
	
	.L__pc.16513: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16514
	
	.p2align 4
	.L__pc.16514: Dma_PatchDst (.L__pc.16514.ST), (.L__movme_cp.79), (.L__pc.16514.ST)
	.L__pc.16514.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16515
	
	.L__pc.16515: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16516
	
	.p2align 4
	.L__pc.16516: Dma_PatchDst (.L__pc.16516.ST), (.L__movme_cp.54), (.L__pc.16516.ST)
	.L__pc.16516.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16517
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.16517: Dma_PatchSrc (.L__pc.16517.LD), (.L__movme_cp.74), (.L__pc.16517.LD)
	.p2align 4
	.L__pc.16517.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16518
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16518: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16519
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.16519: Dma_PatchSrc (.L__pc.16519.LD), (.L__movme_cp.77), (.L__pc.16519.LD)
	.p2align 4
	.L__pc.16519.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16520
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16520: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16521
	
	.L__pc.16521: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16522
	
	.p2align 4
	.L__pc.16522: Dma_PatchDst (.L__pc.16522.ST), ((.L__movme.reg.eax+0)), (.L__pc.16522.ST)
	.L__pc.16522.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16523
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.16523: Dma_PatchSrc (.L__pc.16523.LD), (.L__movme_cp.76), (.L__pc.16523.LD)
	.p2align 4
	.L__pc.16523.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16524
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16524: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16525
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.16525: Dma_PatchSrc (.L__pc.16525.LD), ((.L__movme.reg.eax+0)), (.L__pc.16525.LD)
	.p2align 4
	.L__pc.16525.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16526
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16526: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16527
	
	.L__pc.16527: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16528
	
	.p2align 4
	.L__pc.16528: Dma_PatchDst (.L__pc.16528.ST), (.L__movme_cp.80), (.L__pc.16528.ST)
	.L__pc.16528.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16529
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16529: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16530
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16530: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16531
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.16531: Dma_PatchSrc (.L__pc.16531.LD), (.L__movme_cp.98), (.L__pc.16531.LD)
	.p2align 4
	.L__pc.16531.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16532
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16532: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16533
	.L__pc.16533: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16534
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.88 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.16534: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16535: Dma_PatchSrc (.L__pc.16535.LD), (.L__movme_tmp.1), (.L__pc.16535.LD)
	.p2align 4
	.L__pc.16535.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16536
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16536: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16537
	.L__pc.16537: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16538
	
	.L__pc.16538: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16539
	
	.p2align 4
	.L__pc.16539: Dma_PatchDst (.L__pc.16539.ST), (.L__movme_cp.98), (.L__pc.16539.ST)
	.L__pc.16539.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16540
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.16540: Dma_PatchSrc (.L__pc.16540.LD), (.L__movme_cp.76), (.L__pc.16540.LD)
	.p2align 4
	.L__pc.16540.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16541
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16541: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16542
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.16542: Dma_PatchSrc (.L__pc.16542.LD), (.L__movme_cp.80), (.L__pc.16542.LD)
	.p2align 4
	.L__pc.16542.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16543
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16543: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16544
	
	.L__pc.16544: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16545
	
	.p2align 4
	.L__pc.16545: Dma_PatchDst (.L__pc.16545.ST), ((.L__movme.reg.eax+0)), (.L__pc.16545.ST)
	.L__pc.16545.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16546
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16546: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16547
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16547: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16548
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.16548: Dma_PatchSrc (.L__pc.16548.LD), (.L__movme_cp.97), (.L__pc.16548.LD)
	.p2align 4
	.L__pc.16548.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16549
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16549: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16550
	.L__pc.16550: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16551
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16551: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.89 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16552: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16553: Dma_PatchSrc (.L__pc.16553.LD), (.L__movme_tmp.1), (.L__pc.16553.LD)
	.p2align 4
	.L__pc.16553.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16554
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16554: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16555
	
	.L__pc.16555: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16556
	
	.p2align 4
	.L__pc.16556: Dma_PatchDst (.L__pc.16556.ST), (.L__movme_cp.24), (.L__pc.16556.ST)
	.L__pc.16556.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16557
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16557: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16558
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16558: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16559
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16559: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16560
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16560: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16561
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.16561: Dma_PatchSrc (.L__pc.16561.LD), (.L__movme_cp.63), (.L__pc.16561.LD)
	.p2align 4
	.L__pc.16561.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16562
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16562: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16563
	.L__pc.16563: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16564
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16564: Dma_PatchSrc (.L__pc.16564.LD), (.L__movme_cp.24), (.L__pc.16564.LD)
	.p2align 4
	.L__pc.16564.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16565
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16565: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16566
	.L__pc.16566: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16567
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16567: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16568: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16569: Dma_PatchSrc (.L__pc.16569.LD), (.L__movme_tmp.1), (.L__pc.16569.LD)
	.p2align 4
	.L__pc.16569.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16570
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16570: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16571
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16571: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16572: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16573: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16574: Dma_PatchSrc (.L__pc.16574.LD), (.L__movme_tmp.1), (.L__pc.16574.LD)
	.p2align 4
	.L__pc.16574.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16575
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16575: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16576
	
	.L__pc.16576: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16577
	
	.p2align 4
	.L__pc.16577: Dma_PatchDst (.L__pc.16577.ST), (.L__movme_cp.63), (.L__pc.16577.ST)
	.L__pc.16577.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16578
	
	.L__pc.16578: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16579
	
	.p2align 4
	.L__pc.16579: Dma_PatchDst (.L__pc.16579.ST), (.L__movme_cp.24), (.L__pc.16579.ST)
	.L__pc.16579.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16580
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16580: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16581
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16581: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16582
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16582: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16583
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16583: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16584
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.16584: Dma_PatchSrc (.L__pc.16584.LD), (.L__movme_cp.66), (.L__pc.16584.LD)
	.p2align 4
	.L__pc.16584.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16585
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16585: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16586
	.L__pc.16586: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16587
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16587: Dma_PatchSrc (.L__pc.16587.LD), (.L__movme_cp.24), (.L__pc.16587.LD)
	.p2align 4
	.L__pc.16587.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16588
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16588: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16589
	.L__pc.16589: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16590
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16590: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16591: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16592: Dma_PatchSrc (.L__pc.16592.LD), (.L__movme_tmp.1), (.L__pc.16592.LD)
	.p2align 4
	.L__pc.16592.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16593
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16593: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16594
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16594: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16595: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16596: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16597: Dma_PatchSrc (.L__pc.16597.LD), (.L__movme_tmp.1), (.L__pc.16597.LD)
	.p2align 4
	.L__pc.16597.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16598
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16598: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16599
	
	.L__pc.16599: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16600
	
	.p2align 4
	.L__pc.16600: Dma_PatchDst (.L__pc.16600.ST), (.L__movme_cp.66), (.L__pc.16600.ST)
	.L__pc.16600.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16601
	
	.L__pc.16601: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16602
	
	.p2align 4
	.L__pc.16602: Dma_PatchDst (.L__pc.16602.ST), (.L__movme_cp.24), (.L__pc.16602.ST)
	.L__pc.16602.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16603
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16603: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16604
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16604: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16605
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16605: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16606
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16606: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16607
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.16607: Dma_PatchSrc (.L__pc.16607.LD), (.L__movme_cp.67), (.L__pc.16607.LD)
	.p2align 4
	.L__pc.16607.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16608
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16608: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16609
	.L__pc.16609: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16610
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16610: Dma_PatchSrc (.L__pc.16610.LD), (.L__movme_cp.24), (.L__pc.16610.LD)
	.p2align 4
	.L__pc.16610.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16611
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16611: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16612
	.L__pc.16612: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16613
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16613: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16614: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16615: Dma_PatchSrc (.L__pc.16615.LD), (.L__movme_tmp.1), (.L__pc.16615.LD)
	.p2align 4
	.L__pc.16615.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16616
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16616: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16617
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16617: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16618: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16619: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16620: Dma_PatchSrc (.L__pc.16620.LD), (.L__movme_tmp.1), (.L__pc.16620.LD)
	.p2align 4
	.L__pc.16620.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16621
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16621: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16622
	
	.L__pc.16622: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16623
	
	.p2align 4
	.L__pc.16623: Dma_PatchDst (.L__pc.16623.ST), (.L__movme_cp.67), (.L__pc.16623.ST)
	.L__pc.16623.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16624
	
	.L__pc.16624: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16625
	
	.p2align 4
	.L__pc.16625: Dma_PatchDst (.L__pc.16625.ST), (.L__movme_cp.24), (.L__pc.16625.ST)
	.L__pc.16625.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16626
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16626: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16627
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16627: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16628
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16628: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16629
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16629: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16630
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.16630: Dma_PatchSrc (.L__pc.16630.LD), (.L__movme_cp.68), (.L__pc.16630.LD)
	.p2align 4
	.L__pc.16630.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16631
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16631: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16632
	.L__pc.16632: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16633
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16633: Dma_PatchSrc (.L__pc.16633.LD), (.L__movme_cp.24), (.L__pc.16633.LD)
	.p2align 4
	.L__pc.16633.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16634
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16634: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16635
	.L__pc.16635: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16636
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16636: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16637: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16638: Dma_PatchSrc (.L__pc.16638.LD), (.L__movme_tmp.1), (.L__pc.16638.LD)
	.p2align 4
	.L__pc.16638.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16639
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16639: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16640
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16640: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16641: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16642: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16643: Dma_PatchSrc (.L__pc.16643.LD), (.L__movme_tmp.1), (.L__pc.16643.LD)
	.p2align 4
	.L__pc.16643.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16644
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16644: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16645
	
	.L__pc.16645: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16646
	
	.p2align 4
	.L__pc.16646: Dma_PatchDst (.L__pc.16646.ST), (.L__movme_cp.68), (.L__pc.16646.ST)
	.L__pc.16646.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16647
	
	.L__pc.16647: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16648
	
	.p2align 4
	.L__pc.16648: Dma_PatchDst (.L__pc.16648.ST), (.L__movme_cp.24), (.L__pc.16648.ST)
	.L__pc.16648.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16649
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16649: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16650
	
	.p2align 4
	.L__pc.16650: Dma_PatchDst (.L__pc.16650.ST), (.L__movme_cp.24), (.L__pc.16650.ST)
	.L__pc.16650.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16651
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.16651: Dma_PatchSrc (.L__pc.16651.LD), (.L__movme_cp.60), (.L__pc.16651.LD)
	.p2align 4
	.L__pc.16651.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16652
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16652: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16653
	
	.L__pc.16653: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16654
	
	.p2align 4
	.L__pc.16654: Dma_PatchDst (.L__pc.16654.ST), (.L__movme_cp.21), (.L__pc.16654.ST)
	.L__pc.16654.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16655
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.16655: Dma_PatchSrc (.L__pc.16655.LD), (.L__movme_cp.58), (.L__pc.16655.LD)
	.p2align 4
	.L__pc.16655.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16656
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16656: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16657
	
	.L__pc.16657: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16658
	
	.p2align 4
	.L__pc.16658: Dma_PatchDst (.L__pc.16658.ST), (.L__movme_cp.22), (.L__pc.16658.ST)
	.L__pc.16658.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16659
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16659: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16660
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16660: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16661
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16661: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16662
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16662: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16663
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.16663: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.16664
	
	.p2align 4
	.L__pc.16664: Dma_PatchDst (.L__pc.16664.ST), (.L__movme_cp.24), (.L__pc.16664.ST)
	.L__pc.16664.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16665
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.16665: Dma_PatchSrc (.L__pc.16665.LD), (.L__movme_cp.25), (.L__pc.16665.LD)
	.p2align 4
	.L__pc.16665.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16666
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16666: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16667
	.L__pc.16667: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16668
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.16668: Dma_PatchSrc (.L__pc.16668.LD), (.L__movme_cp.26), (.L__pc.16668.LD)
	.p2align 4
	.L__pc.16668.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16669
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16669: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16670
	.L__pc.16670: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16671
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16671: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16672: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16673: Dma_PatchSrc (.L__pc.16673.LD), (.L__movme_tmp.1), (.L__pc.16673.LD)
	.p2align 4
	.L__pc.16673.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16674
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16674: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16675
	.L__pc.16675: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16676
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16676: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16677: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16678: Dma_PatchSrc (.L__pc.16678.LD), (.L__movme_tmp.1), (.L__pc.16678.LD)
	.p2align 4
	.L__pc.16678.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16679
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16679: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16680
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16680: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16681: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16682: Dma_PatchSrc (.L__pc.16682.LD), (.L__movme_tmp.1), (.L__pc.16682.LD)
	.p2align 4
	.L__pc.16682.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16683
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16683: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16684
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16684: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16685: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16686: Dma_PatchSrc (.L__pc.16686.LD), (.L__movme_tmp.1), (.L__pc.16686.LD)
	.p2align 4
	.L__pc.16686.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16687
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16687: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16688
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16688: Dma_PatchSrc (.L__pc.16688.LD), (.L__movme_cp.24), (.L__pc.16688.LD)
	.p2align 4
	.L__pc.16688.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16689
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16689: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16690
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16690: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16691: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16692: Dma_PatchSrc (.L__pc.16692.LD), (.L__movme_tmp.1), (.L__pc.16692.LD)
	.p2align 4
	.L__pc.16692.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16693
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16693: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16694
	
	.L__pc.16694: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16695
	
	.p2align 4
	.L__pc.16695: Dma_PatchDst (.L__pc.16695.ST), (.L__movme_cp.69), (.L__pc.16695.ST)
	.L__pc.16695.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16696
	
	.L__pc.16696: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16697
	
	.p2align 4
	.L__pc.16697: Dma_PatchDst (.L__pc.16697.ST), (.L__movme_cp.54), (.L__pc.16697.ST)
	.L__pc.16697.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16698
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.16698: Dma_PatchSrc (.L__pc.16698.LD), (.L__movme_cp.30), (.L__pc.16698.LD)
	.p2align 4
	.L__pc.16698.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16699
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16699: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16700
	.L__pc.16700: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16701
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.16701: Dma_PatchSrc (.L__pc.16701.LD), (.L__movme_cp.31), (.L__pc.16701.LD)
	.p2align 4
	.L__pc.16701.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16702
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16702: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16703
	.L__pc.16703: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16704
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16704: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16705: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16706: Dma_PatchSrc (.L__pc.16706.LD), (.L__movme_tmp.1), (.L__pc.16706.LD)
	.p2align 4
	.L__pc.16706.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16707
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16707: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16708
	.L__pc.16708: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16709
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16709: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16710: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16711: Dma_PatchSrc (.L__pc.16711.LD), (.L__movme_tmp.1), (.L__pc.16711.LD)
	.p2align 4
	.L__pc.16711.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16712
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16712: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16713
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16713: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16714: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16715: Dma_PatchSrc (.L__pc.16715.LD), (.L__movme_tmp.1), (.L__pc.16715.LD)
	.p2align 4
	.L__pc.16715.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16716
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16716: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16717
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16717: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16718: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16719: Dma_PatchSrc (.L__pc.16719.LD), (.L__movme_tmp.1), (.L__pc.16719.LD)
	.p2align 4
	.L__pc.16719.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16720
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16720: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16721
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16721: Dma_PatchSrc (.L__pc.16721.LD), (.L__movme_cp.24), (.L__pc.16721.LD)
	.p2align 4
	.L__pc.16721.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16722
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16722: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16723
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16723: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16724: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16725: Dma_PatchSrc (.L__pc.16725.LD), (.L__movme_tmp.1), (.L__pc.16725.LD)
	.p2align 4
	.L__pc.16725.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16726
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16726: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16727
	
	.L__pc.16727: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16728
	
	.p2align 4
	.L__pc.16728: Dma_PatchDst (.L__pc.16728.ST), (.L__movme_cp.70), (.L__pc.16728.ST)
	.L__pc.16728.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16729
	
	.L__pc.16729: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16730
	
	.p2align 4
	.L__pc.16730: Dma_PatchDst (.L__pc.16730.ST), (.L__movme_cp.54), (.L__pc.16730.ST)
	.L__pc.16730.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16731
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16731: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16732
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16732: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16733
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16733: Dma_PatchSrc (.L__pc.16733.LD), (.L__movme_cp.24), (.L__pc.16733.LD)
	.p2align 4
	.L__pc.16733.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16734
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16734: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16735
	.L__pc.16735: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16736
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.16736: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16737: Dma_PatchSrc (.L__pc.16737.LD), (.L__movme_tmp.1), (.L__pc.16737.LD)
	.p2align 4
	.L__pc.16737.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16738
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16738: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16739
	.L__pc.16739: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16740
	
	.L__pc.16740: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16741
	
	.p2align 4
	.L__pc.16741: Dma_PatchDst (.L__pc.16741.ST), (.L__movme_cp.72), (.L__pc.16741.ST)
	.L__pc.16741.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16742
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.16742: Dma_PatchSrc (.L__pc.16742.LD), (.L__movme_cp.72), (.L__pc.16742.LD)
	.p2align 4
	.L__pc.16742.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16743
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16743: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16744
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16744: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16745: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16746: Dma_PatchSrc (.L__pc.16746.LD), (.L__movme_tmp.1), (.L__pc.16746.LD)
	.p2align 4
	.L__pc.16746.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16747
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16747: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16748
	
	.L__pc.16748: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16749
	
	.p2align 4
	.L__pc.16749: Dma_PatchDst (.L__pc.16749.ST), (.L__movme_cp.74), (.L__pc.16749.ST)
	.L__pc.16749.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16750
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16750: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16751: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16752: Dma_PatchSrc (.L__pc.16752.LD), (.L__movme_tmp.1), (.L__pc.16752.LD)
	.p2align 4
	.L__pc.16752.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16753
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16753: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16754
	
	.L__pc.16754: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16755
	
	.p2align 4
	.L__pc.16755: Dma_PatchDst (.L__pc.16755.ST), (.L__movme_cp.76), (.L__pc.16755.ST)
	.L__pc.16755.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16756
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.16756: Dma_PatchSrc (.L__pc.16756.LD), (.L__movme_cp.74), (.L__pc.16756.LD)
	.p2align 4
	.L__pc.16756.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16757
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16757: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16758
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.16758: Dma_PatchSrc (.L__pc.16758.LD), ((.L__movme.reg.eax+0)), (.L__pc.16758.LD)
	.p2align 4
	.L__pc.16758.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16759
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16759: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16760
	
	.L__pc.16760: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16761
	
	.p2align 4
	.L__pc.16761: Dma_PatchDst (.L__pc.16761.ST), (.L__movme_cp.77), (.L__pc.16761.ST)
	.L__pc.16761.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16762
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.16762: Dma_PatchSrc (.L__pc.16762.LD), (.L__movme_cp.77), (.L__pc.16762.LD)
	.p2align 4
	.L__pc.16762.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16763
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16763: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16764
	
	.L__pc.16764: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16765
	
	.p2align 4
	.L__pc.16765: Dma_PatchDst (.L__pc.16765.ST), (.L__movme_cp.21), (.L__pc.16765.ST)
	.L__pc.16765.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16766
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.16766: Dma_PatchSrc (.L__pc.16766.LD), (.L__movme_cp.58), (.L__pc.16766.LD)
	.p2align 4
	.L__pc.16766.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16767
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16767: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16768
	
	.L__pc.16768: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16769
	
	.p2align 4
	.L__pc.16769: Dma_PatchDst (.L__pc.16769.ST), (.L__movme_cp.22), (.L__pc.16769.ST)
	.L__pc.16769.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16770
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16770: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16771
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16771: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16772
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16772: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16773
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16773: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16774
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.16774: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.16775
	
	.p2align 4
	.L__pc.16775: Dma_PatchDst (.L__pc.16775.ST), (.L__movme_cp.24), (.L__pc.16775.ST)
	.L__pc.16775.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16776
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.16776: Dma_PatchSrc (.L__pc.16776.LD), (.L__movme_cp.25), (.L__pc.16776.LD)
	.p2align 4
	.L__pc.16776.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16777
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16777: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16778
	.L__pc.16778: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16779
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.16779: Dma_PatchSrc (.L__pc.16779.LD), (.L__movme_cp.26), (.L__pc.16779.LD)
	.p2align 4
	.L__pc.16779.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16780
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16780: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16781
	.L__pc.16781: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16782
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16782: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16783: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16784: Dma_PatchSrc (.L__pc.16784.LD), (.L__movme_tmp.1), (.L__pc.16784.LD)
	.p2align 4
	.L__pc.16784.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16785
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16785: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16786
	.L__pc.16786: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16787
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16787: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16788: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16789: Dma_PatchSrc (.L__pc.16789.LD), (.L__movme_tmp.1), (.L__pc.16789.LD)
	.p2align 4
	.L__pc.16789.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16790
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16790: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16791
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16791: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16792: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16793: Dma_PatchSrc (.L__pc.16793.LD), (.L__movme_tmp.1), (.L__pc.16793.LD)
	.p2align 4
	.L__pc.16793.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16794
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16794: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16795
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16795: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16796: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16797: Dma_PatchSrc (.L__pc.16797.LD), (.L__movme_tmp.1), (.L__pc.16797.LD)
	.p2align 4
	.L__pc.16797.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16798
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16798: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16799
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16799: Dma_PatchSrc (.L__pc.16799.LD), (.L__movme_cp.24), (.L__pc.16799.LD)
	.p2align 4
	.L__pc.16799.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16800
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16800: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16801
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16801: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16802: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16803: Dma_PatchSrc (.L__pc.16803.LD), (.L__movme_tmp.1), (.L__pc.16803.LD)
	.p2align 4
	.L__pc.16803.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16804
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16804: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16805
	
	.L__pc.16805: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16806
	
	.p2align 4
	.L__pc.16806: Dma_PatchDst (.L__pc.16806.ST), (.L__movme_cp.78), (.L__pc.16806.ST)
	.L__pc.16806.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16807
	
	.L__pc.16807: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16808
	
	.p2align 4
	.L__pc.16808: Dma_PatchDst (.L__pc.16808.ST), (.L__movme_cp.54), (.L__pc.16808.ST)
	.L__pc.16808.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16809
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.16809: Dma_PatchSrc (.L__pc.16809.LD), (.L__movme_cp.30), (.L__pc.16809.LD)
	.p2align 4
	.L__pc.16809.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16810
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16810: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16811
	.L__pc.16811: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16812
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.16812: Dma_PatchSrc (.L__pc.16812.LD), (.L__movme_cp.31), (.L__pc.16812.LD)
	.p2align 4
	.L__pc.16812.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16813
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16813: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16814
	.L__pc.16814: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16815
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16815: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16816: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16817: Dma_PatchSrc (.L__pc.16817.LD), (.L__movme_tmp.1), (.L__pc.16817.LD)
	.p2align 4
	.L__pc.16817.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16818
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16818: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16819
	.L__pc.16819: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16820
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16820: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16821: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16822: Dma_PatchSrc (.L__pc.16822.LD), (.L__movme_tmp.1), (.L__pc.16822.LD)
	.p2align 4
	.L__pc.16822.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16823
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16823: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16824
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16824: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16825: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16826: Dma_PatchSrc (.L__pc.16826.LD), (.L__movme_tmp.1), (.L__pc.16826.LD)
	.p2align 4
	.L__pc.16826.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16827
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16827: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16828
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16828: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16829: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16830: Dma_PatchSrc (.L__pc.16830.LD), (.L__movme_tmp.1), (.L__pc.16830.LD)
	.p2align 4
	.L__pc.16830.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16831
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16831: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16832
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16832: Dma_PatchSrc (.L__pc.16832.LD), (.L__movme_cp.24), (.L__pc.16832.LD)
	.p2align 4
	.L__pc.16832.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16833
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16833: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16834
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.16834: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16835: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16836: Dma_PatchSrc (.L__pc.16836.LD), (.L__movme_tmp.1), (.L__pc.16836.LD)
	.p2align 4
	.L__pc.16836.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16837
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16837: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16838
	
	.L__pc.16838: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.16839
	
	.p2align 4
	.L__pc.16839: Dma_PatchDst (.L__pc.16839.ST), (.L__movme_cp.79), (.L__pc.16839.ST)
	.L__pc.16839.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16840
	
	.L__pc.16840: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16841
	
	.p2align 4
	.L__pc.16841: Dma_PatchDst (.L__pc.16841.ST), (.L__movme_cp.54), (.L__pc.16841.ST)
	.L__pc.16841.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16842
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.16842: Dma_PatchSrc (.L__pc.16842.LD), (.L__movme_cp.74), (.L__pc.16842.LD)
	.p2align 4
	.L__pc.16842.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16843
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16843: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16844
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.16844: Dma_PatchSrc (.L__pc.16844.LD), (.L__movme_cp.77), (.L__pc.16844.LD)
	.p2align 4
	.L__pc.16844.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16845
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16845: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16846
	
	.L__pc.16846: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16847
	
	.p2align 4
	.L__pc.16847: Dma_PatchDst (.L__pc.16847.ST), ((.L__movme.reg.eax+0)), (.L__pc.16847.ST)
	.L__pc.16847.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16848
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.16848: Dma_PatchSrc (.L__pc.16848.LD), (.L__movme_cp.76), (.L__pc.16848.LD)
	.p2align 4
	.L__pc.16848.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16849
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16849: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16850
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.16850: Dma_PatchSrc (.L__pc.16850.LD), ((.L__movme.reg.eax+0)), (.L__pc.16850.LD)
	.p2align 4
	.L__pc.16850.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16851
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16851: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16852
	
	.L__pc.16852: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16853
	
	.p2align 4
	.L__pc.16853: Dma_PatchDst (.L__pc.16853.ST), (.L__movme_cp.80), (.L__pc.16853.ST)
	.L__pc.16853.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16854
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16854: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16855
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16855: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16856
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.16856: Dma_PatchSrc (.L__pc.16856.LD), (.L__movme_cp.98), (.L__pc.16856.LD)
	.p2align 4
	.L__pc.16856.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16857
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16857: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16858
	.L__pc.16858: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16859
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.90 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.16859: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16860: Dma_PatchSrc (.L__pc.16860.LD), (.L__movme_tmp.1), (.L__pc.16860.LD)
	.p2align 4
	.L__pc.16860.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16861
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16861: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16862
	.L__pc.16862: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16863
	
	.L__pc.16863: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16864
	
	.p2align 4
	.L__pc.16864: Dma_PatchDst (.L__pc.16864.ST), (.L__movme_cp.98), (.L__pc.16864.ST)
	.L__pc.16864.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16865
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.16865: Dma_PatchSrc (.L__pc.16865.LD), (.L__movme_cp.76), (.L__pc.16865.LD)
	.p2align 4
	.L__pc.16865.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16866
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16866: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16867
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.16867: Dma_PatchSrc (.L__pc.16867.LD), (.L__movme_cp.80), (.L__pc.16867.LD)
	.p2align 4
	.L__pc.16867.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16868
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16868: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16869
	
	.L__pc.16869: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.16870
	
	.p2align 4
	.L__pc.16870: Dma_PatchDst (.L__pc.16870.ST), ((.L__movme.reg.eax+0)), (.L__pc.16870.ST)
	.L__pc.16870.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16871
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16871: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16872
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16872: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16873
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.16873: Dma_PatchSrc (.L__pc.16873.LD), (.L__movme_cp.97), (.L__pc.16873.LD)
	.p2align 4
	.L__pc.16873.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16874
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16874: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16875
	.L__pc.16875: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16876
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.16876: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.91 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16877: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16878: Dma_PatchSrc (.L__pc.16878.LD), (.L__movme_tmp.1), (.L__pc.16878.LD)
	.p2align 4
	.L__pc.16878.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16879
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16879: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16880
	
	.L__pc.16880: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16881
	
	.p2align 4
	.L__pc.16881: Dma_PatchDst (.L__pc.16881.ST), (.L__movme_cp.24), (.L__pc.16881.ST)
	.L__pc.16881.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16882
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16882: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16883
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16883: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16884
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16884: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16885
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16885: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16886
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.16886: Dma_PatchSrc (.L__pc.16886.LD), (.L__movme_cp.63), (.L__pc.16886.LD)
	.p2align 4
	.L__pc.16886.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16887
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16887: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16888
	.L__pc.16888: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16889
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16889: Dma_PatchSrc (.L__pc.16889.LD), (.L__movme_cp.24), (.L__pc.16889.LD)
	.p2align 4
	.L__pc.16889.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16890
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16890: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16891
	.L__pc.16891: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16892
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16892: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16893: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16894: Dma_PatchSrc (.L__pc.16894.LD), (.L__movme_tmp.1), (.L__pc.16894.LD)
	.p2align 4
	.L__pc.16894.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16895
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16895: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16896
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16896: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16897: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16898: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16899: Dma_PatchSrc (.L__pc.16899.LD), (.L__movme_tmp.1), (.L__pc.16899.LD)
	.p2align 4
	.L__pc.16899.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16900
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16900: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16901
	
	.L__pc.16901: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16902
	
	.p2align 4
	.L__pc.16902: Dma_PatchDst (.L__pc.16902.ST), (.L__movme_cp.63), (.L__pc.16902.ST)
	.L__pc.16902.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16903
	
	.L__pc.16903: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16904
	
	.p2align 4
	.L__pc.16904: Dma_PatchDst (.L__pc.16904.ST), (.L__movme_cp.24), (.L__pc.16904.ST)
	.L__pc.16904.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16905
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16905: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16906
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16906: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16907
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16907: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16908
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16908: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16909
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.16909: Dma_PatchSrc (.L__pc.16909.LD), (.L__movme_cp.66), (.L__pc.16909.LD)
	.p2align 4
	.L__pc.16909.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16910
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16910: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16911
	.L__pc.16911: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16912
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16912: Dma_PatchSrc (.L__pc.16912.LD), (.L__movme_cp.24), (.L__pc.16912.LD)
	.p2align 4
	.L__pc.16912.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16913
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16913: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16914
	.L__pc.16914: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16915
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16915: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16916: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16917: Dma_PatchSrc (.L__pc.16917.LD), (.L__movme_tmp.1), (.L__pc.16917.LD)
	.p2align 4
	.L__pc.16917.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16918
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16918: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16919
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16919: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16920: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16921: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16922: Dma_PatchSrc (.L__pc.16922.LD), (.L__movme_tmp.1), (.L__pc.16922.LD)
	.p2align 4
	.L__pc.16922.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16923
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16923: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16924
	
	.L__pc.16924: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16925
	
	.p2align 4
	.L__pc.16925: Dma_PatchDst (.L__pc.16925.ST), (.L__movme_cp.66), (.L__pc.16925.ST)
	.L__pc.16925.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16926
	
	.L__pc.16926: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16927
	
	.p2align 4
	.L__pc.16927: Dma_PatchDst (.L__pc.16927.ST), (.L__movme_cp.24), (.L__pc.16927.ST)
	.L__pc.16927.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16928
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16928: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16929
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16929: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16930
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16930: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16931
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16931: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16932
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.16932: Dma_PatchSrc (.L__pc.16932.LD), (.L__movme_cp.67), (.L__pc.16932.LD)
	.p2align 4
	.L__pc.16932.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16933
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16933: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16934
	.L__pc.16934: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16935
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16935: Dma_PatchSrc (.L__pc.16935.LD), (.L__movme_cp.24), (.L__pc.16935.LD)
	.p2align 4
	.L__pc.16935.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16936
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16936: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16937
	.L__pc.16937: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16938
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16938: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16939: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16940: Dma_PatchSrc (.L__pc.16940.LD), (.L__movme_tmp.1), (.L__pc.16940.LD)
	.p2align 4
	.L__pc.16940.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16941
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16941: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16942
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16942: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16943: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16944: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16945: Dma_PatchSrc (.L__pc.16945.LD), (.L__movme_tmp.1), (.L__pc.16945.LD)
	.p2align 4
	.L__pc.16945.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16946
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16946: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16947
	
	.L__pc.16947: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16948
	
	.p2align 4
	.L__pc.16948: Dma_PatchDst (.L__pc.16948.ST), (.L__movme_cp.67), (.L__pc.16948.ST)
	.L__pc.16948.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16949
	
	.L__pc.16949: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16950
	
	.p2align 4
	.L__pc.16950: Dma_PatchDst (.L__pc.16950.ST), (.L__movme_cp.24), (.L__pc.16950.ST)
	.L__pc.16950.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16951
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16951: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16952
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16952: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16953
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16953: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16954
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16954: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.16955
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.16955: Dma_PatchSrc (.L__pc.16955.LD), (.L__movme_cp.68), (.L__pc.16955.LD)
	.p2align 4
	.L__pc.16955.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16956
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16956: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.16957
	.L__pc.16957: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.16958
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.16958: Dma_PatchSrc (.L__pc.16958.LD), (.L__movme_cp.24), (.L__pc.16958.LD)
	.p2align 4
	.L__pc.16958.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16959
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.16959: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.16960
	.L__pc.16960: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.16961
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.16961: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16962: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16963: Dma_PatchSrc (.L__pc.16963.LD), (.L__movme_tmp.1), (.L__pc.16963.LD)
	.p2align 4
	.L__pc.16963.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16964
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16964: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16965
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.16965: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.16966: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.16967: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16968: Dma_PatchSrc (.L__pc.16968.LD), (.L__movme_tmp.1), (.L__pc.16968.LD)
	.p2align 4
	.L__pc.16968.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16969
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16969: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16970
	
	.L__pc.16970: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.16971
	
	.p2align 4
	.L__pc.16971: Dma_PatchDst (.L__pc.16971.ST), (.L__movme_cp.68), (.L__pc.16971.ST)
	.L__pc.16971.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16972
	
	.L__pc.16972: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.16973
	
	.p2align 4
	.L__pc.16973: Dma_PatchDst (.L__pc.16973.ST), (.L__movme_cp.24), (.L__pc.16973.ST)
	.L__pc.16973.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16974
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16974: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16975
	
	.p2align 4
	.L__pc.16975: Dma_PatchDst (.L__pc.16975.ST), (.L__movme_cp.24), (.L__pc.16975.ST)
	.L__pc.16975.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16976
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.16976: Dma_PatchSrc (.L__pc.16976.LD), (.L__movme_cp.60), (.L__pc.16976.LD)
	.p2align 4
	.L__pc.16976.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16977
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16977: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16978
	
	.L__pc.16978: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16979
	
	.p2align 4
	.L__pc.16979: Dma_PatchDst (.L__pc.16979.ST), (.L__movme_cp.21), (.L__pc.16979.ST)
	.L__pc.16979.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16980
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.16980: Dma_PatchSrc (.L__pc.16980.LD), (.L__movme_cp.58), (.L__pc.16980.LD)
	.p2align 4
	.L__pc.16980.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16981
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16981: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16982
	
	.L__pc.16982: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.16983
	
	.p2align 4
	.L__pc.16983: Dma_PatchDst (.L__pc.16983.ST), (.L__movme_cp.22), (.L__pc.16983.ST)
	.L__pc.16983.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16984
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16984: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16985
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16985: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.16986
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.16986: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.16987
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16987: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.16988
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.16988: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.16989
	
	.p2align 4
	.L__pc.16989: Dma_PatchDst (.L__pc.16989.ST), (.L__movme_cp.24), (.L__pc.16989.ST)
	.L__pc.16989.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.16990
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.16990: Dma_PatchSrc (.L__pc.16990.LD), (.L__movme_cp.25), (.L__pc.16990.LD)
	.p2align 4
	.L__pc.16990.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16991
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.16991: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.16992
	.L__pc.16992: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.16993
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.16993: Dma_PatchSrc (.L__pc.16993.LD), (.L__movme_cp.26), (.L__pc.16993.LD)
	.p2align 4
	.L__pc.16993.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16994
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16994: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.16995
	.L__pc.16995: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.16996
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.16996: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.16997: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.16998: Dma_PatchSrc (.L__pc.16998.LD), (.L__movme_tmp.1), (.L__pc.16998.LD)
	.p2align 4
	.L__pc.16998.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.16999
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.16999: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17000
	.L__pc.17000: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17001
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17001: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17002: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17003: Dma_PatchSrc (.L__pc.17003.LD), (.L__movme_tmp.1), (.L__pc.17003.LD)
	.p2align 4
	.L__pc.17003.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17004
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17004: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17005
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17005: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17006: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17007: Dma_PatchSrc (.L__pc.17007.LD), (.L__movme_tmp.1), (.L__pc.17007.LD)
	.p2align 4
	.L__pc.17007.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17008
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17008: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17009
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17009: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17010: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17011: Dma_PatchSrc (.L__pc.17011.LD), (.L__movme_tmp.1), (.L__pc.17011.LD)
	.p2align 4
	.L__pc.17011.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17012
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17012: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17013
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17013: Dma_PatchSrc (.L__pc.17013.LD), (.L__movme_cp.24), (.L__pc.17013.LD)
	.p2align 4
	.L__pc.17013.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17014
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17014: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17015
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17015: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17016: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17017: Dma_PatchSrc (.L__pc.17017.LD), (.L__movme_tmp.1), (.L__pc.17017.LD)
	.p2align 4
	.L__pc.17017.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17018
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17018: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17019
	
	.L__pc.17019: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17020
	
	.p2align 4
	.L__pc.17020: Dma_PatchDst (.L__pc.17020.ST), (.L__movme_cp.69), (.L__pc.17020.ST)
	.L__pc.17020.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17021
	
	.L__pc.17021: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17022
	
	.p2align 4
	.L__pc.17022: Dma_PatchDst (.L__pc.17022.ST), (.L__movme_cp.54), (.L__pc.17022.ST)
	.L__pc.17022.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17023
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.17023: Dma_PatchSrc (.L__pc.17023.LD), (.L__movme_cp.30), (.L__pc.17023.LD)
	.p2align 4
	.L__pc.17023.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17024
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17024: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17025
	.L__pc.17025: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17026
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.17026: Dma_PatchSrc (.L__pc.17026.LD), (.L__movme_cp.31), (.L__pc.17026.LD)
	.p2align 4
	.L__pc.17026.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17027
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17027: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17028
	.L__pc.17028: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17029
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17029: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17030: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17031: Dma_PatchSrc (.L__pc.17031.LD), (.L__movme_tmp.1), (.L__pc.17031.LD)
	.p2align 4
	.L__pc.17031.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17032
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17032: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17033
	.L__pc.17033: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17034
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17034: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17035: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17036: Dma_PatchSrc (.L__pc.17036.LD), (.L__movme_tmp.1), (.L__pc.17036.LD)
	.p2align 4
	.L__pc.17036.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17037
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17037: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17038
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17038: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17039: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17040: Dma_PatchSrc (.L__pc.17040.LD), (.L__movme_tmp.1), (.L__pc.17040.LD)
	.p2align 4
	.L__pc.17040.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17041
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17041: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17042
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17042: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17043: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17044: Dma_PatchSrc (.L__pc.17044.LD), (.L__movme_tmp.1), (.L__pc.17044.LD)
	.p2align 4
	.L__pc.17044.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17045
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17045: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17046
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17046: Dma_PatchSrc (.L__pc.17046.LD), (.L__movme_cp.24), (.L__pc.17046.LD)
	.p2align 4
	.L__pc.17046.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17047
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17047: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17048
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17048: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17049: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17050: Dma_PatchSrc (.L__pc.17050.LD), (.L__movme_tmp.1), (.L__pc.17050.LD)
	.p2align 4
	.L__pc.17050.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17051
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17051: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17052
	
	.L__pc.17052: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17053
	
	.p2align 4
	.L__pc.17053: Dma_PatchDst (.L__pc.17053.ST), (.L__movme_cp.70), (.L__pc.17053.ST)
	.L__pc.17053.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17054
	
	.L__pc.17054: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17055
	
	.p2align 4
	.L__pc.17055: Dma_PatchDst (.L__pc.17055.ST), (.L__movme_cp.54), (.L__pc.17055.ST)
	.L__pc.17055.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17056
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17056: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17057
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17057: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17058
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17058: Dma_PatchSrc (.L__pc.17058.LD), (.L__movme_cp.24), (.L__pc.17058.LD)
	.p2align 4
	.L__pc.17058.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17059
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17059: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17060
	.L__pc.17060: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17061
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.17061: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17062: Dma_PatchSrc (.L__pc.17062.LD), (.L__movme_tmp.1), (.L__pc.17062.LD)
	.p2align 4
	.L__pc.17062.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17063
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17063: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17064
	.L__pc.17064: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17065
	
	.L__pc.17065: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17066
	
	.p2align 4
	.L__pc.17066: Dma_PatchDst (.L__pc.17066.ST), (.L__movme_cp.72), (.L__pc.17066.ST)
	.L__pc.17066.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17067
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.17067: Dma_PatchSrc (.L__pc.17067.LD), (.L__movme_cp.72), (.L__pc.17067.LD)
	.p2align 4
	.L__pc.17067.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17068
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17068: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17069
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17069: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17070: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17071: Dma_PatchSrc (.L__pc.17071.LD), (.L__movme_tmp.1), (.L__pc.17071.LD)
	.p2align 4
	.L__pc.17071.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17072
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17072: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17073
	
	.L__pc.17073: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17074
	
	.p2align 4
	.L__pc.17074: Dma_PatchDst (.L__pc.17074.ST), (.L__movme_cp.74), (.L__pc.17074.ST)
	.L__pc.17074.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17075
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17075: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17076: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17077: Dma_PatchSrc (.L__pc.17077.LD), (.L__movme_tmp.1), (.L__pc.17077.LD)
	.p2align 4
	.L__pc.17077.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17078
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17078: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17079
	
	.L__pc.17079: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17080
	
	.p2align 4
	.L__pc.17080: Dma_PatchDst (.L__pc.17080.ST), (.L__movme_cp.76), (.L__pc.17080.ST)
	.L__pc.17080.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17081
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.17081: Dma_PatchSrc (.L__pc.17081.LD), (.L__movme_cp.74), (.L__pc.17081.LD)
	.p2align 4
	.L__pc.17081.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17082
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17082: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17083
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.17083: Dma_PatchSrc (.L__pc.17083.LD), ((.L__movme.reg.eax+0)), (.L__pc.17083.LD)
	.p2align 4
	.L__pc.17083.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17084
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17084: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17085
	
	.L__pc.17085: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17086
	
	.p2align 4
	.L__pc.17086: Dma_PatchDst (.L__pc.17086.ST), (.L__movme_cp.77), (.L__pc.17086.ST)
	.L__pc.17086.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17087
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.17087: Dma_PatchSrc (.L__pc.17087.LD), (.L__movme_cp.77), (.L__pc.17087.LD)
	.p2align 4
	.L__pc.17087.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17088
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17088: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17089
	
	.L__pc.17089: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17090
	
	.p2align 4
	.L__pc.17090: Dma_PatchDst (.L__pc.17090.ST), (.L__movme_cp.21), (.L__pc.17090.ST)
	.L__pc.17090.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17091
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.17091: Dma_PatchSrc (.L__pc.17091.LD), (.L__movme_cp.58), (.L__pc.17091.LD)
	.p2align 4
	.L__pc.17091.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17092
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17092: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17093
	
	.L__pc.17093: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17094
	
	.p2align 4
	.L__pc.17094: Dma_PatchDst (.L__pc.17094.ST), (.L__movme_cp.22), (.L__pc.17094.ST)
	.L__pc.17094.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17095
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17095: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17096
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17096: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17097
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17097: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17098
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17098: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17099
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.17099: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.17100
	
	.p2align 4
	.L__pc.17100: Dma_PatchDst (.L__pc.17100.ST), (.L__movme_cp.24), (.L__pc.17100.ST)
	.L__pc.17100.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17101
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.17101: Dma_PatchSrc (.L__pc.17101.LD), (.L__movme_cp.25), (.L__pc.17101.LD)
	.p2align 4
	.L__pc.17101.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17102
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17102: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17103
	.L__pc.17103: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17104
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.17104: Dma_PatchSrc (.L__pc.17104.LD), (.L__movme_cp.26), (.L__pc.17104.LD)
	.p2align 4
	.L__pc.17104.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17105
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17105: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17106
	.L__pc.17106: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17107
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17107: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17108: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17109: Dma_PatchSrc (.L__pc.17109.LD), (.L__movme_tmp.1), (.L__pc.17109.LD)
	.p2align 4
	.L__pc.17109.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17110
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17110: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17111
	.L__pc.17111: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17112
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17112: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17113: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17114: Dma_PatchSrc (.L__pc.17114.LD), (.L__movme_tmp.1), (.L__pc.17114.LD)
	.p2align 4
	.L__pc.17114.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17115
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17115: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17116
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17116: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17117: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17118: Dma_PatchSrc (.L__pc.17118.LD), (.L__movme_tmp.1), (.L__pc.17118.LD)
	.p2align 4
	.L__pc.17118.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17119
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17119: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17120
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17120: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17121: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17122: Dma_PatchSrc (.L__pc.17122.LD), (.L__movme_tmp.1), (.L__pc.17122.LD)
	.p2align 4
	.L__pc.17122.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17123
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17123: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17124
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17124: Dma_PatchSrc (.L__pc.17124.LD), (.L__movme_cp.24), (.L__pc.17124.LD)
	.p2align 4
	.L__pc.17124.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17125
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17125: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17126
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17126: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17127: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17128: Dma_PatchSrc (.L__pc.17128.LD), (.L__movme_tmp.1), (.L__pc.17128.LD)
	.p2align 4
	.L__pc.17128.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17129
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17129: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17130
	
	.L__pc.17130: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17131
	
	.p2align 4
	.L__pc.17131: Dma_PatchDst (.L__pc.17131.ST), (.L__movme_cp.78), (.L__pc.17131.ST)
	.L__pc.17131.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17132
	
	.L__pc.17132: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17133
	
	.p2align 4
	.L__pc.17133: Dma_PatchDst (.L__pc.17133.ST), (.L__movme_cp.54), (.L__pc.17133.ST)
	.L__pc.17133.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17134
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.17134: Dma_PatchSrc (.L__pc.17134.LD), (.L__movme_cp.30), (.L__pc.17134.LD)
	.p2align 4
	.L__pc.17134.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17135
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17135: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17136
	.L__pc.17136: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17137
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.17137: Dma_PatchSrc (.L__pc.17137.LD), (.L__movme_cp.31), (.L__pc.17137.LD)
	.p2align 4
	.L__pc.17137.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17138
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17138: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17139
	.L__pc.17139: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17140
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17140: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17141: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17142: Dma_PatchSrc (.L__pc.17142.LD), (.L__movme_tmp.1), (.L__pc.17142.LD)
	.p2align 4
	.L__pc.17142.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17143
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17143: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17144
	.L__pc.17144: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17145
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17145: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17146: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17147: Dma_PatchSrc (.L__pc.17147.LD), (.L__movme_tmp.1), (.L__pc.17147.LD)
	.p2align 4
	.L__pc.17147.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17148
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17148: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17149
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17149: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17150: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17151: Dma_PatchSrc (.L__pc.17151.LD), (.L__movme_tmp.1), (.L__pc.17151.LD)
	.p2align 4
	.L__pc.17151.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17152
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17152: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17153
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17153: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17154: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17155: Dma_PatchSrc (.L__pc.17155.LD), (.L__movme_tmp.1), (.L__pc.17155.LD)
	.p2align 4
	.L__pc.17155.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17156
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17156: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17157
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17157: Dma_PatchSrc (.L__pc.17157.LD), (.L__movme_cp.24), (.L__pc.17157.LD)
	.p2align 4
	.L__pc.17157.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17158
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17158: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17159
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17159: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17160: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17161: Dma_PatchSrc (.L__pc.17161.LD), (.L__movme_tmp.1), (.L__pc.17161.LD)
	.p2align 4
	.L__pc.17161.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17162
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17162: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17163
	
	.L__pc.17163: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17164
	
	.p2align 4
	.L__pc.17164: Dma_PatchDst (.L__pc.17164.ST), (.L__movme_cp.79), (.L__pc.17164.ST)
	.L__pc.17164.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17165
	
	.L__pc.17165: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17166
	
	.p2align 4
	.L__pc.17166: Dma_PatchDst (.L__pc.17166.ST), (.L__movme_cp.54), (.L__pc.17166.ST)
	.L__pc.17166.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17167
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.17167: Dma_PatchSrc (.L__pc.17167.LD), (.L__movme_cp.74), (.L__pc.17167.LD)
	.p2align 4
	.L__pc.17167.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17168
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17168: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17169
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.17169: Dma_PatchSrc (.L__pc.17169.LD), (.L__movme_cp.77), (.L__pc.17169.LD)
	.p2align 4
	.L__pc.17169.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17170
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17170: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17171
	
	.L__pc.17171: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17172
	
	.p2align 4
	.L__pc.17172: Dma_PatchDst (.L__pc.17172.ST), ((.L__movme.reg.eax+0)), (.L__pc.17172.ST)
	.L__pc.17172.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17173
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.17173: Dma_PatchSrc (.L__pc.17173.LD), (.L__movme_cp.76), (.L__pc.17173.LD)
	.p2align 4
	.L__pc.17173.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17174
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17174: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17175
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.17175: Dma_PatchSrc (.L__pc.17175.LD), ((.L__movme.reg.eax+0)), (.L__pc.17175.LD)
	.p2align 4
	.L__pc.17175.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17176
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17176: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17177
	
	.L__pc.17177: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17178
	
	.p2align 4
	.L__pc.17178: Dma_PatchDst (.L__pc.17178.ST), (.L__movme_cp.80), (.L__pc.17178.ST)
	.L__pc.17178.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17179
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17179: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17180
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17180: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17181
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.17181: Dma_PatchSrc (.L__pc.17181.LD), (.L__movme_cp.98), (.L__pc.17181.LD)
	.p2align 4
	.L__pc.17181.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17182
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17182: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17183
	.L__pc.17183: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17184
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.92 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.17184: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17185: Dma_PatchSrc (.L__pc.17185.LD), (.L__movme_tmp.1), (.L__pc.17185.LD)
	.p2align 4
	.L__pc.17185.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17186
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17186: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17187
	.L__pc.17187: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17188
	
	.L__pc.17188: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17189
	
	.p2align 4
	.L__pc.17189: Dma_PatchDst (.L__pc.17189.ST), (.L__movme_cp.98), (.L__pc.17189.ST)
	.L__pc.17189.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17190
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.17190: Dma_PatchSrc (.L__pc.17190.LD), (.L__movme_cp.76), (.L__pc.17190.LD)
	.p2align 4
	.L__pc.17190.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17191
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17191: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17192
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.17192: Dma_PatchSrc (.L__pc.17192.LD), (.L__movme_cp.80), (.L__pc.17192.LD)
	.p2align 4
	.L__pc.17192.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17193
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17193: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17194
	
	.L__pc.17194: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17195
	
	.p2align 4
	.L__pc.17195: Dma_PatchDst (.L__pc.17195.ST), ((.L__movme.reg.eax+0)), (.L__pc.17195.ST)
	.L__pc.17195.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17196
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17196: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17197
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17197: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17198
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.17198: Dma_PatchSrc (.L__pc.17198.LD), (.L__movme_cp.97), (.L__pc.17198.LD)
	.p2align 4
	.L__pc.17198.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17199
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17199: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17200
	.L__pc.17200: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17201
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17201: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.93 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17202: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17203: Dma_PatchSrc (.L__pc.17203.LD), (.L__movme_tmp.1), (.L__pc.17203.LD)
	.p2align 4
	.L__pc.17203.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17204
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17204: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17205
	
	.L__pc.17205: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17206
	
	.p2align 4
	.L__pc.17206: Dma_PatchDst (.L__pc.17206.ST), (.L__movme_cp.24), (.L__pc.17206.ST)
	.L__pc.17206.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17207
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17207: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17208
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17208: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17209
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17209: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17210
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17210: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17211
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.17211: Dma_PatchSrc (.L__pc.17211.LD), (.L__movme_cp.63), (.L__pc.17211.LD)
	.p2align 4
	.L__pc.17211.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17212
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17212: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17213
	.L__pc.17213: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17214
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17214: Dma_PatchSrc (.L__pc.17214.LD), (.L__movme_cp.24), (.L__pc.17214.LD)
	.p2align 4
	.L__pc.17214.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17215
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17215: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17216
	.L__pc.17216: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17217
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17217: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17218: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17219: Dma_PatchSrc (.L__pc.17219.LD), (.L__movme_tmp.1), (.L__pc.17219.LD)
	.p2align 4
	.L__pc.17219.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17220
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17220: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17221
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17221: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17222: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17223: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17224: Dma_PatchSrc (.L__pc.17224.LD), (.L__movme_tmp.1), (.L__pc.17224.LD)
	.p2align 4
	.L__pc.17224.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17225
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17225: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17226
	
	.L__pc.17226: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17227
	
	.p2align 4
	.L__pc.17227: Dma_PatchDst (.L__pc.17227.ST), (.L__movme_cp.63), (.L__pc.17227.ST)
	.L__pc.17227.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17228
	
	.L__pc.17228: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17229
	
	.p2align 4
	.L__pc.17229: Dma_PatchDst (.L__pc.17229.ST), (.L__movme_cp.24), (.L__pc.17229.ST)
	.L__pc.17229.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17230
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17230: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17231
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17231: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17232
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17232: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17233
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17233: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17234
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.17234: Dma_PatchSrc (.L__pc.17234.LD), (.L__movme_cp.66), (.L__pc.17234.LD)
	.p2align 4
	.L__pc.17234.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17235
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17235: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17236
	.L__pc.17236: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17237
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17237: Dma_PatchSrc (.L__pc.17237.LD), (.L__movme_cp.24), (.L__pc.17237.LD)
	.p2align 4
	.L__pc.17237.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17238
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17238: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17239
	.L__pc.17239: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17240
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17240: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17241: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17242: Dma_PatchSrc (.L__pc.17242.LD), (.L__movme_tmp.1), (.L__pc.17242.LD)
	.p2align 4
	.L__pc.17242.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17243
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17243: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17244
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17244: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17245: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17246: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17247: Dma_PatchSrc (.L__pc.17247.LD), (.L__movme_tmp.1), (.L__pc.17247.LD)
	.p2align 4
	.L__pc.17247.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17248
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17248: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17249
	
	.L__pc.17249: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17250
	
	.p2align 4
	.L__pc.17250: Dma_PatchDst (.L__pc.17250.ST), (.L__movme_cp.66), (.L__pc.17250.ST)
	.L__pc.17250.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17251
	
	.L__pc.17251: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17252
	
	.p2align 4
	.L__pc.17252: Dma_PatchDst (.L__pc.17252.ST), (.L__movme_cp.24), (.L__pc.17252.ST)
	.L__pc.17252.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17253
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17253: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17254
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17254: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17255
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17255: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17256
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17256: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17257
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.17257: Dma_PatchSrc (.L__pc.17257.LD), (.L__movme_cp.67), (.L__pc.17257.LD)
	.p2align 4
	.L__pc.17257.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17258
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17258: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17259
	.L__pc.17259: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17260
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17260: Dma_PatchSrc (.L__pc.17260.LD), (.L__movme_cp.24), (.L__pc.17260.LD)
	.p2align 4
	.L__pc.17260.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17261
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17261: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17262
	.L__pc.17262: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17263
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17263: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17264: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17265: Dma_PatchSrc (.L__pc.17265.LD), (.L__movme_tmp.1), (.L__pc.17265.LD)
	.p2align 4
	.L__pc.17265.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17266
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17266: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17267
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17267: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17268: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17269: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17270: Dma_PatchSrc (.L__pc.17270.LD), (.L__movme_tmp.1), (.L__pc.17270.LD)
	.p2align 4
	.L__pc.17270.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17271
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17271: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17272
	
	.L__pc.17272: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17273
	
	.p2align 4
	.L__pc.17273: Dma_PatchDst (.L__pc.17273.ST), (.L__movme_cp.67), (.L__pc.17273.ST)
	.L__pc.17273.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17274
	
	.L__pc.17274: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17275
	
	.p2align 4
	.L__pc.17275: Dma_PatchDst (.L__pc.17275.ST), (.L__movme_cp.24), (.L__pc.17275.ST)
	.L__pc.17275.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17276
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17276: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17277
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17277: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17278
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17278: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17279
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17279: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17280
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.17280: Dma_PatchSrc (.L__pc.17280.LD), (.L__movme_cp.68), (.L__pc.17280.LD)
	.p2align 4
	.L__pc.17280.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17281
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17281: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17282
	.L__pc.17282: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17283
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17283: Dma_PatchSrc (.L__pc.17283.LD), (.L__movme_cp.24), (.L__pc.17283.LD)
	.p2align 4
	.L__pc.17283.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17284
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17284: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17285
	.L__pc.17285: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17286
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17286: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17287: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17288: Dma_PatchSrc (.L__pc.17288.LD), (.L__movme_tmp.1), (.L__pc.17288.LD)
	.p2align 4
	.L__pc.17288.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17289
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17289: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17290
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17290: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17291: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17292: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17293: Dma_PatchSrc (.L__pc.17293.LD), (.L__movme_tmp.1), (.L__pc.17293.LD)
	.p2align 4
	.L__pc.17293.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17294
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17294: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17295
	
	.L__pc.17295: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17296
	
	.p2align 4
	.L__pc.17296: Dma_PatchDst (.L__pc.17296.ST), (.L__movme_cp.68), (.L__pc.17296.ST)
	.L__pc.17296.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17297
	
	.L__pc.17297: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17298
	
	.p2align 4
	.L__pc.17298: Dma_PatchDst (.L__pc.17298.ST), (.L__movme_cp.24), (.L__pc.17298.ST)
	.L__pc.17298.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17299
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17299: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17300
	
	.p2align 4
	.L__pc.17300: Dma_PatchDst (.L__pc.17300.ST), (.L__movme_cp.24), (.L__pc.17300.ST)
	.L__pc.17300.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17301
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.17301: Dma_PatchSrc (.L__pc.17301.LD), (.L__movme_cp.60), (.L__pc.17301.LD)
	.p2align 4
	.L__pc.17301.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17302
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17302: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17303
	
	.L__pc.17303: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17304
	
	.p2align 4
	.L__pc.17304: Dma_PatchDst (.L__pc.17304.ST), (.L__movme_cp.21), (.L__pc.17304.ST)
	.L__pc.17304.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17305
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.17305: Dma_PatchSrc (.L__pc.17305.LD), (.L__movme_cp.58), (.L__pc.17305.LD)
	.p2align 4
	.L__pc.17305.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17306
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17306: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17307
	
	.L__pc.17307: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17308
	
	.p2align 4
	.L__pc.17308: Dma_PatchDst (.L__pc.17308.ST), (.L__movme_cp.22), (.L__pc.17308.ST)
	.L__pc.17308.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17309
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17309: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17310
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17310: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17311
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17311: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17312
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17312: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17313
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.17313: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.17314
	
	.p2align 4
	.L__pc.17314: Dma_PatchDst (.L__pc.17314.ST), (.L__movme_cp.24), (.L__pc.17314.ST)
	.L__pc.17314.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17315
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.17315: Dma_PatchSrc (.L__pc.17315.LD), (.L__movme_cp.25), (.L__pc.17315.LD)
	.p2align 4
	.L__pc.17315.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17316
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17316: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17317
	.L__pc.17317: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17318
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.17318: Dma_PatchSrc (.L__pc.17318.LD), (.L__movme_cp.26), (.L__pc.17318.LD)
	.p2align 4
	.L__pc.17318.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17319
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17319: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17320
	.L__pc.17320: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17321
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17321: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17322: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17323: Dma_PatchSrc (.L__pc.17323.LD), (.L__movme_tmp.1), (.L__pc.17323.LD)
	.p2align 4
	.L__pc.17323.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17324
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17324: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17325
	.L__pc.17325: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17326
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17326: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17327: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17328: Dma_PatchSrc (.L__pc.17328.LD), (.L__movme_tmp.1), (.L__pc.17328.LD)
	.p2align 4
	.L__pc.17328.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17329
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17329: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17330
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17330: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17331: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17332: Dma_PatchSrc (.L__pc.17332.LD), (.L__movme_tmp.1), (.L__pc.17332.LD)
	.p2align 4
	.L__pc.17332.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17333
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17333: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17334
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17334: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17335: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17336: Dma_PatchSrc (.L__pc.17336.LD), (.L__movme_tmp.1), (.L__pc.17336.LD)
	.p2align 4
	.L__pc.17336.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17337
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17337: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17338
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17338: Dma_PatchSrc (.L__pc.17338.LD), (.L__movme_cp.24), (.L__pc.17338.LD)
	.p2align 4
	.L__pc.17338.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17339
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17339: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17340
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17340: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17341: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17342: Dma_PatchSrc (.L__pc.17342.LD), (.L__movme_tmp.1), (.L__pc.17342.LD)
	.p2align 4
	.L__pc.17342.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17343
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17343: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17344
	
	.L__pc.17344: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17345
	
	.p2align 4
	.L__pc.17345: Dma_PatchDst (.L__pc.17345.ST), (.L__movme_cp.69), (.L__pc.17345.ST)
	.L__pc.17345.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17346
	
	.L__pc.17346: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17347
	
	.p2align 4
	.L__pc.17347: Dma_PatchDst (.L__pc.17347.ST), (.L__movme_cp.54), (.L__pc.17347.ST)
	.L__pc.17347.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17348
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.17348: Dma_PatchSrc (.L__pc.17348.LD), (.L__movme_cp.30), (.L__pc.17348.LD)
	.p2align 4
	.L__pc.17348.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17349
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17349: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17350
	.L__pc.17350: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17351
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.17351: Dma_PatchSrc (.L__pc.17351.LD), (.L__movme_cp.31), (.L__pc.17351.LD)
	.p2align 4
	.L__pc.17351.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17352
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17352: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17353
	.L__pc.17353: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17354
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17354: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17355: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17356: Dma_PatchSrc (.L__pc.17356.LD), (.L__movme_tmp.1), (.L__pc.17356.LD)
	.p2align 4
	.L__pc.17356.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17357
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17357: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17358
	.L__pc.17358: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17359
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17359: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17360: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17361: Dma_PatchSrc (.L__pc.17361.LD), (.L__movme_tmp.1), (.L__pc.17361.LD)
	.p2align 4
	.L__pc.17361.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17362
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17362: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17363
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17363: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17364: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17365: Dma_PatchSrc (.L__pc.17365.LD), (.L__movme_tmp.1), (.L__pc.17365.LD)
	.p2align 4
	.L__pc.17365.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17366
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17366: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17367
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17367: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17368: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17369: Dma_PatchSrc (.L__pc.17369.LD), (.L__movme_tmp.1), (.L__pc.17369.LD)
	.p2align 4
	.L__pc.17369.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17370
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17370: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17371
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17371: Dma_PatchSrc (.L__pc.17371.LD), (.L__movme_cp.24), (.L__pc.17371.LD)
	.p2align 4
	.L__pc.17371.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17372
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17372: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17373
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17373: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17374: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17375: Dma_PatchSrc (.L__pc.17375.LD), (.L__movme_tmp.1), (.L__pc.17375.LD)
	.p2align 4
	.L__pc.17375.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17376
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17376: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17377
	
	.L__pc.17377: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17378
	
	.p2align 4
	.L__pc.17378: Dma_PatchDst (.L__pc.17378.ST), (.L__movme_cp.70), (.L__pc.17378.ST)
	.L__pc.17378.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17379
	
	.L__pc.17379: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17380
	
	.p2align 4
	.L__pc.17380: Dma_PatchDst (.L__pc.17380.ST), (.L__movme_cp.54), (.L__pc.17380.ST)
	.L__pc.17380.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17381
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17381: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17382
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17382: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17383
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17383: Dma_PatchSrc (.L__pc.17383.LD), (.L__movme_cp.24), (.L__pc.17383.LD)
	.p2align 4
	.L__pc.17383.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17384
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17384: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17385
	.L__pc.17385: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17386
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.17386: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17387: Dma_PatchSrc (.L__pc.17387.LD), (.L__movme_tmp.1), (.L__pc.17387.LD)
	.p2align 4
	.L__pc.17387.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17388
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17388: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17389
	.L__pc.17389: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17390
	
	.L__pc.17390: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17391
	
	.p2align 4
	.L__pc.17391: Dma_PatchDst (.L__pc.17391.ST), (.L__movme_cp.72), (.L__pc.17391.ST)
	.L__pc.17391.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17392
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.17392: Dma_PatchSrc (.L__pc.17392.LD), (.L__movme_cp.72), (.L__pc.17392.LD)
	.p2align 4
	.L__pc.17392.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17393
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17393: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17394
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17394: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17395: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17396: Dma_PatchSrc (.L__pc.17396.LD), (.L__movme_tmp.1), (.L__pc.17396.LD)
	.p2align 4
	.L__pc.17396.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17397
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17397: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17398
	
	.L__pc.17398: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17399
	
	.p2align 4
	.L__pc.17399: Dma_PatchDst (.L__pc.17399.ST), (.L__movme_cp.74), (.L__pc.17399.ST)
	.L__pc.17399.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17400
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17400: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17401: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17402: Dma_PatchSrc (.L__pc.17402.LD), (.L__movme_tmp.1), (.L__pc.17402.LD)
	.p2align 4
	.L__pc.17402.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17403
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17403: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17404
	
	.L__pc.17404: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17405
	
	.p2align 4
	.L__pc.17405: Dma_PatchDst (.L__pc.17405.ST), (.L__movme_cp.76), (.L__pc.17405.ST)
	.L__pc.17405.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17406
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.17406: Dma_PatchSrc (.L__pc.17406.LD), (.L__movme_cp.74), (.L__pc.17406.LD)
	.p2align 4
	.L__pc.17406.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17407
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17407: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17408
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.17408: Dma_PatchSrc (.L__pc.17408.LD), ((.L__movme.reg.eax+0)), (.L__pc.17408.LD)
	.p2align 4
	.L__pc.17408.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17409
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17409: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17410
	
	.L__pc.17410: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17411
	
	.p2align 4
	.L__pc.17411: Dma_PatchDst (.L__pc.17411.ST), (.L__movme_cp.77), (.L__pc.17411.ST)
	.L__pc.17411.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17412
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.17412: Dma_PatchSrc (.L__pc.17412.LD), (.L__movme_cp.77), (.L__pc.17412.LD)
	.p2align 4
	.L__pc.17412.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17413
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17413: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17414
	
	.L__pc.17414: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17415
	
	.p2align 4
	.L__pc.17415: Dma_PatchDst (.L__pc.17415.ST), (.L__movme_cp.21), (.L__pc.17415.ST)
	.L__pc.17415.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17416
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.17416: Dma_PatchSrc (.L__pc.17416.LD), (.L__movme_cp.58), (.L__pc.17416.LD)
	.p2align 4
	.L__pc.17416.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17417
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17417: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17418
	
	.L__pc.17418: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17419
	
	.p2align 4
	.L__pc.17419: Dma_PatchDst (.L__pc.17419.ST), (.L__movme_cp.22), (.L__pc.17419.ST)
	.L__pc.17419.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17420
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17420: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17421
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17421: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17422
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17422: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17423
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17423: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17424
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.17424: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.17425
	
	.p2align 4
	.L__pc.17425: Dma_PatchDst (.L__pc.17425.ST), (.L__movme_cp.24), (.L__pc.17425.ST)
	.L__pc.17425.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17426
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.17426: Dma_PatchSrc (.L__pc.17426.LD), (.L__movme_cp.25), (.L__pc.17426.LD)
	.p2align 4
	.L__pc.17426.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17427
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17427: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17428
	.L__pc.17428: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17429
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.17429: Dma_PatchSrc (.L__pc.17429.LD), (.L__movme_cp.26), (.L__pc.17429.LD)
	.p2align 4
	.L__pc.17429.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17430
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17430: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17431
	.L__pc.17431: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17432
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17432: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17433: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17434: Dma_PatchSrc (.L__pc.17434.LD), (.L__movme_tmp.1), (.L__pc.17434.LD)
	.p2align 4
	.L__pc.17434.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17435
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17435: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17436
	.L__pc.17436: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17437
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17437: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17438: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17439: Dma_PatchSrc (.L__pc.17439.LD), (.L__movme_tmp.1), (.L__pc.17439.LD)
	.p2align 4
	.L__pc.17439.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17440
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17440: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17441
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17441: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17442: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17443: Dma_PatchSrc (.L__pc.17443.LD), (.L__movme_tmp.1), (.L__pc.17443.LD)
	.p2align 4
	.L__pc.17443.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17444
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17444: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17445
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17445: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17446: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17447: Dma_PatchSrc (.L__pc.17447.LD), (.L__movme_tmp.1), (.L__pc.17447.LD)
	.p2align 4
	.L__pc.17447.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17448
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17448: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17449
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17449: Dma_PatchSrc (.L__pc.17449.LD), (.L__movme_cp.24), (.L__pc.17449.LD)
	.p2align 4
	.L__pc.17449.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17450
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17450: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17451
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17451: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17452: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17453: Dma_PatchSrc (.L__pc.17453.LD), (.L__movme_tmp.1), (.L__pc.17453.LD)
	.p2align 4
	.L__pc.17453.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17454
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17454: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17455
	
	.L__pc.17455: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17456
	
	.p2align 4
	.L__pc.17456: Dma_PatchDst (.L__pc.17456.ST), (.L__movme_cp.78), (.L__pc.17456.ST)
	.L__pc.17456.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17457
	
	.L__pc.17457: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17458
	
	.p2align 4
	.L__pc.17458: Dma_PatchDst (.L__pc.17458.ST), (.L__movme_cp.54), (.L__pc.17458.ST)
	.L__pc.17458.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17459
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.17459: Dma_PatchSrc (.L__pc.17459.LD), (.L__movme_cp.30), (.L__pc.17459.LD)
	.p2align 4
	.L__pc.17459.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17460
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17460: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17461
	.L__pc.17461: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17462
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.17462: Dma_PatchSrc (.L__pc.17462.LD), (.L__movme_cp.31), (.L__pc.17462.LD)
	.p2align 4
	.L__pc.17462.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17463
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17463: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17464
	.L__pc.17464: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17465
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17465: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17466: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17467: Dma_PatchSrc (.L__pc.17467.LD), (.L__movme_tmp.1), (.L__pc.17467.LD)
	.p2align 4
	.L__pc.17467.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17468
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17468: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17469
	.L__pc.17469: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17470
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17470: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17471: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17472: Dma_PatchSrc (.L__pc.17472.LD), (.L__movme_tmp.1), (.L__pc.17472.LD)
	.p2align 4
	.L__pc.17472.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17473
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17473: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17474
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17474: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17475: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17476: Dma_PatchSrc (.L__pc.17476.LD), (.L__movme_tmp.1), (.L__pc.17476.LD)
	.p2align 4
	.L__pc.17476.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17477
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17477: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17478
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17478: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17479: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17480: Dma_PatchSrc (.L__pc.17480.LD), (.L__movme_tmp.1), (.L__pc.17480.LD)
	.p2align 4
	.L__pc.17480.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17481
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17481: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17482
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17482: Dma_PatchSrc (.L__pc.17482.LD), (.L__movme_cp.24), (.L__pc.17482.LD)
	.p2align 4
	.L__pc.17482.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17483
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17483: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17484
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17484: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17485: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17486: Dma_PatchSrc (.L__pc.17486.LD), (.L__movme_tmp.1), (.L__pc.17486.LD)
	.p2align 4
	.L__pc.17486.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17487
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17487: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17488
	
	.L__pc.17488: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17489
	
	.p2align 4
	.L__pc.17489: Dma_PatchDst (.L__pc.17489.ST), (.L__movme_cp.79), (.L__pc.17489.ST)
	.L__pc.17489.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17490
	
	.L__pc.17490: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17491
	
	.p2align 4
	.L__pc.17491: Dma_PatchDst (.L__pc.17491.ST), (.L__movme_cp.54), (.L__pc.17491.ST)
	.L__pc.17491.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17492
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.17492: Dma_PatchSrc (.L__pc.17492.LD), (.L__movme_cp.74), (.L__pc.17492.LD)
	.p2align 4
	.L__pc.17492.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17493
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17493: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17494
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.17494: Dma_PatchSrc (.L__pc.17494.LD), (.L__movme_cp.77), (.L__pc.17494.LD)
	.p2align 4
	.L__pc.17494.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17495
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17495: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17496
	
	.L__pc.17496: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17497
	
	.p2align 4
	.L__pc.17497: Dma_PatchDst (.L__pc.17497.ST), ((.L__movme.reg.eax+0)), (.L__pc.17497.ST)
	.L__pc.17497.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17498
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.17498: Dma_PatchSrc (.L__pc.17498.LD), (.L__movme_cp.76), (.L__pc.17498.LD)
	.p2align 4
	.L__pc.17498.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17499
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17499: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17500
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.17500: Dma_PatchSrc (.L__pc.17500.LD), ((.L__movme.reg.eax+0)), (.L__pc.17500.LD)
	.p2align 4
	.L__pc.17500.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17501
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17501: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17502
	
	.L__pc.17502: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17503
	
	.p2align 4
	.L__pc.17503: Dma_PatchDst (.L__pc.17503.ST), (.L__movme_cp.80), (.L__pc.17503.ST)
	.L__pc.17503.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17504
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17504: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17505
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17505: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17506
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.17506: Dma_PatchSrc (.L__pc.17506.LD), (.L__movme_cp.98), (.L__pc.17506.LD)
	.p2align 4
	.L__pc.17506.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17507
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17507: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17508
	.L__pc.17508: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17509
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.94 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.17509: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17510: Dma_PatchSrc (.L__pc.17510.LD), (.L__movme_tmp.1), (.L__pc.17510.LD)
	.p2align 4
	.L__pc.17510.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17511
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17511: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17512
	.L__pc.17512: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17513
	
	.L__pc.17513: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17514
	
	.p2align 4
	.L__pc.17514: Dma_PatchDst (.L__pc.17514.ST), (.L__movme_cp.98), (.L__pc.17514.ST)
	.L__pc.17514.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17515
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.17515: Dma_PatchSrc (.L__pc.17515.LD), (.L__movme_cp.76), (.L__pc.17515.LD)
	.p2align 4
	.L__pc.17515.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17516
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17516: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17517
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.17517: Dma_PatchSrc (.L__pc.17517.LD), (.L__movme_cp.80), (.L__pc.17517.LD)
	.p2align 4
	.L__pc.17517.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17518
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17518: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17519
	
	.L__pc.17519: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17520
	
	.p2align 4
	.L__pc.17520: Dma_PatchDst (.L__pc.17520.ST), ((.L__movme.reg.eax+0)), (.L__pc.17520.ST)
	.L__pc.17520.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17521
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17521: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17522
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17522: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17523
	
	// CG.LOAD4 [.L__movme_cp.97} => .L__movme_tmp.0
	.L__pc.17523: Dma_PatchSrc (.L__pc.17523.LD), (.L__movme_cp.97), (.L__pc.17523.LD)
	.p2align 4
	.L__pc.17523.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17524
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17524: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17525
	.L__pc.17525: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17526
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17526: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.95 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17527: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17528: Dma_PatchSrc (.L__pc.17528.LD), (.L__movme_tmp.1), (.L__pc.17528.LD)
	.p2align 4
	.L__pc.17528.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17529
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17529: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17530
	
	.L__pc.17530: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17531
	
	.p2align 4
	.L__pc.17531: Dma_PatchDst (.L__pc.17531.ST), (.L__movme_cp.24), (.L__pc.17531.ST)
	.L__pc.17531.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17532
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17532: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17533
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17533: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17534
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17534: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17535
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17535: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17536
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.17536: Dma_PatchSrc (.L__pc.17536.LD), (.L__movme_cp.63), (.L__pc.17536.LD)
	.p2align 4
	.L__pc.17536.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17537
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17537: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17538
	.L__pc.17538: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17539
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17539: Dma_PatchSrc (.L__pc.17539.LD), (.L__movme_cp.24), (.L__pc.17539.LD)
	.p2align 4
	.L__pc.17539.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17540
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17540: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17541
	.L__pc.17541: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17542
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17542: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17543: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17544: Dma_PatchSrc (.L__pc.17544.LD), (.L__movme_tmp.1), (.L__pc.17544.LD)
	.p2align 4
	.L__pc.17544.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17545
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17545: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17546
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17546: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17547: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17548: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17549: Dma_PatchSrc (.L__pc.17549.LD), (.L__movme_tmp.1), (.L__pc.17549.LD)
	.p2align 4
	.L__pc.17549.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17550
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17550: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17551
	
	.L__pc.17551: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17552
	
	.p2align 4
	.L__pc.17552: Dma_PatchDst (.L__pc.17552.ST), (.L__movme_cp.63), (.L__pc.17552.ST)
	.L__pc.17552.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17553
	
	.L__pc.17553: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17554
	
	.p2align 4
	.L__pc.17554: Dma_PatchDst (.L__pc.17554.ST), (.L__movme_cp.24), (.L__pc.17554.ST)
	.L__pc.17554.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17555
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17555: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17556
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17556: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17557
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17557: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17558
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17558: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17559
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.17559: Dma_PatchSrc (.L__pc.17559.LD), (.L__movme_cp.66), (.L__pc.17559.LD)
	.p2align 4
	.L__pc.17559.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17560
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17560: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17561
	.L__pc.17561: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17562
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17562: Dma_PatchSrc (.L__pc.17562.LD), (.L__movme_cp.24), (.L__pc.17562.LD)
	.p2align 4
	.L__pc.17562.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17563
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17563: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17564
	.L__pc.17564: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17565
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17565: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17566: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17567: Dma_PatchSrc (.L__pc.17567.LD), (.L__movme_tmp.1), (.L__pc.17567.LD)
	.p2align 4
	.L__pc.17567.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17568
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17568: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17569
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17569: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17570: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17571: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17572: Dma_PatchSrc (.L__pc.17572.LD), (.L__movme_tmp.1), (.L__pc.17572.LD)
	.p2align 4
	.L__pc.17572.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17573
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17573: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17574
	
	.L__pc.17574: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17575
	
	.p2align 4
	.L__pc.17575: Dma_PatchDst (.L__pc.17575.ST), (.L__movme_cp.66), (.L__pc.17575.ST)
	.L__pc.17575.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17576
	
	.L__pc.17576: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17577
	
	.p2align 4
	.L__pc.17577: Dma_PatchDst (.L__pc.17577.ST), (.L__movme_cp.24), (.L__pc.17577.ST)
	.L__pc.17577.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17578
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17578: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17579
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17579: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17580
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17580: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17581
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17581: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17582
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.17582: Dma_PatchSrc (.L__pc.17582.LD), (.L__movme_cp.67), (.L__pc.17582.LD)
	.p2align 4
	.L__pc.17582.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17583
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17583: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17584
	.L__pc.17584: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17585
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17585: Dma_PatchSrc (.L__pc.17585.LD), (.L__movme_cp.24), (.L__pc.17585.LD)
	.p2align 4
	.L__pc.17585.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17586
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17586: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17587
	.L__pc.17587: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17588
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17588: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17589: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17590: Dma_PatchSrc (.L__pc.17590.LD), (.L__movme_tmp.1), (.L__pc.17590.LD)
	.p2align 4
	.L__pc.17590.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17591
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17591: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17592
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17592: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17593: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17594: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17595: Dma_PatchSrc (.L__pc.17595.LD), (.L__movme_tmp.1), (.L__pc.17595.LD)
	.p2align 4
	.L__pc.17595.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17596
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17596: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17597
	
	.L__pc.17597: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17598
	
	.p2align 4
	.L__pc.17598: Dma_PatchDst (.L__pc.17598.ST), (.L__movme_cp.67), (.L__pc.17598.ST)
	.L__pc.17598.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17599
	
	.L__pc.17599: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17600
	
	.p2align 4
	.L__pc.17600: Dma_PatchDst (.L__pc.17600.ST), (.L__movme_cp.24), (.L__pc.17600.ST)
	.L__pc.17600.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17601
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17601: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17602
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17602: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17603
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17603: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17604
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17604: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17605
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.17605: Dma_PatchSrc (.L__pc.17605.LD), (.L__movme_cp.68), (.L__pc.17605.LD)
	.p2align 4
	.L__pc.17605.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17606
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17606: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17607
	.L__pc.17607: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17608
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17608: Dma_PatchSrc (.L__pc.17608.LD), (.L__movme_cp.24), (.L__pc.17608.LD)
	.p2align 4
	.L__pc.17608.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17609
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17609: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17610
	.L__pc.17610: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17611
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17611: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17612: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17613: Dma_PatchSrc (.L__pc.17613.LD), (.L__movme_tmp.1), (.L__pc.17613.LD)
	.p2align 4
	.L__pc.17613.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17614
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17614: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17615
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17615: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17616: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17617: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17618: Dma_PatchSrc (.L__pc.17618.LD), (.L__movme_tmp.1), (.L__pc.17618.LD)
	.p2align 4
	.L__pc.17618.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17619
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17619: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17620
	
	.L__pc.17620: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17621
	
	.p2align 4
	.L__pc.17621: Dma_PatchDst (.L__pc.17621.ST), (.L__movme_cp.68), (.L__pc.17621.ST)
	.L__pc.17621.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17622
	
	.L__pc.17622: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17623
	
	.p2align 4
	.L__pc.17623: Dma_PatchDst (.L__pc.17623.ST), (.L__movme_cp.24), (.L__pc.17623.ST)
	.L__pc.17623.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17624
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17624: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17625
	
	.p2align 4
	.L__pc.17625: Dma_PatchDst (.L__pc.17625.ST), (.L__movme_cp.24), (.L__pc.17625.ST)
	.L__pc.17625.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17626
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.17626: Dma_PatchSrc (.L__pc.17626.LD), (.L__movme_cp.60), (.L__pc.17626.LD)
	.p2align 4
	.L__pc.17626.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17627
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17627: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17628
	
	.L__pc.17628: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17629
	
	.p2align 4
	.L__pc.17629: Dma_PatchDst (.L__pc.17629.ST), (.L__movme_cp.21), (.L__pc.17629.ST)
	.L__pc.17629.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17630
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.17630: Dma_PatchSrc (.L__pc.17630.LD), (.L__movme_cp.58), (.L__pc.17630.LD)
	.p2align 4
	.L__pc.17630.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17631
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17631: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17632
	
	.L__pc.17632: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17633
	
	.p2align 4
	.L__pc.17633: Dma_PatchDst (.L__pc.17633.ST), (.L__movme_cp.22), (.L__pc.17633.ST)
	.L__pc.17633.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17634
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17634: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17635
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17635: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17636
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17636: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17637
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17637: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17638
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.17638: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.17639
	
	.p2align 4
	.L__pc.17639: Dma_PatchDst (.L__pc.17639.ST), (.L__movme_cp.24), (.L__pc.17639.ST)
	.L__pc.17639.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17640
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.17640: Dma_PatchSrc (.L__pc.17640.LD), (.L__movme_cp.25), (.L__pc.17640.LD)
	.p2align 4
	.L__pc.17640.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17641
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17641: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17642
	.L__pc.17642: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17643
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.17643: Dma_PatchSrc (.L__pc.17643.LD), (.L__movme_cp.26), (.L__pc.17643.LD)
	.p2align 4
	.L__pc.17643.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17644
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17644: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17645
	.L__pc.17645: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17646
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17646: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17647: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17648: Dma_PatchSrc (.L__pc.17648.LD), (.L__movme_tmp.1), (.L__pc.17648.LD)
	.p2align 4
	.L__pc.17648.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17649
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17649: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17650
	.L__pc.17650: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17651
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17651: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17652: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17653: Dma_PatchSrc (.L__pc.17653.LD), (.L__movme_tmp.1), (.L__pc.17653.LD)
	.p2align 4
	.L__pc.17653.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17654
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17654: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17655
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17655: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17656: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17657: Dma_PatchSrc (.L__pc.17657.LD), (.L__movme_tmp.1), (.L__pc.17657.LD)
	.p2align 4
	.L__pc.17657.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17658
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17658: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17659
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17659: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17660: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17661: Dma_PatchSrc (.L__pc.17661.LD), (.L__movme_tmp.1), (.L__pc.17661.LD)
	.p2align 4
	.L__pc.17661.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17662
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17662: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17663
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17663: Dma_PatchSrc (.L__pc.17663.LD), (.L__movme_cp.24), (.L__pc.17663.LD)
	.p2align 4
	.L__pc.17663.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17664
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17664: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17665
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17665: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17666: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17667: Dma_PatchSrc (.L__pc.17667.LD), (.L__movme_tmp.1), (.L__pc.17667.LD)
	.p2align 4
	.L__pc.17667.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17668
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17668: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17669
	
	.L__pc.17669: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17670
	
	.p2align 4
	.L__pc.17670: Dma_PatchDst (.L__pc.17670.ST), (.L__movme_cp.69), (.L__pc.17670.ST)
	.L__pc.17670.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17671
	
	.L__pc.17671: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17672
	
	.p2align 4
	.L__pc.17672: Dma_PatchDst (.L__pc.17672.ST), (.L__movme_cp.54), (.L__pc.17672.ST)
	.L__pc.17672.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17673
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.17673: Dma_PatchSrc (.L__pc.17673.LD), (.L__movme_cp.30), (.L__pc.17673.LD)
	.p2align 4
	.L__pc.17673.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17674
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17674: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17675
	.L__pc.17675: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17676
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.17676: Dma_PatchSrc (.L__pc.17676.LD), (.L__movme_cp.31), (.L__pc.17676.LD)
	.p2align 4
	.L__pc.17676.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17677
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17677: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17678
	.L__pc.17678: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17679
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17679: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17680: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17681: Dma_PatchSrc (.L__pc.17681.LD), (.L__movme_tmp.1), (.L__pc.17681.LD)
	.p2align 4
	.L__pc.17681.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17682
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17682: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17683
	.L__pc.17683: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17684
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17684: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17685: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17686: Dma_PatchSrc (.L__pc.17686.LD), (.L__movme_tmp.1), (.L__pc.17686.LD)
	.p2align 4
	.L__pc.17686.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17687
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17687: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17688
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17688: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17689: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17690: Dma_PatchSrc (.L__pc.17690.LD), (.L__movme_tmp.1), (.L__pc.17690.LD)
	.p2align 4
	.L__pc.17690.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17691
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17691: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17692
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17692: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17693: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17694: Dma_PatchSrc (.L__pc.17694.LD), (.L__movme_tmp.1), (.L__pc.17694.LD)
	.p2align 4
	.L__pc.17694.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17695
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17695: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17696
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17696: Dma_PatchSrc (.L__pc.17696.LD), (.L__movme_cp.24), (.L__pc.17696.LD)
	.p2align 4
	.L__pc.17696.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17697
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17697: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17698
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17698: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17699: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17700: Dma_PatchSrc (.L__pc.17700.LD), (.L__movme_tmp.1), (.L__pc.17700.LD)
	.p2align 4
	.L__pc.17700.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17701
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17701: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17702
	
	.L__pc.17702: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17703
	
	.p2align 4
	.L__pc.17703: Dma_PatchDst (.L__pc.17703.ST), (.L__movme_cp.70), (.L__pc.17703.ST)
	.L__pc.17703.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17704
	
	.L__pc.17704: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17705
	
	.p2align 4
	.L__pc.17705: Dma_PatchDst (.L__pc.17705.ST), (.L__movme_cp.54), (.L__pc.17705.ST)
	.L__pc.17705.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17706
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17706: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17707
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17707: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17708
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17708: Dma_PatchSrc (.L__pc.17708.LD), (.L__movme_cp.24), (.L__pc.17708.LD)
	.p2align 4
	.L__pc.17708.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17709
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17709: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17710
	.L__pc.17710: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17711
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.17711: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17712: Dma_PatchSrc (.L__pc.17712.LD), (.L__movme_tmp.1), (.L__pc.17712.LD)
	.p2align 4
	.L__pc.17712.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17713
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17713: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17714
	.L__pc.17714: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17715
	
	.L__pc.17715: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17716
	
	.p2align 4
	.L__pc.17716: Dma_PatchDst (.L__pc.17716.ST), (.L__movme_cp.72), (.L__pc.17716.ST)
	.L__pc.17716.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17717
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.17717: Dma_PatchSrc (.L__pc.17717.LD), (.L__movme_cp.72), (.L__pc.17717.LD)
	.p2align 4
	.L__pc.17717.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17718
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17718: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17719
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17719: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17720: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17721: Dma_PatchSrc (.L__pc.17721.LD), (.L__movme_tmp.1), (.L__pc.17721.LD)
	.p2align 4
	.L__pc.17721.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17722
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17722: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17723
	
	.L__pc.17723: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17724
	
	.p2align 4
	.L__pc.17724: Dma_PatchDst (.L__pc.17724.ST), (.L__movme_cp.74), (.L__pc.17724.ST)
	.L__pc.17724.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17725
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17725: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17726: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17727: Dma_PatchSrc (.L__pc.17727.LD), (.L__movme_tmp.1), (.L__pc.17727.LD)
	.p2align 4
	.L__pc.17727.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17728
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17728: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17729
	
	.L__pc.17729: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17730
	
	.p2align 4
	.L__pc.17730: Dma_PatchDst (.L__pc.17730.ST), (.L__movme_cp.76), (.L__pc.17730.ST)
	.L__pc.17730.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17731
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.17731: Dma_PatchSrc (.L__pc.17731.LD), (.L__movme_cp.74), (.L__pc.17731.LD)
	.p2align 4
	.L__pc.17731.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17732
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17732: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17733
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.17733: Dma_PatchSrc (.L__pc.17733.LD), ((.L__movme.reg.eax+0)), (.L__pc.17733.LD)
	.p2align 4
	.L__pc.17733.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17734
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17734: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17735
	
	.L__pc.17735: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17736
	
	.p2align 4
	.L__pc.17736: Dma_PatchDst (.L__pc.17736.ST), (.L__movme_cp.77), (.L__pc.17736.ST)
	.L__pc.17736.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17737
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.17737: Dma_PatchSrc (.L__pc.17737.LD), (.L__movme_cp.77), (.L__pc.17737.LD)
	.p2align 4
	.L__pc.17737.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17738
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17738: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17739
	
	.L__pc.17739: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17740
	
	.p2align 4
	.L__pc.17740: Dma_PatchDst (.L__pc.17740.ST), (.L__movme_cp.21), (.L__pc.17740.ST)
	.L__pc.17740.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17741
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.17741: Dma_PatchSrc (.L__pc.17741.LD), (.L__movme_cp.58), (.L__pc.17741.LD)
	.p2align 4
	.L__pc.17741.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17742
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17742: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17743
	
	.L__pc.17743: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17744
	
	.p2align 4
	.L__pc.17744: Dma_PatchDst (.L__pc.17744.ST), (.L__movme_cp.22), (.L__pc.17744.ST)
	.L__pc.17744.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17745
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17745: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17746
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17746: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17747
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17747: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17748
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17748: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17749
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.17749: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.17750
	
	.p2align 4
	.L__pc.17750: Dma_PatchDst (.L__pc.17750.ST), (.L__movme_cp.24), (.L__pc.17750.ST)
	.L__pc.17750.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17751
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.17751: Dma_PatchSrc (.L__pc.17751.LD), (.L__movme_cp.25), (.L__pc.17751.LD)
	.p2align 4
	.L__pc.17751.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17752
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17752: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17753
	.L__pc.17753: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17754
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.17754: Dma_PatchSrc (.L__pc.17754.LD), (.L__movme_cp.26), (.L__pc.17754.LD)
	.p2align 4
	.L__pc.17754.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17755
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17755: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17756
	.L__pc.17756: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17757
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17757: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17758: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17759: Dma_PatchSrc (.L__pc.17759.LD), (.L__movme_tmp.1), (.L__pc.17759.LD)
	.p2align 4
	.L__pc.17759.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17760
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17760: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17761
	.L__pc.17761: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17762
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17762: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17763: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17764: Dma_PatchSrc (.L__pc.17764.LD), (.L__movme_tmp.1), (.L__pc.17764.LD)
	.p2align 4
	.L__pc.17764.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17765
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17765: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17766
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17766: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17767: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17768: Dma_PatchSrc (.L__pc.17768.LD), (.L__movme_tmp.1), (.L__pc.17768.LD)
	.p2align 4
	.L__pc.17768.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17769
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17769: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17770
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17770: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17771: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17772: Dma_PatchSrc (.L__pc.17772.LD), (.L__movme_tmp.1), (.L__pc.17772.LD)
	.p2align 4
	.L__pc.17772.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17773
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17773: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17774
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17774: Dma_PatchSrc (.L__pc.17774.LD), (.L__movme_cp.24), (.L__pc.17774.LD)
	.p2align 4
	.L__pc.17774.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17775
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17775: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17776
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17776: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17777: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17778: Dma_PatchSrc (.L__pc.17778.LD), (.L__movme_tmp.1), (.L__pc.17778.LD)
	.p2align 4
	.L__pc.17778.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17779
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17779: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17780
	
	.L__pc.17780: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17781
	
	.p2align 4
	.L__pc.17781: Dma_PatchDst (.L__pc.17781.ST), (.L__movme_cp.78), (.L__pc.17781.ST)
	.L__pc.17781.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17782
	
	.L__pc.17782: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17783
	
	.p2align 4
	.L__pc.17783: Dma_PatchDst (.L__pc.17783.ST), (.L__movme_cp.54), (.L__pc.17783.ST)
	.L__pc.17783.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17784
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.17784: Dma_PatchSrc (.L__pc.17784.LD), (.L__movme_cp.30), (.L__pc.17784.LD)
	.p2align 4
	.L__pc.17784.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17785
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17785: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17786
	.L__pc.17786: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17787
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.17787: Dma_PatchSrc (.L__pc.17787.LD), (.L__movme_cp.31), (.L__pc.17787.LD)
	.p2align 4
	.L__pc.17787.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17788
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17788: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17789
	.L__pc.17789: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17790
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17790: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17791: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17792: Dma_PatchSrc (.L__pc.17792.LD), (.L__movme_tmp.1), (.L__pc.17792.LD)
	.p2align 4
	.L__pc.17792.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17793
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17793: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17794
	.L__pc.17794: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17795
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17795: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17796: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17797: Dma_PatchSrc (.L__pc.17797.LD), (.L__movme_tmp.1), (.L__pc.17797.LD)
	.p2align 4
	.L__pc.17797.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17798
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17798: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17799
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17799: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17800: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17801: Dma_PatchSrc (.L__pc.17801.LD), (.L__movme_tmp.1), (.L__pc.17801.LD)
	.p2align 4
	.L__pc.17801.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17802
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17802: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17803
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17803: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17804: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17805: Dma_PatchSrc (.L__pc.17805.LD), (.L__movme_tmp.1), (.L__pc.17805.LD)
	.p2align 4
	.L__pc.17805.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17806
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17806: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17807
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17807: Dma_PatchSrc (.L__pc.17807.LD), (.L__movme_cp.24), (.L__pc.17807.LD)
	.p2align 4
	.L__pc.17807.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17808
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17808: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17809
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17809: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17810: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17811: Dma_PatchSrc (.L__pc.17811.LD), (.L__movme_tmp.1), (.L__pc.17811.LD)
	.p2align 4
	.L__pc.17811.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17812
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17812: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17813
	
	.L__pc.17813: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17814
	
	.p2align 4
	.L__pc.17814: Dma_PatchDst (.L__pc.17814.ST), (.L__movme_cp.79), (.L__pc.17814.ST)
	.L__pc.17814.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17815
	
	.L__pc.17815: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17816
	
	.p2align 4
	.L__pc.17816: Dma_PatchDst (.L__pc.17816.ST), (.L__movme_cp.54), (.L__pc.17816.ST)
	.L__pc.17816.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17817
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.17817: Dma_PatchSrc (.L__pc.17817.LD), (.L__movme_cp.74), (.L__pc.17817.LD)
	.p2align 4
	.L__pc.17817.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17818
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17818: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17819
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.17819: Dma_PatchSrc (.L__pc.17819.LD), (.L__movme_cp.77), (.L__pc.17819.LD)
	.p2align 4
	.L__pc.17819.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17820
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17820: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17821
	
	.L__pc.17821: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17822
	
	.p2align 4
	.L__pc.17822: Dma_PatchDst (.L__pc.17822.ST), ((.L__movme.reg.eax+0)), (.L__pc.17822.ST)
	.L__pc.17822.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17823
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.17823: Dma_PatchSrc (.L__pc.17823.LD), (.L__movme_cp.76), (.L__pc.17823.LD)
	.p2align 4
	.L__pc.17823.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17824
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17824: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17825
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.17825: Dma_PatchSrc (.L__pc.17825.LD), ((.L__movme.reg.eax+0)), (.L__pc.17825.LD)
	.p2align 4
	.L__pc.17825.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17826
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17826: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17827
	
	.L__pc.17827: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17828
	
	.p2align 4
	.L__pc.17828: Dma_PatchDst (.L__pc.17828.ST), (.L__movme_cp.80), (.L__pc.17828.ST)
	.L__pc.17828.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17829
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17829: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17830
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17830: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17831
	
	// CG.LOAD4 [.L__movme_cp.98} => .L__movme_tmp.0
	.L__pc.17831: Dma_PatchSrc (.L__pc.17831.LD), (.L__movme_cp.98), (.L__pc.17831.LD)
	.p2align 4
	.L__pc.17831.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17832
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17832: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17833
	.L__pc.17833: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17834
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.96 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.17834: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17835: Dma_PatchSrc (.L__pc.17835.LD), (.L__movme_tmp.1), (.L__pc.17835.LD)
	.p2align 4
	.L__pc.17835.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17836
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17836: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17837
	.L__pc.17837: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17838
	
	.L__pc.17838: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17839
	
	.p2align 4
	.L__pc.17839: Dma_PatchDst (.L__pc.17839.ST), (.L__movme_cp.98), (.L__pc.17839.ST)
	.L__pc.17839.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17840
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.17840: Dma_PatchSrc (.L__pc.17840.LD), (.L__movme_cp.76), (.L__pc.17840.LD)
	.p2align 4
	.L__pc.17840.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17841
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17841: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17842
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.17842: Dma_PatchSrc (.L__pc.17842.LD), (.L__movme_cp.80), (.L__pc.17842.LD)
	.p2align 4
	.L__pc.17842.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17843
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17843: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17844
	
	.L__pc.17844: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17845
	
	.p2align 4
	.L__pc.17845: Dma_PatchDst (.L__pc.17845.ST), ((.L__movme.reg.eax+0)), (.L__pc.17845.ST)
	.L__pc.17845.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17846
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17846: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17847
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17847: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17848
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.17848: Dma_PatchSrc (.L__pc.17848.LD), (.L__movme_cp.99), (.L__pc.17848.LD)
	.p2align 4
	.L__pc.17848.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17849
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17849: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17850
	.L__pc.17850: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17851
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17851: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.62 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17852: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17853: Dma_PatchSrc (.L__pc.17853.LD), (.L__movme_tmp.1), (.L__pc.17853.LD)
	.p2align 4
	.L__pc.17853.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17854
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17854: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17855
	
	.L__pc.17855: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17856
	
	.p2align 4
	.L__pc.17856: Dma_PatchDst (.L__pc.17856.ST), (.L__movme_cp.24), (.L__pc.17856.ST)
	.L__pc.17856.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17857
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17857: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17858
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17858: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17859
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17859: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17860
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17860: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17861
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.17861: Dma_PatchSrc (.L__pc.17861.LD), (.L__movme_cp.63), (.L__pc.17861.LD)
	.p2align 4
	.L__pc.17861.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17862
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17862: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17863
	.L__pc.17863: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17864
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17864: Dma_PatchSrc (.L__pc.17864.LD), (.L__movme_cp.24), (.L__pc.17864.LD)
	.p2align 4
	.L__pc.17864.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17865
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17865: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17866
	.L__pc.17866: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17867
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17867: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17868: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17869: Dma_PatchSrc (.L__pc.17869.LD), (.L__movme_tmp.1), (.L__pc.17869.LD)
	.p2align 4
	.L__pc.17869.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17870
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17870: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17871
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17871: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17872: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17873: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17874: Dma_PatchSrc (.L__pc.17874.LD), (.L__movme_tmp.1), (.L__pc.17874.LD)
	.p2align 4
	.L__pc.17874.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17875
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17875: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17876
	
	.L__pc.17876: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17877
	
	.p2align 4
	.L__pc.17877: Dma_PatchDst (.L__pc.17877.ST), (.L__movme_cp.63), (.L__pc.17877.ST)
	.L__pc.17877.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17878
	
	.L__pc.17878: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17879
	
	.p2align 4
	.L__pc.17879: Dma_PatchDst (.L__pc.17879.ST), (.L__movme_cp.24), (.L__pc.17879.ST)
	.L__pc.17879.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17880
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17880: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17881
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17881: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17882
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17882: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17883
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17883: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17884
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.17884: Dma_PatchSrc (.L__pc.17884.LD), (.L__movme_cp.66), (.L__pc.17884.LD)
	.p2align 4
	.L__pc.17884.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17885
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17885: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17886
	.L__pc.17886: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17887
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17887: Dma_PatchSrc (.L__pc.17887.LD), (.L__movme_cp.24), (.L__pc.17887.LD)
	.p2align 4
	.L__pc.17887.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17888
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17888: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17889
	.L__pc.17889: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17890
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17890: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17891: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17892: Dma_PatchSrc (.L__pc.17892.LD), (.L__movme_tmp.1), (.L__pc.17892.LD)
	.p2align 4
	.L__pc.17892.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17893
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17893: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17894
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17894: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17895: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17896: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17897: Dma_PatchSrc (.L__pc.17897.LD), (.L__movme_tmp.1), (.L__pc.17897.LD)
	.p2align 4
	.L__pc.17897.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17898
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17898: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17899
	
	.L__pc.17899: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17900
	
	.p2align 4
	.L__pc.17900: Dma_PatchDst (.L__pc.17900.ST), (.L__movme_cp.66), (.L__pc.17900.ST)
	.L__pc.17900.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17901
	
	.L__pc.17901: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17902
	
	.p2align 4
	.L__pc.17902: Dma_PatchDst (.L__pc.17902.ST), (.L__movme_cp.24), (.L__pc.17902.ST)
	.L__pc.17902.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17903
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17903: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17904
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17904: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17905
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17905: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17906
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17906: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17907
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.17907: Dma_PatchSrc (.L__pc.17907.LD), (.L__movme_cp.67), (.L__pc.17907.LD)
	.p2align 4
	.L__pc.17907.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17908
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17908: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17909
	.L__pc.17909: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17910
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17910: Dma_PatchSrc (.L__pc.17910.LD), (.L__movme_cp.24), (.L__pc.17910.LD)
	.p2align 4
	.L__pc.17910.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17911
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17911: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17912
	.L__pc.17912: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17913
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17913: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17914: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17915: Dma_PatchSrc (.L__pc.17915.LD), (.L__movme_tmp.1), (.L__pc.17915.LD)
	.p2align 4
	.L__pc.17915.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17916
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17916: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17917
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17917: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17918: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17919: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17920: Dma_PatchSrc (.L__pc.17920.LD), (.L__movme_tmp.1), (.L__pc.17920.LD)
	.p2align 4
	.L__pc.17920.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17921
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17921: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17922
	
	.L__pc.17922: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17923
	
	.p2align 4
	.L__pc.17923: Dma_PatchDst (.L__pc.17923.ST), (.L__movme_cp.67), (.L__pc.17923.ST)
	.L__pc.17923.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17924
	
	.L__pc.17924: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17925
	
	.p2align 4
	.L__pc.17925: Dma_PatchDst (.L__pc.17925.ST), (.L__movme_cp.24), (.L__pc.17925.ST)
	.L__pc.17925.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17926
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17926: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17927
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17927: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17928
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17928: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17929
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17929: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17930
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.17930: Dma_PatchSrc (.L__pc.17930.LD), (.L__movme_cp.68), (.L__pc.17930.LD)
	.p2align 4
	.L__pc.17930.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17931
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17931: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.17932
	.L__pc.17932: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.17933
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17933: Dma_PatchSrc (.L__pc.17933.LD), (.L__movme_cp.24), (.L__pc.17933.LD)
	.p2align 4
	.L__pc.17933.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17934
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17934: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.17935
	.L__pc.17935: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.17936
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17936: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17937: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17938: Dma_PatchSrc (.L__pc.17938.LD), (.L__movme_tmp.1), (.L__pc.17938.LD)
	.p2align 4
	.L__pc.17938.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17939
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17939: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17940
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.17940: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.17941: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.17942: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17943: Dma_PatchSrc (.L__pc.17943.LD), (.L__movme_tmp.1), (.L__pc.17943.LD)
	.p2align 4
	.L__pc.17943.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17944
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17944: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17945
	
	.L__pc.17945: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.17946
	
	.p2align 4
	.L__pc.17946: Dma_PatchDst (.L__pc.17946.ST), (.L__movme_cp.68), (.L__pc.17946.ST)
	.L__pc.17946.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17947
	
	.L__pc.17947: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.17948
	
	.p2align 4
	.L__pc.17948: Dma_PatchDst (.L__pc.17948.ST), (.L__movme_cp.24), (.L__pc.17948.ST)
	.L__pc.17948.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17949
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17949: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17950
	
	.p2align 4
	.L__pc.17950: Dma_PatchDst (.L__pc.17950.ST), (.L__movme_cp.24), (.L__pc.17950.ST)
	.L__pc.17950.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17951
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.17951: Dma_PatchSrc (.L__pc.17951.LD), (.L__movme_cp.60), (.L__pc.17951.LD)
	.p2align 4
	.L__pc.17951.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17952
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17952: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17953
	
	.L__pc.17953: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17954
	
	.p2align 4
	.L__pc.17954: Dma_PatchDst (.L__pc.17954.ST), (.L__movme_cp.21), (.L__pc.17954.ST)
	.L__pc.17954.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17955
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.17955: Dma_PatchSrc (.L__pc.17955.LD), (.L__movme_cp.58), (.L__pc.17955.LD)
	.p2align 4
	.L__pc.17955.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17956
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17956: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17957
	
	.L__pc.17957: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.17958
	
	.p2align 4
	.L__pc.17958: Dma_PatchDst (.L__pc.17958.ST), (.L__movme_cp.22), (.L__pc.17958.ST)
	.L__pc.17958.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17959
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17959: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17960
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17960: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.17961
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.17961: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.17962
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17962: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17963
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.17963: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.17964
	
	.p2align 4
	.L__pc.17964: Dma_PatchDst (.L__pc.17964.ST), (.L__movme_cp.24), (.L__pc.17964.ST)
	.L__pc.17964.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17965
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.17965: Dma_PatchSrc (.L__pc.17965.LD), (.L__movme_cp.25), (.L__pc.17965.LD)
	.p2align 4
	.L__pc.17965.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17966
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17966: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.17967
	.L__pc.17967: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.17968
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.17968: Dma_PatchSrc (.L__pc.17968.LD), (.L__movme_cp.26), (.L__pc.17968.LD)
	.p2align 4
	.L__pc.17968.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17969
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17969: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17970
	.L__pc.17970: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17971
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.17971: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17972: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17973: Dma_PatchSrc (.L__pc.17973.LD), (.L__movme_tmp.1), (.L__pc.17973.LD)
	.p2align 4
	.L__pc.17973.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17974
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17974: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.17975
	.L__pc.17975: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.17976
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.17976: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17977: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17978: Dma_PatchSrc (.L__pc.17978.LD), (.L__movme_tmp.1), (.L__pc.17978.LD)
	.p2align 4
	.L__pc.17978.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17979
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17979: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17980
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17980: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17981: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17982: Dma_PatchSrc (.L__pc.17982.LD), (.L__movme_tmp.1), (.L__pc.17982.LD)
	.p2align 4
	.L__pc.17982.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17983
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17983: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17984
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.17984: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17985: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17986: Dma_PatchSrc (.L__pc.17986.LD), (.L__movme_tmp.1), (.L__pc.17986.LD)
	.p2align 4
	.L__pc.17986.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17987
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17987: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17988
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.17988: Dma_PatchSrc (.L__pc.17988.LD), (.L__movme_cp.24), (.L__pc.17988.LD)
	.p2align 4
	.L__pc.17988.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17989
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.17989: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.17990
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.17990: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.17991: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.17992: Dma_PatchSrc (.L__pc.17992.LD), (.L__movme_tmp.1), (.L__pc.17992.LD)
	.p2align 4
	.L__pc.17992.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17993
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.17993: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.17994
	
	.L__pc.17994: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.17995
	
	.p2align 4
	.L__pc.17995: Dma_PatchDst (.L__pc.17995.ST), (.L__movme_cp.69), (.L__pc.17995.ST)
	.L__pc.17995.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17996
	
	.L__pc.17996: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.17997
	
	.p2align 4
	.L__pc.17997: Dma_PatchDst (.L__pc.17997.ST), (.L__movme_cp.54), (.L__pc.17997.ST)
	.L__pc.17997.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.17998
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.17998: Dma_PatchSrc (.L__pc.17998.LD), (.L__movme_cp.30), (.L__pc.17998.LD)
	.p2align 4
	.L__pc.17998.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.17999
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.17999: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18000
	.L__pc.18000: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18001
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.18001: Dma_PatchSrc (.L__pc.18001.LD), (.L__movme_cp.31), (.L__pc.18001.LD)
	.p2align 4
	.L__pc.18001.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18002
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18002: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18003
	.L__pc.18003: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18004
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18004: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18005: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18006: Dma_PatchSrc (.L__pc.18006.LD), (.L__movme_tmp.1), (.L__pc.18006.LD)
	.p2align 4
	.L__pc.18006.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18007
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18007: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18008
	.L__pc.18008: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18009
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18009: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18010: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18011: Dma_PatchSrc (.L__pc.18011.LD), (.L__movme_tmp.1), (.L__pc.18011.LD)
	.p2align 4
	.L__pc.18011.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18012
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18012: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18013
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18013: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18014: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18015: Dma_PatchSrc (.L__pc.18015.LD), (.L__movme_tmp.1), (.L__pc.18015.LD)
	.p2align 4
	.L__pc.18015.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18016
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18016: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18017
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18017: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18018: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18019: Dma_PatchSrc (.L__pc.18019.LD), (.L__movme_tmp.1), (.L__pc.18019.LD)
	.p2align 4
	.L__pc.18019.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18020
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18020: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18021
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18021: Dma_PatchSrc (.L__pc.18021.LD), (.L__movme_cp.24), (.L__pc.18021.LD)
	.p2align 4
	.L__pc.18021.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18022
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18022: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18023
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18023: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18024: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18025: Dma_PatchSrc (.L__pc.18025.LD), (.L__movme_tmp.1), (.L__pc.18025.LD)
	.p2align 4
	.L__pc.18025.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18026
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18026: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18027
	
	.L__pc.18027: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18028
	
	.p2align 4
	.L__pc.18028: Dma_PatchDst (.L__pc.18028.ST), (.L__movme_cp.70), (.L__pc.18028.ST)
	.L__pc.18028.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18029
	
	.L__pc.18029: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18030
	
	.p2align 4
	.L__pc.18030: Dma_PatchDst (.L__pc.18030.ST), (.L__movme_cp.54), (.L__pc.18030.ST)
	.L__pc.18030.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18031
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18031: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18032
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18032: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18033
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18033: Dma_PatchSrc (.L__pc.18033.LD), (.L__movme_cp.24), (.L__pc.18033.LD)
	.p2align 4
	.L__pc.18033.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18034
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18034: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18035
	.L__pc.18035: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18036
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.18036: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18037: Dma_PatchSrc (.L__pc.18037.LD), (.L__movme_tmp.1), (.L__pc.18037.LD)
	.p2align 4
	.L__pc.18037.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18038
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18038: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18039
	.L__pc.18039: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18040
	
	.L__pc.18040: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18041
	
	.p2align 4
	.L__pc.18041: Dma_PatchDst (.L__pc.18041.ST), (.L__movme_cp.72), (.L__pc.18041.ST)
	.L__pc.18041.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18042
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.18042: Dma_PatchSrc (.L__pc.18042.LD), (.L__movme_cp.72), (.L__pc.18042.LD)
	.p2align 4
	.L__pc.18042.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18043
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18043: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18044
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18044: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18045: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18046: Dma_PatchSrc (.L__pc.18046.LD), (.L__movme_tmp.1), (.L__pc.18046.LD)
	.p2align 4
	.L__pc.18046.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18047
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18047: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18048
	
	.L__pc.18048: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18049
	
	.p2align 4
	.L__pc.18049: Dma_PatchDst (.L__pc.18049.ST), (.L__movme_cp.74), (.L__pc.18049.ST)
	.L__pc.18049.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18050
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18050: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18051: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18052: Dma_PatchSrc (.L__pc.18052.LD), (.L__movme_tmp.1), (.L__pc.18052.LD)
	.p2align 4
	.L__pc.18052.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18053
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18053: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18054
	
	.L__pc.18054: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18055
	
	.p2align 4
	.L__pc.18055: Dma_PatchDst (.L__pc.18055.ST), (.L__movme_cp.76), (.L__pc.18055.ST)
	.L__pc.18055.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18056
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.18056: Dma_PatchSrc (.L__pc.18056.LD), (.L__movme_cp.74), (.L__pc.18056.LD)
	.p2align 4
	.L__pc.18056.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18057
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18057: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18058
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.18058: Dma_PatchSrc (.L__pc.18058.LD), ((.L__movme.reg.eax+0)), (.L__pc.18058.LD)
	.p2align 4
	.L__pc.18058.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18059
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18059: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18060
	
	.L__pc.18060: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18061
	
	.p2align 4
	.L__pc.18061: Dma_PatchDst (.L__pc.18061.ST), (.L__movme_cp.77), (.L__pc.18061.ST)
	.L__pc.18061.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18062
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.18062: Dma_PatchSrc (.L__pc.18062.LD), (.L__movme_cp.77), (.L__pc.18062.LD)
	.p2align 4
	.L__pc.18062.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18063
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18063: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18064
	
	.L__pc.18064: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18065
	
	.p2align 4
	.L__pc.18065: Dma_PatchDst (.L__pc.18065.ST), (.L__movme_cp.21), (.L__pc.18065.ST)
	.L__pc.18065.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18066
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.18066: Dma_PatchSrc (.L__pc.18066.LD), (.L__movme_cp.58), (.L__pc.18066.LD)
	.p2align 4
	.L__pc.18066.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18067
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18067: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18068
	
	.L__pc.18068: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18069
	
	.p2align 4
	.L__pc.18069: Dma_PatchDst (.L__pc.18069.ST), (.L__movme_cp.22), (.L__pc.18069.ST)
	.L__pc.18069.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18070
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18070: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18071
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18071: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18072
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18072: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18073
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18073: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18074
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.18074: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.18075
	
	.p2align 4
	.L__pc.18075: Dma_PatchDst (.L__pc.18075.ST), (.L__movme_cp.24), (.L__pc.18075.ST)
	.L__pc.18075.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18076
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.18076: Dma_PatchSrc (.L__pc.18076.LD), (.L__movme_cp.25), (.L__pc.18076.LD)
	.p2align 4
	.L__pc.18076.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18077
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18077: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18078
	.L__pc.18078: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18079
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.18079: Dma_PatchSrc (.L__pc.18079.LD), (.L__movme_cp.26), (.L__pc.18079.LD)
	.p2align 4
	.L__pc.18079.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18080
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18080: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18081
	.L__pc.18081: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18082
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18082: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18083: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18084: Dma_PatchSrc (.L__pc.18084.LD), (.L__movme_tmp.1), (.L__pc.18084.LD)
	.p2align 4
	.L__pc.18084.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18085
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18085: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18086
	.L__pc.18086: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18087
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18087: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18088: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18089: Dma_PatchSrc (.L__pc.18089.LD), (.L__movme_tmp.1), (.L__pc.18089.LD)
	.p2align 4
	.L__pc.18089.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18090
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18090: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18091
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18091: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18092: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18093: Dma_PatchSrc (.L__pc.18093.LD), (.L__movme_tmp.1), (.L__pc.18093.LD)
	.p2align 4
	.L__pc.18093.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18094
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18094: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18095
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18095: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18096: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18097: Dma_PatchSrc (.L__pc.18097.LD), (.L__movme_tmp.1), (.L__pc.18097.LD)
	.p2align 4
	.L__pc.18097.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18098
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18098: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18099
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18099: Dma_PatchSrc (.L__pc.18099.LD), (.L__movme_cp.24), (.L__pc.18099.LD)
	.p2align 4
	.L__pc.18099.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18100
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18100: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18101
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18101: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18102: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18103: Dma_PatchSrc (.L__pc.18103.LD), (.L__movme_tmp.1), (.L__pc.18103.LD)
	.p2align 4
	.L__pc.18103.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18104
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18104: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18105
	
	.L__pc.18105: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18106
	
	.p2align 4
	.L__pc.18106: Dma_PatchDst (.L__pc.18106.ST), (.L__movme_cp.78), (.L__pc.18106.ST)
	.L__pc.18106.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18107
	
	.L__pc.18107: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18108
	
	.p2align 4
	.L__pc.18108: Dma_PatchDst (.L__pc.18108.ST), (.L__movme_cp.54), (.L__pc.18108.ST)
	.L__pc.18108.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18109
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.18109: Dma_PatchSrc (.L__pc.18109.LD), (.L__movme_cp.30), (.L__pc.18109.LD)
	.p2align 4
	.L__pc.18109.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18110
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18110: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18111
	.L__pc.18111: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18112
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.18112: Dma_PatchSrc (.L__pc.18112.LD), (.L__movme_cp.31), (.L__pc.18112.LD)
	.p2align 4
	.L__pc.18112.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18113
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18113: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18114
	.L__pc.18114: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18115
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18115: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18116: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18117: Dma_PatchSrc (.L__pc.18117.LD), (.L__movme_tmp.1), (.L__pc.18117.LD)
	.p2align 4
	.L__pc.18117.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18118
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18118: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18119
	.L__pc.18119: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18120
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18120: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18121: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18122: Dma_PatchSrc (.L__pc.18122.LD), (.L__movme_tmp.1), (.L__pc.18122.LD)
	.p2align 4
	.L__pc.18122.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18123
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18123: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18124
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18124: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18125: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18126: Dma_PatchSrc (.L__pc.18126.LD), (.L__movme_tmp.1), (.L__pc.18126.LD)
	.p2align 4
	.L__pc.18126.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18127
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18127: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18128
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18128: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18129: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18130: Dma_PatchSrc (.L__pc.18130.LD), (.L__movme_tmp.1), (.L__pc.18130.LD)
	.p2align 4
	.L__pc.18130.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18131
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18131: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18132
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18132: Dma_PatchSrc (.L__pc.18132.LD), (.L__movme_cp.24), (.L__pc.18132.LD)
	.p2align 4
	.L__pc.18132.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18133
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18133: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18134
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18134: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18135: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18136: Dma_PatchSrc (.L__pc.18136.LD), (.L__movme_tmp.1), (.L__pc.18136.LD)
	.p2align 4
	.L__pc.18136.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18137
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18137: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18138
	
	.L__pc.18138: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18139
	
	.p2align 4
	.L__pc.18139: Dma_PatchDst (.L__pc.18139.ST), (.L__movme_cp.79), (.L__pc.18139.ST)
	.L__pc.18139.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18140
	
	.L__pc.18140: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18141
	
	.p2align 4
	.L__pc.18141: Dma_PatchDst (.L__pc.18141.ST), (.L__movme_cp.54), (.L__pc.18141.ST)
	.L__pc.18141.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18142
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.18142: Dma_PatchSrc (.L__pc.18142.LD), (.L__movme_cp.74), (.L__pc.18142.LD)
	.p2align 4
	.L__pc.18142.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18143
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18143: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18144
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.18144: Dma_PatchSrc (.L__pc.18144.LD), (.L__movme_cp.77), (.L__pc.18144.LD)
	.p2align 4
	.L__pc.18144.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18145
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18145: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18146
	
	.L__pc.18146: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18147
	
	.p2align 4
	.L__pc.18147: Dma_PatchDst (.L__pc.18147.ST), ((.L__movme.reg.eax+0)), (.L__pc.18147.ST)
	.L__pc.18147.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18148
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.18148: Dma_PatchSrc (.L__pc.18148.LD), (.L__movme_cp.76), (.L__pc.18148.LD)
	.p2align 4
	.L__pc.18148.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18149
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18149: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18150
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.18150: Dma_PatchSrc (.L__pc.18150.LD), ((.L__movme.reg.eax+0)), (.L__pc.18150.LD)
	.p2align 4
	.L__pc.18150.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18151
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18151: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18152
	
	.L__pc.18152: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18153
	
	.p2align 4
	.L__pc.18153: Dma_PatchDst (.L__pc.18153.ST), (.L__movme_cp.80), (.L__pc.18153.ST)
	.L__pc.18153.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18154
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18154: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18155
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18155: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18156
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.18156: Dma_PatchSrc (.L__pc.18156.LD), (.L__movme_cp.100), (.L__pc.18156.LD)
	.p2align 4
	.L__pc.18156.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18157
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18157: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18158
	.L__pc.18158: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18159
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.82 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.18159: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18160: Dma_PatchSrc (.L__pc.18160.LD), (.L__movme_tmp.1), (.L__pc.18160.LD)
	.p2align 4
	.L__pc.18160.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18161
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18161: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18162
	.L__pc.18162: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18163
	
	.L__pc.18163: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18164
	
	.p2align 4
	.L__pc.18164: Dma_PatchDst (.L__pc.18164.ST), (.L__movme_cp.100), (.L__pc.18164.ST)
	.L__pc.18164.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18165
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.18165: Dma_PatchSrc (.L__pc.18165.LD), (.L__movme_cp.76), (.L__pc.18165.LD)
	.p2align 4
	.L__pc.18165.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18166
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18166: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18167
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.18167: Dma_PatchSrc (.L__pc.18167.LD), (.L__movme_cp.80), (.L__pc.18167.LD)
	.p2align 4
	.L__pc.18167.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18168
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18168: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18169
	
	.L__pc.18169: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18170
	
	.p2align 4
	.L__pc.18170: Dma_PatchDst (.L__pc.18170.ST), ((.L__movme.reg.eax+0)), (.L__pc.18170.ST)
	.L__pc.18170.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18171
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18171: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18172
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18172: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18173
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.18173: Dma_PatchSrc (.L__pc.18173.LD), (.L__movme_cp.99), (.L__pc.18173.LD)
	.p2align 4
	.L__pc.18173.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18174
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18174: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18175
	.L__pc.18175: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18176
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18176: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.83 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18177: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18178: Dma_PatchSrc (.L__pc.18178.LD), (.L__movme_tmp.1), (.L__pc.18178.LD)
	.p2align 4
	.L__pc.18178.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18179
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18179: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18180
	
	.L__pc.18180: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18181
	
	.p2align 4
	.L__pc.18181: Dma_PatchDst (.L__pc.18181.ST), (.L__movme_cp.24), (.L__pc.18181.ST)
	.L__pc.18181.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18182
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18182: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18183
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18183: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18184
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18184: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18185
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18185: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18186
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.18186: Dma_PatchSrc (.L__pc.18186.LD), (.L__movme_cp.63), (.L__pc.18186.LD)
	.p2align 4
	.L__pc.18186.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18187
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18187: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18188
	.L__pc.18188: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18189
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18189: Dma_PatchSrc (.L__pc.18189.LD), (.L__movme_cp.24), (.L__pc.18189.LD)
	.p2align 4
	.L__pc.18189.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18190
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18190: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18191
	.L__pc.18191: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18192
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18192: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18193: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18194: Dma_PatchSrc (.L__pc.18194.LD), (.L__movme_tmp.1), (.L__pc.18194.LD)
	.p2align 4
	.L__pc.18194.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18195
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18195: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18196
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18196: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18197: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18198: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18199: Dma_PatchSrc (.L__pc.18199.LD), (.L__movme_tmp.1), (.L__pc.18199.LD)
	.p2align 4
	.L__pc.18199.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18200
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18200: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18201
	
	.L__pc.18201: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18202
	
	.p2align 4
	.L__pc.18202: Dma_PatchDst (.L__pc.18202.ST), (.L__movme_cp.63), (.L__pc.18202.ST)
	.L__pc.18202.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18203
	
	.L__pc.18203: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18204
	
	.p2align 4
	.L__pc.18204: Dma_PatchDst (.L__pc.18204.ST), (.L__movme_cp.24), (.L__pc.18204.ST)
	.L__pc.18204.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18205
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18205: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18206
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18206: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18207
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18207: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18208
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18208: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18209
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.18209: Dma_PatchSrc (.L__pc.18209.LD), (.L__movme_cp.66), (.L__pc.18209.LD)
	.p2align 4
	.L__pc.18209.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18210
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18210: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18211
	.L__pc.18211: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18212
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18212: Dma_PatchSrc (.L__pc.18212.LD), (.L__movme_cp.24), (.L__pc.18212.LD)
	.p2align 4
	.L__pc.18212.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18213
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18213: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18214
	.L__pc.18214: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18215
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18215: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18216: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18217: Dma_PatchSrc (.L__pc.18217.LD), (.L__movme_tmp.1), (.L__pc.18217.LD)
	.p2align 4
	.L__pc.18217.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18218
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18218: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18219
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18219: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18220: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18221: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18222: Dma_PatchSrc (.L__pc.18222.LD), (.L__movme_tmp.1), (.L__pc.18222.LD)
	.p2align 4
	.L__pc.18222.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18223
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18223: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18224
	
	.L__pc.18224: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18225
	
	.p2align 4
	.L__pc.18225: Dma_PatchDst (.L__pc.18225.ST), (.L__movme_cp.66), (.L__pc.18225.ST)
	.L__pc.18225.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18226
	
	.L__pc.18226: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18227
	
	.p2align 4
	.L__pc.18227: Dma_PatchDst (.L__pc.18227.ST), (.L__movme_cp.24), (.L__pc.18227.ST)
	.L__pc.18227.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18228
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18228: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18229
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18229: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18230
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18230: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18231
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18231: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18232
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.18232: Dma_PatchSrc (.L__pc.18232.LD), (.L__movme_cp.67), (.L__pc.18232.LD)
	.p2align 4
	.L__pc.18232.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18233
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18233: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18234
	.L__pc.18234: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18235
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18235: Dma_PatchSrc (.L__pc.18235.LD), (.L__movme_cp.24), (.L__pc.18235.LD)
	.p2align 4
	.L__pc.18235.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18236
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18236: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18237
	.L__pc.18237: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18238
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18238: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18239: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18240: Dma_PatchSrc (.L__pc.18240.LD), (.L__movme_tmp.1), (.L__pc.18240.LD)
	.p2align 4
	.L__pc.18240.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18241
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18241: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18242
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18242: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18243: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18244: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18245: Dma_PatchSrc (.L__pc.18245.LD), (.L__movme_tmp.1), (.L__pc.18245.LD)
	.p2align 4
	.L__pc.18245.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18246
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18246: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18247
	
	.L__pc.18247: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18248
	
	.p2align 4
	.L__pc.18248: Dma_PatchDst (.L__pc.18248.ST), (.L__movme_cp.67), (.L__pc.18248.ST)
	.L__pc.18248.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18249
	
	.L__pc.18249: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18250
	
	.p2align 4
	.L__pc.18250: Dma_PatchDst (.L__pc.18250.ST), (.L__movme_cp.24), (.L__pc.18250.ST)
	.L__pc.18250.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18251
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18251: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18252
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18252: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18253
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18253: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18254
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18254: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18255
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.18255: Dma_PatchSrc (.L__pc.18255.LD), (.L__movme_cp.68), (.L__pc.18255.LD)
	.p2align 4
	.L__pc.18255.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18256
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18256: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18257
	.L__pc.18257: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18258
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18258: Dma_PatchSrc (.L__pc.18258.LD), (.L__movme_cp.24), (.L__pc.18258.LD)
	.p2align 4
	.L__pc.18258.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18259
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18259: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18260
	.L__pc.18260: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18261
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18261: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18262: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18263: Dma_PatchSrc (.L__pc.18263.LD), (.L__movme_tmp.1), (.L__pc.18263.LD)
	.p2align 4
	.L__pc.18263.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18264
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18264: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18265
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18265: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18266: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18267: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18268: Dma_PatchSrc (.L__pc.18268.LD), (.L__movme_tmp.1), (.L__pc.18268.LD)
	.p2align 4
	.L__pc.18268.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18269
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18269: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18270
	
	.L__pc.18270: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18271
	
	.p2align 4
	.L__pc.18271: Dma_PatchDst (.L__pc.18271.ST), (.L__movme_cp.68), (.L__pc.18271.ST)
	.L__pc.18271.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18272
	
	.L__pc.18272: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18273
	
	.p2align 4
	.L__pc.18273: Dma_PatchDst (.L__pc.18273.ST), (.L__movme_cp.24), (.L__pc.18273.ST)
	.L__pc.18273.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18274
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18274: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18275
	
	.p2align 4
	.L__pc.18275: Dma_PatchDst (.L__pc.18275.ST), (.L__movme_cp.24), (.L__pc.18275.ST)
	.L__pc.18275.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18276
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.18276: Dma_PatchSrc (.L__pc.18276.LD), (.L__movme_cp.60), (.L__pc.18276.LD)
	.p2align 4
	.L__pc.18276.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18277
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18277: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18278
	
	.L__pc.18278: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18279
	
	.p2align 4
	.L__pc.18279: Dma_PatchDst (.L__pc.18279.ST), (.L__movme_cp.21), (.L__pc.18279.ST)
	.L__pc.18279.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18280
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.18280: Dma_PatchSrc (.L__pc.18280.LD), (.L__movme_cp.58), (.L__pc.18280.LD)
	.p2align 4
	.L__pc.18280.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18281
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18281: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18282
	
	.L__pc.18282: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18283
	
	.p2align 4
	.L__pc.18283: Dma_PatchDst (.L__pc.18283.ST), (.L__movme_cp.22), (.L__pc.18283.ST)
	.L__pc.18283.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18284
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18284: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18285
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18285: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18286
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18286: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18287
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18287: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18288
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.18288: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.18289
	
	.p2align 4
	.L__pc.18289: Dma_PatchDst (.L__pc.18289.ST), (.L__movme_cp.24), (.L__pc.18289.ST)
	.L__pc.18289.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18290
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.18290: Dma_PatchSrc (.L__pc.18290.LD), (.L__movme_cp.25), (.L__pc.18290.LD)
	.p2align 4
	.L__pc.18290.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18291
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18291: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18292
	.L__pc.18292: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18293
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.18293: Dma_PatchSrc (.L__pc.18293.LD), (.L__movme_cp.26), (.L__pc.18293.LD)
	.p2align 4
	.L__pc.18293.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18294
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18294: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18295
	.L__pc.18295: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18296
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18296: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18297: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18298: Dma_PatchSrc (.L__pc.18298.LD), (.L__movme_tmp.1), (.L__pc.18298.LD)
	.p2align 4
	.L__pc.18298.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18299
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18299: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18300
	.L__pc.18300: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18301
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18301: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18302: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18303: Dma_PatchSrc (.L__pc.18303.LD), (.L__movme_tmp.1), (.L__pc.18303.LD)
	.p2align 4
	.L__pc.18303.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18304
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18304: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18305
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18305: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18306: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18307: Dma_PatchSrc (.L__pc.18307.LD), (.L__movme_tmp.1), (.L__pc.18307.LD)
	.p2align 4
	.L__pc.18307.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18308
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18308: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18309
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18309: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18310: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18311: Dma_PatchSrc (.L__pc.18311.LD), (.L__movme_tmp.1), (.L__pc.18311.LD)
	.p2align 4
	.L__pc.18311.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18312
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18312: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18313
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18313: Dma_PatchSrc (.L__pc.18313.LD), (.L__movme_cp.24), (.L__pc.18313.LD)
	.p2align 4
	.L__pc.18313.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18314
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18314: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18315
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18315: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18316: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18317: Dma_PatchSrc (.L__pc.18317.LD), (.L__movme_tmp.1), (.L__pc.18317.LD)
	.p2align 4
	.L__pc.18317.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18318
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18318: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18319
	
	.L__pc.18319: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18320
	
	.p2align 4
	.L__pc.18320: Dma_PatchDst (.L__pc.18320.ST), (.L__movme_cp.69), (.L__pc.18320.ST)
	.L__pc.18320.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18321
	
	.L__pc.18321: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18322
	
	.p2align 4
	.L__pc.18322: Dma_PatchDst (.L__pc.18322.ST), (.L__movme_cp.54), (.L__pc.18322.ST)
	.L__pc.18322.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18323
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.18323: Dma_PatchSrc (.L__pc.18323.LD), (.L__movme_cp.30), (.L__pc.18323.LD)
	.p2align 4
	.L__pc.18323.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18324
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18324: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18325
	.L__pc.18325: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18326
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.18326: Dma_PatchSrc (.L__pc.18326.LD), (.L__movme_cp.31), (.L__pc.18326.LD)
	.p2align 4
	.L__pc.18326.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18327
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18327: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18328
	.L__pc.18328: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18329
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18329: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18330: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18331: Dma_PatchSrc (.L__pc.18331.LD), (.L__movme_tmp.1), (.L__pc.18331.LD)
	.p2align 4
	.L__pc.18331.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18332
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18332: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18333
	.L__pc.18333: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18334
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18334: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18335: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18336: Dma_PatchSrc (.L__pc.18336.LD), (.L__movme_tmp.1), (.L__pc.18336.LD)
	.p2align 4
	.L__pc.18336.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18337
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18337: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18338
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18338: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18339: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18340: Dma_PatchSrc (.L__pc.18340.LD), (.L__movme_tmp.1), (.L__pc.18340.LD)
	.p2align 4
	.L__pc.18340.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18341
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18341: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18342
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18342: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18343: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18344: Dma_PatchSrc (.L__pc.18344.LD), (.L__movme_tmp.1), (.L__pc.18344.LD)
	.p2align 4
	.L__pc.18344.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18345
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18345: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18346
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18346: Dma_PatchSrc (.L__pc.18346.LD), (.L__movme_cp.24), (.L__pc.18346.LD)
	.p2align 4
	.L__pc.18346.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18347
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18347: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18348
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18348: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18349: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18350: Dma_PatchSrc (.L__pc.18350.LD), (.L__movme_tmp.1), (.L__pc.18350.LD)
	.p2align 4
	.L__pc.18350.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18351
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18351: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18352
	
	.L__pc.18352: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18353
	
	.p2align 4
	.L__pc.18353: Dma_PatchDst (.L__pc.18353.ST), (.L__movme_cp.70), (.L__pc.18353.ST)
	.L__pc.18353.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18354
	
	.L__pc.18354: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18355
	
	.p2align 4
	.L__pc.18355: Dma_PatchDst (.L__pc.18355.ST), (.L__movme_cp.54), (.L__pc.18355.ST)
	.L__pc.18355.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18356
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18356: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18357
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18357: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18358
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18358: Dma_PatchSrc (.L__pc.18358.LD), (.L__movme_cp.24), (.L__pc.18358.LD)
	.p2align 4
	.L__pc.18358.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18359
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18359: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18360
	.L__pc.18360: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18361
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.18361: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18362: Dma_PatchSrc (.L__pc.18362.LD), (.L__movme_tmp.1), (.L__pc.18362.LD)
	.p2align 4
	.L__pc.18362.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18363
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18363: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18364
	.L__pc.18364: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18365
	
	.L__pc.18365: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18366
	
	.p2align 4
	.L__pc.18366: Dma_PatchDst (.L__pc.18366.ST), (.L__movme_cp.72), (.L__pc.18366.ST)
	.L__pc.18366.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18367
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.18367: Dma_PatchSrc (.L__pc.18367.LD), (.L__movme_cp.72), (.L__pc.18367.LD)
	.p2align 4
	.L__pc.18367.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18368
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18368: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18369
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18369: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18370: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18371: Dma_PatchSrc (.L__pc.18371.LD), (.L__movme_tmp.1), (.L__pc.18371.LD)
	.p2align 4
	.L__pc.18371.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18372
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18372: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18373
	
	.L__pc.18373: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18374
	
	.p2align 4
	.L__pc.18374: Dma_PatchDst (.L__pc.18374.ST), (.L__movme_cp.74), (.L__pc.18374.ST)
	.L__pc.18374.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18375
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18375: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18376: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18377: Dma_PatchSrc (.L__pc.18377.LD), (.L__movme_tmp.1), (.L__pc.18377.LD)
	.p2align 4
	.L__pc.18377.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18378
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18378: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18379
	
	.L__pc.18379: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18380
	
	.p2align 4
	.L__pc.18380: Dma_PatchDst (.L__pc.18380.ST), (.L__movme_cp.76), (.L__pc.18380.ST)
	.L__pc.18380.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18381
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.18381: Dma_PatchSrc (.L__pc.18381.LD), (.L__movme_cp.74), (.L__pc.18381.LD)
	.p2align 4
	.L__pc.18381.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18382
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18382: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18383
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.18383: Dma_PatchSrc (.L__pc.18383.LD), ((.L__movme.reg.eax+0)), (.L__pc.18383.LD)
	.p2align 4
	.L__pc.18383.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18384
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18384: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18385
	
	.L__pc.18385: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18386
	
	.p2align 4
	.L__pc.18386: Dma_PatchDst (.L__pc.18386.ST), (.L__movme_cp.77), (.L__pc.18386.ST)
	.L__pc.18386.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18387
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.18387: Dma_PatchSrc (.L__pc.18387.LD), (.L__movme_cp.77), (.L__pc.18387.LD)
	.p2align 4
	.L__pc.18387.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18388
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18388: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18389
	
	.L__pc.18389: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18390
	
	.p2align 4
	.L__pc.18390: Dma_PatchDst (.L__pc.18390.ST), (.L__movme_cp.21), (.L__pc.18390.ST)
	.L__pc.18390.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18391
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.18391: Dma_PatchSrc (.L__pc.18391.LD), (.L__movme_cp.58), (.L__pc.18391.LD)
	.p2align 4
	.L__pc.18391.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18392
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18392: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18393
	
	.L__pc.18393: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18394
	
	.p2align 4
	.L__pc.18394: Dma_PatchDst (.L__pc.18394.ST), (.L__movme_cp.22), (.L__pc.18394.ST)
	.L__pc.18394.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18395
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18395: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18396
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18396: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18397
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18397: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18398
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18398: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18399
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.18399: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.18400
	
	.p2align 4
	.L__pc.18400: Dma_PatchDst (.L__pc.18400.ST), (.L__movme_cp.24), (.L__pc.18400.ST)
	.L__pc.18400.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18401
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.18401: Dma_PatchSrc (.L__pc.18401.LD), (.L__movme_cp.25), (.L__pc.18401.LD)
	.p2align 4
	.L__pc.18401.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18402
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18402: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18403
	.L__pc.18403: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18404
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.18404: Dma_PatchSrc (.L__pc.18404.LD), (.L__movme_cp.26), (.L__pc.18404.LD)
	.p2align 4
	.L__pc.18404.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18405
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18405: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18406
	.L__pc.18406: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18407
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18407: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18408: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18409: Dma_PatchSrc (.L__pc.18409.LD), (.L__movme_tmp.1), (.L__pc.18409.LD)
	.p2align 4
	.L__pc.18409.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18410
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18410: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18411
	.L__pc.18411: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18412
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18412: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18413: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18414: Dma_PatchSrc (.L__pc.18414.LD), (.L__movme_tmp.1), (.L__pc.18414.LD)
	.p2align 4
	.L__pc.18414.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18415
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18415: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18416
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18416: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18417: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18418: Dma_PatchSrc (.L__pc.18418.LD), (.L__movme_tmp.1), (.L__pc.18418.LD)
	.p2align 4
	.L__pc.18418.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18419
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18419: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18420
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18420: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18421: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18422: Dma_PatchSrc (.L__pc.18422.LD), (.L__movme_tmp.1), (.L__pc.18422.LD)
	.p2align 4
	.L__pc.18422.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18423
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18423: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18424
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18424: Dma_PatchSrc (.L__pc.18424.LD), (.L__movme_cp.24), (.L__pc.18424.LD)
	.p2align 4
	.L__pc.18424.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18425
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18425: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18426
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18426: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18427: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18428: Dma_PatchSrc (.L__pc.18428.LD), (.L__movme_tmp.1), (.L__pc.18428.LD)
	.p2align 4
	.L__pc.18428.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18429
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18429: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18430
	
	.L__pc.18430: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18431
	
	.p2align 4
	.L__pc.18431: Dma_PatchDst (.L__pc.18431.ST), (.L__movme_cp.78), (.L__pc.18431.ST)
	.L__pc.18431.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18432
	
	.L__pc.18432: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18433
	
	.p2align 4
	.L__pc.18433: Dma_PatchDst (.L__pc.18433.ST), (.L__movme_cp.54), (.L__pc.18433.ST)
	.L__pc.18433.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18434
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.18434: Dma_PatchSrc (.L__pc.18434.LD), (.L__movme_cp.30), (.L__pc.18434.LD)
	.p2align 4
	.L__pc.18434.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18435
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18435: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18436
	.L__pc.18436: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18437
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.18437: Dma_PatchSrc (.L__pc.18437.LD), (.L__movme_cp.31), (.L__pc.18437.LD)
	.p2align 4
	.L__pc.18437.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18438
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18438: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18439
	.L__pc.18439: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18440
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18440: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18441: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18442: Dma_PatchSrc (.L__pc.18442.LD), (.L__movme_tmp.1), (.L__pc.18442.LD)
	.p2align 4
	.L__pc.18442.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18443
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18443: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18444
	.L__pc.18444: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18445
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18445: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18446: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18447: Dma_PatchSrc (.L__pc.18447.LD), (.L__movme_tmp.1), (.L__pc.18447.LD)
	.p2align 4
	.L__pc.18447.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18448
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18448: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18449
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18449: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18450: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18451: Dma_PatchSrc (.L__pc.18451.LD), (.L__movme_tmp.1), (.L__pc.18451.LD)
	.p2align 4
	.L__pc.18451.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18452
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18452: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18453
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18453: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18454: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18455: Dma_PatchSrc (.L__pc.18455.LD), (.L__movme_tmp.1), (.L__pc.18455.LD)
	.p2align 4
	.L__pc.18455.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18456
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18456: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18457
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18457: Dma_PatchSrc (.L__pc.18457.LD), (.L__movme_cp.24), (.L__pc.18457.LD)
	.p2align 4
	.L__pc.18457.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18458
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18458: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18459
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18459: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18460: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18461: Dma_PatchSrc (.L__pc.18461.LD), (.L__movme_tmp.1), (.L__pc.18461.LD)
	.p2align 4
	.L__pc.18461.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18462
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18462: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18463
	
	.L__pc.18463: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18464
	
	.p2align 4
	.L__pc.18464: Dma_PatchDst (.L__pc.18464.ST), (.L__movme_cp.79), (.L__pc.18464.ST)
	.L__pc.18464.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18465
	
	.L__pc.18465: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18466
	
	.p2align 4
	.L__pc.18466: Dma_PatchDst (.L__pc.18466.ST), (.L__movme_cp.54), (.L__pc.18466.ST)
	.L__pc.18466.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18467
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.18467: Dma_PatchSrc (.L__pc.18467.LD), (.L__movme_cp.74), (.L__pc.18467.LD)
	.p2align 4
	.L__pc.18467.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18468
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18468: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18469
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.18469: Dma_PatchSrc (.L__pc.18469.LD), (.L__movme_cp.77), (.L__pc.18469.LD)
	.p2align 4
	.L__pc.18469.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18470
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18470: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18471
	
	.L__pc.18471: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18472
	
	.p2align 4
	.L__pc.18472: Dma_PatchDst (.L__pc.18472.ST), ((.L__movme.reg.eax+0)), (.L__pc.18472.ST)
	.L__pc.18472.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18473
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.18473: Dma_PatchSrc (.L__pc.18473.LD), (.L__movme_cp.76), (.L__pc.18473.LD)
	.p2align 4
	.L__pc.18473.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18474
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18474: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18475
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.18475: Dma_PatchSrc (.L__pc.18475.LD), ((.L__movme.reg.eax+0)), (.L__pc.18475.LD)
	.p2align 4
	.L__pc.18475.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18476
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18476: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18477
	
	.L__pc.18477: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18478
	
	.p2align 4
	.L__pc.18478: Dma_PatchDst (.L__pc.18478.ST), (.L__movme_cp.80), (.L__pc.18478.ST)
	.L__pc.18478.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18479
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18479: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18480
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18480: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18481
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.18481: Dma_PatchSrc (.L__pc.18481.LD), (.L__movme_cp.100), (.L__pc.18481.LD)
	.p2align 4
	.L__pc.18481.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18482
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18482: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18483
	.L__pc.18483: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18484
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.84 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.18484: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18485: Dma_PatchSrc (.L__pc.18485.LD), (.L__movme_tmp.1), (.L__pc.18485.LD)
	.p2align 4
	.L__pc.18485.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18486
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18486: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18487
	.L__pc.18487: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18488
	
	.L__pc.18488: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18489
	
	.p2align 4
	.L__pc.18489: Dma_PatchDst (.L__pc.18489.ST), (.L__movme_cp.100), (.L__pc.18489.ST)
	.L__pc.18489.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18490
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.18490: Dma_PatchSrc (.L__pc.18490.LD), (.L__movme_cp.76), (.L__pc.18490.LD)
	.p2align 4
	.L__pc.18490.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18491
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18491: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18492
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.18492: Dma_PatchSrc (.L__pc.18492.LD), (.L__movme_cp.80), (.L__pc.18492.LD)
	.p2align 4
	.L__pc.18492.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18493
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18493: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18494
	
	.L__pc.18494: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18495
	
	.p2align 4
	.L__pc.18495: Dma_PatchDst (.L__pc.18495.ST), ((.L__movme.reg.eax+0)), (.L__pc.18495.ST)
	.L__pc.18495.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18496
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18496: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18497
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18497: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18498
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.18498: Dma_PatchSrc (.L__pc.18498.LD), (.L__movme_cp.99), (.L__pc.18498.LD)
	.p2align 4
	.L__pc.18498.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18499
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18499: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18500
	.L__pc.18500: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18501
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18501: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.85 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18502: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18503: Dma_PatchSrc (.L__pc.18503.LD), (.L__movme_tmp.1), (.L__pc.18503.LD)
	.p2align 4
	.L__pc.18503.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18504
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18504: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18505
	
	.L__pc.18505: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18506
	
	.p2align 4
	.L__pc.18506: Dma_PatchDst (.L__pc.18506.ST), (.L__movme_cp.24), (.L__pc.18506.ST)
	.L__pc.18506.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18507
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18507: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18508
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18508: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18509
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18509: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18510
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18510: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18511
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.18511: Dma_PatchSrc (.L__pc.18511.LD), (.L__movme_cp.63), (.L__pc.18511.LD)
	.p2align 4
	.L__pc.18511.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18512
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18512: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18513
	.L__pc.18513: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18514
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18514: Dma_PatchSrc (.L__pc.18514.LD), (.L__movme_cp.24), (.L__pc.18514.LD)
	.p2align 4
	.L__pc.18514.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18515
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18515: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18516
	.L__pc.18516: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18517
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18517: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18518: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18519: Dma_PatchSrc (.L__pc.18519.LD), (.L__movme_tmp.1), (.L__pc.18519.LD)
	.p2align 4
	.L__pc.18519.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18520
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18520: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18521
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18521: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18522: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18523: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18524: Dma_PatchSrc (.L__pc.18524.LD), (.L__movme_tmp.1), (.L__pc.18524.LD)
	.p2align 4
	.L__pc.18524.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18525
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18525: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18526
	
	.L__pc.18526: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18527
	
	.p2align 4
	.L__pc.18527: Dma_PatchDst (.L__pc.18527.ST), (.L__movme_cp.63), (.L__pc.18527.ST)
	.L__pc.18527.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18528
	
	.L__pc.18528: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18529
	
	.p2align 4
	.L__pc.18529: Dma_PatchDst (.L__pc.18529.ST), (.L__movme_cp.24), (.L__pc.18529.ST)
	.L__pc.18529.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18530
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18530: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18531
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18531: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18532
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18532: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18533
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18533: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18534
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.18534: Dma_PatchSrc (.L__pc.18534.LD), (.L__movme_cp.66), (.L__pc.18534.LD)
	.p2align 4
	.L__pc.18534.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18535
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18535: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18536
	.L__pc.18536: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18537
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18537: Dma_PatchSrc (.L__pc.18537.LD), (.L__movme_cp.24), (.L__pc.18537.LD)
	.p2align 4
	.L__pc.18537.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18538
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18538: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18539
	.L__pc.18539: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18540
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18540: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18541: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18542: Dma_PatchSrc (.L__pc.18542.LD), (.L__movme_tmp.1), (.L__pc.18542.LD)
	.p2align 4
	.L__pc.18542.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18543
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18543: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18544
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18544: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18545: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18546: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18547: Dma_PatchSrc (.L__pc.18547.LD), (.L__movme_tmp.1), (.L__pc.18547.LD)
	.p2align 4
	.L__pc.18547.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18548
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18548: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18549
	
	.L__pc.18549: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18550
	
	.p2align 4
	.L__pc.18550: Dma_PatchDst (.L__pc.18550.ST), (.L__movme_cp.66), (.L__pc.18550.ST)
	.L__pc.18550.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18551
	
	.L__pc.18551: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18552
	
	.p2align 4
	.L__pc.18552: Dma_PatchDst (.L__pc.18552.ST), (.L__movme_cp.24), (.L__pc.18552.ST)
	.L__pc.18552.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18553
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18553: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18554
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18554: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18555
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18555: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18556
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18556: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18557
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.18557: Dma_PatchSrc (.L__pc.18557.LD), (.L__movme_cp.67), (.L__pc.18557.LD)
	.p2align 4
	.L__pc.18557.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18558
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18558: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18559
	.L__pc.18559: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18560
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18560: Dma_PatchSrc (.L__pc.18560.LD), (.L__movme_cp.24), (.L__pc.18560.LD)
	.p2align 4
	.L__pc.18560.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18561
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18561: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18562
	.L__pc.18562: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18563
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18563: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18564: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18565: Dma_PatchSrc (.L__pc.18565.LD), (.L__movme_tmp.1), (.L__pc.18565.LD)
	.p2align 4
	.L__pc.18565.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18566
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18566: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18567
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18567: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18568: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18569: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18570: Dma_PatchSrc (.L__pc.18570.LD), (.L__movme_tmp.1), (.L__pc.18570.LD)
	.p2align 4
	.L__pc.18570.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18571
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18571: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18572
	
	.L__pc.18572: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18573
	
	.p2align 4
	.L__pc.18573: Dma_PatchDst (.L__pc.18573.ST), (.L__movme_cp.67), (.L__pc.18573.ST)
	.L__pc.18573.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18574
	
	.L__pc.18574: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18575
	
	.p2align 4
	.L__pc.18575: Dma_PatchDst (.L__pc.18575.ST), (.L__movme_cp.24), (.L__pc.18575.ST)
	.L__pc.18575.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18576
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18576: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18577
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18577: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18578
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18578: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18579
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18579: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18580
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.18580: Dma_PatchSrc (.L__pc.18580.LD), (.L__movme_cp.68), (.L__pc.18580.LD)
	.p2align 4
	.L__pc.18580.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18581
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18581: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18582
	.L__pc.18582: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18583
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18583: Dma_PatchSrc (.L__pc.18583.LD), (.L__movme_cp.24), (.L__pc.18583.LD)
	.p2align 4
	.L__pc.18583.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18584
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18584: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18585
	.L__pc.18585: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18586
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18586: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18587: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18588: Dma_PatchSrc (.L__pc.18588.LD), (.L__movme_tmp.1), (.L__pc.18588.LD)
	.p2align 4
	.L__pc.18588.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18589
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18589: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18590
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18590: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18591: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18592: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18593: Dma_PatchSrc (.L__pc.18593.LD), (.L__movme_tmp.1), (.L__pc.18593.LD)
	.p2align 4
	.L__pc.18593.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18594
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18594: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18595
	
	.L__pc.18595: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18596
	
	.p2align 4
	.L__pc.18596: Dma_PatchDst (.L__pc.18596.ST), (.L__movme_cp.68), (.L__pc.18596.ST)
	.L__pc.18596.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18597
	
	.L__pc.18597: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18598
	
	.p2align 4
	.L__pc.18598: Dma_PatchDst (.L__pc.18598.ST), (.L__movme_cp.24), (.L__pc.18598.ST)
	.L__pc.18598.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18599
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18599: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18600
	
	.p2align 4
	.L__pc.18600: Dma_PatchDst (.L__pc.18600.ST), (.L__movme_cp.24), (.L__pc.18600.ST)
	.L__pc.18600.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18601
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.18601: Dma_PatchSrc (.L__pc.18601.LD), (.L__movme_cp.60), (.L__pc.18601.LD)
	.p2align 4
	.L__pc.18601.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18602
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18602: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18603
	
	.L__pc.18603: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18604
	
	.p2align 4
	.L__pc.18604: Dma_PatchDst (.L__pc.18604.ST), (.L__movme_cp.21), (.L__pc.18604.ST)
	.L__pc.18604.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18605
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.18605: Dma_PatchSrc (.L__pc.18605.LD), (.L__movme_cp.58), (.L__pc.18605.LD)
	.p2align 4
	.L__pc.18605.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18606
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18606: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18607
	
	.L__pc.18607: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18608
	
	.p2align 4
	.L__pc.18608: Dma_PatchDst (.L__pc.18608.ST), (.L__movme_cp.22), (.L__pc.18608.ST)
	.L__pc.18608.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18609
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18609: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18610
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18610: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18611
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18611: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18612
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18612: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18613
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.18613: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.18614
	
	.p2align 4
	.L__pc.18614: Dma_PatchDst (.L__pc.18614.ST), (.L__movme_cp.24), (.L__pc.18614.ST)
	.L__pc.18614.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18615
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.18615: Dma_PatchSrc (.L__pc.18615.LD), (.L__movme_cp.25), (.L__pc.18615.LD)
	.p2align 4
	.L__pc.18615.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18616
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18616: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18617
	.L__pc.18617: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18618
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.18618: Dma_PatchSrc (.L__pc.18618.LD), (.L__movme_cp.26), (.L__pc.18618.LD)
	.p2align 4
	.L__pc.18618.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18619
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18619: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18620
	.L__pc.18620: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18621
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18621: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18622: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18623: Dma_PatchSrc (.L__pc.18623.LD), (.L__movme_tmp.1), (.L__pc.18623.LD)
	.p2align 4
	.L__pc.18623.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18624
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18624: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18625
	.L__pc.18625: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18626
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18626: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18627: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18628: Dma_PatchSrc (.L__pc.18628.LD), (.L__movme_tmp.1), (.L__pc.18628.LD)
	.p2align 4
	.L__pc.18628.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18629
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18629: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18630
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18630: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18631: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18632: Dma_PatchSrc (.L__pc.18632.LD), (.L__movme_tmp.1), (.L__pc.18632.LD)
	.p2align 4
	.L__pc.18632.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18633
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18633: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18634
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18634: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18635: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18636: Dma_PatchSrc (.L__pc.18636.LD), (.L__movme_tmp.1), (.L__pc.18636.LD)
	.p2align 4
	.L__pc.18636.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18637
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18637: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18638
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18638: Dma_PatchSrc (.L__pc.18638.LD), (.L__movme_cp.24), (.L__pc.18638.LD)
	.p2align 4
	.L__pc.18638.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18639
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18639: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18640
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18640: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18641: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18642: Dma_PatchSrc (.L__pc.18642.LD), (.L__movme_tmp.1), (.L__pc.18642.LD)
	.p2align 4
	.L__pc.18642.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18643
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18643: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18644
	
	.L__pc.18644: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18645
	
	.p2align 4
	.L__pc.18645: Dma_PatchDst (.L__pc.18645.ST), (.L__movme_cp.69), (.L__pc.18645.ST)
	.L__pc.18645.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18646
	
	.L__pc.18646: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18647
	
	.p2align 4
	.L__pc.18647: Dma_PatchDst (.L__pc.18647.ST), (.L__movme_cp.54), (.L__pc.18647.ST)
	.L__pc.18647.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18648
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.18648: Dma_PatchSrc (.L__pc.18648.LD), (.L__movme_cp.30), (.L__pc.18648.LD)
	.p2align 4
	.L__pc.18648.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18649
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18649: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18650
	.L__pc.18650: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18651
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.18651: Dma_PatchSrc (.L__pc.18651.LD), (.L__movme_cp.31), (.L__pc.18651.LD)
	.p2align 4
	.L__pc.18651.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18652
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18652: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18653
	.L__pc.18653: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18654
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18654: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18655: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18656: Dma_PatchSrc (.L__pc.18656.LD), (.L__movme_tmp.1), (.L__pc.18656.LD)
	.p2align 4
	.L__pc.18656.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18657
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18657: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18658
	.L__pc.18658: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18659
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18659: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18660: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18661: Dma_PatchSrc (.L__pc.18661.LD), (.L__movme_tmp.1), (.L__pc.18661.LD)
	.p2align 4
	.L__pc.18661.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18662
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18662: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18663
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18663: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18664: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18665: Dma_PatchSrc (.L__pc.18665.LD), (.L__movme_tmp.1), (.L__pc.18665.LD)
	.p2align 4
	.L__pc.18665.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18666
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18666: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18667
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18667: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18668: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18669: Dma_PatchSrc (.L__pc.18669.LD), (.L__movme_tmp.1), (.L__pc.18669.LD)
	.p2align 4
	.L__pc.18669.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18670
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18670: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18671
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18671: Dma_PatchSrc (.L__pc.18671.LD), (.L__movme_cp.24), (.L__pc.18671.LD)
	.p2align 4
	.L__pc.18671.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18672
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18672: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18673
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18673: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18674: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18675: Dma_PatchSrc (.L__pc.18675.LD), (.L__movme_tmp.1), (.L__pc.18675.LD)
	.p2align 4
	.L__pc.18675.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18676
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18676: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18677
	
	.L__pc.18677: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18678
	
	.p2align 4
	.L__pc.18678: Dma_PatchDst (.L__pc.18678.ST), (.L__movme_cp.70), (.L__pc.18678.ST)
	.L__pc.18678.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18679
	
	.L__pc.18679: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18680
	
	.p2align 4
	.L__pc.18680: Dma_PatchDst (.L__pc.18680.ST), (.L__movme_cp.54), (.L__pc.18680.ST)
	.L__pc.18680.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18681
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18681: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18682
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18682: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18683
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18683: Dma_PatchSrc (.L__pc.18683.LD), (.L__movme_cp.24), (.L__pc.18683.LD)
	.p2align 4
	.L__pc.18683.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18684
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18684: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18685
	.L__pc.18685: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18686
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.18686: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18687: Dma_PatchSrc (.L__pc.18687.LD), (.L__movme_tmp.1), (.L__pc.18687.LD)
	.p2align 4
	.L__pc.18687.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18688
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18688: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18689
	.L__pc.18689: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18690
	
	.L__pc.18690: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18691
	
	.p2align 4
	.L__pc.18691: Dma_PatchDst (.L__pc.18691.ST), (.L__movme_cp.72), (.L__pc.18691.ST)
	.L__pc.18691.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18692
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.18692: Dma_PatchSrc (.L__pc.18692.LD), (.L__movme_cp.72), (.L__pc.18692.LD)
	.p2align 4
	.L__pc.18692.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18693
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18693: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18694
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18694: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18695: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18696: Dma_PatchSrc (.L__pc.18696.LD), (.L__movme_tmp.1), (.L__pc.18696.LD)
	.p2align 4
	.L__pc.18696.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18697
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18697: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18698
	
	.L__pc.18698: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18699
	
	.p2align 4
	.L__pc.18699: Dma_PatchDst (.L__pc.18699.ST), (.L__movme_cp.74), (.L__pc.18699.ST)
	.L__pc.18699.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18700
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18700: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18701: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18702: Dma_PatchSrc (.L__pc.18702.LD), (.L__movme_tmp.1), (.L__pc.18702.LD)
	.p2align 4
	.L__pc.18702.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18703
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18703: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18704
	
	.L__pc.18704: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18705
	
	.p2align 4
	.L__pc.18705: Dma_PatchDst (.L__pc.18705.ST), (.L__movme_cp.76), (.L__pc.18705.ST)
	.L__pc.18705.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18706
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.18706: Dma_PatchSrc (.L__pc.18706.LD), (.L__movme_cp.74), (.L__pc.18706.LD)
	.p2align 4
	.L__pc.18706.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18707
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18707: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18708
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.18708: Dma_PatchSrc (.L__pc.18708.LD), ((.L__movme.reg.eax+0)), (.L__pc.18708.LD)
	.p2align 4
	.L__pc.18708.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18709
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18709: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18710
	
	.L__pc.18710: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18711
	
	.p2align 4
	.L__pc.18711: Dma_PatchDst (.L__pc.18711.ST), (.L__movme_cp.77), (.L__pc.18711.ST)
	.L__pc.18711.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18712
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.18712: Dma_PatchSrc (.L__pc.18712.LD), (.L__movme_cp.77), (.L__pc.18712.LD)
	.p2align 4
	.L__pc.18712.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18713
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18713: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18714
	
	.L__pc.18714: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18715
	
	.p2align 4
	.L__pc.18715: Dma_PatchDst (.L__pc.18715.ST), (.L__movme_cp.21), (.L__pc.18715.ST)
	.L__pc.18715.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18716
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.18716: Dma_PatchSrc (.L__pc.18716.LD), (.L__movme_cp.58), (.L__pc.18716.LD)
	.p2align 4
	.L__pc.18716.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18717
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18717: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18718
	
	.L__pc.18718: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18719
	
	.p2align 4
	.L__pc.18719: Dma_PatchDst (.L__pc.18719.ST), (.L__movme_cp.22), (.L__pc.18719.ST)
	.L__pc.18719.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18720
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18720: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18721
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18721: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18722
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18722: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18723
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18723: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18724
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.18724: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.18725
	
	.p2align 4
	.L__pc.18725: Dma_PatchDst (.L__pc.18725.ST), (.L__movme_cp.24), (.L__pc.18725.ST)
	.L__pc.18725.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18726
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.18726: Dma_PatchSrc (.L__pc.18726.LD), (.L__movme_cp.25), (.L__pc.18726.LD)
	.p2align 4
	.L__pc.18726.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18727
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18727: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18728
	.L__pc.18728: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18729
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.18729: Dma_PatchSrc (.L__pc.18729.LD), (.L__movme_cp.26), (.L__pc.18729.LD)
	.p2align 4
	.L__pc.18729.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18730
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18730: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18731
	.L__pc.18731: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18732
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18732: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18733: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18734: Dma_PatchSrc (.L__pc.18734.LD), (.L__movme_tmp.1), (.L__pc.18734.LD)
	.p2align 4
	.L__pc.18734.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18735
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18735: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18736
	.L__pc.18736: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18737
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18737: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18738: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18739: Dma_PatchSrc (.L__pc.18739.LD), (.L__movme_tmp.1), (.L__pc.18739.LD)
	.p2align 4
	.L__pc.18739.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18740
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18740: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18741
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18741: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18742: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18743: Dma_PatchSrc (.L__pc.18743.LD), (.L__movme_tmp.1), (.L__pc.18743.LD)
	.p2align 4
	.L__pc.18743.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18744
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18744: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18745
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18745: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18746: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18747: Dma_PatchSrc (.L__pc.18747.LD), (.L__movme_tmp.1), (.L__pc.18747.LD)
	.p2align 4
	.L__pc.18747.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18748
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18748: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18749
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18749: Dma_PatchSrc (.L__pc.18749.LD), (.L__movme_cp.24), (.L__pc.18749.LD)
	.p2align 4
	.L__pc.18749.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18750
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18750: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18751
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18751: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18752: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18753: Dma_PatchSrc (.L__pc.18753.LD), (.L__movme_tmp.1), (.L__pc.18753.LD)
	.p2align 4
	.L__pc.18753.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18754
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18754: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18755
	
	.L__pc.18755: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18756
	
	.p2align 4
	.L__pc.18756: Dma_PatchDst (.L__pc.18756.ST), (.L__movme_cp.78), (.L__pc.18756.ST)
	.L__pc.18756.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18757
	
	.L__pc.18757: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18758
	
	.p2align 4
	.L__pc.18758: Dma_PatchDst (.L__pc.18758.ST), (.L__movme_cp.54), (.L__pc.18758.ST)
	.L__pc.18758.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18759
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.18759: Dma_PatchSrc (.L__pc.18759.LD), (.L__movme_cp.30), (.L__pc.18759.LD)
	.p2align 4
	.L__pc.18759.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18760
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18760: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18761
	.L__pc.18761: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18762
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.18762: Dma_PatchSrc (.L__pc.18762.LD), (.L__movme_cp.31), (.L__pc.18762.LD)
	.p2align 4
	.L__pc.18762.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18763
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18763: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18764
	.L__pc.18764: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18765
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18765: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18766: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18767: Dma_PatchSrc (.L__pc.18767.LD), (.L__movme_tmp.1), (.L__pc.18767.LD)
	.p2align 4
	.L__pc.18767.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18768
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18768: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18769
	.L__pc.18769: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18770
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18770: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18771: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18772: Dma_PatchSrc (.L__pc.18772.LD), (.L__movme_tmp.1), (.L__pc.18772.LD)
	.p2align 4
	.L__pc.18772.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18773
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18773: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18774
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18774: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18775: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18776: Dma_PatchSrc (.L__pc.18776.LD), (.L__movme_tmp.1), (.L__pc.18776.LD)
	.p2align 4
	.L__pc.18776.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18777
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18777: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18778
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18778: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18779: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18780: Dma_PatchSrc (.L__pc.18780.LD), (.L__movme_tmp.1), (.L__pc.18780.LD)
	.p2align 4
	.L__pc.18780.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18781
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18781: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18782
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18782: Dma_PatchSrc (.L__pc.18782.LD), (.L__movme_cp.24), (.L__pc.18782.LD)
	.p2align 4
	.L__pc.18782.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18783
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18783: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18784
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18784: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18785: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18786: Dma_PatchSrc (.L__pc.18786.LD), (.L__movme_tmp.1), (.L__pc.18786.LD)
	.p2align 4
	.L__pc.18786.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18787
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18787: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18788
	
	.L__pc.18788: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18789
	
	.p2align 4
	.L__pc.18789: Dma_PatchDst (.L__pc.18789.ST), (.L__movme_cp.79), (.L__pc.18789.ST)
	.L__pc.18789.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18790
	
	.L__pc.18790: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18791
	
	.p2align 4
	.L__pc.18791: Dma_PatchDst (.L__pc.18791.ST), (.L__movme_cp.54), (.L__pc.18791.ST)
	.L__pc.18791.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18792
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.18792: Dma_PatchSrc (.L__pc.18792.LD), (.L__movme_cp.74), (.L__pc.18792.LD)
	.p2align 4
	.L__pc.18792.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18793
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18793: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18794
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.18794: Dma_PatchSrc (.L__pc.18794.LD), (.L__movme_cp.77), (.L__pc.18794.LD)
	.p2align 4
	.L__pc.18794.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18795
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18795: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18796
	
	.L__pc.18796: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18797
	
	.p2align 4
	.L__pc.18797: Dma_PatchDst (.L__pc.18797.ST), ((.L__movme.reg.eax+0)), (.L__pc.18797.ST)
	.L__pc.18797.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18798
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.18798: Dma_PatchSrc (.L__pc.18798.LD), (.L__movme_cp.76), (.L__pc.18798.LD)
	.p2align 4
	.L__pc.18798.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18799
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18799: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18800
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.18800: Dma_PatchSrc (.L__pc.18800.LD), ((.L__movme.reg.eax+0)), (.L__pc.18800.LD)
	.p2align 4
	.L__pc.18800.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18801
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18801: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18802
	
	.L__pc.18802: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18803
	
	.p2align 4
	.L__pc.18803: Dma_PatchDst (.L__pc.18803.ST), (.L__movme_cp.80), (.L__pc.18803.ST)
	.L__pc.18803.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18804
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18804: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18805
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18805: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18806
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.18806: Dma_PatchSrc (.L__pc.18806.LD), (.L__movme_cp.100), (.L__pc.18806.LD)
	.p2align 4
	.L__pc.18806.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18807
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18807: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18808
	.L__pc.18808: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18809
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.86 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.18809: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18810: Dma_PatchSrc (.L__pc.18810.LD), (.L__movme_tmp.1), (.L__pc.18810.LD)
	.p2align 4
	.L__pc.18810.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18811
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18811: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18812
	.L__pc.18812: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18813
	
	.L__pc.18813: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18814
	
	.p2align 4
	.L__pc.18814: Dma_PatchDst (.L__pc.18814.ST), (.L__movme_cp.100), (.L__pc.18814.ST)
	.L__pc.18814.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18815
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.18815: Dma_PatchSrc (.L__pc.18815.LD), (.L__movme_cp.76), (.L__pc.18815.LD)
	.p2align 4
	.L__pc.18815.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18816
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18816: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18817
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.18817: Dma_PatchSrc (.L__pc.18817.LD), (.L__movme_cp.80), (.L__pc.18817.LD)
	.p2align 4
	.L__pc.18817.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18818
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18818: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18819
	
	.L__pc.18819: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18820
	
	.p2align 4
	.L__pc.18820: Dma_PatchDst (.L__pc.18820.ST), ((.L__movme.reg.eax+0)), (.L__pc.18820.ST)
	.L__pc.18820.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18821
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18821: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18822
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18822: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18823
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.18823: Dma_PatchSrc (.L__pc.18823.LD), (.L__movme_cp.99), (.L__pc.18823.LD)
	.p2align 4
	.L__pc.18823.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18824
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18824: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18825
	.L__pc.18825: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18826
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18826: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.87 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18827: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18828: Dma_PatchSrc (.L__pc.18828.LD), (.L__movme_tmp.1), (.L__pc.18828.LD)
	.p2align 4
	.L__pc.18828.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18829
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18829: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18830
	
	.L__pc.18830: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18831
	
	.p2align 4
	.L__pc.18831: Dma_PatchDst (.L__pc.18831.ST), (.L__movme_cp.24), (.L__pc.18831.ST)
	.L__pc.18831.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18832
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18832: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18833
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18833: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18834
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18834: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18835
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18835: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18836
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.18836: Dma_PatchSrc (.L__pc.18836.LD), (.L__movme_cp.63), (.L__pc.18836.LD)
	.p2align 4
	.L__pc.18836.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18837
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18837: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18838
	.L__pc.18838: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18839
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18839: Dma_PatchSrc (.L__pc.18839.LD), (.L__movme_cp.24), (.L__pc.18839.LD)
	.p2align 4
	.L__pc.18839.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18840
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18840: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18841
	.L__pc.18841: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18842
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18842: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18843: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18844: Dma_PatchSrc (.L__pc.18844.LD), (.L__movme_tmp.1), (.L__pc.18844.LD)
	.p2align 4
	.L__pc.18844.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18845
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18845: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18846
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18846: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18847: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18848: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18849: Dma_PatchSrc (.L__pc.18849.LD), (.L__movme_tmp.1), (.L__pc.18849.LD)
	.p2align 4
	.L__pc.18849.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18850
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18850: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18851
	
	.L__pc.18851: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18852
	
	.p2align 4
	.L__pc.18852: Dma_PatchDst (.L__pc.18852.ST), (.L__movme_cp.63), (.L__pc.18852.ST)
	.L__pc.18852.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18853
	
	.L__pc.18853: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18854
	
	.p2align 4
	.L__pc.18854: Dma_PatchDst (.L__pc.18854.ST), (.L__movme_cp.24), (.L__pc.18854.ST)
	.L__pc.18854.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18855
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18855: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18856
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18856: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18857
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18857: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18858
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18858: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18859
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.18859: Dma_PatchSrc (.L__pc.18859.LD), (.L__movme_cp.66), (.L__pc.18859.LD)
	.p2align 4
	.L__pc.18859.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18860
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18860: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18861
	.L__pc.18861: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18862
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18862: Dma_PatchSrc (.L__pc.18862.LD), (.L__movme_cp.24), (.L__pc.18862.LD)
	.p2align 4
	.L__pc.18862.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18863
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18863: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18864
	.L__pc.18864: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18865
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18865: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18866: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18867: Dma_PatchSrc (.L__pc.18867.LD), (.L__movme_tmp.1), (.L__pc.18867.LD)
	.p2align 4
	.L__pc.18867.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18868
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18868: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18869
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18869: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18870: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18871: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18872: Dma_PatchSrc (.L__pc.18872.LD), (.L__movme_tmp.1), (.L__pc.18872.LD)
	.p2align 4
	.L__pc.18872.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18873
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18873: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18874
	
	.L__pc.18874: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18875
	
	.p2align 4
	.L__pc.18875: Dma_PatchDst (.L__pc.18875.ST), (.L__movme_cp.66), (.L__pc.18875.ST)
	.L__pc.18875.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18876
	
	.L__pc.18876: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18877
	
	.p2align 4
	.L__pc.18877: Dma_PatchDst (.L__pc.18877.ST), (.L__movme_cp.24), (.L__pc.18877.ST)
	.L__pc.18877.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18878
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18878: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18879
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18879: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18880
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18880: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18881
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18881: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18882
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.18882: Dma_PatchSrc (.L__pc.18882.LD), (.L__movme_cp.67), (.L__pc.18882.LD)
	.p2align 4
	.L__pc.18882.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18883
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18883: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18884
	.L__pc.18884: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18885
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18885: Dma_PatchSrc (.L__pc.18885.LD), (.L__movme_cp.24), (.L__pc.18885.LD)
	.p2align 4
	.L__pc.18885.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18886
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18886: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18887
	.L__pc.18887: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18888
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18888: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18889: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18890: Dma_PatchSrc (.L__pc.18890.LD), (.L__movme_tmp.1), (.L__pc.18890.LD)
	.p2align 4
	.L__pc.18890.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18891
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18891: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18892
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18892: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18893: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18894: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18895: Dma_PatchSrc (.L__pc.18895.LD), (.L__movme_tmp.1), (.L__pc.18895.LD)
	.p2align 4
	.L__pc.18895.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18896
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18896: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18897
	
	.L__pc.18897: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18898
	
	.p2align 4
	.L__pc.18898: Dma_PatchDst (.L__pc.18898.ST), (.L__movme_cp.67), (.L__pc.18898.ST)
	.L__pc.18898.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18899
	
	.L__pc.18899: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18900
	
	.p2align 4
	.L__pc.18900: Dma_PatchDst (.L__pc.18900.ST), (.L__movme_cp.24), (.L__pc.18900.ST)
	.L__pc.18900.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18901
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18901: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18902
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18902: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18903
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18903: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18904
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18904: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18905
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.18905: Dma_PatchSrc (.L__pc.18905.LD), (.L__movme_cp.68), (.L__pc.18905.LD)
	.p2align 4
	.L__pc.18905.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18906
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18906: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.18907
	.L__pc.18907: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.18908
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18908: Dma_PatchSrc (.L__pc.18908.LD), (.L__movme_cp.24), (.L__pc.18908.LD)
	.p2align 4
	.L__pc.18908.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18909
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18909: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.18910
	.L__pc.18910: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.18911
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18911: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18912: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18913: Dma_PatchSrc (.L__pc.18913.LD), (.L__movme_tmp.1), (.L__pc.18913.LD)
	.p2align 4
	.L__pc.18913.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18914
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18914: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18915
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.18915: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.18916: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.18917: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18918: Dma_PatchSrc (.L__pc.18918.LD), (.L__movme_tmp.1), (.L__pc.18918.LD)
	.p2align 4
	.L__pc.18918.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18919
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18919: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18920
	
	.L__pc.18920: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.18921
	
	.p2align 4
	.L__pc.18921: Dma_PatchDst (.L__pc.18921.ST), (.L__movme_cp.68), (.L__pc.18921.ST)
	.L__pc.18921.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18922
	
	.L__pc.18922: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.18923
	
	.p2align 4
	.L__pc.18923: Dma_PatchDst (.L__pc.18923.ST), (.L__movme_cp.24), (.L__pc.18923.ST)
	.L__pc.18923.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18924
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18924: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18925
	
	.p2align 4
	.L__pc.18925: Dma_PatchDst (.L__pc.18925.ST), (.L__movme_cp.24), (.L__pc.18925.ST)
	.L__pc.18925.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18926
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.18926: Dma_PatchSrc (.L__pc.18926.LD), (.L__movme_cp.60), (.L__pc.18926.LD)
	.p2align 4
	.L__pc.18926.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18927
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18927: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18928
	
	.L__pc.18928: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18929
	
	.p2align 4
	.L__pc.18929: Dma_PatchDst (.L__pc.18929.ST), (.L__movme_cp.21), (.L__pc.18929.ST)
	.L__pc.18929.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18930
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.18930: Dma_PatchSrc (.L__pc.18930.LD), (.L__movme_cp.58), (.L__pc.18930.LD)
	.p2align 4
	.L__pc.18930.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18931
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18931: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18932
	
	.L__pc.18932: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.18933
	
	.p2align 4
	.L__pc.18933: Dma_PatchDst (.L__pc.18933.ST), (.L__movme_cp.22), (.L__pc.18933.ST)
	.L__pc.18933.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18934
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18934: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18935
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18935: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.18936
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.18936: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.18937
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18937: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18938
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.18938: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.18939
	
	.p2align 4
	.L__pc.18939: Dma_PatchDst (.L__pc.18939.ST), (.L__movme_cp.24), (.L__pc.18939.ST)
	.L__pc.18939.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18940
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.18940: Dma_PatchSrc (.L__pc.18940.LD), (.L__movme_cp.25), (.L__pc.18940.LD)
	.p2align 4
	.L__pc.18940.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18941
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18941: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18942
	.L__pc.18942: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18943
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.18943: Dma_PatchSrc (.L__pc.18943.LD), (.L__movme_cp.26), (.L__pc.18943.LD)
	.p2align 4
	.L__pc.18943.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18944
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18944: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18945
	.L__pc.18945: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18946
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18946: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18947: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18948: Dma_PatchSrc (.L__pc.18948.LD), (.L__movme_tmp.1), (.L__pc.18948.LD)
	.p2align 4
	.L__pc.18948.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18949
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18949: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18950
	.L__pc.18950: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18951
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18951: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18952: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18953: Dma_PatchSrc (.L__pc.18953.LD), (.L__movme_tmp.1), (.L__pc.18953.LD)
	.p2align 4
	.L__pc.18953.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18954
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18954: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18955
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18955: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18956: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18957: Dma_PatchSrc (.L__pc.18957.LD), (.L__movme_tmp.1), (.L__pc.18957.LD)
	.p2align 4
	.L__pc.18957.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18958
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18958: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18959
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18959: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18960: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18961: Dma_PatchSrc (.L__pc.18961.LD), (.L__movme_tmp.1), (.L__pc.18961.LD)
	.p2align 4
	.L__pc.18961.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18962
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18962: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18963
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18963: Dma_PatchSrc (.L__pc.18963.LD), (.L__movme_cp.24), (.L__pc.18963.LD)
	.p2align 4
	.L__pc.18963.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18964
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18964: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18965
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18965: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18966: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18967: Dma_PatchSrc (.L__pc.18967.LD), (.L__movme_tmp.1), (.L__pc.18967.LD)
	.p2align 4
	.L__pc.18967.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18968
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18968: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18969
	
	.L__pc.18969: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.18970
	
	.p2align 4
	.L__pc.18970: Dma_PatchDst (.L__pc.18970.ST), (.L__movme_cp.69), (.L__pc.18970.ST)
	.L__pc.18970.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18971
	
	.L__pc.18971: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.18972
	
	.p2align 4
	.L__pc.18972: Dma_PatchDst (.L__pc.18972.ST), (.L__movme_cp.54), (.L__pc.18972.ST)
	.L__pc.18972.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.18973
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.18973: Dma_PatchSrc (.L__pc.18973.LD), (.L__movme_cp.30), (.L__pc.18973.LD)
	.p2align 4
	.L__pc.18973.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18974
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.18974: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.18975
	.L__pc.18975: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.18976
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.18976: Dma_PatchSrc (.L__pc.18976.LD), (.L__movme_cp.31), (.L__pc.18976.LD)
	.p2align 4
	.L__pc.18976.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18977
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18977: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18978
	.L__pc.18978: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18979
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.18979: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18980: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18981: Dma_PatchSrc (.L__pc.18981.LD), (.L__movme_tmp.1), (.L__pc.18981.LD)
	.p2align 4
	.L__pc.18981.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18982
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18982: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.18983
	.L__pc.18983: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.18984
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.18984: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18985: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18986: Dma_PatchSrc (.L__pc.18986.LD), (.L__movme_tmp.1), (.L__pc.18986.LD)
	.p2align 4
	.L__pc.18986.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18987
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18987: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18988
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18988: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18989: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18990: Dma_PatchSrc (.L__pc.18990.LD), (.L__movme_tmp.1), (.L__pc.18990.LD)
	.p2align 4
	.L__pc.18990.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18991
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18991: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18992
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.18992: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18993: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.18994: Dma_PatchSrc (.L__pc.18994.LD), (.L__movme_tmp.1), (.L__pc.18994.LD)
	.p2align 4
	.L__pc.18994.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18995
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.18995: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.18996
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.18996: Dma_PatchSrc (.L__pc.18996.LD), (.L__movme_cp.24), (.L__pc.18996.LD)
	.p2align 4
	.L__pc.18996.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.18997
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.18997: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.18998
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.18998: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.18999: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19000: Dma_PatchSrc (.L__pc.19000.LD), (.L__movme_tmp.1), (.L__pc.19000.LD)
	.p2align 4
	.L__pc.19000.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19001
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19001: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19002
	
	.L__pc.19002: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19003
	
	.p2align 4
	.L__pc.19003: Dma_PatchDst (.L__pc.19003.ST), (.L__movme_cp.70), (.L__pc.19003.ST)
	.L__pc.19003.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19004
	
	.L__pc.19004: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19005
	
	.p2align 4
	.L__pc.19005: Dma_PatchDst (.L__pc.19005.ST), (.L__movme_cp.54), (.L__pc.19005.ST)
	.L__pc.19005.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19006
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19006: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19007
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19007: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19008
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19008: Dma_PatchSrc (.L__pc.19008.LD), (.L__movme_cp.24), (.L__pc.19008.LD)
	.p2align 4
	.L__pc.19008.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19009
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19009: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19010
	.L__pc.19010: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19011
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.19011: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19012: Dma_PatchSrc (.L__pc.19012.LD), (.L__movme_tmp.1), (.L__pc.19012.LD)
	.p2align 4
	.L__pc.19012.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19013
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19013: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19014
	.L__pc.19014: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19015
	
	.L__pc.19015: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19016
	
	.p2align 4
	.L__pc.19016: Dma_PatchDst (.L__pc.19016.ST), (.L__movme_cp.72), (.L__pc.19016.ST)
	.L__pc.19016.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19017
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.19017: Dma_PatchSrc (.L__pc.19017.LD), (.L__movme_cp.72), (.L__pc.19017.LD)
	.p2align 4
	.L__pc.19017.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19018
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19018: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19019
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19019: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19020: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19021: Dma_PatchSrc (.L__pc.19021.LD), (.L__movme_tmp.1), (.L__pc.19021.LD)
	.p2align 4
	.L__pc.19021.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19022
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19022: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19023
	
	.L__pc.19023: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19024
	
	.p2align 4
	.L__pc.19024: Dma_PatchDst (.L__pc.19024.ST), (.L__movme_cp.74), (.L__pc.19024.ST)
	.L__pc.19024.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19025
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19025: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19026: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19027: Dma_PatchSrc (.L__pc.19027.LD), (.L__movme_tmp.1), (.L__pc.19027.LD)
	.p2align 4
	.L__pc.19027.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19028
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19028: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19029
	
	.L__pc.19029: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19030
	
	.p2align 4
	.L__pc.19030: Dma_PatchDst (.L__pc.19030.ST), (.L__movme_cp.76), (.L__pc.19030.ST)
	.L__pc.19030.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19031
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.19031: Dma_PatchSrc (.L__pc.19031.LD), (.L__movme_cp.74), (.L__pc.19031.LD)
	.p2align 4
	.L__pc.19031.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19032
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19032: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19033
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.19033: Dma_PatchSrc (.L__pc.19033.LD), ((.L__movme.reg.eax+0)), (.L__pc.19033.LD)
	.p2align 4
	.L__pc.19033.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19034
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19034: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19035
	
	.L__pc.19035: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19036
	
	.p2align 4
	.L__pc.19036: Dma_PatchDst (.L__pc.19036.ST), (.L__movme_cp.77), (.L__pc.19036.ST)
	.L__pc.19036.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19037
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.19037: Dma_PatchSrc (.L__pc.19037.LD), (.L__movme_cp.77), (.L__pc.19037.LD)
	.p2align 4
	.L__pc.19037.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19038
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19038: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19039
	
	.L__pc.19039: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19040
	
	.p2align 4
	.L__pc.19040: Dma_PatchDst (.L__pc.19040.ST), (.L__movme_cp.21), (.L__pc.19040.ST)
	.L__pc.19040.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19041
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.19041: Dma_PatchSrc (.L__pc.19041.LD), (.L__movme_cp.58), (.L__pc.19041.LD)
	.p2align 4
	.L__pc.19041.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19042
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19042: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19043
	
	.L__pc.19043: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19044
	
	.p2align 4
	.L__pc.19044: Dma_PatchDst (.L__pc.19044.ST), (.L__movme_cp.22), (.L__pc.19044.ST)
	.L__pc.19044.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19045
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19045: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19046
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19046: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19047
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19047: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19048
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19048: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19049
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.19049: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.19050
	
	.p2align 4
	.L__pc.19050: Dma_PatchDst (.L__pc.19050.ST), (.L__movme_cp.24), (.L__pc.19050.ST)
	.L__pc.19050.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19051
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.19051: Dma_PatchSrc (.L__pc.19051.LD), (.L__movme_cp.25), (.L__pc.19051.LD)
	.p2align 4
	.L__pc.19051.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19052
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19052: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19053
	.L__pc.19053: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19054
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.19054: Dma_PatchSrc (.L__pc.19054.LD), (.L__movme_cp.26), (.L__pc.19054.LD)
	.p2align 4
	.L__pc.19054.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19055
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19055: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19056
	.L__pc.19056: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19057
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19057: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19058: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19059: Dma_PatchSrc (.L__pc.19059.LD), (.L__movme_tmp.1), (.L__pc.19059.LD)
	.p2align 4
	.L__pc.19059.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19060
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19060: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19061
	.L__pc.19061: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19062
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19062: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19063: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19064: Dma_PatchSrc (.L__pc.19064.LD), (.L__movme_tmp.1), (.L__pc.19064.LD)
	.p2align 4
	.L__pc.19064.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19065
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19065: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19066
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19066: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19067: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19068: Dma_PatchSrc (.L__pc.19068.LD), (.L__movme_tmp.1), (.L__pc.19068.LD)
	.p2align 4
	.L__pc.19068.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19069
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19069: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19070
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19070: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19071: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19072: Dma_PatchSrc (.L__pc.19072.LD), (.L__movme_tmp.1), (.L__pc.19072.LD)
	.p2align 4
	.L__pc.19072.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19073
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19073: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19074
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19074: Dma_PatchSrc (.L__pc.19074.LD), (.L__movme_cp.24), (.L__pc.19074.LD)
	.p2align 4
	.L__pc.19074.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19075
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19075: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19076
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19076: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19077: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19078: Dma_PatchSrc (.L__pc.19078.LD), (.L__movme_tmp.1), (.L__pc.19078.LD)
	.p2align 4
	.L__pc.19078.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19079
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19079: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19080
	
	.L__pc.19080: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19081
	
	.p2align 4
	.L__pc.19081: Dma_PatchDst (.L__pc.19081.ST), (.L__movme_cp.78), (.L__pc.19081.ST)
	.L__pc.19081.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19082
	
	.L__pc.19082: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19083
	
	.p2align 4
	.L__pc.19083: Dma_PatchDst (.L__pc.19083.ST), (.L__movme_cp.54), (.L__pc.19083.ST)
	.L__pc.19083.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19084
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.19084: Dma_PatchSrc (.L__pc.19084.LD), (.L__movme_cp.30), (.L__pc.19084.LD)
	.p2align 4
	.L__pc.19084.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19085
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19085: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19086
	.L__pc.19086: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19087
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.19087: Dma_PatchSrc (.L__pc.19087.LD), (.L__movme_cp.31), (.L__pc.19087.LD)
	.p2align 4
	.L__pc.19087.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19088
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19088: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19089
	.L__pc.19089: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19090
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19090: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19091: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19092: Dma_PatchSrc (.L__pc.19092.LD), (.L__movme_tmp.1), (.L__pc.19092.LD)
	.p2align 4
	.L__pc.19092.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19093
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19093: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19094
	.L__pc.19094: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19095
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19095: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19096: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19097: Dma_PatchSrc (.L__pc.19097.LD), (.L__movme_tmp.1), (.L__pc.19097.LD)
	.p2align 4
	.L__pc.19097.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19098
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19098: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19099
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19099: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19100: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19101: Dma_PatchSrc (.L__pc.19101.LD), (.L__movme_tmp.1), (.L__pc.19101.LD)
	.p2align 4
	.L__pc.19101.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19102
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19102: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19103
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19103: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19104: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19105: Dma_PatchSrc (.L__pc.19105.LD), (.L__movme_tmp.1), (.L__pc.19105.LD)
	.p2align 4
	.L__pc.19105.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19106
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19106: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19107
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19107: Dma_PatchSrc (.L__pc.19107.LD), (.L__movme_cp.24), (.L__pc.19107.LD)
	.p2align 4
	.L__pc.19107.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19108
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19108: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19109
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19109: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19110: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19111: Dma_PatchSrc (.L__pc.19111.LD), (.L__movme_tmp.1), (.L__pc.19111.LD)
	.p2align 4
	.L__pc.19111.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19112
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19112: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19113
	
	.L__pc.19113: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19114
	
	.p2align 4
	.L__pc.19114: Dma_PatchDst (.L__pc.19114.ST), (.L__movme_cp.79), (.L__pc.19114.ST)
	.L__pc.19114.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19115
	
	.L__pc.19115: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19116
	
	.p2align 4
	.L__pc.19116: Dma_PatchDst (.L__pc.19116.ST), (.L__movme_cp.54), (.L__pc.19116.ST)
	.L__pc.19116.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19117
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.19117: Dma_PatchSrc (.L__pc.19117.LD), (.L__movme_cp.74), (.L__pc.19117.LD)
	.p2align 4
	.L__pc.19117.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19118
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19118: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19119
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.19119: Dma_PatchSrc (.L__pc.19119.LD), (.L__movme_cp.77), (.L__pc.19119.LD)
	.p2align 4
	.L__pc.19119.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19120
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19120: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19121
	
	.L__pc.19121: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19122
	
	.p2align 4
	.L__pc.19122: Dma_PatchDst (.L__pc.19122.ST), ((.L__movme.reg.eax+0)), (.L__pc.19122.ST)
	.L__pc.19122.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19123
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.19123: Dma_PatchSrc (.L__pc.19123.LD), (.L__movme_cp.76), (.L__pc.19123.LD)
	.p2align 4
	.L__pc.19123.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19124
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19124: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19125
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.19125: Dma_PatchSrc (.L__pc.19125.LD), ((.L__movme.reg.eax+0)), (.L__pc.19125.LD)
	.p2align 4
	.L__pc.19125.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19126
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19126: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19127
	
	.L__pc.19127: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19128
	
	.p2align 4
	.L__pc.19128: Dma_PatchDst (.L__pc.19128.ST), (.L__movme_cp.80), (.L__pc.19128.ST)
	.L__pc.19128.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19129
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19129: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19130
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19130: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19131
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.19131: Dma_PatchSrc (.L__pc.19131.LD), (.L__movme_cp.100), (.L__pc.19131.LD)
	.p2align 4
	.L__pc.19131.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19132
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19132: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19133
	.L__pc.19133: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19134
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.88 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.19134: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19135: Dma_PatchSrc (.L__pc.19135.LD), (.L__movme_tmp.1), (.L__pc.19135.LD)
	.p2align 4
	.L__pc.19135.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19136
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19136: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19137
	.L__pc.19137: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19138
	
	.L__pc.19138: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19139
	
	.p2align 4
	.L__pc.19139: Dma_PatchDst (.L__pc.19139.ST), (.L__movme_cp.100), (.L__pc.19139.ST)
	.L__pc.19139.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19140
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.19140: Dma_PatchSrc (.L__pc.19140.LD), (.L__movme_cp.76), (.L__pc.19140.LD)
	.p2align 4
	.L__pc.19140.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19141
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19141: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19142
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.19142: Dma_PatchSrc (.L__pc.19142.LD), (.L__movme_cp.80), (.L__pc.19142.LD)
	.p2align 4
	.L__pc.19142.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19143
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19143: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19144
	
	.L__pc.19144: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19145
	
	.p2align 4
	.L__pc.19145: Dma_PatchDst (.L__pc.19145.ST), ((.L__movme.reg.eax+0)), (.L__pc.19145.ST)
	.L__pc.19145.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19146
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19146: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19147
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19147: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19148
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.19148: Dma_PatchSrc (.L__pc.19148.LD), (.L__movme_cp.99), (.L__pc.19148.LD)
	.p2align 4
	.L__pc.19148.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19149
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19149: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19150
	.L__pc.19150: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19151
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19151: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.89 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19152: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19153: Dma_PatchSrc (.L__pc.19153.LD), (.L__movme_tmp.1), (.L__pc.19153.LD)
	.p2align 4
	.L__pc.19153.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19154
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19154: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19155
	
	.L__pc.19155: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19156
	
	.p2align 4
	.L__pc.19156: Dma_PatchDst (.L__pc.19156.ST), (.L__movme_cp.24), (.L__pc.19156.ST)
	.L__pc.19156.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19157
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19157: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19158
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19158: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19159
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19159: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19160
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19160: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19161
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.19161: Dma_PatchSrc (.L__pc.19161.LD), (.L__movme_cp.63), (.L__pc.19161.LD)
	.p2align 4
	.L__pc.19161.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19162
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19162: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19163
	.L__pc.19163: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19164
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19164: Dma_PatchSrc (.L__pc.19164.LD), (.L__movme_cp.24), (.L__pc.19164.LD)
	.p2align 4
	.L__pc.19164.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19165
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19165: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19166
	.L__pc.19166: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19167
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19167: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19168: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19169: Dma_PatchSrc (.L__pc.19169.LD), (.L__movme_tmp.1), (.L__pc.19169.LD)
	.p2align 4
	.L__pc.19169.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19170
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19170: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19171
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19171: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19172: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19173: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19174: Dma_PatchSrc (.L__pc.19174.LD), (.L__movme_tmp.1), (.L__pc.19174.LD)
	.p2align 4
	.L__pc.19174.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19175
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19175: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19176
	
	.L__pc.19176: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19177
	
	.p2align 4
	.L__pc.19177: Dma_PatchDst (.L__pc.19177.ST), (.L__movme_cp.63), (.L__pc.19177.ST)
	.L__pc.19177.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19178
	
	.L__pc.19178: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19179
	
	.p2align 4
	.L__pc.19179: Dma_PatchDst (.L__pc.19179.ST), (.L__movme_cp.24), (.L__pc.19179.ST)
	.L__pc.19179.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19180
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19180: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19181
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19181: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19182
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19182: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19183
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19183: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19184
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.19184: Dma_PatchSrc (.L__pc.19184.LD), (.L__movme_cp.66), (.L__pc.19184.LD)
	.p2align 4
	.L__pc.19184.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19185
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19185: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19186
	.L__pc.19186: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19187
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19187: Dma_PatchSrc (.L__pc.19187.LD), (.L__movme_cp.24), (.L__pc.19187.LD)
	.p2align 4
	.L__pc.19187.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19188
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19188: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19189
	.L__pc.19189: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19190
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19190: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19191: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19192: Dma_PatchSrc (.L__pc.19192.LD), (.L__movme_tmp.1), (.L__pc.19192.LD)
	.p2align 4
	.L__pc.19192.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19193
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19193: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19194
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19194: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19195: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19196: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19197: Dma_PatchSrc (.L__pc.19197.LD), (.L__movme_tmp.1), (.L__pc.19197.LD)
	.p2align 4
	.L__pc.19197.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19198
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19198: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19199
	
	.L__pc.19199: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19200
	
	.p2align 4
	.L__pc.19200: Dma_PatchDst (.L__pc.19200.ST), (.L__movme_cp.66), (.L__pc.19200.ST)
	.L__pc.19200.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19201
	
	.L__pc.19201: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19202
	
	.p2align 4
	.L__pc.19202: Dma_PatchDst (.L__pc.19202.ST), (.L__movme_cp.24), (.L__pc.19202.ST)
	.L__pc.19202.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19203
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19203: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19204
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19204: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19205
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19205: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19206
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19206: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19207
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.19207: Dma_PatchSrc (.L__pc.19207.LD), (.L__movme_cp.67), (.L__pc.19207.LD)
	.p2align 4
	.L__pc.19207.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19208
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19208: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19209
	.L__pc.19209: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19210
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19210: Dma_PatchSrc (.L__pc.19210.LD), (.L__movme_cp.24), (.L__pc.19210.LD)
	.p2align 4
	.L__pc.19210.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19211
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19211: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19212
	.L__pc.19212: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19213
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19213: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19214: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19215: Dma_PatchSrc (.L__pc.19215.LD), (.L__movme_tmp.1), (.L__pc.19215.LD)
	.p2align 4
	.L__pc.19215.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19216
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19216: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19217
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19217: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19218: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19219: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19220: Dma_PatchSrc (.L__pc.19220.LD), (.L__movme_tmp.1), (.L__pc.19220.LD)
	.p2align 4
	.L__pc.19220.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19221
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19221: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19222
	
	.L__pc.19222: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19223
	
	.p2align 4
	.L__pc.19223: Dma_PatchDst (.L__pc.19223.ST), (.L__movme_cp.67), (.L__pc.19223.ST)
	.L__pc.19223.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19224
	
	.L__pc.19224: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19225
	
	.p2align 4
	.L__pc.19225: Dma_PatchDst (.L__pc.19225.ST), (.L__movme_cp.24), (.L__pc.19225.ST)
	.L__pc.19225.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19226
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19226: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19227
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19227: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19228
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19228: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19229
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19229: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19230
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.19230: Dma_PatchSrc (.L__pc.19230.LD), (.L__movme_cp.68), (.L__pc.19230.LD)
	.p2align 4
	.L__pc.19230.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19231
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19231: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19232
	.L__pc.19232: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19233
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19233: Dma_PatchSrc (.L__pc.19233.LD), (.L__movme_cp.24), (.L__pc.19233.LD)
	.p2align 4
	.L__pc.19233.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19234
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19234: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19235
	.L__pc.19235: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19236
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19236: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19237: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19238: Dma_PatchSrc (.L__pc.19238.LD), (.L__movme_tmp.1), (.L__pc.19238.LD)
	.p2align 4
	.L__pc.19238.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19239
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19239: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19240
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19240: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19241: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19242: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19243: Dma_PatchSrc (.L__pc.19243.LD), (.L__movme_tmp.1), (.L__pc.19243.LD)
	.p2align 4
	.L__pc.19243.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19244
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19244: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19245
	
	.L__pc.19245: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19246
	
	.p2align 4
	.L__pc.19246: Dma_PatchDst (.L__pc.19246.ST), (.L__movme_cp.68), (.L__pc.19246.ST)
	.L__pc.19246.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19247
	
	.L__pc.19247: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19248
	
	.p2align 4
	.L__pc.19248: Dma_PatchDst (.L__pc.19248.ST), (.L__movme_cp.24), (.L__pc.19248.ST)
	.L__pc.19248.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19249
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19249: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19250
	
	.p2align 4
	.L__pc.19250: Dma_PatchDst (.L__pc.19250.ST), (.L__movme_cp.24), (.L__pc.19250.ST)
	.L__pc.19250.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19251
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.19251: Dma_PatchSrc (.L__pc.19251.LD), (.L__movme_cp.60), (.L__pc.19251.LD)
	.p2align 4
	.L__pc.19251.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19252
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19252: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19253
	
	.L__pc.19253: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19254
	
	.p2align 4
	.L__pc.19254: Dma_PatchDst (.L__pc.19254.ST), (.L__movme_cp.21), (.L__pc.19254.ST)
	.L__pc.19254.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19255
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.19255: Dma_PatchSrc (.L__pc.19255.LD), (.L__movme_cp.58), (.L__pc.19255.LD)
	.p2align 4
	.L__pc.19255.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19256
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19256: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19257
	
	.L__pc.19257: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19258
	
	.p2align 4
	.L__pc.19258: Dma_PatchDst (.L__pc.19258.ST), (.L__movme_cp.22), (.L__pc.19258.ST)
	.L__pc.19258.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19259
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19259: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19260
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19260: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19261
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19261: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19262
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19262: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19263
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.19263: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.19264
	
	.p2align 4
	.L__pc.19264: Dma_PatchDst (.L__pc.19264.ST), (.L__movme_cp.24), (.L__pc.19264.ST)
	.L__pc.19264.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19265
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.19265: Dma_PatchSrc (.L__pc.19265.LD), (.L__movme_cp.25), (.L__pc.19265.LD)
	.p2align 4
	.L__pc.19265.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19266
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19266: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19267
	.L__pc.19267: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19268
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.19268: Dma_PatchSrc (.L__pc.19268.LD), (.L__movme_cp.26), (.L__pc.19268.LD)
	.p2align 4
	.L__pc.19268.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19269
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19269: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19270
	.L__pc.19270: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19271
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19271: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19272: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19273: Dma_PatchSrc (.L__pc.19273.LD), (.L__movme_tmp.1), (.L__pc.19273.LD)
	.p2align 4
	.L__pc.19273.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19274
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19274: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19275
	.L__pc.19275: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19276
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19276: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19277: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19278: Dma_PatchSrc (.L__pc.19278.LD), (.L__movme_tmp.1), (.L__pc.19278.LD)
	.p2align 4
	.L__pc.19278.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19279
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19279: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19280
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19280: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19281: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19282: Dma_PatchSrc (.L__pc.19282.LD), (.L__movme_tmp.1), (.L__pc.19282.LD)
	.p2align 4
	.L__pc.19282.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19283
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19283: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19284
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19284: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19285: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19286: Dma_PatchSrc (.L__pc.19286.LD), (.L__movme_tmp.1), (.L__pc.19286.LD)
	.p2align 4
	.L__pc.19286.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19287
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19287: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19288
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19288: Dma_PatchSrc (.L__pc.19288.LD), (.L__movme_cp.24), (.L__pc.19288.LD)
	.p2align 4
	.L__pc.19288.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19289
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19289: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19290
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19290: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19291: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19292: Dma_PatchSrc (.L__pc.19292.LD), (.L__movme_tmp.1), (.L__pc.19292.LD)
	.p2align 4
	.L__pc.19292.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19293
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19293: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19294
	
	.L__pc.19294: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19295
	
	.p2align 4
	.L__pc.19295: Dma_PatchDst (.L__pc.19295.ST), (.L__movme_cp.69), (.L__pc.19295.ST)
	.L__pc.19295.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19296
	
	.L__pc.19296: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19297
	
	.p2align 4
	.L__pc.19297: Dma_PatchDst (.L__pc.19297.ST), (.L__movme_cp.54), (.L__pc.19297.ST)
	.L__pc.19297.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19298
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.19298: Dma_PatchSrc (.L__pc.19298.LD), (.L__movme_cp.30), (.L__pc.19298.LD)
	.p2align 4
	.L__pc.19298.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19299
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19299: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19300
	.L__pc.19300: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19301
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.19301: Dma_PatchSrc (.L__pc.19301.LD), (.L__movme_cp.31), (.L__pc.19301.LD)
	.p2align 4
	.L__pc.19301.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19302
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19302: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19303
	.L__pc.19303: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19304
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19304: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19305: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19306: Dma_PatchSrc (.L__pc.19306.LD), (.L__movme_tmp.1), (.L__pc.19306.LD)
	.p2align 4
	.L__pc.19306.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19307
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19307: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19308
	.L__pc.19308: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19309
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19309: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19310: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19311: Dma_PatchSrc (.L__pc.19311.LD), (.L__movme_tmp.1), (.L__pc.19311.LD)
	.p2align 4
	.L__pc.19311.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19312
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19312: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19313
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19313: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19314: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19315: Dma_PatchSrc (.L__pc.19315.LD), (.L__movme_tmp.1), (.L__pc.19315.LD)
	.p2align 4
	.L__pc.19315.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19316
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19316: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19317
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19317: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19318: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19319: Dma_PatchSrc (.L__pc.19319.LD), (.L__movme_tmp.1), (.L__pc.19319.LD)
	.p2align 4
	.L__pc.19319.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19320
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19320: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19321
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19321: Dma_PatchSrc (.L__pc.19321.LD), (.L__movme_cp.24), (.L__pc.19321.LD)
	.p2align 4
	.L__pc.19321.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19322
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19322: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19323
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19323: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19324: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19325: Dma_PatchSrc (.L__pc.19325.LD), (.L__movme_tmp.1), (.L__pc.19325.LD)
	.p2align 4
	.L__pc.19325.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19326
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19326: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19327
	
	.L__pc.19327: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19328
	
	.p2align 4
	.L__pc.19328: Dma_PatchDst (.L__pc.19328.ST), (.L__movme_cp.70), (.L__pc.19328.ST)
	.L__pc.19328.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19329
	
	.L__pc.19329: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19330
	
	.p2align 4
	.L__pc.19330: Dma_PatchDst (.L__pc.19330.ST), (.L__movme_cp.54), (.L__pc.19330.ST)
	.L__pc.19330.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19331
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19331: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19332
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19332: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19333
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19333: Dma_PatchSrc (.L__pc.19333.LD), (.L__movme_cp.24), (.L__pc.19333.LD)
	.p2align 4
	.L__pc.19333.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19334
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19334: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19335
	.L__pc.19335: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19336
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.19336: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19337: Dma_PatchSrc (.L__pc.19337.LD), (.L__movme_tmp.1), (.L__pc.19337.LD)
	.p2align 4
	.L__pc.19337.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19338
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19338: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19339
	.L__pc.19339: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19340
	
	.L__pc.19340: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19341
	
	.p2align 4
	.L__pc.19341: Dma_PatchDst (.L__pc.19341.ST), (.L__movme_cp.72), (.L__pc.19341.ST)
	.L__pc.19341.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19342
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.19342: Dma_PatchSrc (.L__pc.19342.LD), (.L__movme_cp.72), (.L__pc.19342.LD)
	.p2align 4
	.L__pc.19342.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19343
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19343: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19344
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19344: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19345: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19346: Dma_PatchSrc (.L__pc.19346.LD), (.L__movme_tmp.1), (.L__pc.19346.LD)
	.p2align 4
	.L__pc.19346.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19347
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19347: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19348
	
	.L__pc.19348: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19349
	
	.p2align 4
	.L__pc.19349: Dma_PatchDst (.L__pc.19349.ST), (.L__movme_cp.74), (.L__pc.19349.ST)
	.L__pc.19349.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19350
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19350: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19351: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19352: Dma_PatchSrc (.L__pc.19352.LD), (.L__movme_tmp.1), (.L__pc.19352.LD)
	.p2align 4
	.L__pc.19352.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19353
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19353: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19354
	
	.L__pc.19354: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19355
	
	.p2align 4
	.L__pc.19355: Dma_PatchDst (.L__pc.19355.ST), (.L__movme_cp.76), (.L__pc.19355.ST)
	.L__pc.19355.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19356
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.19356: Dma_PatchSrc (.L__pc.19356.LD), (.L__movme_cp.74), (.L__pc.19356.LD)
	.p2align 4
	.L__pc.19356.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19357
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19357: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19358
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.19358: Dma_PatchSrc (.L__pc.19358.LD), ((.L__movme.reg.eax+0)), (.L__pc.19358.LD)
	.p2align 4
	.L__pc.19358.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19359
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19359: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19360
	
	.L__pc.19360: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19361
	
	.p2align 4
	.L__pc.19361: Dma_PatchDst (.L__pc.19361.ST), (.L__movme_cp.77), (.L__pc.19361.ST)
	.L__pc.19361.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19362
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.19362: Dma_PatchSrc (.L__pc.19362.LD), (.L__movme_cp.77), (.L__pc.19362.LD)
	.p2align 4
	.L__pc.19362.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19363
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19363: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19364
	
	.L__pc.19364: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19365
	
	.p2align 4
	.L__pc.19365: Dma_PatchDst (.L__pc.19365.ST), (.L__movme_cp.21), (.L__pc.19365.ST)
	.L__pc.19365.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19366
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.19366: Dma_PatchSrc (.L__pc.19366.LD), (.L__movme_cp.58), (.L__pc.19366.LD)
	.p2align 4
	.L__pc.19366.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19367
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19367: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19368
	
	.L__pc.19368: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19369
	
	.p2align 4
	.L__pc.19369: Dma_PatchDst (.L__pc.19369.ST), (.L__movme_cp.22), (.L__pc.19369.ST)
	.L__pc.19369.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19370
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19370: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19371
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19371: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19372
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19372: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19373
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19373: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19374
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.19374: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.19375
	
	.p2align 4
	.L__pc.19375: Dma_PatchDst (.L__pc.19375.ST), (.L__movme_cp.24), (.L__pc.19375.ST)
	.L__pc.19375.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19376
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.19376: Dma_PatchSrc (.L__pc.19376.LD), (.L__movme_cp.25), (.L__pc.19376.LD)
	.p2align 4
	.L__pc.19376.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19377
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19377: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19378
	.L__pc.19378: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19379
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.19379: Dma_PatchSrc (.L__pc.19379.LD), (.L__movme_cp.26), (.L__pc.19379.LD)
	.p2align 4
	.L__pc.19379.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19380
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19380: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19381
	.L__pc.19381: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19382
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19382: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19383: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19384: Dma_PatchSrc (.L__pc.19384.LD), (.L__movme_tmp.1), (.L__pc.19384.LD)
	.p2align 4
	.L__pc.19384.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19385
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19385: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19386
	.L__pc.19386: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19387
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19387: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19388: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19389: Dma_PatchSrc (.L__pc.19389.LD), (.L__movme_tmp.1), (.L__pc.19389.LD)
	.p2align 4
	.L__pc.19389.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19390
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19390: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19391
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19391: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19392: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19393: Dma_PatchSrc (.L__pc.19393.LD), (.L__movme_tmp.1), (.L__pc.19393.LD)
	.p2align 4
	.L__pc.19393.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19394
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19394: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19395
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19395: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19396: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19397: Dma_PatchSrc (.L__pc.19397.LD), (.L__movme_tmp.1), (.L__pc.19397.LD)
	.p2align 4
	.L__pc.19397.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19398
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19398: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19399
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19399: Dma_PatchSrc (.L__pc.19399.LD), (.L__movme_cp.24), (.L__pc.19399.LD)
	.p2align 4
	.L__pc.19399.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19400
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19400: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19401
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19401: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19402: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19403: Dma_PatchSrc (.L__pc.19403.LD), (.L__movme_tmp.1), (.L__pc.19403.LD)
	.p2align 4
	.L__pc.19403.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19404
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19404: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19405
	
	.L__pc.19405: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19406
	
	.p2align 4
	.L__pc.19406: Dma_PatchDst (.L__pc.19406.ST), (.L__movme_cp.78), (.L__pc.19406.ST)
	.L__pc.19406.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19407
	
	.L__pc.19407: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19408
	
	.p2align 4
	.L__pc.19408: Dma_PatchDst (.L__pc.19408.ST), (.L__movme_cp.54), (.L__pc.19408.ST)
	.L__pc.19408.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19409
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.19409: Dma_PatchSrc (.L__pc.19409.LD), (.L__movme_cp.30), (.L__pc.19409.LD)
	.p2align 4
	.L__pc.19409.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19410
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19410: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19411
	.L__pc.19411: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19412
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.19412: Dma_PatchSrc (.L__pc.19412.LD), (.L__movme_cp.31), (.L__pc.19412.LD)
	.p2align 4
	.L__pc.19412.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19413
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19413: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19414
	.L__pc.19414: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19415
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19415: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19416: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19417: Dma_PatchSrc (.L__pc.19417.LD), (.L__movme_tmp.1), (.L__pc.19417.LD)
	.p2align 4
	.L__pc.19417.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19418
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19418: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19419
	.L__pc.19419: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19420
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19420: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19421: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19422: Dma_PatchSrc (.L__pc.19422.LD), (.L__movme_tmp.1), (.L__pc.19422.LD)
	.p2align 4
	.L__pc.19422.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19423
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19423: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19424
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19424: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19425: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19426: Dma_PatchSrc (.L__pc.19426.LD), (.L__movme_tmp.1), (.L__pc.19426.LD)
	.p2align 4
	.L__pc.19426.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19427
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19427: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19428
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19428: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19429: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19430: Dma_PatchSrc (.L__pc.19430.LD), (.L__movme_tmp.1), (.L__pc.19430.LD)
	.p2align 4
	.L__pc.19430.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19431
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19431: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19432
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19432: Dma_PatchSrc (.L__pc.19432.LD), (.L__movme_cp.24), (.L__pc.19432.LD)
	.p2align 4
	.L__pc.19432.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19433
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19433: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19434
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19434: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19435: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19436: Dma_PatchSrc (.L__pc.19436.LD), (.L__movme_tmp.1), (.L__pc.19436.LD)
	.p2align 4
	.L__pc.19436.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19437
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19437: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19438
	
	.L__pc.19438: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19439
	
	.p2align 4
	.L__pc.19439: Dma_PatchDst (.L__pc.19439.ST), (.L__movme_cp.79), (.L__pc.19439.ST)
	.L__pc.19439.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19440
	
	.L__pc.19440: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19441
	
	.p2align 4
	.L__pc.19441: Dma_PatchDst (.L__pc.19441.ST), (.L__movme_cp.54), (.L__pc.19441.ST)
	.L__pc.19441.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19442
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.19442: Dma_PatchSrc (.L__pc.19442.LD), (.L__movme_cp.74), (.L__pc.19442.LD)
	.p2align 4
	.L__pc.19442.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19443
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19443: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19444
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.19444: Dma_PatchSrc (.L__pc.19444.LD), (.L__movme_cp.77), (.L__pc.19444.LD)
	.p2align 4
	.L__pc.19444.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19445
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19445: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19446
	
	.L__pc.19446: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19447
	
	.p2align 4
	.L__pc.19447: Dma_PatchDst (.L__pc.19447.ST), ((.L__movme.reg.eax+0)), (.L__pc.19447.ST)
	.L__pc.19447.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19448
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.19448: Dma_PatchSrc (.L__pc.19448.LD), (.L__movme_cp.76), (.L__pc.19448.LD)
	.p2align 4
	.L__pc.19448.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19449
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19449: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19450
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.19450: Dma_PatchSrc (.L__pc.19450.LD), ((.L__movme.reg.eax+0)), (.L__pc.19450.LD)
	.p2align 4
	.L__pc.19450.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19451
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19451: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19452
	
	.L__pc.19452: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19453
	
	.p2align 4
	.L__pc.19453: Dma_PatchDst (.L__pc.19453.ST), (.L__movme_cp.80), (.L__pc.19453.ST)
	.L__pc.19453.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19454
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19454: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19455
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19455: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19456
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.19456: Dma_PatchSrc (.L__pc.19456.LD), (.L__movme_cp.100), (.L__pc.19456.LD)
	.p2align 4
	.L__pc.19456.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19457
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19457: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19458
	.L__pc.19458: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19459
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.90 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.19459: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19460: Dma_PatchSrc (.L__pc.19460.LD), (.L__movme_tmp.1), (.L__pc.19460.LD)
	.p2align 4
	.L__pc.19460.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19461
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19461: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19462
	.L__pc.19462: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19463
	
	.L__pc.19463: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19464
	
	.p2align 4
	.L__pc.19464: Dma_PatchDst (.L__pc.19464.ST), (.L__movme_cp.100), (.L__pc.19464.ST)
	.L__pc.19464.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19465
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.19465: Dma_PatchSrc (.L__pc.19465.LD), (.L__movme_cp.76), (.L__pc.19465.LD)
	.p2align 4
	.L__pc.19465.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19466
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19466: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19467
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.19467: Dma_PatchSrc (.L__pc.19467.LD), (.L__movme_cp.80), (.L__pc.19467.LD)
	.p2align 4
	.L__pc.19467.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19468
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19468: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19469
	
	.L__pc.19469: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19470
	
	.p2align 4
	.L__pc.19470: Dma_PatchDst (.L__pc.19470.ST), ((.L__movme.reg.eax+0)), (.L__pc.19470.ST)
	.L__pc.19470.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19471
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19471: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19472
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19472: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19473
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.19473: Dma_PatchSrc (.L__pc.19473.LD), (.L__movme_cp.99), (.L__pc.19473.LD)
	.p2align 4
	.L__pc.19473.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19474
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19474: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19475
	.L__pc.19475: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19476
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19476: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.91 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19477: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19478: Dma_PatchSrc (.L__pc.19478.LD), (.L__movme_tmp.1), (.L__pc.19478.LD)
	.p2align 4
	.L__pc.19478.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19479
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19479: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19480
	
	.L__pc.19480: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19481
	
	.p2align 4
	.L__pc.19481: Dma_PatchDst (.L__pc.19481.ST), (.L__movme_cp.24), (.L__pc.19481.ST)
	.L__pc.19481.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19482
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19482: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19483
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19483: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19484
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19484: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19485
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19485: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19486
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.19486: Dma_PatchSrc (.L__pc.19486.LD), (.L__movme_cp.63), (.L__pc.19486.LD)
	.p2align 4
	.L__pc.19486.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19487
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19487: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19488
	.L__pc.19488: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19489
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19489: Dma_PatchSrc (.L__pc.19489.LD), (.L__movme_cp.24), (.L__pc.19489.LD)
	.p2align 4
	.L__pc.19489.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19490
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19490: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19491
	.L__pc.19491: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19492
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19492: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19493: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19494: Dma_PatchSrc (.L__pc.19494.LD), (.L__movme_tmp.1), (.L__pc.19494.LD)
	.p2align 4
	.L__pc.19494.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19495
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19495: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19496
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19496: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19497: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19498: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19499: Dma_PatchSrc (.L__pc.19499.LD), (.L__movme_tmp.1), (.L__pc.19499.LD)
	.p2align 4
	.L__pc.19499.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19500
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19500: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19501
	
	.L__pc.19501: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19502
	
	.p2align 4
	.L__pc.19502: Dma_PatchDst (.L__pc.19502.ST), (.L__movme_cp.63), (.L__pc.19502.ST)
	.L__pc.19502.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19503
	
	.L__pc.19503: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19504
	
	.p2align 4
	.L__pc.19504: Dma_PatchDst (.L__pc.19504.ST), (.L__movme_cp.24), (.L__pc.19504.ST)
	.L__pc.19504.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19505
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19505: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19506
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19506: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19507
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19507: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19508
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19508: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19509
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.19509: Dma_PatchSrc (.L__pc.19509.LD), (.L__movme_cp.66), (.L__pc.19509.LD)
	.p2align 4
	.L__pc.19509.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19510
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19510: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19511
	.L__pc.19511: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19512
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19512: Dma_PatchSrc (.L__pc.19512.LD), (.L__movme_cp.24), (.L__pc.19512.LD)
	.p2align 4
	.L__pc.19512.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19513
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19513: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19514
	.L__pc.19514: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19515
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19515: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19516: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19517: Dma_PatchSrc (.L__pc.19517.LD), (.L__movme_tmp.1), (.L__pc.19517.LD)
	.p2align 4
	.L__pc.19517.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19518
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19518: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19519
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19519: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19520: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19521: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19522: Dma_PatchSrc (.L__pc.19522.LD), (.L__movme_tmp.1), (.L__pc.19522.LD)
	.p2align 4
	.L__pc.19522.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19523
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19523: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19524
	
	.L__pc.19524: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19525
	
	.p2align 4
	.L__pc.19525: Dma_PatchDst (.L__pc.19525.ST), (.L__movme_cp.66), (.L__pc.19525.ST)
	.L__pc.19525.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19526
	
	.L__pc.19526: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19527
	
	.p2align 4
	.L__pc.19527: Dma_PatchDst (.L__pc.19527.ST), (.L__movme_cp.24), (.L__pc.19527.ST)
	.L__pc.19527.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19528
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19528: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19529
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19529: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19530
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19530: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19531
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19531: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19532
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.19532: Dma_PatchSrc (.L__pc.19532.LD), (.L__movme_cp.67), (.L__pc.19532.LD)
	.p2align 4
	.L__pc.19532.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19533
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19533: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19534
	.L__pc.19534: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19535
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19535: Dma_PatchSrc (.L__pc.19535.LD), (.L__movme_cp.24), (.L__pc.19535.LD)
	.p2align 4
	.L__pc.19535.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19536
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19536: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19537
	.L__pc.19537: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19538
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19538: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19539: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19540: Dma_PatchSrc (.L__pc.19540.LD), (.L__movme_tmp.1), (.L__pc.19540.LD)
	.p2align 4
	.L__pc.19540.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19541
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19541: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19542
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19542: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19543: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19544: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19545: Dma_PatchSrc (.L__pc.19545.LD), (.L__movme_tmp.1), (.L__pc.19545.LD)
	.p2align 4
	.L__pc.19545.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19546
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19546: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19547
	
	.L__pc.19547: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19548
	
	.p2align 4
	.L__pc.19548: Dma_PatchDst (.L__pc.19548.ST), (.L__movme_cp.67), (.L__pc.19548.ST)
	.L__pc.19548.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19549
	
	.L__pc.19549: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19550
	
	.p2align 4
	.L__pc.19550: Dma_PatchDst (.L__pc.19550.ST), (.L__movme_cp.24), (.L__pc.19550.ST)
	.L__pc.19550.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19551
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19551: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19552
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19552: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19553
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19553: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19554
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19554: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19555
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.19555: Dma_PatchSrc (.L__pc.19555.LD), (.L__movme_cp.68), (.L__pc.19555.LD)
	.p2align 4
	.L__pc.19555.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19556
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19556: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19557
	.L__pc.19557: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19558
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19558: Dma_PatchSrc (.L__pc.19558.LD), (.L__movme_cp.24), (.L__pc.19558.LD)
	.p2align 4
	.L__pc.19558.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19559
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19559: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19560
	.L__pc.19560: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19561
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19561: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19562: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19563: Dma_PatchSrc (.L__pc.19563.LD), (.L__movme_tmp.1), (.L__pc.19563.LD)
	.p2align 4
	.L__pc.19563.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19564
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19564: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19565
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19565: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19566: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19567: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19568: Dma_PatchSrc (.L__pc.19568.LD), (.L__movme_tmp.1), (.L__pc.19568.LD)
	.p2align 4
	.L__pc.19568.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19569
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19569: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19570
	
	.L__pc.19570: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19571
	
	.p2align 4
	.L__pc.19571: Dma_PatchDst (.L__pc.19571.ST), (.L__movme_cp.68), (.L__pc.19571.ST)
	.L__pc.19571.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19572
	
	.L__pc.19572: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19573
	
	.p2align 4
	.L__pc.19573: Dma_PatchDst (.L__pc.19573.ST), (.L__movme_cp.24), (.L__pc.19573.ST)
	.L__pc.19573.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19574
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19574: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19575
	
	.p2align 4
	.L__pc.19575: Dma_PatchDst (.L__pc.19575.ST), (.L__movme_cp.24), (.L__pc.19575.ST)
	.L__pc.19575.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19576
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.19576: Dma_PatchSrc (.L__pc.19576.LD), (.L__movme_cp.60), (.L__pc.19576.LD)
	.p2align 4
	.L__pc.19576.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19577
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19577: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19578
	
	.L__pc.19578: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19579
	
	.p2align 4
	.L__pc.19579: Dma_PatchDst (.L__pc.19579.ST), (.L__movme_cp.21), (.L__pc.19579.ST)
	.L__pc.19579.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19580
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.19580: Dma_PatchSrc (.L__pc.19580.LD), (.L__movme_cp.58), (.L__pc.19580.LD)
	.p2align 4
	.L__pc.19580.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19581
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19581: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19582
	
	.L__pc.19582: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19583
	
	.p2align 4
	.L__pc.19583: Dma_PatchDst (.L__pc.19583.ST), (.L__movme_cp.22), (.L__pc.19583.ST)
	.L__pc.19583.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19584
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19584: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19585
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19585: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19586
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19586: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19587
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19587: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19588
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.19588: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.19589
	
	.p2align 4
	.L__pc.19589: Dma_PatchDst (.L__pc.19589.ST), (.L__movme_cp.24), (.L__pc.19589.ST)
	.L__pc.19589.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19590
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.19590: Dma_PatchSrc (.L__pc.19590.LD), (.L__movme_cp.25), (.L__pc.19590.LD)
	.p2align 4
	.L__pc.19590.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19591
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19591: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19592
	.L__pc.19592: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19593
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.19593: Dma_PatchSrc (.L__pc.19593.LD), (.L__movme_cp.26), (.L__pc.19593.LD)
	.p2align 4
	.L__pc.19593.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19594
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19594: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19595
	.L__pc.19595: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19596
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19596: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19597: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19598: Dma_PatchSrc (.L__pc.19598.LD), (.L__movme_tmp.1), (.L__pc.19598.LD)
	.p2align 4
	.L__pc.19598.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19599
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19599: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19600
	.L__pc.19600: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19601
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19601: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19602: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19603: Dma_PatchSrc (.L__pc.19603.LD), (.L__movme_tmp.1), (.L__pc.19603.LD)
	.p2align 4
	.L__pc.19603.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19604
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19604: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19605
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19605: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19606: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19607: Dma_PatchSrc (.L__pc.19607.LD), (.L__movme_tmp.1), (.L__pc.19607.LD)
	.p2align 4
	.L__pc.19607.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19608
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19608: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19609
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19609: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19610: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19611: Dma_PatchSrc (.L__pc.19611.LD), (.L__movme_tmp.1), (.L__pc.19611.LD)
	.p2align 4
	.L__pc.19611.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19612
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19612: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19613
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19613: Dma_PatchSrc (.L__pc.19613.LD), (.L__movme_cp.24), (.L__pc.19613.LD)
	.p2align 4
	.L__pc.19613.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19614
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19614: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19615
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19615: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19616: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19617: Dma_PatchSrc (.L__pc.19617.LD), (.L__movme_tmp.1), (.L__pc.19617.LD)
	.p2align 4
	.L__pc.19617.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19618
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19618: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19619
	
	.L__pc.19619: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19620
	
	.p2align 4
	.L__pc.19620: Dma_PatchDst (.L__pc.19620.ST), (.L__movme_cp.69), (.L__pc.19620.ST)
	.L__pc.19620.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19621
	
	.L__pc.19621: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19622
	
	.p2align 4
	.L__pc.19622: Dma_PatchDst (.L__pc.19622.ST), (.L__movme_cp.54), (.L__pc.19622.ST)
	.L__pc.19622.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19623
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.19623: Dma_PatchSrc (.L__pc.19623.LD), (.L__movme_cp.30), (.L__pc.19623.LD)
	.p2align 4
	.L__pc.19623.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19624
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19624: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19625
	.L__pc.19625: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19626
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.19626: Dma_PatchSrc (.L__pc.19626.LD), (.L__movme_cp.31), (.L__pc.19626.LD)
	.p2align 4
	.L__pc.19626.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19627
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19627: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19628
	.L__pc.19628: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19629
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19629: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19630: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19631: Dma_PatchSrc (.L__pc.19631.LD), (.L__movme_tmp.1), (.L__pc.19631.LD)
	.p2align 4
	.L__pc.19631.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19632
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19632: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19633
	.L__pc.19633: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19634
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19634: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19635: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19636: Dma_PatchSrc (.L__pc.19636.LD), (.L__movme_tmp.1), (.L__pc.19636.LD)
	.p2align 4
	.L__pc.19636.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19637
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19637: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19638
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19638: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19639: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19640: Dma_PatchSrc (.L__pc.19640.LD), (.L__movme_tmp.1), (.L__pc.19640.LD)
	.p2align 4
	.L__pc.19640.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19641
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19641: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19642
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19642: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19643: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19644: Dma_PatchSrc (.L__pc.19644.LD), (.L__movme_tmp.1), (.L__pc.19644.LD)
	.p2align 4
	.L__pc.19644.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19645
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19645: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19646
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19646: Dma_PatchSrc (.L__pc.19646.LD), (.L__movme_cp.24), (.L__pc.19646.LD)
	.p2align 4
	.L__pc.19646.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19647
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19647: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19648
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19648: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19649: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19650: Dma_PatchSrc (.L__pc.19650.LD), (.L__movme_tmp.1), (.L__pc.19650.LD)
	.p2align 4
	.L__pc.19650.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19651
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19651: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19652
	
	.L__pc.19652: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19653
	
	.p2align 4
	.L__pc.19653: Dma_PatchDst (.L__pc.19653.ST), (.L__movme_cp.70), (.L__pc.19653.ST)
	.L__pc.19653.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19654
	
	.L__pc.19654: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19655
	
	.p2align 4
	.L__pc.19655: Dma_PatchDst (.L__pc.19655.ST), (.L__movme_cp.54), (.L__pc.19655.ST)
	.L__pc.19655.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19656
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19656: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19657
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19657: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19658
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19658: Dma_PatchSrc (.L__pc.19658.LD), (.L__movme_cp.24), (.L__pc.19658.LD)
	.p2align 4
	.L__pc.19658.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19659
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19659: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19660
	.L__pc.19660: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19661
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.19661: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19662: Dma_PatchSrc (.L__pc.19662.LD), (.L__movme_tmp.1), (.L__pc.19662.LD)
	.p2align 4
	.L__pc.19662.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19663
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19663: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19664
	.L__pc.19664: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19665
	
	.L__pc.19665: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19666
	
	.p2align 4
	.L__pc.19666: Dma_PatchDst (.L__pc.19666.ST), (.L__movme_cp.72), (.L__pc.19666.ST)
	.L__pc.19666.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19667
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.19667: Dma_PatchSrc (.L__pc.19667.LD), (.L__movme_cp.72), (.L__pc.19667.LD)
	.p2align 4
	.L__pc.19667.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19668
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19668: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19669
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19669: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19670: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19671: Dma_PatchSrc (.L__pc.19671.LD), (.L__movme_tmp.1), (.L__pc.19671.LD)
	.p2align 4
	.L__pc.19671.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19672
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19672: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19673
	
	.L__pc.19673: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19674
	
	.p2align 4
	.L__pc.19674: Dma_PatchDst (.L__pc.19674.ST), (.L__movme_cp.74), (.L__pc.19674.ST)
	.L__pc.19674.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19675
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19675: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19676: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19677: Dma_PatchSrc (.L__pc.19677.LD), (.L__movme_tmp.1), (.L__pc.19677.LD)
	.p2align 4
	.L__pc.19677.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19678
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19678: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19679
	
	.L__pc.19679: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19680
	
	.p2align 4
	.L__pc.19680: Dma_PatchDst (.L__pc.19680.ST), (.L__movme_cp.76), (.L__pc.19680.ST)
	.L__pc.19680.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19681
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.19681: Dma_PatchSrc (.L__pc.19681.LD), (.L__movme_cp.74), (.L__pc.19681.LD)
	.p2align 4
	.L__pc.19681.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19682
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19682: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19683
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.19683: Dma_PatchSrc (.L__pc.19683.LD), ((.L__movme.reg.eax+0)), (.L__pc.19683.LD)
	.p2align 4
	.L__pc.19683.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19684
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19684: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19685
	
	.L__pc.19685: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19686
	
	.p2align 4
	.L__pc.19686: Dma_PatchDst (.L__pc.19686.ST), (.L__movme_cp.77), (.L__pc.19686.ST)
	.L__pc.19686.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19687
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.19687: Dma_PatchSrc (.L__pc.19687.LD), (.L__movme_cp.77), (.L__pc.19687.LD)
	.p2align 4
	.L__pc.19687.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19688
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19688: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19689
	
	.L__pc.19689: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19690
	
	.p2align 4
	.L__pc.19690: Dma_PatchDst (.L__pc.19690.ST), (.L__movme_cp.21), (.L__pc.19690.ST)
	.L__pc.19690.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19691
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.19691: Dma_PatchSrc (.L__pc.19691.LD), (.L__movme_cp.58), (.L__pc.19691.LD)
	.p2align 4
	.L__pc.19691.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19692
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19692: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19693
	
	.L__pc.19693: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19694
	
	.p2align 4
	.L__pc.19694: Dma_PatchDst (.L__pc.19694.ST), (.L__movme_cp.22), (.L__pc.19694.ST)
	.L__pc.19694.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19695
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19695: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19696
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19696: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19697
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19697: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19698
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19698: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19699
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.19699: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.19700
	
	.p2align 4
	.L__pc.19700: Dma_PatchDst (.L__pc.19700.ST), (.L__movme_cp.24), (.L__pc.19700.ST)
	.L__pc.19700.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19701
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.19701: Dma_PatchSrc (.L__pc.19701.LD), (.L__movme_cp.25), (.L__pc.19701.LD)
	.p2align 4
	.L__pc.19701.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19702
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19702: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19703
	.L__pc.19703: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19704
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.19704: Dma_PatchSrc (.L__pc.19704.LD), (.L__movme_cp.26), (.L__pc.19704.LD)
	.p2align 4
	.L__pc.19704.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19705
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19705: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19706
	.L__pc.19706: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19707
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19707: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19708: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19709: Dma_PatchSrc (.L__pc.19709.LD), (.L__movme_tmp.1), (.L__pc.19709.LD)
	.p2align 4
	.L__pc.19709.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19710
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19710: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19711
	.L__pc.19711: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19712
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19712: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19713: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19714: Dma_PatchSrc (.L__pc.19714.LD), (.L__movme_tmp.1), (.L__pc.19714.LD)
	.p2align 4
	.L__pc.19714.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19715
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19715: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19716
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19716: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19717: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19718: Dma_PatchSrc (.L__pc.19718.LD), (.L__movme_tmp.1), (.L__pc.19718.LD)
	.p2align 4
	.L__pc.19718.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19719
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19719: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19720
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19720: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19721: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19722: Dma_PatchSrc (.L__pc.19722.LD), (.L__movme_tmp.1), (.L__pc.19722.LD)
	.p2align 4
	.L__pc.19722.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19723
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19723: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19724
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19724: Dma_PatchSrc (.L__pc.19724.LD), (.L__movme_cp.24), (.L__pc.19724.LD)
	.p2align 4
	.L__pc.19724.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19725
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19725: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19726
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19726: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19727: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19728: Dma_PatchSrc (.L__pc.19728.LD), (.L__movme_tmp.1), (.L__pc.19728.LD)
	.p2align 4
	.L__pc.19728.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19729
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19729: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19730
	
	.L__pc.19730: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19731
	
	.p2align 4
	.L__pc.19731: Dma_PatchDst (.L__pc.19731.ST), (.L__movme_cp.78), (.L__pc.19731.ST)
	.L__pc.19731.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19732
	
	.L__pc.19732: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19733
	
	.p2align 4
	.L__pc.19733: Dma_PatchDst (.L__pc.19733.ST), (.L__movme_cp.54), (.L__pc.19733.ST)
	.L__pc.19733.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19734
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.19734: Dma_PatchSrc (.L__pc.19734.LD), (.L__movme_cp.30), (.L__pc.19734.LD)
	.p2align 4
	.L__pc.19734.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19735
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19735: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19736
	.L__pc.19736: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19737
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.19737: Dma_PatchSrc (.L__pc.19737.LD), (.L__movme_cp.31), (.L__pc.19737.LD)
	.p2align 4
	.L__pc.19737.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19738
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19738: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19739
	.L__pc.19739: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19740
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19740: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19741: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19742: Dma_PatchSrc (.L__pc.19742.LD), (.L__movme_tmp.1), (.L__pc.19742.LD)
	.p2align 4
	.L__pc.19742.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19743
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19743: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19744
	.L__pc.19744: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19745
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19745: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19746: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19747: Dma_PatchSrc (.L__pc.19747.LD), (.L__movme_tmp.1), (.L__pc.19747.LD)
	.p2align 4
	.L__pc.19747.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19748
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19748: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19749
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19749: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19750: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19751: Dma_PatchSrc (.L__pc.19751.LD), (.L__movme_tmp.1), (.L__pc.19751.LD)
	.p2align 4
	.L__pc.19751.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19752
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19752: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19753
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19753: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19754: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19755: Dma_PatchSrc (.L__pc.19755.LD), (.L__movme_tmp.1), (.L__pc.19755.LD)
	.p2align 4
	.L__pc.19755.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19756
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19756: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19757
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19757: Dma_PatchSrc (.L__pc.19757.LD), (.L__movme_cp.24), (.L__pc.19757.LD)
	.p2align 4
	.L__pc.19757.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19758
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19758: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19759
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19759: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19760: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19761: Dma_PatchSrc (.L__pc.19761.LD), (.L__movme_tmp.1), (.L__pc.19761.LD)
	.p2align 4
	.L__pc.19761.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19762
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19762: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19763
	
	.L__pc.19763: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19764
	
	.p2align 4
	.L__pc.19764: Dma_PatchDst (.L__pc.19764.ST), (.L__movme_cp.79), (.L__pc.19764.ST)
	.L__pc.19764.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19765
	
	.L__pc.19765: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19766
	
	.p2align 4
	.L__pc.19766: Dma_PatchDst (.L__pc.19766.ST), (.L__movme_cp.54), (.L__pc.19766.ST)
	.L__pc.19766.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19767
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.19767: Dma_PatchSrc (.L__pc.19767.LD), (.L__movme_cp.74), (.L__pc.19767.LD)
	.p2align 4
	.L__pc.19767.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19768
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19768: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19769
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.19769: Dma_PatchSrc (.L__pc.19769.LD), (.L__movme_cp.77), (.L__pc.19769.LD)
	.p2align 4
	.L__pc.19769.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19770
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19770: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19771
	
	.L__pc.19771: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19772
	
	.p2align 4
	.L__pc.19772: Dma_PatchDst (.L__pc.19772.ST), ((.L__movme.reg.eax+0)), (.L__pc.19772.ST)
	.L__pc.19772.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19773
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.19773: Dma_PatchSrc (.L__pc.19773.LD), (.L__movme_cp.76), (.L__pc.19773.LD)
	.p2align 4
	.L__pc.19773.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19774
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19774: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19775
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.19775: Dma_PatchSrc (.L__pc.19775.LD), ((.L__movme.reg.eax+0)), (.L__pc.19775.LD)
	.p2align 4
	.L__pc.19775.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19776
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19776: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19777
	
	.L__pc.19777: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19778
	
	.p2align 4
	.L__pc.19778: Dma_PatchDst (.L__pc.19778.ST), (.L__movme_cp.80), (.L__pc.19778.ST)
	.L__pc.19778.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19779
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19779: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19780
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19780: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19781
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.19781: Dma_PatchSrc (.L__pc.19781.LD), (.L__movme_cp.100), (.L__pc.19781.LD)
	.p2align 4
	.L__pc.19781.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19782
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19782: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19783
	.L__pc.19783: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19784
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.92 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.19784: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19785: Dma_PatchSrc (.L__pc.19785.LD), (.L__movme_tmp.1), (.L__pc.19785.LD)
	.p2align 4
	.L__pc.19785.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19786
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19786: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19787
	.L__pc.19787: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19788
	
	.L__pc.19788: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19789
	
	.p2align 4
	.L__pc.19789: Dma_PatchDst (.L__pc.19789.ST), (.L__movme_cp.100), (.L__pc.19789.ST)
	.L__pc.19789.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19790
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.19790: Dma_PatchSrc (.L__pc.19790.LD), (.L__movme_cp.76), (.L__pc.19790.LD)
	.p2align 4
	.L__pc.19790.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19791
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19791: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19792
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.19792: Dma_PatchSrc (.L__pc.19792.LD), (.L__movme_cp.80), (.L__pc.19792.LD)
	.p2align 4
	.L__pc.19792.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19793
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19793: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19794
	
	.L__pc.19794: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19795
	
	.p2align 4
	.L__pc.19795: Dma_PatchDst (.L__pc.19795.ST), ((.L__movme.reg.eax+0)), (.L__pc.19795.ST)
	.L__pc.19795.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19796
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19796: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19797
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19797: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19798
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.19798: Dma_PatchSrc (.L__pc.19798.LD), (.L__movme_cp.99), (.L__pc.19798.LD)
	.p2align 4
	.L__pc.19798.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19799
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19799: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19800
	.L__pc.19800: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19801
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19801: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.93 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19802: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19803: Dma_PatchSrc (.L__pc.19803.LD), (.L__movme_tmp.1), (.L__pc.19803.LD)
	.p2align 4
	.L__pc.19803.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19804
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19804: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19805
	
	.L__pc.19805: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19806
	
	.p2align 4
	.L__pc.19806: Dma_PatchDst (.L__pc.19806.ST), (.L__movme_cp.24), (.L__pc.19806.ST)
	.L__pc.19806.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19807
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19807: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19808
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19808: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19809
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19809: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19810
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19810: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19811
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.19811: Dma_PatchSrc (.L__pc.19811.LD), (.L__movme_cp.63), (.L__pc.19811.LD)
	.p2align 4
	.L__pc.19811.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19812
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19812: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19813
	.L__pc.19813: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19814
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19814: Dma_PatchSrc (.L__pc.19814.LD), (.L__movme_cp.24), (.L__pc.19814.LD)
	.p2align 4
	.L__pc.19814.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19815
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19815: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19816
	.L__pc.19816: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19817
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19817: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19818: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19819: Dma_PatchSrc (.L__pc.19819.LD), (.L__movme_tmp.1), (.L__pc.19819.LD)
	.p2align 4
	.L__pc.19819.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19820
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19820: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19821
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19821: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19822: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19823: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19824: Dma_PatchSrc (.L__pc.19824.LD), (.L__movme_tmp.1), (.L__pc.19824.LD)
	.p2align 4
	.L__pc.19824.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19825
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19825: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19826
	
	.L__pc.19826: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19827
	
	.p2align 4
	.L__pc.19827: Dma_PatchDst (.L__pc.19827.ST), (.L__movme_cp.63), (.L__pc.19827.ST)
	.L__pc.19827.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19828
	
	.L__pc.19828: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19829
	
	.p2align 4
	.L__pc.19829: Dma_PatchDst (.L__pc.19829.ST), (.L__movme_cp.24), (.L__pc.19829.ST)
	.L__pc.19829.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19830
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19830: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19831
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19831: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19832
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19832: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19833
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19833: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19834
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.19834: Dma_PatchSrc (.L__pc.19834.LD), (.L__movme_cp.66), (.L__pc.19834.LD)
	.p2align 4
	.L__pc.19834.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19835
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19835: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19836
	.L__pc.19836: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19837
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19837: Dma_PatchSrc (.L__pc.19837.LD), (.L__movme_cp.24), (.L__pc.19837.LD)
	.p2align 4
	.L__pc.19837.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19838
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19838: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19839
	.L__pc.19839: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19840
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19840: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19841: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19842: Dma_PatchSrc (.L__pc.19842.LD), (.L__movme_tmp.1), (.L__pc.19842.LD)
	.p2align 4
	.L__pc.19842.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19843
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19843: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19844
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19844: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19845: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19846: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19847: Dma_PatchSrc (.L__pc.19847.LD), (.L__movme_tmp.1), (.L__pc.19847.LD)
	.p2align 4
	.L__pc.19847.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19848
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19848: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19849
	
	.L__pc.19849: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19850
	
	.p2align 4
	.L__pc.19850: Dma_PatchDst (.L__pc.19850.ST), (.L__movme_cp.66), (.L__pc.19850.ST)
	.L__pc.19850.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19851
	
	.L__pc.19851: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19852
	
	.p2align 4
	.L__pc.19852: Dma_PatchDst (.L__pc.19852.ST), (.L__movme_cp.24), (.L__pc.19852.ST)
	.L__pc.19852.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19853
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19853: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19854
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19854: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19855
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19855: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19856
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19856: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19857
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.19857: Dma_PatchSrc (.L__pc.19857.LD), (.L__movme_cp.67), (.L__pc.19857.LD)
	.p2align 4
	.L__pc.19857.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19858
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19858: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19859
	.L__pc.19859: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19860
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19860: Dma_PatchSrc (.L__pc.19860.LD), (.L__movme_cp.24), (.L__pc.19860.LD)
	.p2align 4
	.L__pc.19860.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19861
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19861: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19862
	.L__pc.19862: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19863
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19863: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19864: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19865: Dma_PatchSrc (.L__pc.19865.LD), (.L__movme_tmp.1), (.L__pc.19865.LD)
	.p2align 4
	.L__pc.19865.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19866
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19866: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19867
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19867: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19868: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19869: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19870: Dma_PatchSrc (.L__pc.19870.LD), (.L__movme_tmp.1), (.L__pc.19870.LD)
	.p2align 4
	.L__pc.19870.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19871
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19871: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19872
	
	.L__pc.19872: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19873
	
	.p2align 4
	.L__pc.19873: Dma_PatchDst (.L__pc.19873.ST), (.L__movme_cp.67), (.L__pc.19873.ST)
	.L__pc.19873.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19874
	
	.L__pc.19874: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19875
	
	.p2align 4
	.L__pc.19875: Dma_PatchDst (.L__pc.19875.ST), (.L__movme_cp.24), (.L__pc.19875.ST)
	.L__pc.19875.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19876
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19876: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19877
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19877: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19878
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19878: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19879
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19879: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19880
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.19880: Dma_PatchSrc (.L__pc.19880.LD), (.L__movme_cp.68), (.L__pc.19880.LD)
	.p2align 4
	.L__pc.19880.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19881
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19881: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19882
	.L__pc.19882: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19883
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19883: Dma_PatchSrc (.L__pc.19883.LD), (.L__movme_cp.24), (.L__pc.19883.LD)
	.p2align 4
	.L__pc.19883.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19884
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19884: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.19885
	.L__pc.19885: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.19886
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19886: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19887: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19888: Dma_PatchSrc (.L__pc.19888.LD), (.L__movme_tmp.1), (.L__pc.19888.LD)
	.p2align 4
	.L__pc.19888.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19889
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19889: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19890
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.19890: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.19891: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.19892: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19893: Dma_PatchSrc (.L__pc.19893.LD), (.L__movme_tmp.1), (.L__pc.19893.LD)
	.p2align 4
	.L__pc.19893.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19894
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19894: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19895
	
	.L__pc.19895: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.19896
	
	.p2align 4
	.L__pc.19896: Dma_PatchDst (.L__pc.19896.ST), (.L__movme_cp.68), (.L__pc.19896.ST)
	.L__pc.19896.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19897
	
	.L__pc.19897: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.19898
	
	.p2align 4
	.L__pc.19898: Dma_PatchDst (.L__pc.19898.ST), (.L__movme_cp.24), (.L__pc.19898.ST)
	.L__pc.19898.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19899
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19899: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19900
	
	.p2align 4
	.L__pc.19900: Dma_PatchDst (.L__pc.19900.ST), (.L__movme_cp.24), (.L__pc.19900.ST)
	.L__pc.19900.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19901
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.19901: Dma_PatchSrc (.L__pc.19901.LD), (.L__movme_cp.60), (.L__pc.19901.LD)
	.p2align 4
	.L__pc.19901.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19902
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19902: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19903
	
	.L__pc.19903: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19904
	
	.p2align 4
	.L__pc.19904: Dma_PatchDst (.L__pc.19904.ST), (.L__movme_cp.21), (.L__pc.19904.ST)
	.L__pc.19904.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19905
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.19905: Dma_PatchSrc (.L__pc.19905.LD), (.L__movme_cp.58), (.L__pc.19905.LD)
	.p2align 4
	.L__pc.19905.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19906
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19906: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19907
	
	.L__pc.19907: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19908
	
	.p2align 4
	.L__pc.19908: Dma_PatchDst (.L__pc.19908.ST), (.L__movme_cp.22), (.L__pc.19908.ST)
	.L__pc.19908.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19909
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19909: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19910
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19910: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19911
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19911: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19912
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19912: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19913
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.19913: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.19914
	
	.p2align 4
	.L__pc.19914: Dma_PatchDst (.L__pc.19914.ST), (.L__movme_cp.24), (.L__pc.19914.ST)
	.L__pc.19914.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19915
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.19915: Dma_PatchSrc (.L__pc.19915.LD), (.L__movme_cp.25), (.L__pc.19915.LD)
	.p2align 4
	.L__pc.19915.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19916
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19916: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19917
	.L__pc.19917: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19918
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.19918: Dma_PatchSrc (.L__pc.19918.LD), (.L__movme_cp.26), (.L__pc.19918.LD)
	.p2align 4
	.L__pc.19918.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19919
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19919: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19920
	.L__pc.19920: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19921
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19921: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19922: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19923: Dma_PatchSrc (.L__pc.19923.LD), (.L__movme_tmp.1), (.L__pc.19923.LD)
	.p2align 4
	.L__pc.19923.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19924
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19924: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19925
	.L__pc.19925: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19926
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19926: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19927: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19928: Dma_PatchSrc (.L__pc.19928.LD), (.L__movme_tmp.1), (.L__pc.19928.LD)
	.p2align 4
	.L__pc.19928.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19929
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19929: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19930
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19930: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19931: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19932: Dma_PatchSrc (.L__pc.19932.LD), (.L__movme_tmp.1), (.L__pc.19932.LD)
	.p2align 4
	.L__pc.19932.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19933
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19933: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19934
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19934: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19935: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19936: Dma_PatchSrc (.L__pc.19936.LD), (.L__movme_tmp.1), (.L__pc.19936.LD)
	.p2align 4
	.L__pc.19936.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19937
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19937: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19938
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19938: Dma_PatchSrc (.L__pc.19938.LD), (.L__movme_cp.24), (.L__pc.19938.LD)
	.p2align 4
	.L__pc.19938.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19939
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19939: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19940
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19940: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19941: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19942: Dma_PatchSrc (.L__pc.19942.LD), (.L__movme_tmp.1), (.L__pc.19942.LD)
	.p2align 4
	.L__pc.19942.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19943
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19943: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19944
	
	.L__pc.19944: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19945
	
	.p2align 4
	.L__pc.19945: Dma_PatchDst (.L__pc.19945.ST), (.L__movme_cp.69), (.L__pc.19945.ST)
	.L__pc.19945.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19946
	
	.L__pc.19946: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19947
	
	.p2align 4
	.L__pc.19947: Dma_PatchDst (.L__pc.19947.ST), (.L__movme_cp.54), (.L__pc.19947.ST)
	.L__pc.19947.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19948
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.19948: Dma_PatchSrc (.L__pc.19948.LD), (.L__movme_cp.30), (.L__pc.19948.LD)
	.p2align 4
	.L__pc.19948.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19949
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19949: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.19950
	.L__pc.19950: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.19951
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.19951: Dma_PatchSrc (.L__pc.19951.LD), (.L__movme_cp.31), (.L__pc.19951.LD)
	.p2align 4
	.L__pc.19951.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19952
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19952: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19953
	.L__pc.19953: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19954
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.19954: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19955: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19956: Dma_PatchSrc (.L__pc.19956.LD), (.L__movme_tmp.1), (.L__pc.19956.LD)
	.p2align 4
	.L__pc.19956.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19957
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19957: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.19958
	.L__pc.19958: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.19959
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19959: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19960: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19961: Dma_PatchSrc (.L__pc.19961.LD), (.L__movme_tmp.1), (.L__pc.19961.LD)
	.p2align 4
	.L__pc.19961.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19962
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19962: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19963
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19963: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19964: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19965: Dma_PatchSrc (.L__pc.19965.LD), (.L__movme_tmp.1), (.L__pc.19965.LD)
	.p2align 4
	.L__pc.19965.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19966
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19966: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19967
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.19967: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19968: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19969: Dma_PatchSrc (.L__pc.19969.LD), (.L__movme_tmp.1), (.L__pc.19969.LD)
	.p2align 4
	.L__pc.19969.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19970
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19970: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19971
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19971: Dma_PatchSrc (.L__pc.19971.LD), (.L__movme_cp.24), (.L__pc.19971.LD)
	.p2align 4
	.L__pc.19971.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19972
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.19972: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.19973
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.19973: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19974: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19975: Dma_PatchSrc (.L__pc.19975.LD), (.L__movme_tmp.1), (.L__pc.19975.LD)
	.p2align 4
	.L__pc.19975.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19976
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19976: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19977
	
	.L__pc.19977: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.19978
	
	.p2align 4
	.L__pc.19978: Dma_PatchDst (.L__pc.19978.ST), (.L__movme_cp.70), (.L__pc.19978.ST)
	.L__pc.19978.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19979
	
	.L__pc.19979: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19980
	
	.p2align 4
	.L__pc.19980: Dma_PatchDst (.L__pc.19980.ST), (.L__movme_cp.54), (.L__pc.19980.ST)
	.L__pc.19980.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19981
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.19981: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.19982
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19982: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19983
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.19983: Dma_PatchSrc (.L__pc.19983.LD), (.L__movme_cp.24), (.L__pc.19983.LD)
	.p2align 4
	.L__pc.19983.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19984
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19984: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19985
	.L__pc.19985: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19986
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.19986: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19987: Dma_PatchSrc (.L__pc.19987.LD), (.L__movme_tmp.1), (.L__pc.19987.LD)
	.p2align 4
	.L__pc.19987.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19988
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19988: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.19989
	.L__pc.19989: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.19990
	
	.L__pc.19990: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.19991
	
	.p2align 4
	.L__pc.19991: Dma_PatchDst (.L__pc.19991.ST), (.L__movme_cp.72), (.L__pc.19991.ST)
	.L__pc.19991.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.19992
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.19992: Dma_PatchSrc (.L__pc.19992.LD), (.L__movme_cp.72), (.L__pc.19992.LD)
	.p2align 4
	.L__pc.19992.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19993
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.19993: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.19994
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.19994: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.19995: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.19996: Dma_PatchSrc (.L__pc.19996.LD), (.L__movme_tmp.1), (.L__pc.19996.LD)
	.p2align 4
	.L__pc.19996.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.19997
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.19997: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.19998
	
	.L__pc.19998: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.19999
	
	.p2align 4
	.L__pc.19999: Dma_PatchDst (.L__pc.19999.ST), (.L__movme_cp.74), (.L__pc.19999.ST)
	.L__pc.19999.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20000
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20000: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20001: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20002: Dma_PatchSrc (.L__pc.20002.LD), (.L__movme_tmp.1), (.L__pc.20002.LD)
	.p2align 4
	.L__pc.20002.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20003
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20003: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20004
	
	.L__pc.20004: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20005
	
	.p2align 4
	.L__pc.20005: Dma_PatchDst (.L__pc.20005.ST), (.L__movme_cp.76), (.L__pc.20005.ST)
	.L__pc.20005.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20006
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.20006: Dma_PatchSrc (.L__pc.20006.LD), (.L__movme_cp.74), (.L__pc.20006.LD)
	.p2align 4
	.L__pc.20006.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20007
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20007: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20008
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.20008: Dma_PatchSrc (.L__pc.20008.LD), ((.L__movme.reg.eax+0)), (.L__pc.20008.LD)
	.p2align 4
	.L__pc.20008.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20009
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20009: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20010
	
	.L__pc.20010: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20011
	
	.p2align 4
	.L__pc.20011: Dma_PatchDst (.L__pc.20011.ST), (.L__movme_cp.77), (.L__pc.20011.ST)
	.L__pc.20011.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20012
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.20012: Dma_PatchSrc (.L__pc.20012.LD), (.L__movme_cp.77), (.L__pc.20012.LD)
	.p2align 4
	.L__pc.20012.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20013
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20013: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20014
	
	.L__pc.20014: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20015
	
	.p2align 4
	.L__pc.20015: Dma_PatchDst (.L__pc.20015.ST), (.L__movme_cp.21), (.L__pc.20015.ST)
	.L__pc.20015.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20016
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.20016: Dma_PatchSrc (.L__pc.20016.LD), (.L__movme_cp.58), (.L__pc.20016.LD)
	.p2align 4
	.L__pc.20016.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20017
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20017: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20018
	
	.L__pc.20018: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20019
	
	.p2align 4
	.L__pc.20019: Dma_PatchDst (.L__pc.20019.ST), (.L__movme_cp.22), (.L__pc.20019.ST)
	.L__pc.20019.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20020
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20020: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20021
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20021: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20022
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20022: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20023
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20023: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20024
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.20024: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.20025
	
	.p2align 4
	.L__pc.20025: Dma_PatchDst (.L__pc.20025.ST), (.L__movme_cp.24), (.L__pc.20025.ST)
	.L__pc.20025.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20026
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.20026: Dma_PatchSrc (.L__pc.20026.LD), (.L__movme_cp.25), (.L__pc.20026.LD)
	.p2align 4
	.L__pc.20026.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20027
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20027: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20028
	.L__pc.20028: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20029
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.20029: Dma_PatchSrc (.L__pc.20029.LD), (.L__movme_cp.26), (.L__pc.20029.LD)
	.p2align 4
	.L__pc.20029.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20030
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20030: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20031
	.L__pc.20031: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20032
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20032: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20033: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20034: Dma_PatchSrc (.L__pc.20034.LD), (.L__movme_tmp.1), (.L__pc.20034.LD)
	.p2align 4
	.L__pc.20034.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20035
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20035: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20036
	.L__pc.20036: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20037
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20037: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20038: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20039: Dma_PatchSrc (.L__pc.20039.LD), (.L__movme_tmp.1), (.L__pc.20039.LD)
	.p2align 4
	.L__pc.20039.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20040
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20040: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20041
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20041: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20042: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20043: Dma_PatchSrc (.L__pc.20043.LD), (.L__movme_tmp.1), (.L__pc.20043.LD)
	.p2align 4
	.L__pc.20043.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20044
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20044: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20045
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20045: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20046: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20047: Dma_PatchSrc (.L__pc.20047.LD), (.L__movme_tmp.1), (.L__pc.20047.LD)
	.p2align 4
	.L__pc.20047.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20048
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20048: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20049
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20049: Dma_PatchSrc (.L__pc.20049.LD), (.L__movme_cp.24), (.L__pc.20049.LD)
	.p2align 4
	.L__pc.20049.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20050
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20050: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20051
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20051: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20052: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20053: Dma_PatchSrc (.L__pc.20053.LD), (.L__movme_tmp.1), (.L__pc.20053.LD)
	.p2align 4
	.L__pc.20053.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20054
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20054: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20055
	
	.L__pc.20055: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20056
	
	.p2align 4
	.L__pc.20056: Dma_PatchDst (.L__pc.20056.ST), (.L__movme_cp.78), (.L__pc.20056.ST)
	.L__pc.20056.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20057
	
	.L__pc.20057: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20058
	
	.p2align 4
	.L__pc.20058: Dma_PatchDst (.L__pc.20058.ST), (.L__movme_cp.54), (.L__pc.20058.ST)
	.L__pc.20058.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20059
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.20059: Dma_PatchSrc (.L__pc.20059.LD), (.L__movme_cp.30), (.L__pc.20059.LD)
	.p2align 4
	.L__pc.20059.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20060
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20060: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20061
	.L__pc.20061: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20062
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.20062: Dma_PatchSrc (.L__pc.20062.LD), (.L__movme_cp.31), (.L__pc.20062.LD)
	.p2align 4
	.L__pc.20062.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20063
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20063: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20064
	.L__pc.20064: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20065
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20065: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20066: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20067: Dma_PatchSrc (.L__pc.20067.LD), (.L__movme_tmp.1), (.L__pc.20067.LD)
	.p2align 4
	.L__pc.20067.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20068
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20068: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20069
	.L__pc.20069: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20070
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20070: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20071: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20072: Dma_PatchSrc (.L__pc.20072.LD), (.L__movme_tmp.1), (.L__pc.20072.LD)
	.p2align 4
	.L__pc.20072.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20073
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20073: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20074
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20074: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20075: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20076: Dma_PatchSrc (.L__pc.20076.LD), (.L__movme_tmp.1), (.L__pc.20076.LD)
	.p2align 4
	.L__pc.20076.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20077
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20077: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20078
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20078: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20079: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20080: Dma_PatchSrc (.L__pc.20080.LD), (.L__movme_tmp.1), (.L__pc.20080.LD)
	.p2align 4
	.L__pc.20080.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20081
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20081: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20082
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20082: Dma_PatchSrc (.L__pc.20082.LD), (.L__movme_cp.24), (.L__pc.20082.LD)
	.p2align 4
	.L__pc.20082.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20083
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20083: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20084
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20084: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20085: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20086: Dma_PatchSrc (.L__pc.20086.LD), (.L__movme_tmp.1), (.L__pc.20086.LD)
	.p2align 4
	.L__pc.20086.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20087
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20087: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20088
	
	.L__pc.20088: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20089
	
	.p2align 4
	.L__pc.20089: Dma_PatchDst (.L__pc.20089.ST), (.L__movme_cp.79), (.L__pc.20089.ST)
	.L__pc.20089.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20090
	
	.L__pc.20090: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20091
	
	.p2align 4
	.L__pc.20091: Dma_PatchDst (.L__pc.20091.ST), (.L__movme_cp.54), (.L__pc.20091.ST)
	.L__pc.20091.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20092
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.20092: Dma_PatchSrc (.L__pc.20092.LD), (.L__movme_cp.74), (.L__pc.20092.LD)
	.p2align 4
	.L__pc.20092.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20093
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20093: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20094
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.20094: Dma_PatchSrc (.L__pc.20094.LD), (.L__movme_cp.77), (.L__pc.20094.LD)
	.p2align 4
	.L__pc.20094.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20095
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20095: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20096
	
	.L__pc.20096: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20097
	
	.p2align 4
	.L__pc.20097: Dma_PatchDst (.L__pc.20097.ST), ((.L__movme.reg.eax+0)), (.L__pc.20097.ST)
	.L__pc.20097.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20098
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.20098: Dma_PatchSrc (.L__pc.20098.LD), (.L__movme_cp.76), (.L__pc.20098.LD)
	.p2align 4
	.L__pc.20098.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20099
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20099: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20100
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.20100: Dma_PatchSrc (.L__pc.20100.LD), ((.L__movme.reg.eax+0)), (.L__pc.20100.LD)
	.p2align 4
	.L__pc.20100.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20101
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20101: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20102
	
	.L__pc.20102: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20103
	
	.p2align 4
	.L__pc.20103: Dma_PatchDst (.L__pc.20103.ST), (.L__movme_cp.80), (.L__pc.20103.ST)
	.L__pc.20103.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20104
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20104: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20105
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20105: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20106
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.20106: Dma_PatchSrc (.L__pc.20106.LD), (.L__movme_cp.100), (.L__pc.20106.LD)
	.p2align 4
	.L__pc.20106.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20107
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20107: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20108
	.L__pc.20108: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20109
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.94 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.20109: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20110: Dma_PatchSrc (.L__pc.20110.LD), (.L__movme_tmp.1), (.L__pc.20110.LD)
	.p2align 4
	.L__pc.20110.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20111
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20111: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20112
	.L__pc.20112: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20113
	
	.L__pc.20113: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20114
	
	.p2align 4
	.L__pc.20114: Dma_PatchDst (.L__pc.20114.ST), (.L__movme_cp.100), (.L__pc.20114.ST)
	.L__pc.20114.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20115
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.20115: Dma_PatchSrc (.L__pc.20115.LD), (.L__movme_cp.76), (.L__pc.20115.LD)
	.p2align 4
	.L__pc.20115.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20116
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20116: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20117
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.20117: Dma_PatchSrc (.L__pc.20117.LD), (.L__movme_cp.80), (.L__pc.20117.LD)
	.p2align 4
	.L__pc.20117.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20118
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20118: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20119
	
	.L__pc.20119: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20120
	
	.p2align 4
	.L__pc.20120: Dma_PatchDst (.L__pc.20120.ST), ((.L__movme.reg.eax+0)), (.L__pc.20120.ST)
	.L__pc.20120.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20121
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20121: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20122
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20122: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20123
	
	// CG.LOAD4 [.L__movme_cp.99} => .L__movme_tmp.0
	.L__pc.20123: Dma_PatchSrc (.L__pc.20123.LD), (.L__movme_cp.99), (.L__pc.20123.LD)
	.p2align 4
	.L__pc.20123.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20124
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20124: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20125
	.L__pc.20125: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20126
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20126: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.95 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20127: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20128: Dma_PatchSrc (.L__pc.20128.LD), (.L__movme_tmp.1), (.L__pc.20128.LD)
	.p2align 4
	.L__pc.20128.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20129
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20129: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20130
	
	.L__pc.20130: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20131
	
	.p2align 4
	.L__pc.20131: Dma_PatchDst (.L__pc.20131.ST), (.L__movme_cp.24), (.L__pc.20131.ST)
	.L__pc.20131.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20132
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20132: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20133
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20133: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20134
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20134: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20135
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20135: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20136
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.20136: Dma_PatchSrc (.L__pc.20136.LD), (.L__movme_cp.63), (.L__pc.20136.LD)
	.p2align 4
	.L__pc.20136.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20137
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20137: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20138
	.L__pc.20138: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20139
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20139: Dma_PatchSrc (.L__pc.20139.LD), (.L__movme_cp.24), (.L__pc.20139.LD)
	.p2align 4
	.L__pc.20139.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20140
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20140: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20141
	.L__pc.20141: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20142
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20142: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20143: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20144: Dma_PatchSrc (.L__pc.20144.LD), (.L__movme_tmp.1), (.L__pc.20144.LD)
	.p2align 4
	.L__pc.20144.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20145
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20145: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20146
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20146: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20147: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20148: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20149: Dma_PatchSrc (.L__pc.20149.LD), (.L__movme_tmp.1), (.L__pc.20149.LD)
	.p2align 4
	.L__pc.20149.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20150
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20150: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20151
	
	.L__pc.20151: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20152
	
	.p2align 4
	.L__pc.20152: Dma_PatchDst (.L__pc.20152.ST), (.L__movme_cp.63), (.L__pc.20152.ST)
	.L__pc.20152.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20153
	
	.L__pc.20153: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20154
	
	.p2align 4
	.L__pc.20154: Dma_PatchDst (.L__pc.20154.ST), (.L__movme_cp.24), (.L__pc.20154.ST)
	.L__pc.20154.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20155
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20155: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20156
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20156: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20157
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20157: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20158
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20158: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20159
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.20159: Dma_PatchSrc (.L__pc.20159.LD), (.L__movme_cp.66), (.L__pc.20159.LD)
	.p2align 4
	.L__pc.20159.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20160
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20160: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20161
	.L__pc.20161: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20162
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20162: Dma_PatchSrc (.L__pc.20162.LD), (.L__movme_cp.24), (.L__pc.20162.LD)
	.p2align 4
	.L__pc.20162.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20163
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20163: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20164
	.L__pc.20164: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20165
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20165: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20166: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20167: Dma_PatchSrc (.L__pc.20167.LD), (.L__movme_tmp.1), (.L__pc.20167.LD)
	.p2align 4
	.L__pc.20167.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20168
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20168: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20169
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20169: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20170: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20171: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20172: Dma_PatchSrc (.L__pc.20172.LD), (.L__movme_tmp.1), (.L__pc.20172.LD)
	.p2align 4
	.L__pc.20172.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20173
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20173: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20174
	
	.L__pc.20174: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20175
	
	.p2align 4
	.L__pc.20175: Dma_PatchDst (.L__pc.20175.ST), (.L__movme_cp.66), (.L__pc.20175.ST)
	.L__pc.20175.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20176
	
	.L__pc.20176: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20177
	
	.p2align 4
	.L__pc.20177: Dma_PatchDst (.L__pc.20177.ST), (.L__movme_cp.24), (.L__pc.20177.ST)
	.L__pc.20177.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20178
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20178: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20179
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20179: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20180
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20180: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20181
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20181: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20182
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.20182: Dma_PatchSrc (.L__pc.20182.LD), (.L__movme_cp.67), (.L__pc.20182.LD)
	.p2align 4
	.L__pc.20182.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20183
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20183: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20184
	.L__pc.20184: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20185
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20185: Dma_PatchSrc (.L__pc.20185.LD), (.L__movme_cp.24), (.L__pc.20185.LD)
	.p2align 4
	.L__pc.20185.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20186
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20186: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20187
	.L__pc.20187: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20188
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20188: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20189: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20190: Dma_PatchSrc (.L__pc.20190.LD), (.L__movme_tmp.1), (.L__pc.20190.LD)
	.p2align 4
	.L__pc.20190.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20191
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20191: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20192
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20192: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20193: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20194: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20195: Dma_PatchSrc (.L__pc.20195.LD), (.L__movme_tmp.1), (.L__pc.20195.LD)
	.p2align 4
	.L__pc.20195.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20196
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20196: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20197
	
	.L__pc.20197: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20198
	
	.p2align 4
	.L__pc.20198: Dma_PatchDst (.L__pc.20198.ST), (.L__movme_cp.67), (.L__pc.20198.ST)
	.L__pc.20198.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20199
	
	.L__pc.20199: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20200
	
	.p2align 4
	.L__pc.20200: Dma_PatchDst (.L__pc.20200.ST), (.L__movme_cp.24), (.L__pc.20200.ST)
	.L__pc.20200.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20201
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20201: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20202
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20202: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20203
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20203: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20204
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20204: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20205
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.20205: Dma_PatchSrc (.L__pc.20205.LD), (.L__movme_cp.68), (.L__pc.20205.LD)
	.p2align 4
	.L__pc.20205.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20206
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20206: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20207
	.L__pc.20207: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20208
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20208: Dma_PatchSrc (.L__pc.20208.LD), (.L__movme_cp.24), (.L__pc.20208.LD)
	.p2align 4
	.L__pc.20208.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20209
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20209: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20210
	.L__pc.20210: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20211
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20211: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20212: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20213: Dma_PatchSrc (.L__pc.20213.LD), (.L__movme_tmp.1), (.L__pc.20213.LD)
	.p2align 4
	.L__pc.20213.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20214
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20214: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20215
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20215: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20216: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20217: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20218: Dma_PatchSrc (.L__pc.20218.LD), (.L__movme_tmp.1), (.L__pc.20218.LD)
	.p2align 4
	.L__pc.20218.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20219
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20219: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20220
	
	.L__pc.20220: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20221
	
	.p2align 4
	.L__pc.20221: Dma_PatchDst (.L__pc.20221.ST), (.L__movme_cp.68), (.L__pc.20221.ST)
	.L__pc.20221.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20222
	
	.L__pc.20222: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20223
	
	.p2align 4
	.L__pc.20223: Dma_PatchDst (.L__pc.20223.ST), (.L__movme_cp.24), (.L__pc.20223.ST)
	.L__pc.20223.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20224
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20224: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20225
	
	.p2align 4
	.L__pc.20225: Dma_PatchDst (.L__pc.20225.ST), (.L__movme_cp.24), (.L__pc.20225.ST)
	.L__pc.20225.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20226
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.20226: Dma_PatchSrc (.L__pc.20226.LD), (.L__movme_cp.60), (.L__pc.20226.LD)
	.p2align 4
	.L__pc.20226.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20227
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20227: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20228
	
	.L__pc.20228: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20229
	
	.p2align 4
	.L__pc.20229: Dma_PatchDst (.L__pc.20229.ST), (.L__movme_cp.21), (.L__pc.20229.ST)
	.L__pc.20229.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20230
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.20230: Dma_PatchSrc (.L__pc.20230.LD), (.L__movme_cp.58), (.L__pc.20230.LD)
	.p2align 4
	.L__pc.20230.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20231
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20231: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20232
	
	.L__pc.20232: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20233
	
	.p2align 4
	.L__pc.20233: Dma_PatchDst (.L__pc.20233.ST), (.L__movme_cp.22), (.L__pc.20233.ST)
	.L__pc.20233.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20234
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20234: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20235
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20235: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20236
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20236: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20237
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20237: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20238
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.20238: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.20239
	
	.p2align 4
	.L__pc.20239: Dma_PatchDst (.L__pc.20239.ST), (.L__movme_cp.24), (.L__pc.20239.ST)
	.L__pc.20239.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20240
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.20240: Dma_PatchSrc (.L__pc.20240.LD), (.L__movme_cp.25), (.L__pc.20240.LD)
	.p2align 4
	.L__pc.20240.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20241
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20241: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20242
	.L__pc.20242: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20243
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.20243: Dma_PatchSrc (.L__pc.20243.LD), (.L__movme_cp.26), (.L__pc.20243.LD)
	.p2align 4
	.L__pc.20243.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20244
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20244: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20245
	.L__pc.20245: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20246
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20246: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20247: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20248: Dma_PatchSrc (.L__pc.20248.LD), (.L__movme_tmp.1), (.L__pc.20248.LD)
	.p2align 4
	.L__pc.20248.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20249
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20249: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20250
	.L__pc.20250: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20251
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20251: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20252: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20253: Dma_PatchSrc (.L__pc.20253.LD), (.L__movme_tmp.1), (.L__pc.20253.LD)
	.p2align 4
	.L__pc.20253.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20254
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20254: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20255
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20255: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20256: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20257: Dma_PatchSrc (.L__pc.20257.LD), (.L__movme_tmp.1), (.L__pc.20257.LD)
	.p2align 4
	.L__pc.20257.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20258
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20258: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20259
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20259: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20260: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20261: Dma_PatchSrc (.L__pc.20261.LD), (.L__movme_tmp.1), (.L__pc.20261.LD)
	.p2align 4
	.L__pc.20261.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20262
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20262: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20263
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20263: Dma_PatchSrc (.L__pc.20263.LD), (.L__movme_cp.24), (.L__pc.20263.LD)
	.p2align 4
	.L__pc.20263.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20264
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20264: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20265
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20265: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20266: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20267: Dma_PatchSrc (.L__pc.20267.LD), (.L__movme_tmp.1), (.L__pc.20267.LD)
	.p2align 4
	.L__pc.20267.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20268
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20268: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20269
	
	.L__pc.20269: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20270
	
	.p2align 4
	.L__pc.20270: Dma_PatchDst (.L__pc.20270.ST), (.L__movme_cp.69), (.L__pc.20270.ST)
	.L__pc.20270.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20271
	
	.L__pc.20271: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20272
	
	.p2align 4
	.L__pc.20272: Dma_PatchDst (.L__pc.20272.ST), (.L__movme_cp.54), (.L__pc.20272.ST)
	.L__pc.20272.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20273
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.20273: Dma_PatchSrc (.L__pc.20273.LD), (.L__movme_cp.30), (.L__pc.20273.LD)
	.p2align 4
	.L__pc.20273.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20274
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20274: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20275
	.L__pc.20275: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20276
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.20276: Dma_PatchSrc (.L__pc.20276.LD), (.L__movme_cp.31), (.L__pc.20276.LD)
	.p2align 4
	.L__pc.20276.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20277
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20277: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20278
	.L__pc.20278: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20279
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20279: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20280: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20281: Dma_PatchSrc (.L__pc.20281.LD), (.L__movme_tmp.1), (.L__pc.20281.LD)
	.p2align 4
	.L__pc.20281.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20282
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20282: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20283
	.L__pc.20283: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20284
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20284: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20285: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20286: Dma_PatchSrc (.L__pc.20286.LD), (.L__movme_tmp.1), (.L__pc.20286.LD)
	.p2align 4
	.L__pc.20286.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20287
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20287: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20288
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20288: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20289: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20290: Dma_PatchSrc (.L__pc.20290.LD), (.L__movme_tmp.1), (.L__pc.20290.LD)
	.p2align 4
	.L__pc.20290.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20291
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20291: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20292
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20292: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20293: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20294: Dma_PatchSrc (.L__pc.20294.LD), (.L__movme_tmp.1), (.L__pc.20294.LD)
	.p2align 4
	.L__pc.20294.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20295
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20295: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20296
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20296: Dma_PatchSrc (.L__pc.20296.LD), (.L__movme_cp.24), (.L__pc.20296.LD)
	.p2align 4
	.L__pc.20296.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20297
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20297: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20298
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20298: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20299: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20300: Dma_PatchSrc (.L__pc.20300.LD), (.L__movme_tmp.1), (.L__pc.20300.LD)
	.p2align 4
	.L__pc.20300.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20301
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20301: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20302
	
	.L__pc.20302: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20303
	
	.p2align 4
	.L__pc.20303: Dma_PatchDst (.L__pc.20303.ST), (.L__movme_cp.70), (.L__pc.20303.ST)
	.L__pc.20303.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20304
	
	.L__pc.20304: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20305
	
	.p2align 4
	.L__pc.20305: Dma_PatchDst (.L__pc.20305.ST), (.L__movme_cp.54), (.L__pc.20305.ST)
	.L__pc.20305.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20306
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20306: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20307
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20307: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20308
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20308: Dma_PatchSrc (.L__pc.20308.LD), (.L__movme_cp.24), (.L__pc.20308.LD)
	.p2align 4
	.L__pc.20308.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20309
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20309: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20310
	.L__pc.20310: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20311
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.20311: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20312: Dma_PatchSrc (.L__pc.20312.LD), (.L__movme_tmp.1), (.L__pc.20312.LD)
	.p2align 4
	.L__pc.20312.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20313
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20313: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20314
	.L__pc.20314: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20315
	
	.L__pc.20315: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20316
	
	.p2align 4
	.L__pc.20316: Dma_PatchDst (.L__pc.20316.ST), (.L__movme_cp.72), (.L__pc.20316.ST)
	.L__pc.20316.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20317
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.20317: Dma_PatchSrc (.L__pc.20317.LD), (.L__movme_cp.72), (.L__pc.20317.LD)
	.p2align 4
	.L__pc.20317.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20318
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20318: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20319
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20319: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20320: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20321: Dma_PatchSrc (.L__pc.20321.LD), (.L__movme_tmp.1), (.L__pc.20321.LD)
	.p2align 4
	.L__pc.20321.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20322
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20322: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20323
	
	.L__pc.20323: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20324
	
	.p2align 4
	.L__pc.20324: Dma_PatchDst (.L__pc.20324.ST), (.L__movme_cp.74), (.L__pc.20324.ST)
	.L__pc.20324.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20325
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20325: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20326: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20327: Dma_PatchSrc (.L__pc.20327.LD), (.L__movme_tmp.1), (.L__pc.20327.LD)
	.p2align 4
	.L__pc.20327.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20328
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20328: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20329
	
	.L__pc.20329: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20330
	
	.p2align 4
	.L__pc.20330: Dma_PatchDst (.L__pc.20330.ST), (.L__movme_cp.76), (.L__pc.20330.ST)
	.L__pc.20330.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20331
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.20331: Dma_PatchSrc (.L__pc.20331.LD), (.L__movme_cp.74), (.L__pc.20331.LD)
	.p2align 4
	.L__pc.20331.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20332
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20332: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20333
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.20333: Dma_PatchSrc (.L__pc.20333.LD), ((.L__movme.reg.eax+0)), (.L__pc.20333.LD)
	.p2align 4
	.L__pc.20333.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20334
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20334: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20335
	
	.L__pc.20335: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20336
	
	.p2align 4
	.L__pc.20336: Dma_PatchDst (.L__pc.20336.ST), (.L__movme_cp.77), (.L__pc.20336.ST)
	.L__pc.20336.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20337
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.20337: Dma_PatchSrc (.L__pc.20337.LD), (.L__movme_cp.77), (.L__pc.20337.LD)
	.p2align 4
	.L__pc.20337.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20338
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20338: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20339
	
	.L__pc.20339: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20340
	
	.p2align 4
	.L__pc.20340: Dma_PatchDst (.L__pc.20340.ST), (.L__movme_cp.21), (.L__pc.20340.ST)
	.L__pc.20340.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20341
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.20341: Dma_PatchSrc (.L__pc.20341.LD), (.L__movme_cp.58), (.L__pc.20341.LD)
	.p2align 4
	.L__pc.20341.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20342
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20342: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20343
	
	.L__pc.20343: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20344
	
	.p2align 4
	.L__pc.20344: Dma_PatchDst (.L__pc.20344.ST), (.L__movme_cp.22), (.L__pc.20344.ST)
	.L__pc.20344.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20345
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20345: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20346
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20346: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20347
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20347: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20348
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20348: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20349
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.20349: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.20350
	
	.p2align 4
	.L__pc.20350: Dma_PatchDst (.L__pc.20350.ST), (.L__movme_cp.24), (.L__pc.20350.ST)
	.L__pc.20350.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20351
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.20351: Dma_PatchSrc (.L__pc.20351.LD), (.L__movme_cp.25), (.L__pc.20351.LD)
	.p2align 4
	.L__pc.20351.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20352
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20352: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20353
	.L__pc.20353: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20354
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.20354: Dma_PatchSrc (.L__pc.20354.LD), (.L__movme_cp.26), (.L__pc.20354.LD)
	.p2align 4
	.L__pc.20354.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20355
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20355: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20356
	.L__pc.20356: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20357
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20357: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20358: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20359: Dma_PatchSrc (.L__pc.20359.LD), (.L__movme_tmp.1), (.L__pc.20359.LD)
	.p2align 4
	.L__pc.20359.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20360
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20360: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20361
	.L__pc.20361: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20362
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20362: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20363: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20364: Dma_PatchSrc (.L__pc.20364.LD), (.L__movme_tmp.1), (.L__pc.20364.LD)
	.p2align 4
	.L__pc.20364.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20365
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20365: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20366
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20366: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20367: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20368: Dma_PatchSrc (.L__pc.20368.LD), (.L__movme_tmp.1), (.L__pc.20368.LD)
	.p2align 4
	.L__pc.20368.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20369
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20369: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20370
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20370: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20371: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20372: Dma_PatchSrc (.L__pc.20372.LD), (.L__movme_tmp.1), (.L__pc.20372.LD)
	.p2align 4
	.L__pc.20372.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20373
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20373: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20374
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20374: Dma_PatchSrc (.L__pc.20374.LD), (.L__movme_cp.24), (.L__pc.20374.LD)
	.p2align 4
	.L__pc.20374.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20375
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20375: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20376
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20376: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20377: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20378: Dma_PatchSrc (.L__pc.20378.LD), (.L__movme_tmp.1), (.L__pc.20378.LD)
	.p2align 4
	.L__pc.20378.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20379
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20379: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20380
	
	.L__pc.20380: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20381
	
	.p2align 4
	.L__pc.20381: Dma_PatchDst (.L__pc.20381.ST), (.L__movme_cp.78), (.L__pc.20381.ST)
	.L__pc.20381.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20382
	
	.L__pc.20382: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20383
	
	.p2align 4
	.L__pc.20383: Dma_PatchDst (.L__pc.20383.ST), (.L__movme_cp.54), (.L__pc.20383.ST)
	.L__pc.20383.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20384
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.20384: Dma_PatchSrc (.L__pc.20384.LD), (.L__movme_cp.30), (.L__pc.20384.LD)
	.p2align 4
	.L__pc.20384.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20385
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20385: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20386
	.L__pc.20386: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20387
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.20387: Dma_PatchSrc (.L__pc.20387.LD), (.L__movme_cp.31), (.L__pc.20387.LD)
	.p2align 4
	.L__pc.20387.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20388
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20388: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20389
	.L__pc.20389: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20390
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20390: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20391: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20392: Dma_PatchSrc (.L__pc.20392.LD), (.L__movme_tmp.1), (.L__pc.20392.LD)
	.p2align 4
	.L__pc.20392.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20393
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20393: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20394
	.L__pc.20394: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20395
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20395: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20396: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20397: Dma_PatchSrc (.L__pc.20397.LD), (.L__movme_tmp.1), (.L__pc.20397.LD)
	.p2align 4
	.L__pc.20397.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20398
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20398: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20399
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20399: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20400: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20401: Dma_PatchSrc (.L__pc.20401.LD), (.L__movme_tmp.1), (.L__pc.20401.LD)
	.p2align 4
	.L__pc.20401.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20402
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20402: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20403
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20403: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20404: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20405: Dma_PatchSrc (.L__pc.20405.LD), (.L__movme_tmp.1), (.L__pc.20405.LD)
	.p2align 4
	.L__pc.20405.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20406
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20406: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20407
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20407: Dma_PatchSrc (.L__pc.20407.LD), (.L__movme_cp.24), (.L__pc.20407.LD)
	.p2align 4
	.L__pc.20407.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20408
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20408: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20409
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20409: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20410: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20411: Dma_PatchSrc (.L__pc.20411.LD), (.L__movme_tmp.1), (.L__pc.20411.LD)
	.p2align 4
	.L__pc.20411.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20412
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20412: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20413
	
	.L__pc.20413: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20414
	
	.p2align 4
	.L__pc.20414: Dma_PatchDst (.L__pc.20414.ST), (.L__movme_cp.79), (.L__pc.20414.ST)
	.L__pc.20414.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20415
	
	.L__pc.20415: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20416
	
	.p2align 4
	.L__pc.20416: Dma_PatchDst (.L__pc.20416.ST), (.L__movme_cp.54), (.L__pc.20416.ST)
	.L__pc.20416.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20417
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.20417: Dma_PatchSrc (.L__pc.20417.LD), (.L__movme_cp.74), (.L__pc.20417.LD)
	.p2align 4
	.L__pc.20417.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20418
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20418: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20419
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.20419: Dma_PatchSrc (.L__pc.20419.LD), (.L__movme_cp.77), (.L__pc.20419.LD)
	.p2align 4
	.L__pc.20419.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20420
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20420: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20421
	
	.L__pc.20421: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20422
	
	.p2align 4
	.L__pc.20422: Dma_PatchDst (.L__pc.20422.ST), ((.L__movme.reg.eax+0)), (.L__pc.20422.ST)
	.L__pc.20422.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20423
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.20423: Dma_PatchSrc (.L__pc.20423.LD), (.L__movme_cp.76), (.L__pc.20423.LD)
	.p2align 4
	.L__pc.20423.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20424
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20424: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20425
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.20425: Dma_PatchSrc (.L__pc.20425.LD), ((.L__movme.reg.eax+0)), (.L__pc.20425.LD)
	.p2align 4
	.L__pc.20425.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20426
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20426: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20427
	
	.L__pc.20427: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20428
	
	.p2align 4
	.L__pc.20428: Dma_PatchDst (.L__pc.20428.ST), (.L__movme_cp.80), (.L__pc.20428.ST)
	.L__pc.20428.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20429
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20429: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20430
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20430: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20431
	
	// CG.LOAD4 [.L__movme_cp.100} => .L__movme_tmp.0
	.L__pc.20431: Dma_PatchSrc (.L__pc.20431.LD), (.L__movme_cp.100), (.L__pc.20431.LD)
	.p2align 4
	.L__pc.20431.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20432
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20432: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20433
	.L__pc.20433: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20434
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.96 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.20434: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20435: Dma_PatchSrc (.L__pc.20435.LD), (.L__movme_tmp.1), (.L__pc.20435.LD)
	.p2align 4
	.L__pc.20435.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20436
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20436: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20437
	.L__pc.20437: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20438
	
	.L__pc.20438: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20439
	
	.p2align 4
	.L__pc.20439: Dma_PatchDst (.L__pc.20439.ST), (.L__movme_cp.100), (.L__pc.20439.ST)
	.L__pc.20439.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20440
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.20440: Dma_PatchSrc (.L__pc.20440.LD), (.L__movme_cp.76), (.L__pc.20440.LD)
	.p2align 4
	.L__pc.20440.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20441
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20441: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20442
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.20442: Dma_PatchSrc (.L__pc.20442.LD), (.L__movme_cp.80), (.L__pc.20442.LD)
	.p2align 4
	.L__pc.20442.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20443
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20443: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20444
	
	.L__pc.20444: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20445
	
	.p2align 4
	.L__pc.20445: Dma_PatchDst (.L__pc.20445.ST), ((.L__movme.reg.eax+0)), (.L__pc.20445.ST)
	.L__pc.20445.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20446
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20446: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20447
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20447: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20448
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.20448: Dma_PatchSrc (.L__pc.20448.LD), (.L__movme_cp.101), (.L__pc.20448.LD)
	.p2align 4
	.L__pc.20448.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20449
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20449: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20450
	.L__pc.20450: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20451
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20451: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.62 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20452: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20453: Dma_PatchSrc (.L__pc.20453.LD), (.L__movme_tmp.1), (.L__pc.20453.LD)
	.p2align 4
	.L__pc.20453.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20454
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20454: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20455
	
	.L__pc.20455: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20456
	
	.p2align 4
	.L__pc.20456: Dma_PatchDst (.L__pc.20456.ST), (.L__movme_cp.24), (.L__pc.20456.ST)
	.L__pc.20456.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20457
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20457: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20458
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20458: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20459
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20459: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20460
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20460: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20461
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.20461: Dma_PatchSrc (.L__pc.20461.LD), (.L__movme_cp.63), (.L__pc.20461.LD)
	.p2align 4
	.L__pc.20461.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20462
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20462: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20463
	.L__pc.20463: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20464
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20464: Dma_PatchSrc (.L__pc.20464.LD), (.L__movme_cp.24), (.L__pc.20464.LD)
	.p2align 4
	.L__pc.20464.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20465
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20465: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20466
	.L__pc.20466: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20467
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20467: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20468: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20469: Dma_PatchSrc (.L__pc.20469.LD), (.L__movme_tmp.1), (.L__pc.20469.LD)
	.p2align 4
	.L__pc.20469.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20470
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20470: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20471
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20471: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20472: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20473: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20474: Dma_PatchSrc (.L__pc.20474.LD), (.L__movme_tmp.1), (.L__pc.20474.LD)
	.p2align 4
	.L__pc.20474.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20475
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20475: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20476
	
	.L__pc.20476: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20477
	
	.p2align 4
	.L__pc.20477: Dma_PatchDst (.L__pc.20477.ST), (.L__movme_cp.63), (.L__pc.20477.ST)
	.L__pc.20477.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20478
	
	.L__pc.20478: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20479
	
	.p2align 4
	.L__pc.20479: Dma_PatchDst (.L__pc.20479.ST), (.L__movme_cp.24), (.L__pc.20479.ST)
	.L__pc.20479.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20480
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20480: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20481
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20481: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20482
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20482: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20483
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20483: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20484
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.20484: Dma_PatchSrc (.L__pc.20484.LD), (.L__movme_cp.66), (.L__pc.20484.LD)
	.p2align 4
	.L__pc.20484.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20485
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20485: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20486
	.L__pc.20486: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20487
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20487: Dma_PatchSrc (.L__pc.20487.LD), (.L__movme_cp.24), (.L__pc.20487.LD)
	.p2align 4
	.L__pc.20487.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20488
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20488: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20489
	.L__pc.20489: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20490
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20490: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20491: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20492: Dma_PatchSrc (.L__pc.20492.LD), (.L__movme_tmp.1), (.L__pc.20492.LD)
	.p2align 4
	.L__pc.20492.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20493
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20493: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20494
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20494: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20495: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20496: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20497: Dma_PatchSrc (.L__pc.20497.LD), (.L__movme_tmp.1), (.L__pc.20497.LD)
	.p2align 4
	.L__pc.20497.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20498
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20498: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20499
	
	.L__pc.20499: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20500
	
	.p2align 4
	.L__pc.20500: Dma_PatchDst (.L__pc.20500.ST), (.L__movme_cp.66), (.L__pc.20500.ST)
	.L__pc.20500.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20501
	
	.L__pc.20501: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20502
	
	.p2align 4
	.L__pc.20502: Dma_PatchDst (.L__pc.20502.ST), (.L__movme_cp.24), (.L__pc.20502.ST)
	.L__pc.20502.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20503
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20503: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20504
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20504: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20505
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20505: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20506
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20506: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20507
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.20507: Dma_PatchSrc (.L__pc.20507.LD), (.L__movme_cp.67), (.L__pc.20507.LD)
	.p2align 4
	.L__pc.20507.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20508
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20508: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20509
	.L__pc.20509: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20510
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20510: Dma_PatchSrc (.L__pc.20510.LD), (.L__movme_cp.24), (.L__pc.20510.LD)
	.p2align 4
	.L__pc.20510.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20511
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20511: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20512
	.L__pc.20512: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20513
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20513: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20514: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20515: Dma_PatchSrc (.L__pc.20515.LD), (.L__movme_tmp.1), (.L__pc.20515.LD)
	.p2align 4
	.L__pc.20515.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20516
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20516: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20517
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20517: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20518: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20519: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20520: Dma_PatchSrc (.L__pc.20520.LD), (.L__movme_tmp.1), (.L__pc.20520.LD)
	.p2align 4
	.L__pc.20520.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20521
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20521: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20522
	
	.L__pc.20522: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20523
	
	.p2align 4
	.L__pc.20523: Dma_PatchDst (.L__pc.20523.ST), (.L__movme_cp.67), (.L__pc.20523.ST)
	.L__pc.20523.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20524
	
	.L__pc.20524: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20525
	
	.p2align 4
	.L__pc.20525: Dma_PatchDst (.L__pc.20525.ST), (.L__movme_cp.24), (.L__pc.20525.ST)
	.L__pc.20525.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20526
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20526: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20527
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20527: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20528
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20528: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20529
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20529: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20530
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.20530: Dma_PatchSrc (.L__pc.20530.LD), (.L__movme_cp.68), (.L__pc.20530.LD)
	.p2align 4
	.L__pc.20530.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20531
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20531: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20532
	.L__pc.20532: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20533
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20533: Dma_PatchSrc (.L__pc.20533.LD), (.L__movme_cp.24), (.L__pc.20533.LD)
	.p2align 4
	.L__pc.20533.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20534
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20534: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20535
	.L__pc.20535: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20536
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20536: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20537: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20538: Dma_PatchSrc (.L__pc.20538.LD), (.L__movme_tmp.1), (.L__pc.20538.LD)
	.p2align 4
	.L__pc.20538.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20539
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20539: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20540
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20540: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20541: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20542: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20543: Dma_PatchSrc (.L__pc.20543.LD), (.L__movme_tmp.1), (.L__pc.20543.LD)
	.p2align 4
	.L__pc.20543.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20544
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20544: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20545
	
	.L__pc.20545: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20546
	
	.p2align 4
	.L__pc.20546: Dma_PatchDst (.L__pc.20546.ST), (.L__movme_cp.68), (.L__pc.20546.ST)
	.L__pc.20546.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20547
	
	.L__pc.20547: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20548
	
	.p2align 4
	.L__pc.20548: Dma_PatchDst (.L__pc.20548.ST), (.L__movme_cp.24), (.L__pc.20548.ST)
	.L__pc.20548.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20549
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20549: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20550
	
	.p2align 4
	.L__pc.20550: Dma_PatchDst (.L__pc.20550.ST), (.L__movme_cp.24), (.L__pc.20550.ST)
	.L__pc.20550.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20551
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.20551: Dma_PatchSrc (.L__pc.20551.LD), (.L__movme_cp.60), (.L__pc.20551.LD)
	.p2align 4
	.L__pc.20551.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20552
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20552: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20553
	
	.L__pc.20553: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20554
	
	.p2align 4
	.L__pc.20554: Dma_PatchDst (.L__pc.20554.ST), (.L__movme_cp.21), (.L__pc.20554.ST)
	.L__pc.20554.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20555
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.20555: Dma_PatchSrc (.L__pc.20555.LD), (.L__movme_cp.58), (.L__pc.20555.LD)
	.p2align 4
	.L__pc.20555.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20556
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20556: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20557
	
	.L__pc.20557: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20558
	
	.p2align 4
	.L__pc.20558: Dma_PatchDst (.L__pc.20558.ST), (.L__movme_cp.22), (.L__pc.20558.ST)
	.L__pc.20558.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20559
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20559: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20560
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20560: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20561
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20561: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20562
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20562: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20563
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.20563: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.20564
	
	.p2align 4
	.L__pc.20564: Dma_PatchDst (.L__pc.20564.ST), (.L__movme_cp.24), (.L__pc.20564.ST)
	.L__pc.20564.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20565
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.20565: Dma_PatchSrc (.L__pc.20565.LD), (.L__movme_cp.25), (.L__pc.20565.LD)
	.p2align 4
	.L__pc.20565.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20566
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20566: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20567
	.L__pc.20567: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20568
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.20568: Dma_PatchSrc (.L__pc.20568.LD), (.L__movme_cp.26), (.L__pc.20568.LD)
	.p2align 4
	.L__pc.20568.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20569
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20569: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20570
	.L__pc.20570: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20571
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20571: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20572: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20573: Dma_PatchSrc (.L__pc.20573.LD), (.L__movme_tmp.1), (.L__pc.20573.LD)
	.p2align 4
	.L__pc.20573.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20574
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20574: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20575
	.L__pc.20575: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20576
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20576: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20577: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20578: Dma_PatchSrc (.L__pc.20578.LD), (.L__movme_tmp.1), (.L__pc.20578.LD)
	.p2align 4
	.L__pc.20578.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20579
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20579: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20580
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20580: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20581: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20582: Dma_PatchSrc (.L__pc.20582.LD), (.L__movme_tmp.1), (.L__pc.20582.LD)
	.p2align 4
	.L__pc.20582.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20583
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20583: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20584
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20584: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20585: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20586: Dma_PatchSrc (.L__pc.20586.LD), (.L__movme_tmp.1), (.L__pc.20586.LD)
	.p2align 4
	.L__pc.20586.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20587
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20587: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20588
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20588: Dma_PatchSrc (.L__pc.20588.LD), (.L__movme_cp.24), (.L__pc.20588.LD)
	.p2align 4
	.L__pc.20588.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20589
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20589: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20590
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20590: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20591: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20592: Dma_PatchSrc (.L__pc.20592.LD), (.L__movme_tmp.1), (.L__pc.20592.LD)
	.p2align 4
	.L__pc.20592.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20593
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20593: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20594
	
	.L__pc.20594: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20595
	
	.p2align 4
	.L__pc.20595: Dma_PatchDst (.L__pc.20595.ST), (.L__movme_cp.69), (.L__pc.20595.ST)
	.L__pc.20595.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20596
	
	.L__pc.20596: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20597
	
	.p2align 4
	.L__pc.20597: Dma_PatchDst (.L__pc.20597.ST), (.L__movme_cp.54), (.L__pc.20597.ST)
	.L__pc.20597.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20598
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.20598: Dma_PatchSrc (.L__pc.20598.LD), (.L__movme_cp.30), (.L__pc.20598.LD)
	.p2align 4
	.L__pc.20598.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20599
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20599: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20600
	.L__pc.20600: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20601
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.20601: Dma_PatchSrc (.L__pc.20601.LD), (.L__movme_cp.31), (.L__pc.20601.LD)
	.p2align 4
	.L__pc.20601.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20602
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20602: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20603
	.L__pc.20603: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20604
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20604: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20605: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20606: Dma_PatchSrc (.L__pc.20606.LD), (.L__movme_tmp.1), (.L__pc.20606.LD)
	.p2align 4
	.L__pc.20606.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20607
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20607: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20608
	.L__pc.20608: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20609
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20609: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20610: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20611: Dma_PatchSrc (.L__pc.20611.LD), (.L__movme_tmp.1), (.L__pc.20611.LD)
	.p2align 4
	.L__pc.20611.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20612
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20612: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20613
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20613: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20614: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20615: Dma_PatchSrc (.L__pc.20615.LD), (.L__movme_tmp.1), (.L__pc.20615.LD)
	.p2align 4
	.L__pc.20615.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20616
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20616: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20617
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20617: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20618: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20619: Dma_PatchSrc (.L__pc.20619.LD), (.L__movme_tmp.1), (.L__pc.20619.LD)
	.p2align 4
	.L__pc.20619.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20620
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20620: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20621
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20621: Dma_PatchSrc (.L__pc.20621.LD), (.L__movme_cp.24), (.L__pc.20621.LD)
	.p2align 4
	.L__pc.20621.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20622
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20622: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20623
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20623: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20624: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20625: Dma_PatchSrc (.L__pc.20625.LD), (.L__movme_tmp.1), (.L__pc.20625.LD)
	.p2align 4
	.L__pc.20625.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20626
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20626: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20627
	
	.L__pc.20627: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20628
	
	.p2align 4
	.L__pc.20628: Dma_PatchDst (.L__pc.20628.ST), (.L__movme_cp.70), (.L__pc.20628.ST)
	.L__pc.20628.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20629
	
	.L__pc.20629: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20630
	
	.p2align 4
	.L__pc.20630: Dma_PatchDst (.L__pc.20630.ST), (.L__movme_cp.54), (.L__pc.20630.ST)
	.L__pc.20630.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20631
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20631: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20632
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20632: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20633
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20633: Dma_PatchSrc (.L__pc.20633.LD), (.L__movme_cp.24), (.L__pc.20633.LD)
	.p2align 4
	.L__pc.20633.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20634
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20634: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20635
	.L__pc.20635: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20636
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.20636: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20637: Dma_PatchSrc (.L__pc.20637.LD), (.L__movme_tmp.1), (.L__pc.20637.LD)
	.p2align 4
	.L__pc.20637.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20638
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20638: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20639
	.L__pc.20639: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20640
	
	.L__pc.20640: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20641
	
	.p2align 4
	.L__pc.20641: Dma_PatchDst (.L__pc.20641.ST), (.L__movme_cp.72), (.L__pc.20641.ST)
	.L__pc.20641.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20642
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.20642: Dma_PatchSrc (.L__pc.20642.LD), (.L__movme_cp.72), (.L__pc.20642.LD)
	.p2align 4
	.L__pc.20642.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20643
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20643: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20644
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20644: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20645: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20646: Dma_PatchSrc (.L__pc.20646.LD), (.L__movme_tmp.1), (.L__pc.20646.LD)
	.p2align 4
	.L__pc.20646.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20647
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20647: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20648
	
	.L__pc.20648: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20649
	
	.p2align 4
	.L__pc.20649: Dma_PatchDst (.L__pc.20649.ST), (.L__movme_cp.74), (.L__pc.20649.ST)
	.L__pc.20649.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20650
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20650: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20651: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20652: Dma_PatchSrc (.L__pc.20652.LD), (.L__movme_tmp.1), (.L__pc.20652.LD)
	.p2align 4
	.L__pc.20652.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20653
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20653: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20654
	
	.L__pc.20654: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20655
	
	.p2align 4
	.L__pc.20655: Dma_PatchDst (.L__pc.20655.ST), (.L__movme_cp.76), (.L__pc.20655.ST)
	.L__pc.20655.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20656
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.20656: Dma_PatchSrc (.L__pc.20656.LD), (.L__movme_cp.74), (.L__pc.20656.LD)
	.p2align 4
	.L__pc.20656.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20657
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20657: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20658
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.20658: Dma_PatchSrc (.L__pc.20658.LD), ((.L__movme.reg.eax+0)), (.L__pc.20658.LD)
	.p2align 4
	.L__pc.20658.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20659
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20659: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20660
	
	.L__pc.20660: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20661
	
	.p2align 4
	.L__pc.20661: Dma_PatchDst (.L__pc.20661.ST), (.L__movme_cp.77), (.L__pc.20661.ST)
	.L__pc.20661.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20662
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.20662: Dma_PatchSrc (.L__pc.20662.LD), (.L__movme_cp.77), (.L__pc.20662.LD)
	.p2align 4
	.L__pc.20662.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20663
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20663: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20664
	
	.L__pc.20664: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20665
	
	.p2align 4
	.L__pc.20665: Dma_PatchDst (.L__pc.20665.ST), (.L__movme_cp.21), (.L__pc.20665.ST)
	.L__pc.20665.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20666
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.20666: Dma_PatchSrc (.L__pc.20666.LD), (.L__movme_cp.58), (.L__pc.20666.LD)
	.p2align 4
	.L__pc.20666.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20667
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20667: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20668
	
	.L__pc.20668: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20669
	
	.p2align 4
	.L__pc.20669: Dma_PatchDst (.L__pc.20669.ST), (.L__movme_cp.22), (.L__pc.20669.ST)
	.L__pc.20669.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20670
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20670: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20671
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20671: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20672
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20672: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20673
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20673: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20674
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.20674: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.20675
	
	.p2align 4
	.L__pc.20675: Dma_PatchDst (.L__pc.20675.ST), (.L__movme_cp.24), (.L__pc.20675.ST)
	.L__pc.20675.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20676
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.20676: Dma_PatchSrc (.L__pc.20676.LD), (.L__movme_cp.25), (.L__pc.20676.LD)
	.p2align 4
	.L__pc.20676.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20677
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20677: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20678
	.L__pc.20678: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20679
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.20679: Dma_PatchSrc (.L__pc.20679.LD), (.L__movme_cp.26), (.L__pc.20679.LD)
	.p2align 4
	.L__pc.20679.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20680
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20680: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20681
	.L__pc.20681: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20682
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20682: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20683: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20684: Dma_PatchSrc (.L__pc.20684.LD), (.L__movme_tmp.1), (.L__pc.20684.LD)
	.p2align 4
	.L__pc.20684.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20685
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20685: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20686
	.L__pc.20686: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20687
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20687: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20688: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20689: Dma_PatchSrc (.L__pc.20689.LD), (.L__movme_tmp.1), (.L__pc.20689.LD)
	.p2align 4
	.L__pc.20689.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20690
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20690: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20691
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20691: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20692: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20693: Dma_PatchSrc (.L__pc.20693.LD), (.L__movme_tmp.1), (.L__pc.20693.LD)
	.p2align 4
	.L__pc.20693.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20694
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20694: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20695
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20695: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20696: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20697: Dma_PatchSrc (.L__pc.20697.LD), (.L__movme_tmp.1), (.L__pc.20697.LD)
	.p2align 4
	.L__pc.20697.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20698
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20698: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20699
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20699: Dma_PatchSrc (.L__pc.20699.LD), (.L__movme_cp.24), (.L__pc.20699.LD)
	.p2align 4
	.L__pc.20699.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20700
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20700: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20701
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20701: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20702: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20703: Dma_PatchSrc (.L__pc.20703.LD), (.L__movme_tmp.1), (.L__pc.20703.LD)
	.p2align 4
	.L__pc.20703.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20704
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20704: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20705
	
	.L__pc.20705: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20706
	
	.p2align 4
	.L__pc.20706: Dma_PatchDst (.L__pc.20706.ST), (.L__movme_cp.78), (.L__pc.20706.ST)
	.L__pc.20706.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20707
	
	.L__pc.20707: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20708
	
	.p2align 4
	.L__pc.20708: Dma_PatchDst (.L__pc.20708.ST), (.L__movme_cp.54), (.L__pc.20708.ST)
	.L__pc.20708.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20709
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.20709: Dma_PatchSrc (.L__pc.20709.LD), (.L__movme_cp.30), (.L__pc.20709.LD)
	.p2align 4
	.L__pc.20709.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20710
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20710: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20711
	.L__pc.20711: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20712
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.20712: Dma_PatchSrc (.L__pc.20712.LD), (.L__movme_cp.31), (.L__pc.20712.LD)
	.p2align 4
	.L__pc.20712.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20713
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20713: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20714
	.L__pc.20714: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20715
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20715: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20716: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20717: Dma_PatchSrc (.L__pc.20717.LD), (.L__movme_tmp.1), (.L__pc.20717.LD)
	.p2align 4
	.L__pc.20717.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20718
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20718: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20719
	.L__pc.20719: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20720
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20720: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20721: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20722: Dma_PatchSrc (.L__pc.20722.LD), (.L__movme_tmp.1), (.L__pc.20722.LD)
	.p2align 4
	.L__pc.20722.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20723
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20723: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20724
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20724: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20725: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20726: Dma_PatchSrc (.L__pc.20726.LD), (.L__movme_tmp.1), (.L__pc.20726.LD)
	.p2align 4
	.L__pc.20726.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20727
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20727: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20728
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20728: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20729: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20730: Dma_PatchSrc (.L__pc.20730.LD), (.L__movme_tmp.1), (.L__pc.20730.LD)
	.p2align 4
	.L__pc.20730.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20731
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20731: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20732
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20732: Dma_PatchSrc (.L__pc.20732.LD), (.L__movme_cp.24), (.L__pc.20732.LD)
	.p2align 4
	.L__pc.20732.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20733
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20733: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20734
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20734: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20735: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20736: Dma_PatchSrc (.L__pc.20736.LD), (.L__movme_tmp.1), (.L__pc.20736.LD)
	.p2align 4
	.L__pc.20736.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20737
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20737: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20738
	
	.L__pc.20738: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20739
	
	.p2align 4
	.L__pc.20739: Dma_PatchDst (.L__pc.20739.ST), (.L__movme_cp.79), (.L__pc.20739.ST)
	.L__pc.20739.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20740
	
	.L__pc.20740: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20741
	
	.p2align 4
	.L__pc.20741: Dma_PatchDst (.L__pc.20741.ST), (.L__movme_cp.54), (.L__pc.20741.ST)
	.L__pc.20741.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20742
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.20742: Dma_PatchSrc (.L__pc.20742.LD), (.L__movme_cp.74), (.L__pc.20742.LD)
	.p2align 4
	.L__pc.20742.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20743
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20743: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20744
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.20744: Dma_PatchSrc (.L__pc.20744.LD), (.L__movme_cp.77), (.L__pc.20744.LD)
	.p2align 4
	.L__pc.20744.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20745
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20745: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20746
	
	.L__pc.20746: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20747
	
	.p2align 4
	.L__pc.20747: Dma_PatchDst (.L__pc.20747.ST), ((.L__movme.reg.eax+0)), (.L__pc.20747.ST)
	.L__pc.20747.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20748
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.20748: Dma_PatchSrc (.L__pc.20748.LD), (.L__movme_cp.76), (.L__pc.20748.LD)
	.p2align 4
	.L__pc.20748.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20749
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20749: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20750
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.20750: Dma_PatchSrc (.L__pc.20750.LD), ((.L__movme.reg.eax+0)), (.L__pc.20750.LD)
	.p2align 4
	.L__pc.20750.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20751
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20751: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20752
	
	.L__pc.20752: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20753
	
	.p2align 4
	.L__pc.20753: Dma_PatchDst (.L__pc.20753.ST), (.L__movme_cp.80), (.L__pc.20753.ST)
	.L__pc.20753.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20754
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20754: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20755
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20755: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20756
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.20756: Dma_PatchSrc (.L__pc.20756.LD), (.L__movme_cp.102), (.L__pc.20756.LD)
	.p2align 4
	.L__pc.20756.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20757
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20757: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20758
	.L__pc.20758: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20759
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.82 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.20759: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20760: Dma_PatchSrc (.L__pc.20760.LD), (.L__movme_tmp.1), (.L__pc.20760.LD)
	.p2align 4
	.L__pc.20760.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20761
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20761: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20762
	.L__pc.20762: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20763
	
	.L__pc.20763: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20764
	
	.p2align 4
	.L__pc.20764: Dma_PatchDst (.L__pc.20764.ST), (.L__movme_cp.102), (.L__pc.20764.ST)
	.L__pc.20764.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20765
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.20765: Dma_PatchSrc (.L__pc.20765.LD), (.L__movme_cp.76), (.L__pc.20765.LD)
	.p2align 4
	.L__pc.20765.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20766
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20766: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20767
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.20767: Dma_PatchSrc (.L__pc.20767.LD), (.L__movme_cp.80), (.L__pc.20767.LD)
	.p2align 4
	.L__pc.20767.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20768
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20768: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20769
	
	.L__pc.20769: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20770
	
	.p2align 4
	.L__pc.20770: Dma_PatchDst (.L__pc.20770.ST), ((.L__movme.reg.eax+0)), (.L__pc.20770.ST)
	.L__pc.20770.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20771
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20771: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20772
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20772: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20773
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.20773: Dma_PatchSrc (.L__pc.20773.LD), (.L__movme_cp.101), (.L__pc.20773.LD)
	.p2align 4
	.L__pc.20773.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20774
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20774: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20775
	.L__pc.20775: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20776
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20776: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.83 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20777: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20778: Dma_PatchSrc (.L__pc.20778.LD), (.L__movme_tmp.1), (.L__pc.20778.LD)
	.p2align 4
	.L__pc.20778.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20779
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20779: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20780
	
	.L__pc.20780: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20781
	
	.p2align 4
	.L__pc.20781: Dma_PatchDst (.L__pc.20781.ST), (.L__movme_cp.24), (.L__pc.20781.ST)
	.L__pc.20781.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20782
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20782: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20783
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20783: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20784
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20784: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20785
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20785: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20786
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.20786: Dma_PatchSrc (.L__pc.20786.LD), (.L__movme_cp.63), (.L__pc.20786.LD)
	.p2align 4
	.L__pc.20786.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20787
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20787: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20788
	.L__pc.20788: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20789
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20789: Dma_PatchSrc (.L__pc.20789.LD), (.L__movme_cp.24), (.L__pc.20789.LD)
	.p2align 4
	.L__pc.20789.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20790
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20790: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20791
	.L__pc.20791: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20792
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20792: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20793: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20794: Dma_PatchSrc (.L__pc.20794.LD), (.L__movme_tmp.1), (.L__pc.20794.LD)
	.p2align 4
	.L__pc.20794.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20795
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20795: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20796
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20796: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20797: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20798: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20799: Dma_PatchSrc (.L__pc.20799.LD), (.L__movme_tmp.1), (.L__pc.20799.LD)
	.p2align 4
	.L__pc.20799.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20800
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20800: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20801
	
	.L__pc.20801: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20802
	
	.p2align 4
	.L__pc.20802: Dma_PatchDst (.L__pc.20802.ST), (.L__movme_cp.63), (.L__pc.20802.ST)
	.L__pc.20802.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20803
	
	.L__pc.20803: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20804
	
	.p2align 4
	.L__pc.20804: Dma_PatchDst (.L__pc.20804.ST), (.L__movme_cp.24), (.L__pc.20804.ST)
	.L__pc.20804.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20805
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20805: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20806
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20806: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20807
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20807: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20808
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20808: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20809
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.20809: Dma_PatchSrc (.L__pc.20809.LD), (.L__movme_cp.66), (.L__pc.20809.LD)
	.p2align 4
	.L__pc.20809.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20810
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20810: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20811
	.L__pc.20811: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20812
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20812: Dma_PatchSrc (.L__pc.20812.LD), (.L__movme_cp.24), (.L__pc.20812.LD)
	.p2align 4
	.L__pc.20812.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20813
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20813: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20814
	.L__pc.20814: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20815
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20815: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20816: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20817: Dma_PatchSrc (.L__pc.20817.LD), (.L__movme_tmp.1), (.L__pc.20817.LD)
	.p2align 4
	.L__pc.20817.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20818
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20818: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20819
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20819: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20820: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20821: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20822: Dma_PatchSrc (.L__pc.20822.LD), (.L__movme_tmp.1), (.L__pc.20822.LD)
	.p2align 4
	.L__pc.20822.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20823
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20823: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20824
	
	.L__pc.20824: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20825
	
	.p2align 4
	.L__pc.20825: Dma_PatchDst (.L__pc.20825.ST), (.L__movme_cp.66), (.L__pc.20825.ST)
	.L__pc.20825.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20826
	
	.L__pc.20826: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20827
	
	.p2align 4
	.L__pc.20827: Dma_PatchDst (.L__pc.20827.ST), (.L__movme_cp.24), (.L__pc.20827.ST)
	.L__pc.20827.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20828
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20828: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20829
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20829: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20830
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20830: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20831
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20831: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20832
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.20832: Dma_PatchSrc (.L__pc.20832.LD), (.L__movme_cp.67), (.L__pc.20832.LD)
	.p2align 4
	.L__pc.20832.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20833
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20833: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20834
	.L__pc.20834: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20835
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20835: Dma_PatchSrc (.L__pc.20835.LD), (.L__movme_cp.24), (.L__pc.20835.LD)
	.p2align 4
	.L__pc.20835.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20836
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20836: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20837
	.L__pc.20837: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20838
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20838: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20839: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20840: Dma_PatchSrc (.L__pc.20840.LD), (.L__movme_tmp.1), (.L__pc.20840.LD)
	.p2align 4
	.L__pc.20840.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20841
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20841: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20842
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20842: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20843: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20844: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20845: Dma_PatchSrc (.L__pc.20845.LD), (.L__movme_tmp.1), (.L__pc.20845.LD)
	.p2align 4
	.L__pc.20845.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20846
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20846: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20847
	
	.L__pc.20847: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20848
	
	.p2align 4
	.L__pc.20848: Dma_PatchDst (.L__pc.20848.ST), (.L__movme_cp.67), (.L__pc.20848.ST)
	.L__pc.20848.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20849
	
	.L__pc.20849: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20850
	
	.p2align 4
	.L__pc.20850: Dma_PatchDst (.L__pc.20850.ST), (.L__movme_cp.24), (.L__pc.20850.ST)
	.L__pc.20850.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20851
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20851: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20852
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20852: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20853
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20853: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20854
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20854: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20855
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.20855: Dma_PatchSrc (.L__pc.20855.LD), (.L__movme_cp.68), (.L__pc.20855.LD)
	.p2align 4
	.L__pc.20855.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20856
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20856: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20857
	.L__pc.20857: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20858
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20858: Dma_PatchSrc (.L__pc.20858.LD), (.L__movme_cp.24), (.L__pc.20858.LD)
	.p2align 4
	.L__pc.20858.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20859
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20859: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.20860
	.L__pc.20860: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.20861
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20861: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20862: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20863: Dma_PatchSrc (.L__pc.20863.LD), (.L__movme_tmp.1), (.L__pc.20863.LD)
	.p2align 4
	.L__pc.20863.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20864
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20864: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20865
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.20865: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.20866: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.20867: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20868: Dma_PatchSrc (.L__pc.20868.LD), (.L__movme_tmp.1), (.L__pc.20868.LD)
	.p2align 4
	.L__pc.20868.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20869
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20869: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20870
	
	.L__pc.20870: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.20871
	
	.p2align 4
	.L__pc.20871: Dma_PatchDst (.L__pc.20871.ST), (.L__movme_cp.68), (.L__pc.20871.ST)
	.L__pc.20871.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20872
	
	.L__pc.20872: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.20873
	
	.p2align 4
	.L__pc.20873: Dma_PatchDst (.L__pc.20873.ST), (.L__movme_cp.24), (.L__pc.20873.ST)
	.L__pc.20873.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20874
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20874: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20875
	
	.p2align 4
	.L__pc.20875: Dma_PatchDst (.L__pc.20875.ST), (.L__movme_cp.24), (.L__pc.20875.ST)
	.L__pc.20875.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20876
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.20876: Dma_PatchSrc (.L__pc.20876.LD), (.L__movme_cp.60), (.L__pc.20876.LD)
	.p2align 4
	.L__pc.20876.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20877
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20877: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20878
	
	.L__pc.20878: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20879
	
	.p2align 4
	.L__pc.20879: Dma_PatchDst (.L__pc.20879.ST), (.L__movme_cp.21), (.L__pc.20879.ST)
	.L__pc.20879.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20880
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.20880: Dma_PatchSrc (.L__pc.20880.LD), (.L__movme_cp.58), (.L__pc.20880.LD)
	.p2align 4
	.L__pc.20880.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20881
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20881: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20882
	
	.L__pc.20882: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20883
	
	.p2align 4
	.L__pc.20883: Dma_PatchDst (.L__pc.20883.ST), (.L__movme_cp.22), (.L__pc.20883.ST)
	.L__pc.20883.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20884
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20884: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20885
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20885: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20886
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20886: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20887
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20887: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20888
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.20888: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.20889
	
	.p2align 4
	.L__pc.20889: Dma_PatchDst (.L__pc.20889.ST), (.L__movme_cp.24), (.L__pc.20889.ST)
	.L__pc.20889.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20890
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.20890: Dma_PatchSrc (.L__pc.20890.LD), (.L__movme_cp.25), (.L__pc.20890.LD)
	.p2align 4
	.L__pc.20890.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20891
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20891: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20892
	.L__pc.20892: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20893
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.20893: Dma_PatchSrc (.L__pc.20893.LD), (.L__movme_cp.26), (.L__pc.20893.LD)
	.p2align 4
	.L__pc.20893.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20894
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20894: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20895
	.L__pc.20895: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20896
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20896: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20897: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20898: Dma_PatchSrc (.L__pc.20898.LD), (.L__movme_tmp.1), (.L__pc.20898.LD)
	.p2align 4
	.L__pc.20898.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20899
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20899: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20900
	.L__pc.20900: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20901
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20901: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20902: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20903: Dma_PatchSrc (.L__pc.20903.LD), (.L__movme_tmp.1), (.L__pc.20903.LD)
	.p2align 4
	.L__pc.20903.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20904
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20904: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20905
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20905: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20906: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20907: Dma_PatchSrc (.L__pc.20907.LD), (.L__movme_tmp.1), (.L__pc.20907.LD)
	.p2align 4
	.L__pc.20907.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20908
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20908: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20909
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20909: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20910: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20911: Dma_PatchSrc (.L__pc.20911.LD), (.L__movme_tmp.1), (.L__pc.20911.LD)
	.p2align 4
	.L__pc.20911.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20912
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20912: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20913
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20913: Dma_PatchSrc (.L__pc.20913.LD), (.L__movme_cp.24), (.L__pc.20913.LD)
	.p2align 4
	.L__pc.20913.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20914
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20914: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20915
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20915: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20916: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20917: Dma_PatchSrc (.L__pc.20917.LD), (.L__movme_tmp.1), (.L__pc.20917.LD)
	.p2align 4
	.L__pc.20917.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20918
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20918: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20919
	
	.L__pc.20919: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20920
	
	.p2align 4
	.L__pc.20920: Dma_PatchDst (.L__pc.20920.ST), (.L__movme_cp.69), (.L__pc.20920.ST)
	.L__pc.20920.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20921
	
	.L__pc.20921: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20922
	
	.p2align 4
	.L__pc.20922: Dma_PatchDst (.L__pc.20922.ST), (.L__movme_cp.54), (.L__pc.20922.ST)
	.L__pc.20922.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20923
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.20923: Dma_PatchSrc (.L__pc.20923.LD), (.L__movme_cp.30), (.L__pc.20923.LD)
	.p2align 4
	.L__pc.20923.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20924
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20924: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.20925
	.L__pc.20925: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.20926
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.20926: Dma_PatchSrc (.L__pc.20926.LD), (.L__movme_cp.31), (.L__pc.20926.LD)
	.p2align 4
	.L__pc.20926.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20927
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20927: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20928
	.L__pc.20928: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20929
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.20929: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20930: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20931: Dma_PatchSrc (.L__pc.20931.LD), (.L__movme_tmp.1), (.L__pc.20931.LD)
	.p2align 4
	.L__pc.20931.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20932
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20932: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.20933
	.L__pc.20933: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.20934
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20934: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20935: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20936: Dma_PatchSrc (.L__pc.20936.LD), (.L__movme_tmp.1), (.L__pc.20936.LD)
	.p2align 4
	.L__pc.20936.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20937
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20937: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20938
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20938: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20939: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20940: Dma_PatchSrc (.L__pc.20940.LD), (.L__movme_tmp.1), (.L__pc.20940.LD)
	.p2align 4
	.L__pc.20940.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20941
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20941: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20942
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.20942: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20943: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20944: Dma_PatchSrc (.L__pc.20944.LD), (.L__movme_tmp.1), (.L__pc.20944.LD)
	.p2align 4
	.L__pc.20944.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20945
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20945: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20946
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20946: Dma_PatchSrc (.L__pc.20946.LD), (.L__movme_cp.24), (.L__pc.20946.LD)
	.p2align 4
	.L__pc.20946.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20947
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20947: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20948
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.20948: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20949: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20950: Dma_PatchSrc (.L__pc.20950.LD), (.L__movme_tmp.1), (.L__pc.20950.LD)
	.p2align 4
	.L__pc.20950.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20951
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20951: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20952
	
	.L__pc.20952: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.20953
	
	.p2align 4
	.L__pc.20953: Dma_PatchDst (.L__pc.20953.ST), (.L__movme_cp.70), (.L__pc.20953.ST)
	.L__pc.20953.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20954
	
	.L__pc.20954: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20955
	
	.p2align 4
	.L__pc.20955: Dma_PatchDst (.L__pc.20955.ST), (.L__movme_cp.54), (.L__pc.20955.ST)
	.L__pc.20955.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20956
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20956: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20957
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20957: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20958
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.20958: Dma_PatchSrc (.L__pc.20958.LD), (.L__movme_cp.24), (.L__pc.20958.LD)
	.p2align 4
	.L__pc.20958.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20959
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20959: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20960
	.L__pc.20960: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20961
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.20961: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20962: Dma_PatchSrc (.L__pc.20962.LD), (.L__movme_tmp.1), (.L__pc.20962.LD)
	.p2align 4
	.L__pc.20962.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20963
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20963: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.20964
	.L__pc.20964: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.20965
	
	.L__pc.20965: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20966
	
	.p2align 4
	.L__pc.20966: Dma_PatchDst (.L__pc.20966.ST), (.L__movme_cp.72), (.L__pc.20966.ST)
	.L__pc.20966.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20967
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.20967: Dma_PatchSrc (.L__pc.20967.LD), (.L__movme_cp.72), (.L__pc.20967.LD)
	.p2align 4
	.L__pc.20967.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20968
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20968: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20969
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20969: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20970: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20971: Dma_PatchSrc (.L__pc.20971.LD), (.L__movme_tmp.1), (.L__pc.20971.LD)
	.p2align 4
	.L__pc.20971.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20972
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20972: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20973
	
	.L__pc.20973: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20974
	
	.p2align 4
	.L__pc.20974: Dma_PatchDst (.L__pc.20974.ST), (.L__movme_cp.74), (.L__pc.20974.ST)
	.L__pc.20974.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20975
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.20975: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.20976: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.20977: Dma_PatchSrc (.L__pc.20977.LD), (.L__movme_tmp.1), (.L__pc.20977.LD)
	.p2align 4
	.L__pc.20977.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20978
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.20978: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.20979
	
	.L__pc.20979: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.20980
	
	.p2align 4
	.L__pc.20980: Dma_PatchDst (.L__pc.20980.ST), (.L__movme_cp.76), (.L__pc.20980.ST)
	.L__pc.20980.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20981
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.20981: Dma_PatchSrc (.L__pc.20981.LD), (.L__movme_cp.74), (.L__pc.20981.LD)
	.p2align 4
	.L__pc.20981.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20982
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20982: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20983
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.20983: Dma_PatchSrc (.L__pc.20983.LD), ((.L__movme.reg.eax+0)), (.L__pc.20983.LD)
	.p2align 4
	.L__pc.20983.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20984
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20984: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20985
	
	.L__pc.20985: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20986
	
	.p2align 4
	.L__pc.20986: Dma_PatchDst (.L__pc.20986.ST), (.L__movme_cp.77), (.L__pc.20986.ST)
	.L__pc.20986.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20987
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.20987: Dma_PatchSrc (.L__pc.20987.LD), (.L__movme_cp.77), (.L__pc.20987.LD)
	.p2align 4
	.L__pc.20987.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20988
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20988: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20989
	
	.L__pc.20989: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20990
	
	.p2align 4
	.L__pc.20990: Dma_PatchDst (.L__pc.20990.ST), (.L__movme_cp.21), (.L__pc.20990.ST)
	.L__pc.20990.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20991
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.20991: Dma_PatchSrc (.L__pc.20991.LD), (.L__movme_cp.58), (.L__pc.20991.LD)
	.p2align 4
	.L__pc.20991.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.20992
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20992: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20993
	
	.L__pc.20993: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.20994
	
	.p2align 4
	.L__pc.20994: Dma_PatchDst (.L__pc.20994.ST), (.L__movme_cp.22), (.L__pc.20994.ST)
	.L__pc.20994.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.20995
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20995: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20996
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.20996: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.20997
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.20997: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.20998
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.20998: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.20999
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.20999: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.21000
	
	.p2align 4
	.L__pc.21000: Dma_PatchDst (.L__pc.21000.ST), (.L__movme_cp.24), (.L__pc.21000.ST)
	.L__pc.21000.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21001
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.21001: Dma_PatchSrc (.L__pc.21001.LD), (.L__movme_cp.25), (.L__pc.21001.LD)
	.p2align 4
	.L__pc.21001.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21002
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21002: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21003
	.L__pc.21003: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21004
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.21004: Dma_PatchSrc (.L__pc.21004.LD), (.L__movme_cp.26), (.L__pc.21004.LD)
	.p2align 4
	.L__pc.21004.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21005
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21005: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21006
	.L__pc.21006: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21007
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21007: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21008: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21009: Dma_PatchSrc (.L__pc.21009.LD), (.L__movme_tmp.1), (.L__pc.21009.LD)
	.p2align 4
	.L__pc.21009.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21010
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21010: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21011
	.L__pc.21011: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21012
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21012: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21013: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21014: Dma_PatchSrc (.L__pc.21014.LD), (.L__movme_tmp.1), (.L__pc.21014.LD)
	.p2align 4
	.L__pc.21014.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21015
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21015: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21016
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21016: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21017: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21018: Dma_PatchSrc (.L__pc.21018.LD), (.L__movme_tmp.1), (.L__pc.21018.LD)
	.p2align 4
	.L__pc.21018.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21019
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21019: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21020
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21020: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21021: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21022: Dma_PatchSrc (.L__pc.21022.LD), (.L__movme_tmp.1), (.L__pc.21022.LD)
	.p2align 4
	.L__pc.21022.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21023
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21023: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21024
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21024: Dma_PatchSrc (.L__pc.21024.LD), (.L__movme_cp.24), (.L__pc.21024.LD)
	.p2align 4
	.L__pc.21024.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21025
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21025: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21026
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21026: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21027: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21028: Dma_PatchSrc (.L__pc.21028.LD), (.L__movme_tmp.1), (.L__pc.21028.LD)
	.p2align 4
	.L__pc.21028.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21029
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21029: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21030
	
	.L__pc.21030: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21031
	
	.p2align 4
	.L__pc.21031: Dma_PatchDst (.L__pc.21031.ST), (.L__movme_cp.78), (.L__pc.21031.ST)
	.L__pc.21031.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21032
	
	.L__pc.21032: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21033
	
	.p2align 4
	.L__pc.21033: Dma_PatchDst (.L__pc.21033.ST), (.L__movme_cp.54), (.L__pc.21033.ST)
	.L__pc.21033.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21034
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.21034: Dma_PatchSrc (.L__pc.21034.LD), (.L__movme_cp.30), (.L__pc.21034.LD)
	.p2align 4
	.L__pc.21034.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21035
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21035: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21036
	.L__pc.21036: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21037
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.21037: Dma_PatchSrc (.L__pc.21037.LD), (.L__movme_cp.31), (.L__pc.21037.LD)
	.p2align 4
	.L__pc.21037.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21038
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21038: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21039
	.L__pc.21039: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21040
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21040: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21041: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21042: Dma_PatchSrc (.L__pc.21042.LD), (.L__movme_tmp.1), (.L__pc.21042.LD)
	.p2align 4
	.L__pc.21042.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21043
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21043: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21044
	.L__pc.21044: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21045
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21045: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21046: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21047: Dma_PatchSrc (.L__pc.21047.LD), (.L__movme_tmp.1), (.L__pc.21047.LD)
	.p2align 4
	.L__pc.21047.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21048
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21048: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21049
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21049: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21050: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21051: Dma_PatchSrc (.L__pc.21051.LD), (.L__movme_tmp.1), (.L__pc.21051.LD)
	.p2align 4
	.L__pc.21051.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21052
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21052: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21053
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21053: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21054: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21055: Dma_PatchSrc (.L__pc.21055.LD), (.L__movme_tmp.1), (.L__pc.21055.LD)
	.p2align 4
	.L__pc.21055.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21056
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21056: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21057
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21057: Dma_PatchSrc (.L__pc.21057.LD), (.L__movme_cp.24), (.L__pc.21057.LD)
	.p2align 4
	.L__pc.21057.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21058
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21058: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21059
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21059: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21060: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21061: Dma_PatchSrc (.L__pc.21061.LD), (.L__movme_tmp.1), (.L__pc.21061.LD)
	.p2align 4
	.L__pc.21061.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21062
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21062: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21063
	
	.L__pc.21063: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21064
	
	.p2align 4
	.L__pc.21064: Dma_PatchDst (.L__pc.21064.ST), (.L__movme_cp.79), (.L__pc.21064.ST)
	.L__pc.21064.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21065
	
	.L__pc.21065: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21066
	
	.p2align 4
	.L__pc.21066: Dma_PatchDst (.L__pc.21066.ST), (.L__movme_cp.54), (.L__pc.21066.ST)
	.L__pc.21066.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21067
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.21067: Dma_PatchSrc (.L__pc.21067.LD), (.L__movme_cp.74), (.L__pc.21067.LD)
	.p2align 4
	.L__pc.21067.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21068
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21068: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21069
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.21069: Dma_PatchSrc (.L__pc.21069.LD), (.L__movme_cp.77), (.L__pc.21069.LD)
	.p2align 4
	.L__pc.21069.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21070
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21070: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21071
	
	.L__pc.21071: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21072
	
	.p2align 4
	.L__pc.21072: Dma_PatchDst (.L__pc.21072.ST), ((.L__movme.reg.eax+0)), (.L__pc.21072.ST)
	.L__pc.21072.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21073
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.21073: Dma_PatchSrc (.L__pc.21073.LD), (.L__movme_cp.76), (.L__pc.21073.LD)
	.p2align 4
	.L__pc.21073.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21074
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21074: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21075
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.21075: Dma_PatchSrc (.L__pc.21075.LD), ((.L__movme.reg.eax+0)), (.L__pc.21075.LD)
	.p2align 4
	.L__pc.21075.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21076
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21076: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21077
	
	.L__pc.21077: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21078
	
	.p2align 4
	.L__pc.21078: Dma_PatchDst (.L__pc.21078.ST), (.L__movme_cp.80), (.L__pc.21078.ST)
	.L__pc.21078.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21079
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21079: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21080
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21080: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21081
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.21081: Dma_PatchSrc (.L__pc.21081.LD), (.L__movme_cp.102), (.L__pc.21081.LD)
	.p2align 4
	.L__pc.21081.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21082
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21082: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21083
	.L__pc.21083: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21084
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.84 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.21084: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21085: Dma_PatchSrc (.L__pc.21085.LD), (.L__movme_tmp.1), (.L__pc.21085.LD)
	.p2align 4
	.L__pc.21085.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21086
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21086: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21087
	.L__pc.21087: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21088
	
	.L__pc.21088: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21089
	
	.p2align 4
	.L__pc.21089: Dma_PatchDst (.L__pc.21089.ST), (.L__movme_cp.102), (.L__pc.21089.ST)
	.L__pc.21089.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21090
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.21090: Dma_PatchSrc (.L__pc.21090.LD), (.L__movme_cp.76), (.L__pc.21090.LD)
	.p2align 4
	.L__pc.21090.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21091
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21091: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21092
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.21092: Dma_PatchSrc (.L__pc.21092.LD), (.L__movme_cp.80), (.L__pc.21092.LD)
	.p2align 4
	.L__pc.21092.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21093
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21093: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21094
	
	.L__pc.21094: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21095
	
	.p2align 4
	.L__pc.21095: Dma_PatchDst (.L__pc.21095.ST), ((.L__movme.reg.eax+0)), (.L__pc.21095.ST)
	.L__pc.21095.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21096
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21096: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21097
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21097: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21098
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.21098: Dma_PatchSrc (.L__pc.21098.LD), (.L__movme_cp.101), (.L__pc.21098.LD)
	.p2align 4
	.L__pc.21098.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21099
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21099: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21100
	.L__pc.21100: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21101
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21101: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.85 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21102: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21103: Dma_PatchSrc (.L__pc.21103.LD), (.L__movme_tmp.1), (.L__pc.21103.LD)
	.p2align 4
	.L__pc.21103.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21104
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21104: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21105
	
	.L__pc.21105: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21106
	
	.p2align 4
	.L__pc.21106: Dma_PatchDst (.L__pc.21106.ST), (.L__movme_cp.24), (.L__pc.21106.ST)
	.L__pc.21106.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21107
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21107: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21108
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21108: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21109
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21109: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21110
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21110: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21111
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.21111: Dma_PatchSrc (.L__pc.21111.LD), (.L__movme_cp.63), (.L__pc.21111.LD)
	.p2align 4
	.L__pc.21111.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21112
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21112: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21113
	.L__pc.21113: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21114
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21114: Dma_PatchSrc (.L__pc.21114.LD), (.L__movme_cp.24), (.L__pc.21114.LD)
	.p2align 4
	.L__pc.21114.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21115
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21115: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21116
	.L__pc.21116: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21117
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21117: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21118: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21119: Dma_PatchSrc (.L__pc.21119.LD), (.L__movme_tmp.1), (.L__pc.21119.LD)
	.p2align 4
	.L__pc.21119.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21120
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21120: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21121
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21121: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21122: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21123: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21124: Dma_PatchSrc (.L__pc.21124.LD), (.L__movme_tmp.1), (.L__pc.21124.LD)
	.p2align 4
	.L__pc.21124.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21125
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21125: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21126
	
	.L__pc.21126: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21127
	
	.p2align 4
	.L__pc.21127: Dma_PatchDst (.L__pc.21127.ST), (.L__movme_cp.63), (.L__pc.21127.ST)
	.L__pc.21127.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21128
	
	.L__pc.21128: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21129
	
	.p2align 4
	.L__pc.21129: Dma_PatchDst (.L__pc.21129.ST), (.L__movme_cp.24), (.L__pc.21129.ST)
	.L__pc.21129.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21130
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21130: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21131
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21131: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21132
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21132: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21133
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21133: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21134
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.21134: Dma_PatchSrc (.L__pc.21134.LD), (.L__movme_cp.66), (.L__pc.21134.LD)
	.p2align 4
	.L__pc.21134.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21135
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21135: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21136
	.L__pc.21136: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21137
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21137: Dma_PatchSrc (.L__pc.21137.LD), (.L__movme_cp.24), (.L__pc.21137.LD)
	.p2align 4
	.L__pc.21137.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21138
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21138: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21139
	.L__pc.21139: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21140
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21140: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21141: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21142: Dma_PatchSrc (.L__pc.21142.LD), (.L__movme_tmp.1), (.L__pc.21142.LD)
	.p2align 4
	.L__pc.21142.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21143
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21143: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21144
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21144: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21145: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21146: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21147: Dma_PatchSrc (.L__pc.21147.LD), (.L__movme_tmp.1), (.L__pc.21147.LD)
	.p2align 4
	.L__pc.21147.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21148
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21148: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21149
	
	.L__pc.21149: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21150
	
	.p2align 4
	.L__pc.21150: Dma_PatchDst (.L__pc.21150.ST), (.L__movme_cp.66), (.L__pc.21150.ST)
	.L__pc.21150.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21151
	
	.L__pc.21151: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21152
	
	.p2align 4
	.L__pc.21152: Dma_PatchDst (.L__pc.21152.ST), (.L__movme_cp.24), (.L__pc.21152.ST)
	.L__pc.21152.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21153
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21153: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21154
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21154: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21155
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21155: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21156
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21156: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21157
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.21157: Dma_PatchSrc (.L__pc.21157.LD), (.L__movme_cp.67), (.L__pc.21157.LD)
	.p2align 4
	.L__pc.21157.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21158
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21158: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21159
	.L__pc.21159: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21160
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21160: Dma_PatchSrc (.L__pc.21160.LD), (.L__movme_cp.24), (.L__pc.21160.LD)
	.p2align 4
	.L__pc.21160.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21161
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21161: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21162
	.L__pc.21162: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21163
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21163: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21164: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21165: Dma_PatchSrc (.L__pc.21165.LD), (.L__movme_tmp.1), (.L__pc.21165.LD)
	.p2align 4
	.L__pc.21165.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21166
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21166: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21167
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21167: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21168: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21169: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21170: Dma_PatchSrc (.L__pc.21170.LD), (.L__movme_tmp.1), (.L__pc.21170.LD)
	.p2align 4
	.L__pc.21170.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21171
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21171: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21172
	
	.L__pc.21172: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21173
	
	.p2align 4
	.L__pc.21173: Dma_PatchDst (.L__pc.21173.ST), (.L__movme_cp.67), (.L__pc.21173.ST)
	.L__pc.21173.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21174
	
	.L__pc.21174: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21175
	
	.p2align 4
	.L__pc.21175: Dma_PatchDst (.L__pc.21175.ST), (.L__movme_cp.24), (.L__pc.21175.ST)
	.L__pc.21175.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21176
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21176: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21177
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21177: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21178
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21178: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21179
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21179: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21180
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.21180: Dma_PatchSrc (.L__pc.21180.LD), (.L__movme_cp.68), (.L__pc.21180.LD)
	.p2align 4
	.L__pc.21180.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21181
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21181: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21182
	.L__pc.21182: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21183
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21183: Dma_PatchSrc (.L__pc.21183.LD), (.L__movme_cp.24), (.L__pc.21183.LD)
	.p2align 4
	.L__pc.21183.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21184
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21184: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21185
	.L__pc.21185: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21186
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21186: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21187: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21188: Dma_PatchSrc (.L__pc.21188.LD), (.L__movme_tmp.1), (.L__pc.21188.LD)
	.p2align 4
	.L__pc.21188.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21189
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21189: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21190
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21190: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21191: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21192: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21193: Dma_PatchSrc (.L__pc.21193.LD), (.L__movme_tmp.1), (.L__pc.21193.LD)
	.p2align 4
	.L__pc.21193.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21194
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21194: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21195
	
	.L__pc.21195: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21196
	
	.p2align 4
	.L__pc.21196: Dma_PatchDst (.L__pc.21196.ST), (.L__movme_cp.68), (.L__pc.21196.ST)
	.L__pc.21196.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21197
	
	.L__pc.21197: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21198
	
	.p2align 4
	.L__pc.21198: Dma_PatchDst (.L__pc.21198.ST), (.L__movme_cp.24), (.L__pc.21198.ST)
	.L__pc.21198.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21199
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21199: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21200
	
	.p2align 4
	.L__pc.21200: Dma_PatchDst (.L__pc.21200.ST), (.L__movme_cp.24), (.L__pc.21200.ST)
	.L__pc.21200.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21201
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.21201: Dma_PatchSrc (.L__pc.21201.LD), (.L__movme_cp.60), (.L__pc.21201.LD)
	.p2align 4
	.L__pc.21201.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21202
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21202: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21203
	
	.L__pc.21203: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21204
	
	.p2align 4
	.L__pc.21204: Dma_PatchDst (.L__pc.21204.ST), (.L__movme_cp.21), (.L__pc.21204.ST)
	.L__pc.21204.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21205
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.21205: Dma_PatchSrc (.L__pc.21205.LD), (.L__movme_cp.58), (.L__pc.21205.LD)
	.p2align 4
	.L__pc.21205.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21206
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21206: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21207
	
	.L__pc.21207: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21208
	
	.p2align 4
	.L__pc.21208: Dma_PatchDst (.L__pc.21208.ST), (.L__movme_cp.22), (.L__pc.21208.ST)
	.L__pc.21208.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21209
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21209: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21210
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21210: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21211
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21211: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21212
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21212: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21213
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.21213: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.21214
	
	.p2align 4
	.L__pc.21214: Dma_PatchDst (.L__pc.21214.ST), (.L__movme_cp.24), (.L__pc.21214.ST)
	.L__pc.21214.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21215
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.21215: Dma_PatchSrc (.L__pc.21215.LD), (.L__movme_cp.25), (.L__pc.21215.LD)
	.p2align 4
	.L__pc.21215.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21216
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21216: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21217
	.L__pc.21217: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21218
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.21218: Dma_PatchSrc (.L__pc.21218.LD), (.L__movme_cp.26), (.L__pc.21218.LD)
	.p2align 4
	.L__pc.21218.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21219
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21219: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21220
	.L__pc.21220: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21221
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21221: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21222: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21223: Dma_PatchSrc (.L__pc.21223.LD), (.L__movme_tmp.1), (.L__pc.21223.LD)
	.p2align 4
	.L__pc.21223.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21224
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21224: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21225
	.L__pc.21225: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21226
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21226: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21227: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21228: Dma_PatchSrc (.L__pc.21228.LD), (.L__movme_tmp.1), (.L__pc.21228.LD)
	.p2align 4
	.L__pc.21228.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21229
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21229: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21230
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21230: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21231: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21232: Dma_PatchSrc (.L__pc.21232.LD), (.L__movme_tmp.1), (.L__pc.21232.LD)
	.p2align 4
	.L__pc.21232.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21233
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21233: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21234
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21234: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21235: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21236: Dma_PatchSrc (.L__pc.21236.LD), (.L__movme_tmp.1), (.L__pc.21236.LD)
	.p2align 4
	.L__pc.21236.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21237
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21237: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21238
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21238: Dma_PatchSrc (.L__pc.21238.LD), (.L__movme_cp.24), (.L__pc.21238.LD)
	.p2align 4
	.L__pc.21238.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21239
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21239: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21240
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21240: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21241: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21242: Dma_PatchSrc (.L__pc.21242.LD), (.L__movme_tmp.1), (.L__pc.21242.LD)
	.p2align 4
	.L__pc.21242.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21243
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21243: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21244
	
	.L__pc.21244: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21245
	
	.p2align 4
	.L__pc.21245: Dma_PatchDst (.L__pc.21245.ST), (.L__movme_cp.69), (.L__pc.21245.ST)
	.L__pc.21245.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21246
	
	.L__pc.21246: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21247
	
	.p2align 4
	.L__pc.21247: Dma_PatchDst (.L__pc.21247.ST), (.L__movme_cp.54), (.L__pc.21247.ST)
	.L__pc.21247.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21248
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.21248: Dma_PatchSrc (.L__pc.21248.LD), (.L__movme_cp.30), (.L__pc.21248.LD)
	.p2align 4
	.L__pc.21248.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21249
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21249: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21250
	.L__pc.21250: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21251
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.21251: Dma_PatchSrc (.L__pc.21251.LD), (.L__movme_cp.31), (.L__pc.21251.LD)
	.p2align 4
	.L__pc.21251.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21252
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21252: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21253
	.L__pc.21253: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21254
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21254: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21255: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21256: Dma_PatchSrc (.L__pc.21256.LD), (.L__movme_tmp.1), (.L__pc.21256.LD)
	.p2align 4
	.L__pc.21256.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21257
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21257: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21258
	.L__pc.21258: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21259
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21259: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21260: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21261: Dma_PatchSrc (.L__pc.21261.LD), (.L__movme_tmp.1), (.L__pc.21261.LD)
	.p2align 4
	.L__pc.21261.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21262
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21262: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21263
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21263: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21264: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21265: Dma_PatchSrc (.L__pc.21265.LD), (.L__movme_tmp.1), (.L__pc.21265.LD)
	.p2align 4
	.L__pc.21265.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21266
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21266: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21267
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21267: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21268: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21269: Dma_PatchSrc (.L__pc.21269.LD), (.L__movme_tmp.1), (.L__pc.21269.LD)
	.p2align 4
	.L__pc.21269.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21270
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21270: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21271
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21271: Dma_PatchSrc (.L__pc.21271.LD), (.L__movme_cp.24), (.L__pc.21271.LD)
	.p2align 4
	.L__pc.21271.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21272
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21272: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21273
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21273: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21274: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21275: Dma_PatchSrc (.L__pc.21275.LD), (.L__movme_tmp.1), (.L__pc.21275.LD)
	.p2align 4
	.L__pc.21275.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21276
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21276: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21277
	
	.L__pc.21277: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21278
	
	.p2align 4
	.L__pc.21278: Dma_PatchDst (.L__pc.21278.ST), (.L__movme_cp.70), (.L__pc.21278.ST)
	.L__pc.21278.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21279
	
	.L__pc.21279: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21280
	
	.p2align 4
	.L__pc.21280: Dma_PatchDst (.L__pc.21280.ST), (.L__movme_cp.54), (.L__pc.21280.ST)
	.L__pc.21280.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21281
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21281: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21282
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21282: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21283
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21283: Dma_PatchSrc (.L__pc.21283.LD), (.L__movme_cp.24), (.L__pc.21283.LD)
	.p2align 4
	.L__pc.21283.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21284
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21284: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21285
	.L__pc.21285: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21286
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.21286: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21287: Dma_PatchSrc (.L__pc.21287.LD), (.L__movme_tmp.1), (.L__pc.21287.LD)
	.p2align 4
	.L__pc.21287.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21288
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21288: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21289
	.L__pc.21289: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21290
	
	.L__pc.21290: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21291
	
	.p2align 4
	.L__pc.21291: Dma_PatchDst (.L__pc.21291.ST), (.L__movme_cp.72), (.L__pc.21291.ST)
	.L__pc.21291.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21292
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.21292: Dma_PatchSrc (.L__pc.21292.LD), (.L__movme_cp.72), (.L__pc.21292.LD)
	.p2align 4
	.L__pc.21292.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21293
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21293: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21294
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21294: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21295: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21296: Dma_PatchSrc (.L__pc.21296.LD), (.L__movme_tmp.1), (.L__pc.21296.LD)
	.p2align 4
	.L__pc.21296.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21297
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21297: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21298
	
	.L__pc.21298: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21299
	
	.p2align 4
	.L__pc.21299: Dma_PatchDst (.L__pc.21299.ST), (.L__movme_cp.74), (.L__pc.21299.ST)
	.L__pc.21299.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21300
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21300: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21301: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21302: Dma_PatchSrc (.L__pc.21302.LD), (.L__movme_tmp.1), (.L__pc.21302.LD)
	.p2align 4
	.L__pc.21302.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21303
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21303: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21304
	
	.L__pc.21304: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21305
	
	.p2align 4
	.L__pc.21305: Dma_PatchDst (.L__pc.21305.ST), (.L__movme_cp.76), (.L__pc.21305.ST)
	.L__pc.21305.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21306
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.21306: Dma_PatchSrc (.L__pc.21306.LD), (.L__movme_cp.74), (.L__pc.21306.LD)
	.p2align 4
	.L__pc.21306.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21307
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21307: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21308
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.21308: Dma_PatchSrc (.L__pc.21308.LD), ((.L__movme.reg.eax+0)), (.L__pc.21308.LD)
	.p2align 4
	.L__pc.21308.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21309
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21309: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21310
	
	.L__pc.21310: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21311
	
	.p2align 4
	.L__pc.21311: Dma_PatchDst (.L__pc.21311.ST), (.L__movme_cp.77), (.L__pc.21311.ST)
	.L__pc.21311.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21312
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.21312: Dma_PatchSrc (.L__pc.21312.LD), (.L__movme_cp.77), (.L__pc.21312.LD)
	.p2align 4
	.L__pc.21312.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21313
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21313: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21314
	
	.L__pc.21314: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21315
	
	.p2align 4
	.L__pc.21315: Dma_PatchDst (.L__pc.21315.ST), (.L__movme_cp.21), (.L__pc.21315.ST)
	.L__pc.21315.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21316
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.21316: Dma_PatchSrc (.L__pc.21316.LD), (.L__movme_cp.58), (.L__pc.21316.LD)
	.p2align 4
	.L__pc.21316.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21317
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21317: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21318
	
	.L__pc.21318: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21319
	
	.p2align 4
	.L__pc.21319: Dma_PatchDst (.L__pc.21319.ST), (.L__movme_cp.22), (.L__pc.21319.ST)
	.L__pc.21319.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21320
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21320: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21321
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21321: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21322
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21322: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21323
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21323: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21324
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.21324: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.21325
	
	.p2align 4
	.L__pc.21325: Dma_PatchDst (.L__pc.21325.ST), (.L__movme_cp.24), (.L__pc.21325.ST)
	.L__pc.21325.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21326
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.21326: Dma_PatchSrc (.L__pc.21326.LD), (.L__movme_cp.25), (.L__pc.21326.LD)
	.p2align 4
	.L__pc.21326.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21327
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21327: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21328
	.L__pc.21328: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21329
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.21329: Dma_PatchSrc (.L__pc.21329.LD), (.L__movme_cp.26), (.L__pc.21329.LD)
	.p2align 4
	.L__pc.21329.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21330
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21330: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21331
	.L__pc.21331: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21332
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21332: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21333: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21334: Dma_PatchSrc (.L__pc.21334.LD), (.L__movme_tmp.1), (.L__pc.21334.LD)
	.p2align 4
	.L__pc.21334.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21335
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21335: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21336
	.L__pc.21336: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21337
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21337: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21338: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21339: Dma_PatchSrc (.L__pc.21339.LD), (.L__movme_tmp.1), (.L__pc.21339.LD)
	.p2align 4
	.L__pc.21339.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21340
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21340: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21341
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21341: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21342: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21343: Dma_PatchSrc (.L__pc.21343.LD), (.L__movme_tmp.1), (.L__pc.21343.LD)
	.p2align 4
	.L__pc.21343.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21344
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21344: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21345
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21345: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21346: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21347: Dma_PatchSrc (.L__pc.21347.LD), (.L__movme_tmp.1), (.L__pc.21347.LD)
	.p2align 4
	.L__pc.21347.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21348
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21348: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21349
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21349: Dma_PatchSrc (.L__pc.21349.LD), (.L__movme_cp.24), (.L__pc.21349.LD)
	.p2align 4
	.L__pc.21349.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21350
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21350: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21351
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21351: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21352: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21353: Dma_PatchSrc (.L__pc.21353.LD), (.L__movme_tmp.1), (.L__pc.21353.LD)
	.p2align 4
	.L__pc.21353.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21354
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21354: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21355
	
	.L__pc.21355: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21356
	
	.p2align 4
	.L__pc.21356: Dma_PatchDst (.L__pc.21356.ST), (.L__movme_cp.78), (.L__pc.21356.ST)
	.L__pc.21356.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21357
	
	.L__pc.21357: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21358
	
	.p2align 4
	.L__pc.21358: Dma_PatchDst (.L__pc.21358.ST), (.L__movme_cp.54), (.L__pc.21358.ST)
	.L__pc.21358.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21359
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.21359: Dma_PatchSrc (.L__pc.21359.LD), (.L__movme_cp.30), (.L__pc.21359.LD)
	.p2align 4
	.L__pc.21359.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21360
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21360: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21361
	.L__pc.21361: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21362
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.21362: Dma_PatchSrc (.L__pc.21362.LD), (.L__movme_cp.31), (.L__pc.21362.LD)
	.p2align 4
	.L__pc.21362.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21363
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21363: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21364
	.L__pc.21364: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21365
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21365: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21366: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21367: Dma_PatchSrc (.L__pc.21367.LD), (.L__movme_tmp.1), (.L__pc.21367.LD)
	.p2align 4
	.L__pc.21367.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21368
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21368: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21369
	.L__pc.21369: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21370
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21370: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21371: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21372: Dma_PatchSrc (.L__pc.21372.LD), (.L__movme_tmp.1), (.L__pc.21372.LD)
	.p2align 4
	.L__pc.21372.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21373
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21373: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21374
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21374: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21375: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21376: Dma_PatchSrc (.L__pc.21376.LD), (.L__movme_tmp.1), (.L__pc.21376.LD)
	.p2align 4
	.L__pc.21376.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21377
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21377: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21378
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21378: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21379: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21380: Dma_PatchSrc (.L__pc.21380.LD), (.L__movme_tmp.1), (.L__pc.21380.LD)
	.p2align 4
	.L__pc.21380.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21381
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21381: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21382
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21382: Dma_PatchSrc (.L__pc.21382.LD), (.L__movme_cp.24), (.L__pc.21382.LD)
	.p2align 4
	.L__pc.21382.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21383
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21383: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21384
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21384: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21385: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21386: Dma_PatchSrc (.L__pc.21386.LD), (.L__movme_tmp.1), (.L__pc.21386.LD)
	.p2align 4
	.L__pc.21386.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21387
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21387: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21388
	
	.L__pc.21388: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21389
	
	.p2align 4
	.L__pc.21389: Dma_PatchDst (.L__pc.21389.ST), (.L__movme_cp.79), (.L__pc.21389.ST)
	.L__pc.21389.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21390
	
	.L__pc.21390: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21391
	
	.p2align 4
	.L__pc.21391: Dma_PatchDst (.L__pc.21391.ST), (.L__movme_cp.54), (.L__pc.21391.ST)
	.L__pc.21391.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21392
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.21392: Dma_PatchSrc (.L__pc.21392.LD), (.L__movme_cp.74), (.L__pc.21392.LD)
	.p2align 4
	.L__pc.21392.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21393
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21393: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21394
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.21394: Dma_PatchSrc (.L__pc.21394.LD), (.L__movme_cp.77), (.L__pc.21394.LD)
	.p2align 4
	.L__pc.21394.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21395
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21395: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21396
	
	.L__pc.21396: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21397
	
	.p2align 4
	.L__pc.21397: Dma_PatchDst (.L__pc.21397.ST), ((.L__movme.reg.eax+0)), (.L__pc.21397.ST)
	.L__pc.21397.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21398
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.21398: Dma_PatchSrc (.L__pc.21398.LD), (.L__movme_cp.76), (.L__pc.21398.LD)
	.p2align 4
	.L__pc.21398.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21399
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21399: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21400
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.21400: Dma_PatchSrc (.L__pc.21400.LD), ((.L__movme.reg.eax+0)), (.L__pc.21400.LD)
	.p2align 4
	.L__pc.21400.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21401
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21401: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21402
	
	.L__pc.21402: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21403
	
	.p2align 4
	.L__pc.21403: Dma_PatchDst (.L__pc.21403.ST), (.L__movme_cp.80), (.L__pc.21403.ST)
	.L__pc.21403.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21404
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21404: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21405
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21405: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21406
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.21406: Dma_PatchSrc (.L__pc.21406.LD), (.L__movme_cp.102), (.L__pc.21406.LD)
	.p2align 4
	.L__pc.21406.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21407
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21407: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21408
	.L__pc.21408: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21409
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.86 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.21409: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21410: Dma_PatchSrc (.L__pc.21410.LD), (.L__movme_tmp.1), (.L__pc.21410.LD)
	.p2align 4
	.L__pc.21410.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21411
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21411: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21412
	.L__pc.21412: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21413
	
	.L__pc.21413: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21414
	
	.p2align 4
	.L__pc.21414: Dma_PatchDst (.L__pc.21414.ST), (.L__movme_cp.102), (.L__pc.21414.ST)
	.L__pc.21414.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21415
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.21415: Dma_PatchSrc (.L__pc.21415.LD), (.L__movme_cp.76), (.L__pc.21415.LD)
	.p2align 4
	.L__pc.21415.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21416
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21416: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21417
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.21417: Dma_PatchSrc (.L__pc.21417.LD), (.L__movme_cp.80), (.L__pc.21417.LD)
	.p2align 4
	.L__pc.21417.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21418
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21418: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21419
	
	.L__pc.21419: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21420
	
	.p2align 4
	.L__pc.21420: Dma_PatchDst (.L__pc.21420.ST), ((.L__movme.reg.eax+0)), (.L__pc.21420.ST)
	.L__pc.21420.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21421
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21421: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21422
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21422: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21423
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.21423: Dma_PatchSrc (.L__pc.21423.LD), (.L__movme_cp.101), (.L__pc.21423.LD)
	.p2align 4
	.L__pc.21423.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21424
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21424: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21425
	.L__pc.21425: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21426
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21426: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.87 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21427: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21428: Dma_PatchSrc (.L__pc.21428.LD), (.L__movme_tmp.1), (.L__pc.21428.LD)
	.p2align 4
	.L__pc.21428.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21429
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21429: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21430
	
	.L__pc.21430: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21431
	
	.p2align 4
	.L__pc.21431: Dma_PatchDst (.L__pc.21431.ST), (.L__movme_cp.24), (.L__pc.21431.ST)
	.L__pc.21431.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21432
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21432: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21433
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21433: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21434
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21434: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21435
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21435: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21436
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.21436: Dma_PatchSrc (.L__pc.21436.LD), (.L__movme_cp.63), (.L__pc.21436.LD)
	.p2align 4
	.L__pc.21436.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21437
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21437: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21438
	.L__pc.21438: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21439
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21439: Dma_PatchSrc (.L__pc.21439.LD), (.L__movme_cp.24), (.L__pc.21439.LD)
	.p2align 4
	.L__pc.21439.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21440
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21440: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21441
	.L__pc.21441: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21442
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21442: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21443: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21444: Dma_PatchSrc (.L__pc.21444.LD), (.L__movme_tmp.1), (.L__pc.21444.LD)
	.p2align 4
	.L__pc.21444.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21445
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21445: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21446
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21446: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21447: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21448: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21449: Dma_PatchSrc (.L__pc.21449.LD), (.L__movme_tmp.1), (.L__pc.21449.LD)
	.p2align 4
	.L__pc.21449.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21450
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21450: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21451
	
	.L__pc.21451: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21452
	
	.p2align 4
	.L__pc.21452: Dma_PatchDst (.L__pc.21452.ST), (.L__movme_cp.63), (.L__pc.21452.ST)
	.L__pc.21452.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21453
	
	.L__pc.21453: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21454
	
	.p2align 4
	.L__pc.21454: Dma_PatchDst (.L__pc.21454.ST), (.L__movme_cp.24), (.L__pc.21454.ST)
	.L__pc.21454.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21455
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21455: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21456
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21456: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21457
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21457: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21458
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21458: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21459
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.21459: Dma_PatchSrc (.L__pc.21459.LD), (.L__movme_cp.66), (.L__pc.21459.LD)
	.p2align 4
	.L__pc.21459.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21460
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21460: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21461
	.L__pc.21461: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21462
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21462: Dma_PatchSrc (.L__pc.21462.LD), (.L__movme_cp.24), (.L__pc.21462.LD)
	.p2align 4
	.L__pc.21462.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21463
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21463: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21464
	.L__pc.21464: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21465
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21465: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21466: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21467: Dma_PatchSrc (.L__pc.21467.LD), (.L__movme_tmp.1), (.L__pc.21467.LD)
	.p2align 4
	.L__pc.21467.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21468
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21468: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21469
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21469: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21470: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21471: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21472: Dma_PatchSrc (.L__pc.21472.LD), (.L__movme_tmp.1), (.L__pc.21472.LD)
	.p2align 4
	.L__pc.21472.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21473
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21473: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21474
	
	.L__pc.21474: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21475
	
	.p2align 4
	.L__pc.21475: Dma_PatchDst (.L__pc.21475.ST), (.L__movme_cp.66), (.L__pc.21475.ST)
	.L__pc.21475.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21476
	
	.L__pc.21476: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21477
	
	.p2align 4
	.L__pc.21477: Dma_PatchDst (.L__pc.21477.ST), (.L__movme_cp.24), (.L__pc.21477.ST)
	.L__pc.21477.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21478
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21478: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21479
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21479: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21480
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21480: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21481
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21481: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21482
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.21482: Dma_PatchSrc (.L__pc.21482.LD), (.L__movme_cp.67), (.L__pc.21482.LD)
	.p2align 4
	.L__pc.21482.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21483
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21483: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21484
	.L__pc.21484: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21485
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21485: Dma_PatchSrc (.L__pc.21485.LD), (.L__movme_cp.24), (.L__pc.21485.LD)
	.p2align 4
	.L__pc.21485.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21486
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21486: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21487
	.L__pc.21487: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21488
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21488: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21489: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21490: Dma_PatchSrc (.L__pc.21490.LD), (.L__movme_tmp.1), (.L__pc.21490.LD)
	.p2align 4
	.L__pc.21490.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21491
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21491: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21492
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21492: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21493: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21494: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21495: Dma_PatchSrc (.L__pc.21495.LD), (.L__movme_tmp.1), (.L__pc.21495.LD)
	.p2align 4
	.L__pc.21495.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21496
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21496: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21497
	
	.L__pc.21497: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21498
	
	.p2align 4
	.L__pc.21498: Dma_PatchDst (.L__pc.21498.ST), (.L__movme_cp.67), (.L__pc.21498.ST)
	.L__pc.21498.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21499
	
	.L__pc.21499: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21500
	
	.p2align 4
	.L__pc.21500: Dma_PatchDst (.L__pc.21500.ST), (.L__movme_cp.24), (.L__pc.21500.ST)
	.L__pc.21500.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21501
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21501: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21502
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21502: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21503
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21503: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21504
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21504: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21505
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.21505: Dma_PatchSrc (.L__pc.21505.LD), (.L__movme_cp.68), (.L__pc.21505.LD)
	.p2align 4
	.L__pc.21505.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21506
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21506: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21507
	.L__pc.21507: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21508
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21508: Dma_PatchSrc (.L__pc.21508.LD), (.L__movme_cp.24), (.L__pc.21508.LD)
	.p2align 4
	.L__pc.21508.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21509
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21509: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21510
	.L__pc.21510: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21511
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21511: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21512: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21513: Dma_PatchSrc (.L__pc.21513.LD), (.L__movme_tmp.1), (.L__pc.21513.LD)
	.p2align 4
	.L__pc.21513.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21514
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21514: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21515
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21515: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21516: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21517: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21518: Dma_PatchSrc (.L__pc.21518.LD), (.L__movme_tmp.1), (.L__pc.21518.LD)
	.p2align 4
	.L__pc.21518.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21519
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21519: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21520
	
	.L__pc.21520: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21521
	
	.p2align 4
	.L__pc.21521: Dma_PatchDst (.L__pc.21521.ST), (.L__movme_cp.68), (.L__pc.21521.ST)
	.L__pc.21521.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21522
	
	.L__pc.21522: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21523
	
	.p2align 4
	.L__pc.21523: Dma_PatchDst (.L__pc.21523.ST), (.L__movme_cp.24), (.L__pc.21523.ST)
	.L__pc.21523.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21524
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21524: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21525
	
	.p2align 4
	.L__pc.21525: Dma_PatchDst (.L__pc.21525.ST), (.L__movme_cp.24), (.L__pc.21525.ST)
	.L__pc.21525.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21526
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.21526: Dma_PatchSrc (.L__pc.21526.LD), (.L__movme_cp.60), (.L__pc.21526.LD)
	.p2align 4
	.L__pc.21526.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21527
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21527: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21528
	
	.L__pc.21528: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21529
	
	.p2align 4
	.L__pc.21529: Dma_PatchDst (.L__pc.21529.ST), (.L__movme_cp.21), (.L__pc.21529.ST)
	.L__pc.21529.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21530
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.21530: Dma_PatchSrc (.L__pc.21530.LD), (.L__movme_cp.58), (.L__pc.21530.LD)
	.p2align 4
	.L__pc.21530.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21531
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21531: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21532
	
	.L__pc.21532: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21533
	
	.p2align 4
	.L__pc.21533: Dma_PatchDst (.L__pc.21533.ST), (.L__movme_cp.22), (.L__pc.21533.ST)
	.L__pc.21533.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21534
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21534: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21535
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21535: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21536
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21536: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21537
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21537: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21538
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.21538: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.21539
	
	.p2align 4
	.L__pc.21539: Dma_PatchDst (.L__pc.21539.ST), (.L__movme_cp.24), (.L__pc.21539.ST)
	.L__pc.21539.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21540
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.21540: Dma_PatchSrc (.L__pc.21540.LD), (.L__movme_cp.25), (.L__pc.21540.LD)
	.p2align 4
	.L__pc.21540.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21541
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21541: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21542
	.L__pc.21542: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21543
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.21543: Dma_PatchSrc (.L__pc.21543.LD), (.L__movme_cp.26), (.L__pc.21543.LD)
	.p2align 4
	.L__pc.21543.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21544
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21544: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21545
	.L__pc.21545: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21546
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21546: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21547: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21548: Dma_PatchSrc (.L__pc.21548.LD), (.L__movme_tmp.1), (.L__pc.21548.LD)
	.p2align 4
	.L__pc.21548.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21549
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21549: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21550
	.L__pc.21550: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21551
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21551: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21552: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21553: Dma_PatchSrc (.L__pc.21553.LD), (.L__movme_tmp.1), (.L__pc.21553.LD)
	.p2align 4
	.L__pc.21553.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21554
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21554: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21555
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21555: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21556: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21557: Dma_PatchSrc (.L__pc.21557.LD), (.L__movme_tmp.1), (.L__pc.21557.LD)
	.p2align 4
	.L__pc.21557.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21558
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21558: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21559
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21559: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21560: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21561: Dma_PatchSrc (.L__pc.21561.LD), (.L__movme_tmp.1), (.L__pc.21561.LD)
	.p2align 4
	.L__pc.21561.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21562
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21562: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21563
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21563: Dma_PatchSrc (.L__pc.21563.LD), (.L__movme_cp.24), (.L__pc.21563.LD)
	.p2align 4
	.L__pc.21563.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21564
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21564: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21565
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21565: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21566: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21567: Dma_PatchSrc (.L__pc.21567.LD), (.L__movme_tmp.1), (.L__pc.21567.LD)
	.p2align 4
	.L__pc.21567.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21568
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21568: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21569
	
	.L__pc.21569: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21570
	
	.p2align 4
	.L__pc.21570: Dma_PatchDst (.L__pc.21570.ST), (.L__movme_cp.69), (.L__pc.21570.ST)
	.L__pc.21570.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21571
	
	.L__pc.21571: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21572
	
	.p2align 4
	.L__pc.21572: Dma_PatchDst (.L__pc.21572.ST), (.L__movme_cp.54), (.L__pc.21572.ST)
	.L__pc.21572.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21573
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.21573: Dma_PatchSrc (.L__pc.21573.LD), (.L__movme_cp.30), (.L__pc.21573.LD)
	.p2align 4
	.L__pc.21573.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21574
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21574: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21575
	.L__pc.21575: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21576
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.21576: Dma_PatchSrc (.L__pc.21576.LD), (.L__movme_cp.31), (.L__pc.21576.LD)
	.p2align 4
	.L__pc.21576.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21577
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21577: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21578
	.L__pc.21578: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21579
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21579: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21580: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21581: Dma_PatchSrc (.L__pc.21581.LD), (.L__movme_tmp.1), (.L__pc.21581.LD)
	.p2align 4
	.L__pc.21581.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21582
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21582: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21583
	.L__pc.21583: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21584
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21584: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21585: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21586: Dma_PatchSrc (.L__pc.21586.LD), (.L__movme_tmp.1), (.L__pc.21586.LD)
	.p2align 4
	.L__pc.21586.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21587
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21587: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21588
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21588: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21589: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21590: Dma_PatchSrc (.L__pc.21590.LD), (.L__movme_tmp.1), (.L__pc.21590.LD)
	.p2align 4
	.L__pc.21590.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21591
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21591: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21592
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21592: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21593: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21594: Dma_PatchSrc (.L__pc.21594.LD), (.L__movme_tmp.1), (.L__pc.21594.LD)
	.p2align 4
	.L__pc.21594.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21595
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21595: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21596
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21596: Dma_PatchSrc (.L__pc.21596.LD), (.L__movme_cp.24), (.L__pc.21596.LD)
	.p2align 4
	.L__pc.21596.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21597
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21597: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21598
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21598: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21599: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21600: Dma_PatchSrc (.L__pc.21600.LD), (.L__movme_tmp.1), (.L__pc.21600.LD)
	.p2align 4
	.L__pc.21600.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21601
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21601: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21602
	
	.L__pc.21602: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21603
	
	.p2align 4
	.L__pc.21603: Dma_PatchDst (.L__pc.21603.ST), (.L__movme_cp.70), (.L__pc.21603.ST)
	.L__pc.21603.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21604
	
	.L__pc.21604: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21605
	
	.p2align 4
	.L__pc.21605: Dma_PatchDst (.L__pc.21605.ST), (.L__movme_cp.54), (.L__pc.21605.ST)
	.L__pc.21605.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21606
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21606: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21607
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21607: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21608
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21608: Dma_PatchSrc (.L__pc.21608.LD), (.L__movme_cp.24), (.L__pc.21608.LD)
	.p2align 4
	.L__pc.21608.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21609
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21609: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21610
	.L__pc.21610: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21611
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.21611: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21612: Dma_PatchSrc (.L__pc.21612.LD), (.L__movme_tmp.1), (.L__pc.21612.LD)
	.p2align 4
	.L__pc.21612.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21613
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21613: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21614
	.L__pc.21614: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21615
	
	.L__pc.21615: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21616
	
	.p2align 4
	.L__pc.21616: Dma_PatchDst (.L__pc.21616.ST), (.L__movme_cp.72), (.L__pc.21616.ST)
	.L__pc.21616.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21617
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.21617: Dma_PatchSrc (.L__pc.21617.LD), (.L__movme_cp.72), (.L__pc.21617.LD)
	.p2align 4
	.L__pc.21617.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21618
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21618: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21619
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21619: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21620: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21621: Dma_PatchSrc (.L__pc.21621.LD), (.L__movme_tmp.1), (.L__pc.21621.LD)
	.p2align 4
	.L__pc.21621.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21622
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21622: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21623
	
	.L__pc.21623: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21624
	
	.p2align 4
	.L__pc.21624: Dma_PatchDst (.L__pc.21624.ST), (.L__movme_cp.74), (.L__pc.21624.ST)
	.L__pc.21624.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21625
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21625: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21626: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21627: Dma_PatchSrc (.L__pc.21627.LD), (.L__movme_tmp.1), (.L__pc.21627.LD)
	.p2align 4
	.L__pc.21627.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21628
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21628: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21629
	
	.L__pc.21629: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21630
	
	.p2align 4
	.L__pc.21630: Dma_PatchDst (.L__pc.21630.ST), (.L__movme_cp.76), (.L__pc.21630.ST)
	.L__pc.21630.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21631
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.21631: Dma_PatchSrc (.L__pc.21631.LD), (.L__movme_cp.74), (.L__pc.21631.LD)
	.p2align 4
	.L__pc.21631.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21632
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21632: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21633
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.21633: Dma_PatchSrc (.L__pc.21633.LD), ((.L__movme.reg.eax+0)), (.L__pc.21633.LD)
	.p2align 4
	.L__pc.21633.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21634
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21634: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21635
	
	.L__pc.21635: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21636
	
	.p2align 4
	.L__pc.21636: Dma_PatchDst (.L__pc.21636.ST), (.L__movme_cp.77), (.L__pc.21636.ST)
	.L__pc.21636.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21637
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.21637: Dma_PatchSrc (.L__pc.21637.LD), (.L__movme_cp.77), (.L__pc.21637.LD)
	.p2align 4
	.L__pc.21637.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21638
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21638: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21639
	
	.L__pc.21639: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21640
	
	.p2align 4
	.L__pc.21640: Dma_PatchDst (.L__pc.21640.ST), (.L__movme_cp.21), (.L__pc.21640.ST)
	.L__pc.21640.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21641
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.21641: Dma_PatchSrc (.L__pc.21641.LD), (.L__movme_cp.58), (.L__pc.21641.LD)
	.p2align 4
	.L__pc.21641.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21642
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21642: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21643
	
	.L__pc.21643: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21644
	
	.p2align 4
	.L__pc.21644: Dma_PatchDst (.L__pc.21644.ST), (.L__movme_cp.22), (.L__pc.21644.ST)
	.L__pc.21644.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21645
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21645: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21646
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21646: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21647
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21647: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21648
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21648: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21649
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.21649: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.21650
	
	.p2align 4
	.L__pc.21650: Dma_PatchDst (.L__pc.21650.ST), (.L__movme_cp.24), (.L__pc.21650.ST)
	.L__pc.21650.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21651
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.21651: Dma_PatchSrc (.L__pc.21651.LD), (.L__movme_cp.25), (.L__pc.21651.LD)
	.p2align 4
	.L__pc.21651.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21652
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21652: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21653
	.L__pc.21653: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21654
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.21654: Dma_PatchSrc (.L__pc.21654.LD), (.L__movme_cp.26), (.L__pc.21654.LD)
	.p2align 4
	.L__pc.21654.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21655
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21655: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21656
	.L__pc.21656: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21657
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21657: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21658: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21659: Dma_PatchSrc (.L__pc.21659.LD), (.L__movme_tmp.1), (.L__pc.21659.LD)
	.p2align 4
	.L__pc.21659.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21660
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21660: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21661
	.L__pc.21661: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21662
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21662: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21663: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21664: Dma_PatchSrc (.L__pc.21664.LD), (.L__movme_tmp.1), (.L__pc.21664.LD)
	.p2align 4
	.L__pc.21664.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21665
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21665: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21666
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21666: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21667: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21668: Dma_PatchSrc (.L__pc.21668.LD), (.L__movme_tmp.1), (.L__pc.21668.LD)
	.p2align 4
	.L__pc.21668.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21669
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21669: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21670
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21670: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21671: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21672: Dma_PatchSrc (.L__pc.21672.LD), (.L__movme_tmp.1), (.L__pc.21672.LD)
	.p2align 4
	.L__pc.21672.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21673
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21673: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21674
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21674: Dma_PatchSrc (.L__pc.21674.LD), (.L__movme_cp.24), (.L__pc.21674.LD)
	.p2align 4
	.L__pc.21674.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21675
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21675: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21676
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21676: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21677: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21678: Dma_PatchSrc (.L__pc.21678.LD), (.L__movme_tmp.1), (.L__pc.21678.LD)
	.p2align 4
	.L__pc.21678.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21679
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21679: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21680
	
	.L__pc.21680: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21681
	
	.p2align 4
	.L__pc.21681: Dma_PatchDst (.L__pc.21681.ST), (.L__movme_cp.78), (.L__pc.21681.ST)
	.L__pc.21681.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21682
	
	.L__pc.21682: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21683
	
	.p2align 4
	.L__pc.21683: Dma_PatchDst (.L__pc.21683.ST), (.L__movme_cp.54), (.L__pc.21683.ST)
	.L__pc.21683.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21684
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.21684: Dma_PatchSrc (.L__pc.21684.LD), (.L__movme_cp.30), (.L__pc.21684.LD)
	.p2align 4
	.L__pc.21684.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21685
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21685: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21686
	.L__pc.21686: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21687
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.21687: Dma_PatchSrc (.L__pc.21687.LD), (.L__movme_cp.31), (.L__pc.21687.LD)
	.p2align 4
	.L__pc.21687.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21688
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21688: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21689
	.L__pc.21689: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21690
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21690: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21691: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21692: Dma_PatchSrc (.L__pc.21692.LD), (.L__movme_tmp.1), (.L__pc.21692.LD)
	.p2align 4
	.L__pc.21692.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21693
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21693: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21694
	.L__pc.21694: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21695
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21695: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21696: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21697: Dma_PatchSrc (.L__pc.21697.LD), (.L__movme_tmp.1), (.L__pc.21697.LD)
	.p2align 4
	.L__pc.21697.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21698
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21698: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21699
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21699: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21700: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21701: Dma_PatchSrc (.L__pc.21701.LD), (.L__movme_tmp.1), (.L__pc.21701.LD)
	.p2align 4
	.L__pc.21701.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21702
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21702: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21703
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21703: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21704: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21705: Dma_PatchSrc (.L__pc.21705.LD), (.L__movme_tmp.1), (.L__pc.21705.LD)
	.p2align 4
	.L__pc.21705.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21706
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21706: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21707
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21707: Dma_PatchSrc (.L__pc.21707.LD), (.L__movme_cp.24), (.L__pc.21707.LD)
	.p2align 4
	.L__pc.21707.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21708
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21708: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21709
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21709: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21710: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21711: Dma_PatchSrc (.L__pc.21711.LD), (.L__movme_tmp.1), (.L__pc.21711.LD)
	.p2align 4
	.L__pc.21711.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21712
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21712: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21713
	
	.L__pc.21713: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21714
	
	.p2align 4
	.L__pc.21714: Dma_PatchDst (.L__pc.21714.ST), (.L__movme_cp.79), (.L__pc.21714.ST)
	.L__pc.21714.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21715
	
	.L__pc.21715: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21716
	
	.p2align 4
	.L__pc.21716: Dma_PatchDst (.L__pc.21716.ST), (.L__movme_cp.54), (.L__pc.21716.ST)
	.L__pc.21716.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21717
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.21717: Dma_PatchSrc (.L__pc.21717.LD), (.L__movme_cp.74), (.L__pc.21717.LD)
	.p2align 4
	.L__pc.21717.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21718
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21718: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21719
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.21719: Dma_PatchSrc (.L__pc.21719.LD), (.L__movme_cp.77), (.L__pc.21719.LD)
	.p2align 4
	.L__pc.21719.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21720
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21720: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21721
	
	.L__pc.21721: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21722
	
	.p2align 4
	.L__pc.21722: Dma_PatchDst (.L__pc.21722.ST), ((.L__movme.reg.eax+0)), (.L__pc.21722.ST)
	.L__pc.21722.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21723
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.21723: Dma_PatchSrc (.L__pc.21723.LD), (.L__movme_cp.76), (.L__pc.21723.LD)
	.p2align 4
	.L__pc.21723.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21724
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21724: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21725
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.21725: Dma_PatchSrc (.L__pc.21725.LD), ((.L__movme.reg.eax+0)), (.L__pc.21725.LD)
	.p2align 4
	.L__pc.21725.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21726
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21726: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21727
	
	.L__pc.21727: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21728
	
	.p2align 4
	.L__pc.21728: Dma_PatchDst (.L__pc.21728.ST), (.L__movme_cp.80), (.L__pc.21728.ST)
	.L__pc.21728.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21729
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21729: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21730
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21730: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21731
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.21731: Dma_PatchSrc (.L__pc.21731.LD), (.L__movme_cp.102), (.L__pc.21731.LD)
	.p2align 4
	.L__pc.21731.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21732
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21732: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21733
	.L__pc.21733: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21734
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.88 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.21734: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21735: Dma_PatchSrc (.L__pc.21735.LD), (.L__movme_tmp.1), (.L__pc.21735.LD)
	.p2align 4
	.L__pc.21735.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21736
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21736: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21737
	.L__pc.21737: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21738
	
	.L__pc.21738: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21739
	
	.p2align 4
	.L__pc.21739: Dma_PatchDst (.L__pc.21739.ST), (.L__movme_cp.102), (.L__pc.21739.ST)
	.L__pc.21739.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21740
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.21740: Dma_PatchSrc (.L__pc.21740.LD), (.L__movme_cp.76), (.L__pc.21740.LD)
	.p2align 4
	.L__pc.21740.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21741
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21741: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21742
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.21742: Dma_PatchSrc (.L__pc.21742.LD), (.L__movme_cp.80), (.L__pc.21742.LD)
	.p2align 4
	.L__pc.21742.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21743
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21743: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21744
	
	.L__pc.21744: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21745
	
	.p2align 4
	.L__pc.21745: Dma_PatchDst (.L__pc.21745.ST), ((.L__movme.reg.eax+0)), (.L__pc.21745.ST)
	.L__pc.21745.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21746
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21746: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21747
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21747: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21748
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.21748: Dma_PatchSrc (.L__pc.21748.LD), (.L__movme_cp.101), (.L__pc.21748.LD)
	.p2align 4
	.L__pc.21748.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21749
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21749: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21750
	.L__pc.21750: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21751
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21751: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.89 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21752: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21753: Dma_PatchSrc (.L__pc.21753.LD), (.L__movme_tmp.1), (.L__pc.21753.LD)
	.p2align 4
	.L__pc.21753.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21754
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21754: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21755
	
	.L__pc.21755: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21756
	
	.p2align 4
	.L__pc.21756: Dma_PatchDst (.L__pc.21756.ST), (.L__movme_cp.24), (.L__pc.21756.ST)
	.L__pc.21756.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21757
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21757: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21758
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21758: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21759
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21759: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21760
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21760: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21761
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.21761: Dma_PatchSrc (.L__pc.21761.LD), (.L__movme_cp.63), (.L__pc.21761.LD)
	.p2align 4
	.L__pc.21761.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21762
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21762: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21763
	.L__pc.21763: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21764
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21764: Dma_PatchSrc (.L__pc.21764.LD), (.L__movme_cp.24), (.L__pc.21764.LD)
	.p2align 4
	.L__pc.21764.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21765
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21765: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21766
	.L__pc.21766: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21767
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21767: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21768: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21769: Dma_PatchSrc (.L__pc.21769.LD), (.L__movme_tmp.1), (.L__pc.21769.LD)
	.p2align 4
	.L__pc.21769.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21770
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21770: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21771
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21771: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21772: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21773: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21774: Dma_PatchSrc (.L__pc.21774.LD), (.L__movme_tmp.1), (.L__pc.21774.LD)
	.p2align 4
	.L__pc.21774.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21775
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21775: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21776
	
	.L__pc.21776: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21777
	
	.p2align 4
	.L__pc.21777: Dma_PatchDst (.L__pc.21777.ST), (.L__movme_cp.63), (.L__pc.21777.ST)
	.L__pc.21777.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21778
	
	.L__pc.21778: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21779
	
	.p2align 4
	.L__pc.21779: Dma_PatchDst (.L__pc.21779.ST), (.L__movme_cp.24), (.L__pc.21779.ST)
	.L__pc.21779.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21780
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21780: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21781
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21781: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21782
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21782: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21783
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21783: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21784
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.21784: Dma_PatchSrc (.L__pc.21784.LD), (.L__movme_cp.66), (.L__pc.21784.LD)
	.p2align 4
	.L__pc.21784.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21785
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21785: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21786
	.L__pc.21786: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21787
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21787: Dma_PatchSrc (.L__pc.21787.LD), (.L__movme_cp.24), (.L__pc.21787.LD)
	.p2align 4
	.L__pc.21787.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21788
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21788: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21789
	.L__pc.21789: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21790
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21790: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21791: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21792: Dma_PatchSrc (.L__pc.21792.LD), (.L__movme_tmp.1), (.L__pc.21792.LD)
	.p2align 4
	.L__pc.21792.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21793
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21793: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21794
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21794: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21795: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21796: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21797: Dma_PatchSrc (.L__pc.21797.LD), (.L__movme_tmp.1), (.L__pc.21797.LD)
	.p2align 4
	.L__pc.21797.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21798
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21798: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21799
	
	.L__pc.21799: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21800
	
	.p2align 4
	.L__pc.21800: Dma_PatchDst (.L__pc.21800.ST), (.L__movme_cp.66), (.L__pc.21800.ST)
	.L__pc.21800.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21801
	
	.L__pc.21801: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21802
	
	.p2align 4
	.L__pc.21802: Dma_PatchDst (.L__pc.21802.ST), (.L__movme_cp.24), (.L__pc.21802.ST)
	.L__pc.21802.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21803
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21803: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21804
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21804: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21805
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21805: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21806
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21806: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21807
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.21807: Dma_PatchSrc (.L__pc.21807.LD), (.L__movme_cp.67), (.L__pc.21807.LD)
	.p2align 4
	.L__pc.21807.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21808
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21808: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21809
	.L__pc.21809: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21810
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21810: Dma_PatchSrc (.L__pc.21810.LD), (.L__movme_cp.24), (.L__pc.21810.LD)
	.p2align 4
	.L__pc.21810.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21811
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21811: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21812
	.L__pc.21812: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21813
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21813: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21814: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21815: Dma_PatchSrc (.L__pc.21815.LD), (.L__movme_tmp.1), (.L__pc.21815.LD)
	.p2align 4
	.L__pc.21815.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21816
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21816: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21817
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21817: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21818: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21819: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21820: Dma_PatchSrc (.L__pc.21820.LD), (.L__movme_tmp.1), (.L__pc.21820.LD)
	.p2align 4
	.L__pc.21820.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21821
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21821: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21822
	
	.L__pc.21822: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21823
	
	.p2align 4
	.L__pc.21823: Dma_PatchDst (.L__pc.21823.ST), (.L__movme_cp.67), (.L__pc.21823.ST)
	.L__pc.21823.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21824
	
	.L__pc.21824: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21825
	
	.p2align 4
	.L__pc.21825: Dma_PatchDst (.L__pc.21825.ST), (.L__movme_cp.24), (.L__pc.21825.ST)
	.L__pc.21825.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21826
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21826: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21827
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21827: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21828
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21828: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21829
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21829: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21830
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.21830: Dma_PatchSrc (.L__pc.21830.LD), (.L__movme_cp.68), (.L__pc.21830.LD)
	.p2align 4
	.L__pc.21830.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21831
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21831: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21832
	.L__pc.21832: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21833
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21833: Dma_PatchSrc (.L__pc.21833.LD), (.L__movme_cp.24), (.L__pc.21833.LD)
	.p2align 4
	.L__pc.21833.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21834
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21834: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.21835
	.L__pc.21835: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.21836
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21836: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21837: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21838: Dma_PatchSrc (.L__pc.21838.LD), (.L__movme_tmp.1), (.L__pc.21838.LD)
	.p2align 4
	.L__pc.21838.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21839
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21839: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21840
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.21840: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.21841: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.21842: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21843: Dma_PatchSrc (.L__pc.21843.LD), (.L__movme_tmp.1), (.L__pc.21843.LD)
	.p2align 4
	.L__pc.21843.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21844
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21844: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21845
	
	.L__pc.21845: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.21846
	
	.p2align 4
	.L__pc.21846: Dma_PatchDst (.L__pc.21846.ST), (.L__movme_cp.68), (.L__pc.21846.ST)
	.L__pc.21846.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21847
	
	.L__pc.21847: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.21848
	
	.p2align 4
	.L__pc.21848: Dma_PatchDst (.L__pc.21848.ST), (.L__movme_cp.24), (.L__pc.21848.ST)
	.L__pc.21848.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21849
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21849: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21850
	
	.p2align 4
	.L__pc.21850: Dma_PatchDst (.L__pc.21850.ST), (.L__movme_cp.24), (.L__pc.21850.ST)
	.L__pc.21850.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21851
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.21851: Dma_PatchSrc (.L__pc.21851.LD), (.L__movme_cp.60), (.L__pc.21851.LD)
	.p2align 4
	.L__pc.21851.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21852
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21852: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21853
	
	.L__pc.21853: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21854
	
	.p2align 4
	.L__pc.21854: Dma_PatchDst (.L__pc.21854.ST), (.L__movme_cp.21), (.L__pc.21854.ST)
	.L__pc.21854.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21855
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.21855: Dma_PatchSrc (.L__pc.21855.LD), (.L__movme_cp.58), (.L__pc.21855.LD)
	.p2align 4
	.L__pc.21855.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21856
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21856: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21857
	
	.L__pc.21857: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21858
	
	.p2align 4
	.L__pc.21858: Dma_PatchDst (.L__pc.21858.ST), (.L__movme_cp.22), (.L__pc.21858.ST)
	.L__pc.21858.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21859
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21859: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21860
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21860: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21861
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21861: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21862
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21862: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21863
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.21863: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.21864
	
	.p2align 4
	.L__pc.21864: Dma_PatchDst (.L__pc.21864.ST), (.L__movme_cp.24), (.L__pc.21864.ST)
	.L__pc.21864.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21865
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.21865: Dma_PatchSrc (.L__pc.21865.LD), (.L__movme_cp.25), (.L__pc.21865.LD)
	.p2align 4
	.L__pc.21865.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21866
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21866: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21867
	.L__pc.21867: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21868
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.21868: Dma_PatchSrc (.L__pc.21868.LD), (.L__movme_cp.26), (.L__pc.21868.LD)
	.p2align 4
	.L__pc.21868.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21869
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21869: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21870
	.L__pc.21870: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21871
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21871: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21872: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21873: Dma_PatchSrc (.L__pc.21873.LD), (.L__movme_tmp.1), (.L__pc.21873.LD)
	.p2align 4
	.L__pc.21873.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21874
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21874: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21875
	.L__pc.21875: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21876
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21876: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21877: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21878: Dma_PatchSrc (.L__pc.21878.LD), (.L__movme_tmp.1), (.L__pc.21878.LD)
	.p2align 4
	.L__pc.21878.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21879
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21879: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21880
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21880: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21881: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21882: Dma_PatchSrc (.L__pc.21882.LD), (.L__movme_tmp.1), (.L__pc.21882.LD)
	.p2align 4
	.L__pc.21882.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21883
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21883: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21884
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21884: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21885: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21886: Dma_PatchSrc (.L__pc.21886.LD), (.L__movme_tmp.1), (.L__pc.21886.LD)
	.p2align 4
	.L__pc.21886.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21887
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21887: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21888
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21888: Dma_PatchSrc (.L__pc.21888.LD), (.L__movme_cp.24), (.L__pc.21888.LD)
	.p2align 4
	.L__pc.21888.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21889
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21889: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21890
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21890: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21891: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21892: Dma_PatchSrc (.L__pc.21892.LD), (.L__movme_tmp.1), (.L__pc.21892.LD)
	.p2align 4
	.L__pc.21892.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21893
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21893: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21894
	
	.L__pc.21894: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21895
	
	.p2align 4
	.L__pc.21895: Dma_PatchDst (.L__pc.21895.ST), (.L__movme_cp.69), (.L__pc.21895.ST)
	.L__pc.21895.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21896
	
	.L__pc.21896: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21897
	
	.p2align 4
	.L__pc.21897: Dma_PatchDst (.L__pc.21897.ST), (.L__movme_cp.54), (.L__pc.21897.ST)
	.L__pc.21897.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21898
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.21898: Dma_PatchSrc (.L__pc.21898.LD), (.L__movme_cp.30), (.L__pc.21898.LD)
	.p2align 4
	.L__pc.21898.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21899
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21899: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21900
	.L__pc.21900: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21901
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.21901: Dma_PatchSrc (.L__pc.21901.LD), (.L__movme_cp.31), (.L__pc.21901.LD)
	.p2align 4
	.L__pc.21901.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21902
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21902: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21903
	.L__pc.21903: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21904
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21904: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21905: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21906: Dma_PatchSrc (.L__pc.21906.LD), (.L__movme_tmp.1), (.L__pc.21906.LD)
	.p2align 4
	.L__pc.21906.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21907
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21907: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21908
	.L__pc.21908: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21909
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21909: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21910: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21911: Dma_PatchSrc (.L__pc.21911.LD), (.L__movme_tmp.1), (.L__pc.21911.LD)
	.p2align 4
	.L__pc.21911.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21912
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21912: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21913
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21913: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21914: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21915: Dma_PatchSrc (.L__pc.21915.LD), (.L__movme_tmp.1), (.L__pc.21915.LD)
	.p2align 4
	.L__pc.21915.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21916
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21916: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21917
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21917: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21918: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21919: Dma_PatchSrc (.L__pc.21919.LD), (.L__movme_tmp.1), (.L__pc.21919.LD)
	.p2align 4
	.L__pc.21919.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21920
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21920: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21921
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21921: Dma_PatchSrc (.L__pc.21921.LD), (.L__movme_cp.24), (.L__pc.21921.LD)
	.p2align 4
	.L__pc.21921.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21922
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21922: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21923
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21923: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21924: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21925: Dma_PatchSrc (.L__pc.21925.LD), (.L__movme_tmp.1), (.L__pc.21925.LD)
	.p2align 4
	.L__pc.21925.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21926
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21926: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21927
	
	.L__pc.21927: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.21928
	
	.p2align 4
	.L__pc.21928: Dma_PatchDst (.L__pc.21928.ST), (.L__movme_cp.70), (.L__pc.21928.ST)
	.L__pc.21928.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21929
	
	.L__pc.21929: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21930
	
	.p2align 4
	.L__pc.21930: Dma_PatchDst (.L__pc.21930.ST), (.L__movme_cp.54), (.L__pc.21930.ST)
	.L__pc.21930.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21931
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21931: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21932
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21932: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21933
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21933: Dma_PatchSrc (.L__pc.21933.LD), (.L__movme_cp.24), (.L__pc.21933.LD)
	.p2align 4
	.L__pc.21933.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21934
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21934: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21935
	.L__pc.21935: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21936
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.21936: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21937: Dma_PatchSrc (.L__pc.21937.LD), (.L__movme_tmp.1), (.L__pc.21937.LD)
	.p2align 4
	.L__pc.21937.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21938
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21938: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.21939
	.L__pc.21939: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.21940
	
	.L__pc.21940: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21941
	
	.p2align 4
	.L__pc.21941: Dma_PatchDst (.L__pc.21941.ST), (.L__movme_cp.72), (.L__pc.21941.ST)
	.L__pc.21941.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21942
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.21942: Dma_PatchSrc (.L__pc.21942.LD), (.L__movme_cp.72), (.L__pc.21942.LD)
	.p2align 4
	.L__pc.21942.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21943
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21943: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21944
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21944: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21945: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21946: Dma_PatchSrc (.L__pc.21946.LD), (.L__movme_tmp.1), (.L__pc.21946.LD)
	.p2align 4
	.L__pc.21946.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21947
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21947: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21948
	
	.L__pc.21948: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21949
	
	.p2align 4
	.L__pc.21949: Dma_PatchDst (.L__pc.21949.ST), (.L__movme_cp.74), (.L__pc.21949.ST)
	.L__pc.21949.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21950
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21950: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21951: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21952: Dma_PatchSrc (.L__pc.21952.LD), (.L__movme_tmp.1), (.L__pc.21952.LD)
	.p2align 4
	.L__pc.21952.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21953
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21953: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21954
	
	.L__pc.21954: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.21955
	
	.p2align 4
	.L__pc.21955: Dma_PatchDst (.L__pc.21955.ST), (.L__movme_cp.76), (.L__pc.21955.ST)
	.L__pc.21955.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21956
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.21956: Dma_PatchSrc (.L__pc.21956.LD), (.L__movme_cp.74), (.L__pc.21956.LD)
	.p2align 4
	.L__pc.21956.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21957
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21957: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21958
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.21958: Dma_PatchSrc (.L__pc.21958.LD), ((.L__movme.reg.eax+0)), (.L__pc.21958.LD)
	.p2align 4
	.L__pc.21958.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21959
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21959: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21960
	
	.L__pc.21960: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21961
	
	.p2align 4
	.L__pc.21961: Dma_PatchDst (.L__pc.21961.ST), (.L__movme_cp.77), (.L__pc.21961.ST)
	.L__pc.21961.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21962
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.21962: Dma_PatchSrc (.L__pc.21962.LD), (.L__movme_cp.77), (.L__pc.21962.LD)
	.p2align 4
	.L__pc.21962.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21963
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21963: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21964
	
	.L__pc.21964: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21965
	
	.p2align 4
	.L__pc.21965: Dma_PatchDst (.L__pc.21965.ST), (.L__movme_cp.21), (.L__pc.21965.ST)
	.L__pc.21965.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21966
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.21966: Dma_PatchSrc (.L__pc.21966.LD), (.L__movme_cp.58), (.L__pc.21966.LD)
	.p2align 4
	.L__pc.21966.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21967
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21967: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21968
	
	.L__pc.21968: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.21969
	
	.p2align 4
	.L__pc.21969: Dma_PatchDst (.L__pc.21969.ST), (.L__movme_cp.22), (.L__pc.21969.ST)
	.L__pc.21969.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21970
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21970: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21971
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21971: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.21972
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.21972: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.21973
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21973: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.21974
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.21974: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.21975
	
	.p2align 4
	.L__pc.21975: Dma_PatchDst (.L__pc.21975.ST), (.L__movme_cp.24), (.L__pc.21975.ST)
	.L__pc.21975.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.21976
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.21976: Dma_PatchSrc (.L__pc.21976.LD), (.L__movme_cp.25), (.L__pc.21976.LD)
	.p2align 4
	.L__pc.21976.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21977
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.21977: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.21978
	.L__pc.21978: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.21979
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.21979: Dma_PatchSrc (.L__pc.21979.LD), (.L__movme_cp.26), (.L__pc.21979.LD)
	.p2align 4
	.L__pc.21979.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21980
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21980: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21981
	.L__pc.21981: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21982
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.21982: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21983: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21984: Dma_PatchSrc (.L__pc.21984.LD), (.L__movme_tmp.1), (.L__pc.21984.LD)
	.p2align 4
	.L__pc.21984.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21985
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.21985: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.21986
	.L__pc.21986: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.21987
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.21987: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21988: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21989: Dma_PatchSrc (.L__pc.21989.LD), (.L__movme_tmp.1), (.L__pc.21989.LD)
	.p2align 4
	.L__pc.21989.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21990
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21990: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21991
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.21991: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21992: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21993: Dma_PatchSrc (.L__pc.21993.LD), (.L__movme_tmp.1), (.L__pc.21993.LD)
	.p2align 4
	.L__pc.21993.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21994
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21994: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21995
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.21995: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.21996: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.21997: Dma_PatchSrc (.L__pc.21997.LD), (.L__movme_tmp.1), (.L__pc.21997.LD)
	.p2align 4
	.L__pc.21997.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.21998
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.21998: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.21999
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.21999: Dma_PatchSrc (.L__pc.21999.LD), (.L__movme_cp.24), (.L__pc.21999.LD)
	.p2align 4
	.L__pc.21999.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22000
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22000: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22001
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22001: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22002: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22003: Dma_PatchSrc (.L__pc.22003.LD), (.L__movme_tmp.1), (.L__pc.22003.LD)
	.p2align 4
	.L__pc.22003.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22004
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22004: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22005
	
	.L__pc.22005: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22006
	
	.p2align 4
	.L__pc.22006: Dma_PatchDst (.L__pc.22006.ST), (.L__movme_cp.78), (.L__pc.22006.ST)
	.L__pc.22006.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22007
	
	.L__pc.22007: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22008
	
	.p2align 4
	.L__pc.22008: Dma_PatchDst (.L__pc.22008.ST), (.L__movme_cp.54), (.L__pc.22008.ST)
	.L__pc.22008.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22009
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.22009: Dma_PatchSrc (.L__pc.22009.LD), (.L__movme_cp.30), (.L__pc.22009.LD)
	.p2align 4
	.L__pc.22009.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22010
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22010: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22011
	.L__pc.22011: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22012
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.22012: Dma_PatchSrc (.L__pc.22012.LD), (.L__movme_cp.31), (.L__pc.22012.LD)
	.p2align 4
	.L__pc.22012.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22013
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22013: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22014
	.L__pc.22014: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22015
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22015: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22016: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22017: Dma_PatchSrc (.L__pc.22017.LD), (.L__movme_tmp.1), (.L__pc.22017.LD)
	.p2align 4
	.L__pc.22017.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22018
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22018: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22019
	.L__pc.22019: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22020
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22020: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22021: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22022: Dma_PatchSrc (.L__pc.22022.LD), (.L__movme_tmp.1), (.L__pc.22022.LD)
	.p2align 4
	.L__pc.22022.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22023
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22023: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22024
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22024: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22025: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22026: Dma_PatchSrc (.L__pc.22026.LD), (.L__movme_tmp.1), (.L__pc.22026.LD)
	.p2align 4
	.L__pc.22026.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22027
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22027: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22028
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22028: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22029: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22030: Dma_PatchSrc (.L__pc.22030.LD), (.L__movme_tmp.1), (.L__pc.22030.LD)
	.p2align 4
	.L__pc.22030.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22031
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22031: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22032
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22032: Dma_PatchSrc (.L__pc.22032.LD), (.L__movme_cp.24), (.L__pc.22032.LD)
	.p2align 4
	.L__pc.22032.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22033
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22033: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22034
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22034: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22035: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22036: Dma_PatchSrc (.L__pc.22036.LD), (.L__movme_tmp.1), (.L__pc.22036.LD)
	.p2align 4
	.L__pc.22036.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22037
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22037: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22038
	
	.L__pc.22038: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22039
	
	.p2align 4
	.L__pc.22039: Dma_PatchDst (.L__pc.22039.ST), (.L__movme_cp.79), (.L__pc.22039.ST)
	.L__pc.22039.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22040
	
	.L__pc.22040: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22041
	
	.p2align 4
	.L__pc.22041: Dma_PatchDst (.L__pc.22041.ST), (.L__movme_cp.54), (.L__pc.22041.ST)
	.L__pc.22041.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22042
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.22042: Dma_PatchSrc (.L__pc.22042.LD), (.L__movme_cp.74), (.L__pc.22042.LD)
	.p2align 4
	.L__pc.22042.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22043
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22043: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22044
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.22044: Dma_PatchSrc (.L__pc.22044.LD), (.L__movme_cp.77), (.L__pc.22044.LD)
	.p2align 4
	.L__pc.22044.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22045
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22045: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22046
	
	.L__pc.22046: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22047
	
	.p2align 4
	.L__pc.22047: Dma_PatchDst (.L__pc.22047.ST), ((.L__movme.reg.eax+0)), (.L__pc.22047.ST)
	.L__pc.22047.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22048
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.22048: Dma_PatchSrc (.L__pc.22048.LD), (.L__movme_cp.76), (.L__pc.22048.LD)
	.p2align 4
	.L__pc.22048.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22049
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22049: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22050
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.22050: Dma_PatchSrc (.L__pc.22050.LD), ((.L__movme.reg.eax+0)), (.L__pc.22050.LD)
	.p2align 4
	.L__pc.22050.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22051
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22051: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22052
	
	.L__pc.22052: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22053
	
	.p2align 4
	.L__pc.22053: Dma_PatchDst (.L__pc.22053.ST), (.L__movme_cp.80), (.L__pc.22053.ST)
	.L__pc.22053.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22054
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22054: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22055
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22055: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22056
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.22056: Dma_PatchSrc (.L__pc.22056.LD), (.L__movme_cp.102), (.L__pc.22056.LD)
	.p2align 4
	.L__pc.22056.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22057
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22057: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22058
	.L__pc.22058: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22059
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.90 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.22059: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22060: Dma_PatchSrc (.L__pc.22060.LD), (.L__movme_tmp.1), (.L__pc.22060.LD)
	.p2align 4
	.L__pc.22060.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22061
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22061: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22062
	.L__pc.22062: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22063
	
	.L__pc.22063: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22064
	
	.p2align 4
	.L__pc.22064: Dma_PatchDst (.L__pc.22064.ST), (.L__movme_cp.102), (.L__pc.22064.ST)
	.L__pc.22064.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22065
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.22065: Dma_PatchSrc (.L__pc.22065.LD), (.L__movme_cp.76), (.L__pc.22065.LD)
	.p2align 4
	.L__pc.22065.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22066
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22066: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22067
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.22067: Dma_PatchSrc (.L__pc.22067.LD), (.L__movme_cp.80), (.L__pc.22067.LD)
	.p2align 4
	.L__pc.22067.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22068
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22068: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22069
	
	.L__pc.22069: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22070
	
	.p2align 4
	.L__pc.22070: Dma_PatchDst (.L__pc.22070.ST), ((.L__movme.reg.eax+0)), (.L__pc.22070.ST)
	.L__pc.22070.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22071
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22071: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22072
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22072: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22073
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.22073: Dma_PatchSrc (.L__pc.22073.LD), (.L__movme_cp.101), (.L__pc.22073.LD)
	.p2align 4
	.L__pc.22073.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22074
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22074: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22075
	.L__pc.22075: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22076
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22076: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.91 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22077: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22078: Dma_PatchSrc (.L__pc.22078.LD), (.L__movme_tmp.1), (.L__pc.22078.LD)
	.p2align 4
	.L__pc.22078.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22079
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22079: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22080
	
	.L__pc.22080: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22081
	
	.p2align 4
	.L__pc.22081: Dma_PatchDst (.L__pc.22081.ST), (.L__movme_cp.24), (.L__pc.22081.ST)
	.L__pc.22081.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22082
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22082: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22083
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22083: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22084
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22084: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22085
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22085: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22086
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.22086: Dma_PatchSrc (.L__pc.22086.LD), (.L__movme_cp.63), (.L__pc.22086.LD)
	.p2align 4
	.L__pc.22086.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22087
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22087: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22088
	.L__pc.22088: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22089
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22089: Dma_PatchSrc (.L__pc.22089.LD), (.L__movme_cp.24), (.L__pc.22089.LD)
	.p2align 4
	.L__pc.22089.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22090
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22090: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22091
	.L__pc.22091: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22092
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22092: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22093: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22094: Dma_PatchSrc (.L__pc.22094.LD), (.L__movme_tmp.1), (.L__pc.22094.LD)
	.p2align 4
	.L__pc.22094.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22095
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22095: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22096
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22096: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22097: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22098: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22099: Dma_PatchSrc (.L__pc.22099.LD), (.L__movme_tmp.1), (.L__pc.22099.LD)
	.p2align 4
	.L__pc.22099.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22100
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22100: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22101
	
	.L__pc.22101: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22102
	
	.p2align 4
	.L__pc.22102: Dma_PatchDst (.L__pc.22102.ST), (.L__movme_cp.63), (.L__pc.22102.ST)
	.L__pc.22102.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22103
	
	.L__pc.22103: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22104
	
	.p2align 4
	.L__pc.22104: Dma_PatchDst (.L__pc.22104.ST), (.L__movme_cp.24), (.L__pc.22104.ST)
	.L__pc.22104.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22105
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22105: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22106
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22106: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22107
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22107: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22108
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22108: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22109
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.22109: Dma_PatchSrc (.L__pc.22109.LD), (.L__movme_cp.66), (.L__pc.22109.LD)
	.p2align 4
	.L__pc.22109.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22110
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22110: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22111
	.L__pc.22111: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22112
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22112: Dma_PatchSrc (.L__pc.22112.LD), (.L__movme_cp.24), (.L__pc.22112.LD)
	.p2align 4
	.L__pc.22112.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22113
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22113: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22114
	.L__pc.22114: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22115
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22115: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22116: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22117: Dma_PatchSrc (.L__pc.22117.LD), (.L__movme_tmp.1), (.L__pc.22117.LD)
	.p2align 4
	.L__pc.22117.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22118
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22118: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22119
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22119: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22120: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22121: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22122: Dma_PatchSrc (.L__pc.22122.LD), (.L__movme_tmp.1), (.L__pc.22122.LD)
	.p2align 4
	.L__pc.22122.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22123
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22123: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22124
	
	.L__pc.22124: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22125
	
	.p2align 4
	.L__pc.22125: Dma_PatchDst (.L__pc.22125.ST), (.L__movme_cp.66), (.L__pc.22125.ST)
	.L__pc.22125.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22126
	
	.L__pc.22126: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22127
	
	.p2align 4
	.L__pc.22127: Dma_PatchDst (.L__pc.22127.ST), (.L__movme_cp.24), (.L__pc.22127.ST)
	.L__pc.22127.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22128
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22128: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22129
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22129: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22130
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22130: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22131
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22131: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22132
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.22132: Dma_PatchSrc (.L__pc.22132.LD), (.L__movme_cp.67), (.L__pc.22132.LD)
	.p2align 4
	.L__pc.22132.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22133
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22133: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22134
	.L__pc.22134: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22135
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22135: Dma_PatchSrc (.L__pc.22135.LD), (.L__movme_cp.24), (.L__pc.22135.LD)
	.p2align 4
	.L__pc.22135.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22136
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22136: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22137
	.L__pc.22137: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22138
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22138: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22139: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22140: Dma_PatchSrc (.L__pc.22140.LD), (.L__movme_tmp.1), (.L__pc.22140.LD)
	.p2align 4
	.L__pc.22140.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22141
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22141: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22142
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22142: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22143: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22144: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22145: Dma_PatchSrc (.L__pc.22145.LD), (.L__movme_tmp.1), (.L__pc.22145.LD)
	.p2align 4
	.L__pc.22145.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22146
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22146: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22147
	
	.L__pc.22147: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22148
	
	.p2align 4
	.L__pc.22148: Dma_PatchDst (.L__pc.22148.ST), (.L__movme_cp.67), (.L__pc.22148.ST)
	.L__pc.22148.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22149
	
	.L__pc.22149: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22150
	
	.p2align 4
	.L__pc.22150: Dma_PatchDst (.L__pc.22150.ST), (.L__movme_cp.24), (.L__pc.22150.ST)
	.L__pc.22150.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22151
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22151: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22152
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22152: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22153
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22153: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22154
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22154: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22155
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.22155: Dma_PatchSrc (.L__pc.22155.LD), (.L__movme_cp.68), (.L__pc.22155.LD)
	.p2align 4
	.L__pc.22155.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22156
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22156: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22157
	.L__pc.22157: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22158
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22158: Dma_PatchSrc (.L__pc.22158.LD), (.L__movme_cp.24), (.L__pc.22158.LD)
	.p2align 4
	.L__pc.22158.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22159
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22159: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22160
	.L__pc.22160: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22161
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22161: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22162: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22163: Dma_PatchSrc (.L__pc.22163.LD), (.L__movme_tmp.1), (.L__pc.22163.LD)
	.p2align 4
	.L__pc.22163.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22164
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22164: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22165
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22165: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22166: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22167: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22168: Dma_PatchSrc (.L__pc.22168.LD), (.L__movme_tmp.1), (.L__pc.22168.LD)
	.p2align 4
	.L__pc.22168.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22169
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22169: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22170
	
	.L__pc.22170: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22171
	
	.p2align 4
	.L__pc.22171: Dma_PatchDst (.L__pc.22171.ST), (.L__movme_cp.68), (.L__pc.22171.ST)
	.L__pc.22171.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22172
	
	.L__pc.22172: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22173
	
	.p2align 4
	.L__pc.22173: Dma_PatchDst (.L__pc.22173.ST), (.L__movme_cp.24), (.L__pc.22173.ST)
	.L__pc.22173.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22174
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22174: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22175
	
	.p2align 4
	.L__pc.22175: Dma_PatchDst (.L__pc.22175.ST), (.L__movme_cp.24), (.L__pc.22175.ST)
	.L__pc.22175.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22176
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.22176: Dma_PatchSrc (.L__pc.22176.LD), (.L__movme_cp.60), (.L__pc.22176.LD)
	.p2align 4
	.L__pc.22176.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22177
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22177: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22178
	
	.L__pc.22178: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22179
	
	.p2align 4
	.L__pc.22179: Dma_PatchDst (.L__pc.22179.ST), (.L__movme_cp.21), (.L__pc.22179.ST)
	.L__pc.22179.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22180
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.22180: Dma_PatchSrc (.L__pc.22180.LD), (.L__movme_cp.58), (.L__pc.22180.LD)
	.p2align 4
	.L__pc.22180.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22181
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22181: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22182
	
	.L__pc.22182: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22183
	
	.p2align 4
	.L__pc.22183: Dma_PatchDst (.L__pc.22183.ST), (.L__movme_cp.22), (.L__pc.22183.ST)
	.L__pc.22183.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22184
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22184: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22185
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22185: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22186
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22186: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22187
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22187: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22188
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.22188: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.22189
	
	.p2align 4
	.L__pc.22189: Dma_PatchDst (.L__pc.22189.ST), (.L__movme_cp.24), (.L__pc.22189.ST)
	.L__pc.22189.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22190
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.22190: Dma_PatchSrc (.L__pc.22190.LD), (.L__movme_cp.25), (.L__pc.22190.LD)
	.p2align 4
	.L__pc.22190.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22191
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22191: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22192
	.L__pc.22192: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22193
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.22193: Dma_PatchSrc (.L__pc.22193.LD), (.L__movme_cp.26), (.L__pc.22193.LD)
	.p2align 4
	.L__pc.22193.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22194
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22194: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22195
	.L__pc.22195: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22196
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22196: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22197: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22198: Dma_PatchSrc (.L__pc.22198.LD), (.L__movme_tmp.1), (.L__pc.22198.LD)
	.p2align 4
	.L__pc.22198.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22199
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22199: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22200
	.L__pc.22200: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22201
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22201: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22202: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22203: Dma_PatchSrc (.L__pc.22203.LD), (.L__movme_tmp.1), (.L__pc.22203.LD)
	.p2align 4
	.L__pc.22203.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22204
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22204: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22205
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22205: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22206: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22207: Dma_PatchSrc (.L__pc.22207.LD), (.L__movme_tmp.1), (.L__pc.22207.LD)
	.p2align 4
	.L__pc.22207.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22208
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22208: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22209
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22209: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22210: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22211: Dma_PatchSrc (.L__pc.22211.LD), (.L__movme_tmp.1), (.L__pc.22211.LD)
	.p2align 4
	.L__pc.22211.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22212
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22212: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22213
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22213: Dma_PatchSrc (.L__pc.22213.LD), (.L__movme_cp.24), (.L__pc.22213.LD)
	.p2align 4
	.L__pc.22213.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22214
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22214: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22215
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22215: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22216: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22217: Dma_PatchSrc (.L__pc.22217.LD), (.L__movme_tmp.1), (.L__pc.22217.LD)
	.p2align 4
	.L__pc.22217.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22218
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22218: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22219
	
	.L__pc.22219: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22220
	
	.p2align 4
	.L__pc.22220: Dma_PatchDst (.L__pc.22220.ST), (.L__movme_cp.69), (.L__pc.22220.ST)
	.L__pc.22220.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22221
	
	.L__pc.22221: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22222
	
	.p2align 4
	.L__pc.22222: Dma_PatchDst (.L__pc.22222.ST), (.L__movme_cp.54), (.L__pc.22222.ST)
	.L__pc.22222.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22223
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.22223: Dma_PatchSrc (.L__pc.22223.LD), (.L__movme_cp.30), (.L__pc.22223.LD)
	.p2align 4
	.L__pc.22223.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22224
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22224: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22225
	.L__pc.22225: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22226
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.22226: Dma_PatchSrc (.L__pc.22226.LD), (.L__movme_cp.31), (.L__pc.22226.LD)
	.p2align 4
	.L__pc.22226.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22227
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22227: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22228
	.L__pc.22228: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22229
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22229: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22230: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22231: Dma_PatchSrc (.L__pc.22231.LD), (.L__movme_tmp.1), (.L__pc.22231.LD)
	.p2align 4
	.L__pc.22231.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22232
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22232: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22233
	.L__pc.22233: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22234
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22234: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22235: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22236: Dma_PatchSrc (.L__pc.22236.LD), (.L__movme_tmp.1), (.L__pc.22236.LD)
	.p2align 4
	.L__pc.22236.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22237
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22237: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22238
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22238: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22239: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22240: Dma_PatchSrc (.L__pc.22240.LD), (.L__movme_tmp.1), (.L__pc.22240.LD)
	.p2align 4
	.L__pc.22240.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22241
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22241: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22242
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22242: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22243: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22244: Dma_PatchSrc (.L__pc.22244.LD), (.L__movme_tmp.1), (.L__pc.22244.LD)
	.p2align 4
	.L__pc.22244.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22245
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22245: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22246
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22246: Dma_PatchSrc (.L__pc.22246.LD), (.L__movme_cp.24), (.L__pc.22246.LD)
	.p2align 4
	.L__pc.22246.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22247
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22247: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22248
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22248: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22249: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22250: Dma_PatchSrc (.L__pc.22250.LD), (.L__movme_tmp.1), (.L__pc.22250.LD)
	.p2align 4
	.L__pc.22250.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22251
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22251: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22252
	
	.L__pc.22252: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22253
	
	.p2align 4
	.L__pc.22253: Dma_PatchDst (.L__pc.22253.ST), (.L__movme_cp.70), (.L__pc.22253.ST)
	.L__pc.22253.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22254
	
	.L__pc.22254: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22255
	
	.p2align 4
	.L__pc.22255: Dma_PatchDst (.L__pc.22255.ST), (.L__movme_cp.54), (.L__pc.22255.ST)
	.L__pc.22255.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22256
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22256: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22257
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22257: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22258
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22258: Dma_PatchSrc (.L__pc.22258.LD), (.L__movme_cp.24), (.L__pc.22258.LD)
	.p2align 4
	.L__pc.22258.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22259
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22259: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22260
	.L__pc.22260: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22261
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.22261: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22262: Dma_PatchSrc (.L__pc.22262.LD), (.L__movme_tmp.1), (.L__pc.22262.LD)
	.p2align 4
	.L__pc.22262.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22263
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22263: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22264
	.L__pc.22264: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22265
	
	.L__pc.22265: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22266
	
	.p2align 4
	.L__pc.22266: Dma_PatchDst (.L__pc.22266.ST), (.L__movme_cp.72), (.L__pc.22266.ST)
	.L__pc.22266.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22267
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.22267: Dma_PatchSrc (.L__pc.22267.LD), (.L__movme_cp.72), (.L__pc.22267.LD)
	.p2align 4
	.L__pc.22267.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22268
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22268: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22269
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22269: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22270: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22271: Dma_PatchSrc (.L__pc.22271.LD), (.L__movme_tmp.1), (.L__pc.22271.LD)
	.p2align 4
	.L__pc.22271.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22272
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22272: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22273
	
	.L__pc.22273: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22274
	
	.p2align 4
	.L__pc.22274: Dma_PatchDst (.L__pc.22274.ST), (.L__movme_cp.74), (.L__pc.22274.ST)
	.L__pc.22274.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22275
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22275: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22276: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22277: Dma_PatchSrc (.L__pc.22277.LD), (.L__movme_tmp.1), (.L__pc.22277.LD)
	.p2align 4
	.L__pc.22277.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22278
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22278: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22279
	
	.L__pc.22279: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22280
	
	.p2align 4
	.L__pc.22280: Dma_PatchDst (.L__pc.22280.ST), (.L__movme_cp.76), (.L__pc.22280.ST)
	.L__pc.22280.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22281
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.22281: Dma_PatchSrc (.L__pc.22281.LD), (.L__movme_cp.74), (.L__pc.22281.LD)
	.p2align 4
	.L__pc.22281.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22282
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22282: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22283
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.22283: Dma_PatchSrc (.L__pc.22283.LD), ((.L__movme.reg.eax+0)), (.L__pc.22283.LD)
	.p2align 4
	.L__pc.22283.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22284
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22284: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22285
	
	.L__pc.22285: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22286
	
	.p2align 4
	.L__pc.22286: Dma_PatchDst (.L__pc.22286.ST), (.L__movme_cp.77), (.L__pc.22286.ST)
	.L__pc.22286.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22287
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.22287: Dma_PatchSrc (.L__pc.22287.LD), (.L__movme_cp.77), (.L__pc.22287.LD)
	.p2align 4
	.L__pc.22287.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22288
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22288: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22289
	
	.L__pc.22289: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22290
	
	.p2align 4
	.L__pc.22290: Dma_PatchDst (.L__pc.22290.ST), (.L__movme_cp.21), (.L__pc.22290.ST)
	.L__pc.22290.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22291
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.22291: Dma_PatchSrc (.L__pc.22291.LD), (.L__movme_cp.58), (.L__pc.22291.LD)
	.p2align 4
	.L__pc.22291.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22292
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22292: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22293
	
	.L__pc.22293: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22294
	
	.p2align 4
	.L__pc.22294: Dma_PatchDst (.L__pc.22294.ST), (.L__movme_cp.22), (.L__pc.22294.ST)
	.L__pc.22294.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22295
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22295: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22296
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22296: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22297
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22297: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22298
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22298: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22299
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.22299: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.22300
	
	.p2align 4
	.L__pc.22300: Dma_PatchDst (.L__pc.22300.ST), (.L__movme_cp.24), (.L__pc.22300.ST)
	.L__pc.22300.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22301
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.22301: Dma_PatchSrc (.L__pc.22301.LD), (.L__movme_cp.25), (.L__pc.22301.LD)
	.p2align 4
	.L__pc.22301.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22302
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22302: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22303
	.L__pc.22303: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22304
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.22304: Dma_PatchSrc (.L__pc.22304.LD), (.L__movme_cp.26), (.L__pc.22304.LD)
	.p2align 4
	.L__pc.22304.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22305
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22305: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22306
	.L__pc.22306: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22307
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22307: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22308: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22309: Dma_PatchSrc (.L__pc.22309.LD), (.L__movme_tmp.1), (.L__pc.22309.LD)
	.p2align 4
	.L__pc.22309.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22310
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22310: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22311
	.L__pc.22311: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22312
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22312: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22313: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22314: Dma_PatchSrc (.L__pc.22314.LD), (.L__movme_tmp.1), (.L__pc.22314.LD)
	.p2align 4
	.L__pc.22314.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22315
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22315: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22316
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22316: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22317: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22318: Dma_PatchSrc (.L__pc.22318.LD), (.L__movme_tmp.1), (.L__pc.22318.LD)
	.p2align 4
	.L__pc.22318.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22319
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22319: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22320
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22320: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22321: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22322: Dma_PatchSrc (.L__pc.22322.LD), (.L__movme_tmp.1), (.L__pc.22322.LD)
	.p2align 4
	.L__pc.22322.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22323
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22323: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22324
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22324: Dma_PatchSrc (.L__pc.22324.LD), (.L__movme_cp.24), (.L__pc.22324.LD)
	.p2align 4
	.L__pc.22324.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22325
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22325: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22326
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22326: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22327: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22328: Dma_PatchSrc (.L__pc.22328.LD), (.L__movme_tmp.1), (.L__pc.22328.LD)
	.p2align 4
	.L__pc.22328.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22329
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22329: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22330
	
	.L__pc.22330: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22331
	
	.p2align 4
	.L__pc.22331: Dma_PatchDst (.L__pc.22331.ST), (.L__movme_cp.78), (.L__pc.22331.ST)
	.L__pc.22331.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22332
	
	.L__pc.22332: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22333
	
	.p2align 4
	.L__pc.22333: Dma_PatchDst (.L__pc.22333.ST), (.L__movme_cp.54), (.L__pc.22333.ST)
	.L__pc.22333.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22334
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.22334: Dma_PatchSrc (.L__pc.22334.LD), (.L__movme_cp.30), (.L__pc.22334.LD)
	.p2align 4
	.L__pc.22334.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22335
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22335: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22336
	.L__pc.22336: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22337
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.22337: Dma_PatchSrc (.L__pc.22337.LD), (.L__movme_cp.31), (.L__pc.22337.LD)
	.p2align 4
	.L__pc.22337.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22338
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22338: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22339
	.L__pc.22339: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22340
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22340: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22341: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22342: Dma_PatchSrc (.L__pc.22342.LD), (.L__movme_tmp.1), (.L__pc.22342.LD)
	.p2align 4
	.L__pc.22342.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22343
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22343: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22344
	.L__pc.22344: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22345
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22345: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22346: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22347: Dma_PatchSrc (.L__pc.22347.LD), (.L__movme_tmp.1), (.L__pc.22347.LD)
	.p2align 4
	.L__pc.22347.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22348
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22348: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22349
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22349: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22350: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22351: Dma_PatchSrc (.L__pc.22351.LD), (.L__movme_tmp.1), (.L__pc.22351.LD)
	.p2align 4
	.L__pc.22351.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22352
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22352: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22353
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22353: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22354: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22355: Dma_PatchSrc (.L__pc.22355.LD), (.L__movme_tmp.1), (.L__pc.22355.LD)
	.p2align 4
	.L__pc.22355.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22356
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22356: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22357
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22357: Dma_PatchSrc (.L__pc.22357.LD), (.L__movme_cp.24), (.L__pc.22357.LD)
	.p2align 4
	.L__pc.22357.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22358
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22358: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22359
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22359: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22360: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22361: Dma_PatchSrc (.L__pc.22361.LD), (.L__movme_tmp.1), (.L__pc.22361.LD)
	.p2align 4
	.L__pc.22361.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22362
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22362: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22363
	
	.L__pc.22363: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22364
	
	.p2align 4
	.L__pc.22364: Dma_PatchDst (.L__pc.22364.ST), (.L__movme_cp.79), (.L__pc.22364.ST)
	.L__pc.22364.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22365
	
	.L__pc.22365: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22366
	
	.p2align 4
	.L__pc.22366: Dma_PatchDst (.L__pc.22366.ST), (.L__movme_cp.54), (.L__pc.22366.ST)
	.L__pc.22366.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22367
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.22367: Dma_PatchSrc (.L__pc.22367.LD), (.L__movme_cp.74), (.L__pc.22367.LD)
	.p2align 4
	.L__pc.22367.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22368
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22368: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22369
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.22369: Dma_PatchSrc (.L__pc.22369.LD), (.L__movme_cp.77), (.L__pc.22369.LD)
	.p2align 4
	.L__pc.22369.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22370
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22370: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22371
	
	.L__pc.22371: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22372
	
	.p2align 4
	.L__pc.22372: Dma_PatchDst (.L__pc.22372.ST), ((.L__movme.reg.eax+0)), (.L__pc.22372.ST)
	.L__pc.22372.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22373
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.22373: Dma_PatchSrc (.L__pc.22373.LD), (.L__movme_cp.76), (.L__pc.22373.LD)
	.p2align 4
	.L__pc.22373.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22374
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22374: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22375
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.22375: Dma_PatchSrc (.L__pc.22375.LD), ((.L__movme.reg.eax+0)), (.L__pc.22375.LD)
	.p2align 4
	.L__pc.22375.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22376
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22376: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22377
	
	.L__pc.22377: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22378
	
	.p2align 4
	.L__pc.22378: Dma_PatchDst (.L__pc.22378.ST), (.L__movme_cp.80), (.L__pc.22378.ST)
	.L__pc.22378.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22379
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22379: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22380
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22380: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22381
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.22381: Dma_PatchSrc (.L__pc.22381.LD), (.L__movme_cp.102), (.L__pc.22381.LD)
	.p2align 4
	.L__pc.22381.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22382
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22382: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22383
	.L__pc.22383: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22384
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.92 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.22384: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22385: Dma_PatchSrc (.L__pc.22385.LD), (.L__movme_tmp.1), (.L__pc.22385.LD)
	.p2align 4
	.L__pc.22385.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22386
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22386: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22387
	.L__pc.22387: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22388
	
	.L__pc.22388: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22389
	
	.p2align 4
	.L__pc.22389: Dma_PatchDst (.L__pc.22389.ST), (.L__movme_cp.102), (.L__pc.22389.ST)
	.L__pc.22389.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22390
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.22390: Dma_PatchSrc (.L__pc.22390.LD), (.L__movme_cp.76), (.L__pc.22390.LD)
	.p2align 4
	.L__pc.22390.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22391
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22391: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22392
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.22392: Dma_PatchSrc (.L__pc.22392.LD), (.L__movme_cp.80), (.L__pc.22392.LD)
	.p2align 4
	.L__pc.22392.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22393
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22393: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22394
	
	.L__pc.22394: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22395
	
	.p2align 4
	.L__pc.22395: Dma_PatchDst (.L__pc.22395.ST), ((.L__movme.reg.eax+0)), (.L__pc.22395.ST)
	.L__pc.22395.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22396
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22396: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22397
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22397: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22398
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.22398: Dma_PatchSrc (.L__pc.22398.LD), (.L__movme_cp.101), (.L__pc.22398.LD)
	.p2align 4
	.L__pc.22398.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22399
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22399: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22400
	.L__pc.22400: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22401
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22401: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.93 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22402: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22403: Dma_PatchSrc (.L__pc.22403.LD), (.L__movme_tmp.1), (.L__pc.22403.LD)
	.p2align 4
	.L__pc.22403.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22404
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22404: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22405
	
	.L__pc.22405: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22406
	
	.p2align 4
	.L__pc.22406: Dma_PatchDst (.L__pc.22406.ST), (.L__movme_cp.24), (.L__pc.22406.ST)
	.L__pc.22406.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22407
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22407: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22408
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22408: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22409
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22409: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22410
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22410: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22411
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.22411: Dma_PatchSrc (.L__pc.22411.LD), (.L__movme_cp.63), (.L__pc.22411.LD)
	.p2align 4
	.L__pc.22411.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22412
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22412: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22413
	.L__pc.22413: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22414
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22414: Dma_PatchSrc (.L__pc.22414.LD), (.L__movme_cp.24), (.L__pc.22414.LD)
	.p2align 4
	.L__pc.22414.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22415
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22415: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22416
	.L__pc.22416: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22417
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22417: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22418: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22419: Dma_PatchSrc (.L__pc.22419.LD), (.L__movme_tmp.1), (.L__pc.22419.LD)
	.p2align 4
	.L__pc.22419.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22420
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22420: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22421
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22421: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22422: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22423: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22424: Dma_PatchSrc (.L__pc.22424.LD), (.L__movme_tmp.1), (.L__pc.22424.LD)
	.p2align 4
	.L__pc.22424.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22425
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22425: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22426
	
	.L__pc.22426: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22427
	
	.p2align 4
	.L__pc.22427: Dma_PatchDst (.L__pc.22427.ST), (.L__movme_cp.63), (.L__pc.22427.ST)
	.L__pc.22427.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22428
	
	.L__pc.22428: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22429
	
	.p2align 4
	.L__pc.22429: Dma_PatchDst (.L__pc.22429.ST), (.L__movme_cp.24), (.L__pc.22429.ST)
	.L__pc.22429.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22430
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22430: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22431
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22431: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22432
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22432: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22433
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22433: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22434
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.22434: Dma_PatchSrc (.L__pc.22434.LD), (.L__movme_cp.66), (.L__pc.22434.LD)
	.p2align 4
	.L__pc.22434.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22435
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22435: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22436
	.L__pc.22436: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22437
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22437: Dma_PatchSrc (.L__pc.22437.LD), (.L__movme_cp.24), (.L__pc.22437.LD)
	.p2align 4
	.L__pc.22437.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22438
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22438: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22439
	.L__pc.22439: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22440
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22440: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22441: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22442: Dma_PatchSrc (.L__pc.22442.LD), (.L__movme_tmp.1), (.L__pc.22442.LD)
	.p2align 4
	.L__pc.22442.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22443
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22443: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22444
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22444: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22445: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22446: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22447: Dma_PatchSrc (.L__pc.22447.LD), (.L__movme_tmp.1), (.L__pc.22447.LD)
	.p2align 4
	.L__pc.22447.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22448
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22448: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22449
	
	.L__pc.22449: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22450
	
	.p2align 4
	.L__pc.22450: Dma_PatchDst (.L__pc.22450.ST), (.L__movme_cp.66), (.L__pc.22450.ST)
	.L__pc.22450.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22451
	
	.L__pc.22451: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22452
	
	.p2align 4
	.L__pc.22452: Dma_PatchDst (.L__pc.22452.ST), (.L__movme_cp.24), (.L__pc.22452.ST)
	.L__pc.22452.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22453
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22453: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22454
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22454: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22455
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22455: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22456
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22456: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22457
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.22457: Dma_PatchSrc (.L__pc.22457.LD), (.L__movme_cp.67), (.L__pc.22457.LD)
	.p2align 4
	.L__pc.22457.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22458
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22458: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22459
	.L__pc.22459: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22460
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22460: Dma_PatchSrc (.L__pc.22460.LD), (.L__movme_cp.24), (.L__pc.22460.LD)
	.p2align 4
	.L__pc.22460.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22461
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22461: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22462
	.L__pc.22462: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22463
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22463: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22464: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22465: Dma_PatchSrc (.L__pc.22465.LD), (.L__movme_tmp.1), (.L__pc.22465.LD)
	.p2align 4
	.L__pc.22465.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22466
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22466: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22467
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22467: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22468: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22469: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22470: Dma_PatchSrc (.L__pc.22470.LD), (.L__movme_tmp.1), (.L__pc.22470.LD)
	.p2align 4
	.L__pc.22470.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22471
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22471: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22472
	
	.L__pc.22472: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22473
	
	.p2align 4
	.L__pc.22473: Dma_PatchDst (.L__pc.22473.ST), (.L__movme_cp.67), (.L__pc.22473.ST)
	.L__pc.22473.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22474
	
	.L__pc.22474: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22475
	
	.p2align 4
	.L__pc.22475: Dma_PatchDst (.L__pc.22475.ST), (.L__movme_cp.24), (.L__pc.22475.ST)
	.L__pc.22475.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22476
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22476: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22477
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22477: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22478
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22478: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22479
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22479: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22480
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.22480: Dma_PatchSrc (.L__pc.22480.LD), (.L__movme_cp.68), (.L__pc.22480.LD)
	.p2align 4
	.L__pc.22480.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22481
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22481: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22482
	.L__pc.22482: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22483
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22483: Dma_PatchSrc (.L__pc.22483.LD), (.L__movme_cp.24), (.L__pc.22483.LD)
	.p2align 4
	.L__pc.22483.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22484
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22484: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22485
	.L__pc.22485: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22486
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22486: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22487: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22488: Dma_PatchSrc (.L__pc.22488.LD), (.L__movme_tmp.1), (.L__pc.22488.LD)
	.p2align 4
	.L__pc.22488.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22489
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22489: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22490
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22490: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22491: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22492: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22493: Dma_PatchSrc (.L__pc.22493.LD), (.L__movme_tmp.1), (.L__pc.22493.LD)
	.p2align 4
	.L__pc.22493.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22494
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22494: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22495
	
	.L__pc.22495: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22496
	
	.p2align 4
	.L__pc.22496: Dma_PatchDst (.L__pc.22496.ST), (.L__movme_cp.68), (.L__pc.22496.ST)
	.L__pc.22496.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22497
	
	.L__pc.22497: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22498
	
	.p2align 4
	.L__pc.22498: Dma_PatchDst (.L__pc.22498.ST), (.L__movme_cp.24), (.L__pc.22498.ST)
	.L__pc.22498.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22499
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22499: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22500
	
	.p2align 4
	.L__pc.22500: Dma_PatchDst (.L__pc.22500.ST), (.L__movme_cp.24), (.L__pc.22500.ST)
	.L__pc.22500.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22501
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.22501: Dma_PatchSrc (.L__pc.22501.LD), (.L__movme_cp.60), (.L__pc.22501.LD)
	.p2align 4
	.L__pc.22501.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22502
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22502: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22503
	
	.L__pc.22503: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22504
	
	.p2align 4
	.L__pc.22504: Dma_PatchDst (.L__pc.22504.ST), (.L__movme_cp.21), (.L__pc.22504.ST)
	.L__pc.22504.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22505
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.22505: Dma_PatchSrc (.L__pc.22505.LD), (.L__movme_cp.58), (.L__pc.22505.LD)
	.p2align 4
	.L__pc.22505.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22506
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22506: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22507
	
	.L__pc.22507: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22508
	
	.p2align 4
	.L__pc.22508: Dma_PatchDst (.L__pc.22508.ST), (.L__movme_cp.22), (.L__pc.22508.ST)
	.L__pc.22508.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22509
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22509: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22510
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22510: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22511
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22511: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22512
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22512: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22513
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.22513: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.22514
	
	.p2align 4
	.L__pc.22514: Dma_PatchDst (.L__pc.22514.ST), (.L__movme_cp.24), (.L__pc.22514.ST)
	.L__pc.22514.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22515
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.22515: Dma_PatchSrc (.L__pc.22515.LD), (.L__movme_cp.25), (.L__pc.22515.LD)
	.p2align 4
	.L__pc.22515.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22516
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22516: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22517
	.L__pc.22517: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22518
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.22518: Dma_PatchSrc (.L__pc.22518.LD), (.L__movme_cp.26), (.L__pc.22518.LD)
	.p2align 4
	.L__pc.22518.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22519
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22519: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22520
	.L__pc.22520: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22521
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22521: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22522: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22523: Dma_PatchSrc (.L__pc.22523.LD), (.L__movme_tmp.1), (.L__pc.22523.LD)
	.p2align 4
	.L__pc.22523.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22524
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22524: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22525
	.L__pc.22525: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22526
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22526: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22527: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22528: Dma_PatchSrc (.L__pc.22528.LD), (.L__movme_tmp.1), (.L__pc.22528.LD)
	.p2align 4
	.L__pc.22528.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22529
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22529: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22530
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22530: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22531: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22532: Dma_PatchSrc (.L__pc.22532.LD), (.L__movme_tmp.1), (.L__pc.22532.LD)
	.p2align 4
	.L__pc.22532.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22533
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22533: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22534
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22534: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22535: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22536: Dma_PatchSrc (.L__pc.22536.LD), (.L__movme_tmp.1), (.L__pc.22536.LD)
	.p2align 4
	.L__pc.22536.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22537
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22537: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22538
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22538: Dma_PatchSrc (.L__pc.22538.LD), (.L__movme_cp.24), (.L__pc.22538.LD)
	.p2align 4
	.L__pc.22538.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22539
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22539: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22540
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22540: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22541: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22542: Dma_PatchSrc (.L__pc.22542.LD), (.L__movme_tmp.1), (.L__pc.22542.LD)
	.p2align 4
	.L__pc.22542.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22543
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22543: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22544
	
	.L__pc.22544: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22545
	
	.p2align 4
	.L__pc.22545: Dma_PatchDst (.L__pc.22545.ST), (.L__movme_cp.69), (.L__pc.22545.ST)
	.L__pc.22545.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22546
	
	.L__pc.22546: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22547
	
	.p2align 4
	.L__pc.22547: Dma_PatchDst (.L__pc.22547.ST), (.L__movme_cp.54), (.L__pc.22547.ST)
	.L__pc.22547.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22548
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.22548: Dma_PatchSrc (.L__pc.22548.LD), (.L__movme_cp.30), (.L__pc.22548.LD)
	.p2align 4
	.L__pc.22548.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22549
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22549: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22550
	.L__pc.22550: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22551
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.22551: Dma_PatchSrc (.L__pc.22551.LD), (.L__movme_cp.31), (.L__pc.22551.LD)
	.p2align 4
	.L__pc.22551.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22552
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22552: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22553
	.L__pc.22553: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22554
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22554: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22555: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22556: Dma_PatchSrc (.L__pc.22556.LD), (.L__movme_tmp.1), (.L__pc.22556.LD)
	.p2align 4
	.L__pc.22556.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22557
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22557: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22558
	.L__pc.22558: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22559
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22559: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22560: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22561: Dma_PatchSrc (.L__pc.22561.LD), (.L__movme_tmp.1), (.L__pc.22561.LD)
	.p2align 4
	.L__pc.22561.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22562
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22562: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22563
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22563: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22564: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22565: Dma_PatchSrc (.L__pc.22565.LD), (.L__movme_tmp.1), (.L__pc.22565.LD)
	.p2align 4
	.L__pc.22565.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22566
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22566: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22567
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22567: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22568: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22569: Dma_PatchSrc (.L__pc.22569.LD), (.L__movme_tmp.1), (.L__pc.22569.LD)
	.p2align 4
	.L__pc.22569.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22570
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22570: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22571
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22571: Dma_PatchSrc (.L__pc.22571.LD), (.L__movme_cp.24), (.L__pc.22571.LD)
	.p2align 4
	.L__pc.22571.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22572
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22572: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22573
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22573: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22574: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22575: Dma_PatchSrc (.L__pc.22575.LD), (.L__movme_tmp.1), (.L__pc.22575.LD)
	.p2align 4
	.L__pc.22575.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22576
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22576: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22577
	
	.L__pc.22577: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22578
	
	.p2align 4
	.L__pc.22578: Dma_PatchDst (.L__pc.22578.ST), (.L__movme_cp.70), (.L__pc.22578.ST)
	.L__pc.22578.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22579
	
	.L__pc.22579: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22580
	
	.p2align 4
	.L__pc.22580: Dma_PatchDst (.L__pc.22580.ST), (.L__movme_cp.54), (.L__pc.22580.ST)
	.L__pc.22580.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22581
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22581: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22582
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22582: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22583
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22583: Dma_PatchSrc (.L__pc.22583.LD), (.L__movme_cp.24), (.L__pc.22583.LD)
	.p2align 4
	.L__pc.22583.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22584
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22584: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22585
	.L__pc.22585: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22586
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.22586: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22587: Dma_PatchSrc (.L__pc.22587.LD), (.L__movme_tmp.1), (.L__pc.22587.LD)
	.p2align 4
	.L__pc.22587.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22588
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22588: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22589
	.L__pc.22589: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22590
	
	.L__pc.22590: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22591
	
	.p2align 4
	.L__pc.22591: Dma_PatchDst (.L__pc.22591.ST), (.L__movme_cp.72), (.L__pc.22591.ST)
	.L__pc.22591.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22592
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.22592: Dma_PatchSrc (.L__pc.22592.LD), (.L__movme_cp.72), (.L__pc.22592.LD)
	.p2align 4
	.L__pc.22592.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22593
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22593: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22594
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22594: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22595: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22596: Dma_PatchSrc (.L__pc.22596.LD), (.L__movme_tmp.1), (.L__pc.22596.LD)
	.p2align 4
	.L__pc.22596.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22597
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22597: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22598
	
	.L__pc.22598: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22599
	
	.p2align 4
	.L__pc.22599: Dma_PatchDst (.L__pc.22599.ST), (.L__movme_cp.74), (.L__pc.22599.ST)
	.L__pc.22599.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22600
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22600: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22601: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22602: Dma_PatchSrc (.L__pc.22602.LD), (.L__movme_tmp.1), (.L__pc.22602.LD)
	.p2align 4
	.L__pc.22602.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22603
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22603: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22604
	
	.L__pc.22604: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22605
	
	.p2align 4
	.L__pc.22605: Dma_PatchDst (.L__pc.22605.ST), (.L__movme_cp.76), (.L__pc.22605.ST)
	.L__pc.22605.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22606
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.22606: Dma_PatchSrc (.L__pc.22606.LD), (.L__movme_cp.74), (.L__pc.22606.LD)
	.p2align 4
	.L__pc.22606.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22607
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22607: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22608
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.22608: Dma_PatchSrc (.L__pc.22608.LD), ((.L__movme.reg.eax+0)), (.L__pc.22608.LD)
	.p2align 4
	.L__pc.22608.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22609
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22609: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22610
	
	.L__pc.22610: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22611
	
	.p2align 4
	.L__pc.22611: Dma_PatchDst (.L__pc.22611.ST), (.L__movme_cp.77), (.L__pc.22611.ST)
	.L__pc.22611.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22612
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.22612: Dma_PatchSrc (.L__pc.22612.LD), (.L__movme_cp.77), (.L__pc.22612.LD)
	.p2align 4
	.L__pc.22612.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22613
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22613: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22614
	
	.L__pc.22614: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22615
	
	.p2align 4
	.L__pc.22615: Dma_PatchDst (.L__pc.22615.ST), (.L__movme_cp.21), (.L__pc.22615.ST)
	.L__pc.22615.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22616
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.22616: Dma_PatchSrc (.L__pc.22616.LD), (.L__movme_cp.58), (.L__pc.22616.LD)
	.p2align 4
	.L__pc.22616.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22617
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22617: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22618
	
	.L__pc.22618: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22619
	
	.p2align 4
	.L__pc.22619: Dma_PatchDst (.L__pc.22619.ST), (.L__movme_cp.22), (.L__pc.22619.ST)
	.L__pc.22619.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22620
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22620: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22621
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22621: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22622
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22622: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22623
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22623: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22624
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.22624: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.22625
	
	.p2align 4
	.L__pc.22625: Dma_PatchDst (.L__pc.22625.ST), (.L__movme_cp.24), (.L__pc.22625.ST)
	.L__pc.22625.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22626
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.22626: Dma_PatchSrc (.L__pc.22626.LD), (.L__movme_cp.25), (.L__pc.22626.LD)
	.p2align 4
	.L__pc.22626.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22627
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22627: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22628
	.L__pc.22628: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22629
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.22629: Dma_PatchSrc (.L__pc.22629.LD), (.L__movme_cp.26), (.L__pc.22629.LD)
	.p2align 4
	.L__pc.22629.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22630
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22630: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22631
	.L__pc.22631: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22632
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22632: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22633: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22634: Dma_PatchSrc (.L__pc.22634.LD), (.L__movme_tmp.1), (.L__pc.22634.LD)
	.p2align 4
	.L__pc.22634.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22635
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22635: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22636
	.L__pc.22636: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22637
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22637: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22638: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22639: Dma_PatchSrc (.L__pc.22639.LD), (.L__movme_tmp.1), (.L__pc.22639.LD)
	.p2align 4
	.L__pc.22639.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22640
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22640: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22641
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22641: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22642: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22643: Dma_PatchSrc (.L__pc.22643.LD), (.L__movme_tmp.1), (.L__pc.22643.LD)
	.p2align 4
	.L__pc.22643.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22644
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22644: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22645
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22645: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22646: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22647: Dma_PatchSrc (.L__pc.22647.LD), (.L__movme_tmp.1), (.L__pc.22647.LD)
	.p2align 4
	.L__pc.22647.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22648
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22648: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22649
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22649: Dma_PatchSrc (.L__pc.22649.LD), (.L__movme_cp.24), (.L__pc.22649.LD)
	.p2align 4
	.L__pc.22649.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22650
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22650: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22651
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22651: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22652: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22653: Dma_PatchSrc (.L__pc.22653.LD), (.L__movme_tmp.1), (.L__pc.22653.LD)
	.p2align 4
	.L__pc.22653.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22654
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22654: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22655
	
	.L__pc.22655: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22656
	
	.p2align 4
	.L__pc.22656: Dma_PatchDst (.L__pc.22656.ST), (.L__movme_cp.78), (.L__pc.22656.ST)
	.L__pc.22656.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22657
	
	.L__pc.22657: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22658
	
	.p2align 4
	.L__pc.22658: Dma_PatchDst (.L__pc.22658.ST), (.L__movme_cp.54), (.L__pc.22658.ST)
	.L__pc.22658.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22659
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.22659: Dma_PatchSrc (.L__pc.22659.LD), (.L__movme_cp.30), (.L__pc.22659.LD)
	.p2align 4
	.L__pc.22659.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22660
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22660: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22661
	.L__pc.22661: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22662
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.22662: Dma_PatchSrc (.L__pc.22662.LD), (.L__movme_cp.31), (.L__pc.22662.LD)
	.p2align 4
	.L__pc.22662.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22663
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22663: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22664
	.L__pc.22664: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22665
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22665: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22666: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22667: Dma_PatchSrc (.L__pc.22667.LD), (.L__movme_tmp.1), (.L__pc.22667.LD)
	.p2align 4
	.L__pc.22667.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22668
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22668: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22669
	.L__pc.22669: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22670
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22670: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22671: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22672: Dma_PatchSrc (.L__pc.22672.LD), (.L__movme_tmp.1), (.L__pc.22672.LD)
	.p2align 4
	.L__pc.22672.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22673
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22673: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22674
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22674: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22675: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22676: Dma_PatchSrc (.L__pc.22676.LD), (.L__movme_tmp.1), (.L__pc.22676.LD)
	.p2align 4
	.L__pc.22676.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22677
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22677: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22678
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22678: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22679: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22680: Dma_PatchSrc (.L__pc.22680.LD), (.L__movme_tmp.1), (.L__pc.22680.LD)
	.p2align 4
	.L__pc.22680.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22681
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22681: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22682
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22682: Dma_PatchSrc (.L__pc.22682.LD), (.L__movme_cp.24), (.L__pc.22682.LD)
	.p2align 4
	.L__pc.22682.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22683
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22683: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22684
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22684: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22685: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22686: Dma_PatchSrc (.L__pc.22686.LD), (.L__movme_tmp.1), (.L__pc.22686.LD)
	.p2align 4
	.L__pc.22686.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22687
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22687: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22688
	
	.L__pc.22688: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22689
	
	.p2align 4
	.L__pc.22689: Dma_PatchDst (.L__pc.22689.ST), (.L__movme_cp.79), (.L__pc.22689.ST)
	.L__pc.22689.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22690
	
	.L__pc.22690: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22691
	
	.p2align 4
	.L__pc.22691: Dma_PatchDst (.L__pc.22691.ST), (.L__movme_cp.54), (.L__pc.22691.ST)
	.L__pc.22691.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22692
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.22692: Dma_PatchSrc (.L__pc.22692.LD), (.L__movme_cp.74), (.L__pc.22692.LD)
	.p2align 4
	.L__pc.22692.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22693
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22693: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22694
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.22694: Dma_PatchSrc (.L__pc.22694.LD), (.L__movme_cp.77), (.L__pc.22694.LD)
	.p2align 4
	.L__pc.22694.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22695
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22695: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22696
	
	.L__pc.22696: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22697
	
	.p2align 4
	.L__pc.22697: Dma_PatchDst (.L__pc.22697.ST), ((.L__movme.reg.eax+0)), (.L__pc.22697.ST)
	.L__pc.22697.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22698
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.22698: Dma_PatchSrc (.L__pc.22698.LD), (.L__movme_cp.76), (.L__pc.22698.LD)
	.p2align 4
	.L__pc.22698.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22699
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22699: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22700
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.22700: Dma_PatchSrc (.L__pc.22700.LD), ((.L__movme.reg.eax+0)), (.L__pc.22700.LD)
	.p2align 4
	.L__pc.22700.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22701
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22701: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22702
	
	.L__pc.22702: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22703
	
	.p2align 4
	.L__pc.22703: Dma_PatchDst (.L__pc.22703.ST), (.L__movme_cp.80), (.L__pc.22703.ST)
	.L__pc.22703.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22704
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22704: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22705
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22705: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22706
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.22706: Dma_PatchSrc (.L__pc.22706.LD), (.L__movme_cp.102), (.L__pc.22706.LD)
	.p2align 4
	.L__pc.22706.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22707
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22707: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22708
	.L__pc.22708: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22709
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.94 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.22709: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22710: Dma_PatchSrc (.L__pc.22710.LD), (.L__movme_tmp.1), (.L__pc.22710.LD)
	.p2align 4
	.L__pc.22710.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22711
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22711: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22712
	.L__pc.22712: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22713
	
	.L__pc.22713: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22714
	
	.p2align 4
	.L__pc.22714: Dma_PatchDst (.L__pc.22714.ST), (.L__movme_cp.102), (.L__pc.22714.ST)
	.L__pc.22714.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22715
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.22715: Dma_PatchSrc (.L__pc.22715.LD), (.L__movme_cp.76), (.L__pc.22715.LD)
	.p2align 4
	.L__pc.22715.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22716
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22716: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22717
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.22717: Dma_PatchSrc (.L__pc.22717.LD), (.L__movme_cp.80), (.L__pc.22717.LD)
	.p2align 4
	.L__pc.22717.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22718
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22718: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22719
	
	.L__pc.22719: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22720
	
	.p2align 4
	.L__pc.22720: Dma_PatchDst (.L__pc.22720.ST), ((.L__movme.reg.eax+0)), (.L__pc.22720.ST)
	.L__pc.22720.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22721
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22721: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22722
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22722: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22723
	
	// CG.LOAD4 [.L__movme_cp.101} => .L__movme_tmp.0
	.L__pc.22723: Dma_PatchSrc (.L__pc.22723.LD), (.L__movme_cp.101), (.L__pc.22723.LD)
	.p2align 4
	.L__pc.22723.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22724
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22724: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22725
	.L__pc.22725: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22726
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22726: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.95 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22727: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22728: Dma_PatchSrc (.L__pc.22728.LD), (.L__movme_tmp.1), (.L__pc.22728.LD)
	.p2align 4
	.L__pc.22728.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22729
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22729: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22730
	
	.L__pc.22730: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22731
	
	.p2align 4
	.L__pc.22731: Dma_PatchDst (.L__pc.22731.ST), (.L__movme_cp.24), (.L__pc.22731.ST)
	.L__pc.22731.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22732
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22732: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22733
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22733: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22734
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22734: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22735
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22735: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22736
	
	// CG.LOAD4 [.L__movme_cp.63} => .L__movme_tmp.0
	.L__pc.22736: Dma_PatchSrc (.L__pc.22736.LD), (.L__movme_cp.63), (.L__pc.22736.LD)
	.p2align 4
	.L__pc.22736.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22737
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22737: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22738
	.L__pc.22738: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22739
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22739: Dma_PatchSrc (.L__pc.22739.LD), (.L__movme_cp.24), (.L__pc.22739.LD)
	.p2align 4
	.L__pc.22739.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22740
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22740: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22741
	.L__pc.22741: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22742
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22742: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22743: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22744: Dma_PatchSrc (.L__pc.22744.LD), (.L__movme_tmp.1), (.L__pc.22744.LD)
	.p2align 4
	.L__pc.22744.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22745
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22745: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22746
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22746: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22747: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22748: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22749: Dma_PatchSrc (.L__pc.22749.LD), (.L__movme_tmp.1), (.L__pc.22749.LD)
	.p2align 4
	.L__pc.22749.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22750
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22750: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22751
	
	.L__pc.22751: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22752
	
	.p2align 4
	.L__pc.22752: Dma_PatchDst (.L__pc.22752.ST), (.L__movme_cp.63), (.L__pc.22752.ST)
	.L__pc.22752.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22753
	
	.L__pc.22753: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22754
	
	.p2align 4
	.L__pc.22754: Dma_PatchDst (.L__pc.22754.ST), (.L__movme_cp.24), (.L__pc.22754.ST)
	.L__pc.22754.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22755
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22755: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22756
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22756: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22757
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22757: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22758
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22758: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22759
	
	// CG.LOAD4 [.L__movme_cp.66} => .L__movme_tmp.0
	.L__pc.22759: Dma_PatchSrc (.L__pc.22759.LD), (.L__movme_cp.66), (.L__pc.22759.LD)
	.p2align 4
	.L__pc.22759.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22760
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22760: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22761
	.L__pc.22761: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22762
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22762: Dma_PatchSrc (.L__pc.22762.LD), (.L__movme_cp.24), (.L__pc.22762.LD)
	.p2align 4
	.L__pc.22762.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22763
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22763: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22764
	.L__pc.22764: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22765
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22765: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22766: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22767: Dma_PatchSrc (.L__pc.22767.LD), (.L__movme_tmp.1), (.L__pc.22767.LD)
	.p2align 4
	.L__pc.22767.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22768
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22768: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22769
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22769: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22770: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22771: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22772: Dma_PatchSrc (.L__pc.22772.LD), (.L__movme_tmp.1), (.L__pc.22772.LD)
	.p2align 4
	.L__pc.22772.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22773
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22773: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22774
	
	.L__pc.22774: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22775
	
	.p2align 4
	.L__pc.22775: Dma_PatchDst (.L__pc.22775.ST), (.L__movme_cp.66), (.L__pc.22775.ST)
	.L__pc.22775.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22776
	
	.L__pc.22776: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22777
	
	.p2align 4
	.L__pc.22777: Dma_PatchDst (.L__pc.22777.ST), (.L__movme_cp.24), (.L__pc.22777.ST)
	.L__pc.22777.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22778
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22778: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22779
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22779: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22780
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22780: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22781
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22781: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22782
	
	// CG.LOAD4 [.L__movme_cp.67} => .L__movme_tmp.0
	.L__pc.22782: Dma_PatchSrc (.L__pc.22782.LD), (.L__movme_cp.67), (.L__pc.22782.LD)
	.p2align 4
	.L__pc.22782.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22783
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22783: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22784
	.L__pc.22784: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22785
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22785: Dma_PatchSrc (.L__pc.22785.LD), (.L__movme_cp.24), (.L__pc.22785.LD)
	.p2align 4
	.L__pc.22785.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22786
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22786: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22787
	.L__pc.22787: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22788
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22788: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22789: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22790: Dma_PatchSrc (.L__pc.22790.LD), (.L__movme_tmp.1), (.L__pc.22790.LD)
	.p2align 4
	.L__pc.22790.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22791
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22791: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22792
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22792: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22793: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22794: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22795: Dma_PatchSrc (.L__pc.22795.LD), (.L__movme_tmp.1), (.L__pc.22795.LD)
	.p2align 4
	.L__pc.22795.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22796
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22796: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22797
	
	.L__pc.22797: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22798
	
	.p2align 4
	.L__pc.22798: Dma_PatchDst (.L__pc.22798.ST), (.L__movme_cp.67), (.L__pc.22798.ST)
	.L__pc.22798.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22799
	
	.L__pc.22799: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22800
	
	.p2align 4
	.L__pc.22800: Dma_PatchDst (.L__pc.22800.ST), (.L__movme_cp.24), (.L__pc.22800.ST)
	.L__pc.22800.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22801
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22801: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22802
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22802: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22803
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22803: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22804
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22804: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22805
	
	// CG.LOAD4 [.L__movme_cp.68} => .L__movme_tmp.0
	.L__pc.22805: Dma_PatchSrc (.L__pc.22805.LD), (.L__movme_cp.68), (.L__pc.22805.LD)
	.p2align 4
	.L__pc.22805.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22806
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22806: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22807
	.L__pc.22807: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22808
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22808: Dma_PatchSrc (.L__pc.22808.LD), (.L__movme_cp.24), (.L__pc.22808.LD)
	.p2align 4
	.L__pc.22808.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22809
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22809: Dma_ByteCopy ((.L__movme.reg.edx+0)+1), (.L__movme_cp.23), 3, .L__pc.22810
	.L__pc.22810: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 1, .L__pc.22811
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22811: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.64 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22812: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22813: Dma_PatchSrc (.L__pc.22813.LD), (.L__movme_tmp.1), (.L__pc.22813.LD)
	.p2align 4
	.L__pc.22813.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22814
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22814: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22815
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.65 + (.L__movme.reg.eax+0) => .L__movme_tmp.2
	.L__pc.22815: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.3
	.L__pc.22816: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_tmp.2 + .L__movme_tmp.3 => .L__movme_tmp.1
	.L__pc.22817: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22818: Dma_PatchSrc (.L__pc.22818.LD), (.L__movme_tmp.1), (.L__pc.22818.LD)
	.p2align 4
	.L__pc.22818.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22819
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22819: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22820
	
	.L__pc.22820: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.22821
	
	.p2align 4
	.L__pc.22821: Dma_PatchDst (.L__pc.22821.ST), (.L__movme_cp.68), (.L__pc.22821.ST)
	.L__pc.22821.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22822
	
	.L__pc.22822: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+1)), 1, .L__pc.22823
	
	.p2align 4
	.L__pc.22823: Dma_PatchDst (.L__pc.22823.ST), (.L__movme_cp.24), (.L__pc.22823.ST)
	.L__pc.22823.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22824
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22824: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22825
	
	.p2align 4
	.L__pc.22825: Dma_PatchDst (.L__pc.22825.ST), (.L__movme_cp.24), (.L__pc.22825.ST)
	.L__pc.22825.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22826
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.22826: Dma_PatchSrc (.L__pc.22826.LD), (.L__movme_cp.60), (.L__pc.22826.LD)
	.p2align 4
	.L__pc.22826.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22827
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22827: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22828
	
	.L__pc.22828: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22829
	
	.p2align 4
	.L__pc.22829: Dma_PatchDst (.L__pc.22829.ST), (.L__movme_cp.21), (.L__pc.22829.ST)
	.L__pc.22829.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22830
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.22830: Dma_PatchSrc (.L__pc.22830.LD), (.L__movme_cp.58), (.L__pc.22830.LD)
	.p2align 4
	.L__pc.22830.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22831
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22831: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22832
	
	.L__pc.22832: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22833
	
	.p2align 4
	.L__pc.22833: Dma_PatchDst (.L__pc.22833.ST), (.L__movme_cp.22), (.L__pc.22833.ST)
	.L__pc.22833.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22834
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22834: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22835
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22835: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22836
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22836: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22837
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22837: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22838
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.22838: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.22839
	
	.p2align 4
	.L__pc.22839: Dma_PatchDst (.L__pc.22839.ST), (.L__movme_cp.24), (.L__pc.22839.ST)
	.L__pc.22839.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22840
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.22840: Dma_PatchSrc (.L__pc.22840.LD), (.L__movme_cp.25), (.L__pc.22840.LD)
	.p2align 4
	.L__pc.22840.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22841
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22841: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22842
	.L__pc.22842: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22843
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.22843: Dma_PatchSrc (.L__pc.22843.LD), (.L__movme_cp.26), (.L__pc.22843.LD)
	.p2align 4
	.L__pc.22843.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22844
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22844: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22845
	.L__pc.22845: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22846
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22846: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22847: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22848: Dma_PatchSrc (.L__pc.22848.LD), (.L__movme_tmp.1), (.L__pc.22848.LD)
	.p2align 4
	.L__pc.22848.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22849
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22849: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22850
	.L__pc.22850: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22851
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22851: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22852: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22853: Dma_PatchSrc (.L__pc.22853.LD), (.L__movme_tmp.1), (.L__pc.22853.LD)
	.p2align 4
	.L__pc.22853.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22854
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22854: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22855
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22855: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22856: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22857: Dma_PatchSrc (.L__pc.22857.LD), (.L__movme_tmp.1), (.L__pc.22857.LD)
	.p2align 4
	.L__pc.22857.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22858
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22858: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22859
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22859: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22860: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22861: Dma_PatchSrc (.L__pc.22861.LD), (.L__movme_tmp.1), (.L__pc.22861.LD)
	.p2align 4
	.L__pc.22861.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22862
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22862: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22863
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22863: Dma_PatchSrc (.L__pc.22863.LD), (.L__movme_cp.24), (.L__pc.22863.LD)
	.p2align 4
	.L__pc.22863.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22864
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22864: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22865
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22865: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22866: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22867: Dma_PatchSrc (.L__pc.22867.LD), (.L__movme_tmp.1), (.L__pc.22867.LD)
	.p2align 4
	.L__pc.22867.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22868
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22868: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22869
	
	.L__pc.22869: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22870
	
	.p2align 4
	.L__pc.22870: Dma_PatchDst (.L__pc.22870.ST), (.L__movme_cp.69), (.L__pc.22870.ST)
	.L__pc.22870.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22871
	
	.L__pc.22871: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22872
	
	.p2align 4
	.L__pc.22872: Dma_PatchDst (.L__pc.22872.ST), (.L__movme_cp.54), (.L__pc.22872.ST)
	.L__pc.22872.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22873
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.22873: Dma_PatchSrc (.L__pc.22873.LD), (.L__movme_cp.30), (.L__pc.22873.LD)
	.p2align 4
	.L__pc.22873.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22874
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22874: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22875
	.L__pc.22875: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22876
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.22876: Dma_PatchSrc (.L__pc.22876.LD), (.L__movme_cp.31), (.L__pc.22876.LD)
	.p2align 4
	.L__pc.22876.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22877
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22877: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22878
	.L__pc.22878: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22879
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22879: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22880: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22881: Dma_PatchSrc (.L__pc.22881.LD), (.L__movme_tmp.1), (.L__pc.22881.LD)
	.p2align 4
	.L__pc.22881.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22882
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22882: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22883
	.L__pc.22883: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22884
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22884: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22885: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22886: Dma_PatchSrc (.L__pc.22886.LD), (.L__movme_tmp.1), (.L__pc.22886.LD)
	.p2align 4
	.L__pc.22886.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22887
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22887: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22888
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22888: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22889: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22890: Dma_PatchSrc (.L__pc.22890.LD), (.L__movme_tmp.1), (.L__pc.22890.LD)
	.p2align 4
	.L__pc.22890.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22891
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22891: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22892
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22892: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22893: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22894: Dma_PatchSrc (.L__pc.22894.LD), (.L__movme_tmp.1), (.L__pc.22894.LD)
	.p2align 4
	.L__pc.22894.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22895
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22895: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22896
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22896: Dma_PatchSrc (.L__pc.22896.LD), (.L__movme_cp.24), (.L__pc.22896.LD)
	.p2align 4
	.L__pc.22896.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22897
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22897: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22898
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22898: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22899: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22900: Dma_PatchSrc (.L__pc.22900.LD), (.L__movme_tmp.1), (.L__pc.22900.LD)
	.p2align 4
	.L__pc.22900.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22901
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22901: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22902
	
	.L__pc.22902: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22903
	
	.p2align 4
	.L__pc.22903: Dma_PatchDst (.L__pc.22903.ST), (.L__movme_cp.70), (.L__pc.22903.ST)
	.L__pc.22903.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22904
	
	.L__pc.22904: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22905
	
	.p2align 4
	.L__pc.22905: Dma_PatchDst (.L__pc.22905.ST), (.L__movme_cp.54), (.L__pc.22905.ST)
	.L__pc.22905.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22906
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22906: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22907
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22907: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22908
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22908: Dma_PatchSrc (.L__pc.22908.LD), (.L__movme_cp.24), (.L__pc.22908.LD)
	.p2align 4
	.L__pc.22908.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22909
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22909: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22910
	.L__pc.22910: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22911
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.71 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.22911: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22912: Dma_PatchSrc (.L__pc.22912.LD), (.L__movme_tmp.1), (.L__pc.22912.LD)
	.p2align 4
	.L__pc.22912.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22913
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22913: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.22914
	.L__pc.22914: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.22915
	
	.L__pc.22915: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22916
	
	.p2align 4
	.L__pc.22916: Dma_PatchDst (.L__pc.22916.ST), (.L__movme_cp.72), (.L__pc.22916.ST)
	.L__pc.22916.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22917
	
	// CG.LOAD4 [.L__movme_cp.72} => .L__movme_tmp.0
	.L__pc.22917: Dma_PatchSrc (.L__pc.22917.LD), (.L__movme_cp.72), (.L__pc.22917.LD)
	.p2align 4
	.L__pc.22917.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22918
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22918: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22919
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22919: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.73 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22920: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22921: Dma_PatchSrc (.L__pc.22921.LD), (.L__movme_tmp.1), (.L__pc.22921.LD)
	.p2align 4
	.L__pc.22921.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22922
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22922: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22923
	
	.L__pc.22923: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22924
	
	.p2align 4
	.L__pc.22924: Dma_PatchDst (.L__pc.22924.ST), (.L__movme_cp.74), (.L__pc.22924.ST)
	.L__pc.22924.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22925
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22925: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.75 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22926: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22927: Dma_PatchSrc (.L__pc.22927.LD), (.L__movme_tmp.1), (.L__pc.22927.LD)
	.p2align 4
	.L__pc.22927.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22928
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22928: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22929
	
	.L__pc.22929: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22930
	
	.p2align 4
	.L__pc.22930: Dma_PatchDst (.L__pc.22930.ST), (.L__movme_cp.76), (.L__pc.22930.ST)
	.L__pc.22930.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22931
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.22931: Dma_PatchSrc (.L__pc.22931.LD), (.L__movme_cp.74), (.L__pc.22931.LD)
	.p2align 4
	.L__pc.22931.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22932
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22932: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22933
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.22933: Dma_PatchSrc (.L__pc.22933.LD), ((.L__movme.reg.eax+0)), (.L__pc.22933.LD)
	.p2align 4
	.L__pc.22933.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22934
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22934: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22935
	
	.L__pc.22935: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22936
	
	.p2align 4
	.L__pc.22936: Dma_PatchDst (.L__pc.22936.ST), (.L__movme_cp.77), (.L__pc.22936.ST)
	.L__pc.22936.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22937
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.22937: Dma_PatchSrc (.L__pc.22937.LD), (.L__movme_cp.77), (.L__pc.22937.LD)
	.p2align 4
	.L__pc.22937.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22938
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22938: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22939
	
	.L__pc.22939: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22940
	
	.p2align 4
	.L__pc.22940: Dma_PatchDst (.L__pc.22940.ST), (.L__movme_cp.21), (.L__pc.22940.ST)
	.L__pc.22940.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22941
	
	// CG.LOAD4 [.L__movme_cp.58} => .L__movme_tmp.0
	.L__pc.22941: Dma_PatchSrc (.L__pc.22941.LD), (.L__movme_cp.58), (.L__pc.22941.LD)
	.p2align 4
	.L__pc.22941.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22942
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22942: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22943
	
	.L__pc.22943: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.22944
	
	.p2align 4
	.L__pc.22944: Dma_PatchDst (.L__pc.22944.ST), (.L__movme_cp.22), (.L__pc.22944.ST)
	.L__pc.22944.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22945
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22945: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22946
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22946: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.22947
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.22947: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.22948
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22948: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22949
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.22949: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.22950
	
	.p2align 4
	.L__pc.22950: Dma_PatchDst (.L__pc.22950.ST), (.L__movme_cp.24), (.L__pc.22950.ST)
	.L__pc.22950.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22951
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.22951: Dma_PatchSrc (.L__pc.22951.LD), (.L__movme_cp.25), (.L__pc.22951.LD)
	.p2align 4
	.L__pc.22951.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22952
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22952: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22953
	.L__pc.22953: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22954
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.22954: Dma_PatchSrc (.L__pc.22954.LD), (.L__movme_cp.26), (.L__pc.22954.LD)
	.p2align 4
	.L__pc.22954.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22955
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22955: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22956
	.L__pc.22956: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22957
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22957: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22958: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22959: Dma_PatchSrc (.L__pc.22959.LD), (.L__movme_tmp.1), (.L__pc.22959.LD)
	.p2align 4
	.L__pc.22959.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22960
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22960: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22961
	.L__pc.22961: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22962
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22962: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22963: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22964: Dma_PatchSrc (.L__pc.22964.LD), (.L__movme_tmp.1), (.L__pc.22964.LD)
	.p2align 4
	.L__pc.22964.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22965
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22965: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22966
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22966: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22967: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22968: Dma_PatchSrc (.L__pc.22968.LD), (.L__movme_tmp.1), (.L__pc.22968.LD)
	.p2align 4
	.L__pc.22968.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22969
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22969: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22970
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.22970: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22971: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22972: Dma_PatchSrc (.L__pc.22972.LD), (.L__movme_tmp.1), (.L__pc.22972.LD)
	.p2align 4
	.L__pc.22972.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22973
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22973: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22974
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.22974: Dma_PatchSrc (.L__pc.22974.LD), (.L__movme_cp.24), (.L__pc.22974.LD)
	.p2align 4
	.L__pc.22974.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22975
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22975: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.22976
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22976: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22977: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22978: Dma_PatchSrc (.L__pc.22978.LD), (.L__movme_tmp.1), (.L__pc.22978.LD)
	.p2align 4
	.L__pc.22978.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22979
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22979: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22980
	
	.L__pc.22980: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.22981
	
	.p2align 4
	.L__pc.22981: Dma_PatchDst (.L__pc.22981.ST), (.L__movme_cp.78), (.L__pc.22981.ST)
	.L__pc.22981.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22982
	
	.L__pc.22982: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.22983
	
	.p2align 4
	.L__pc.22983: Dma_PatchDst (.L__pc.22983.ST), (.L__movme_cp.54), (.L__pc.22983.ST)
	.L__pc.22983.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.22984
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.22984: Dma_PatchSrc (.L__pc.22984.LD), (.L__movme_cp.30), (.L__pc.22984.LD)
	.p2align 4
	.L__pc.22984.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22985
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.22985: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.22986
	.L__pc.22986: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.22987
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.22987: Dma_PatchSrc (.L__pc.22987.LD), (.L__movme_cp.31), (.L__pc.22987.LD)
	.p2align 4
	.L__pc.22987.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22988
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22988: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22989
	.L__pc.22989: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22990
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.22990: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22991: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22992: Dma_PatchSrc (.L__pc.22992.LD), (.L__movme_tmp.1), (.L__pc.22992.LD)
	.p2align 4
	.L__pc.22992.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22993
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.22993: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.22994
	.L__pc.22994: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.22995
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.22995: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.22996: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.22997: Dma_PatchSrc (.L__pc.22997.LD), (.L__movme_tmp.1), (.L__pc.22997.LD)
	.p2align 4
	.L__pc.22997.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.22998
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.22998: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.22999
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.22999: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23000: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23001: Dma_PatchSrc (.L__pc.23001.LD), (.L__movme_tmp.1), (.L__pc.23001.LD)
	.p2align 4
	.L__pc.23001.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23002
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23002: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23003
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23003: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23004: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23005: Dma_PatchSrc (.L__pc.23005.LD), (.L__movme_tmp.1), (.L__pc.23005.LD)
	.p2align 4
	.L__pc.23005.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23006
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23006: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23007
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.23007: Dma_PatchSrc (.L__pc.23007.LD), (.L__movme_cp.24), (.L__pc.23007.LD)
	.p2align 4
	.L__pc.23007.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23008
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.23008: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.23009
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.23009: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23010: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23011: Dma_PatchSrc (.L__pc.23011.LD), (.L__movme_tmp.1), (.L__pc.23011.LD)
	.p2align 4
	.L__pc.23011.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23012
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23012: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23013
	
	.L__pc.23013: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.23014
	
	.p2align 4
	.L__pc.23014: Dma_PatchDst (.L__pc.23014.ST), (.L__movme_cp.79), (.L__pc.23014.ST)
	.L__pc.23014.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23015
	
	.L__pc.23015: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23016
	
	.p2align 4
	.L__pc.23016: Dma_PatchDst (.L__pc.23016.ST), (.L__movme_cp.54), (.L__pc.23016.ST)
	.L__pc.23016.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23017
	
	// CG.LOAD4 [.L__movme_cp.74} => .L__movme_tmp.0
	.L__pc.23017: Dma_PatchSrc (.L__pc.23017.LD), (.L__movme_cp.74), (.L__pc.23017.LD)
	.p2align 4
	.L__pc.23017.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23018
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23018: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23019
	
	// CG.LOAD4 [.L__movme_cp.77} => .L__movme_tmp.0
	.L__pc.23019: Dma_PatchSrc (.L__pc.23019.LD), (.L__movme_cp.77), (.L__pc.23019.LD)
	.p2align 4
	.L__pc.23019.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23020
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23020: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23021
	
	.L__pc.23021: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23022
	
	.p2align 4
	.L__pc.23022: Dma_PatchDst (.L__pc.23022.ST), ((.L__movme.reg.eax+0)), (.L__pc.23022.ST)
	.L__pc.23022.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23023
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.23023: Dma_PatchSrc (.L__pc.23023.LD), (.L__movme_cp.76), (.L__pc.23023.LD)
	.p2align 4
	.L__pc.23023.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23024
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23024: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23025
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.23025: Dma_PatchSrc (.L__pc.23025.LD), ((.L__movme.reg.eax+0)), (.L__pc.23025.LD)
	.p2align 4
	.L__pc.23025.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23026
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23026: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23027
	
	.L__pc.23027: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23028
	
	.p2align 4
	.L__pc.23028: Dma_PatchDst (.L__pc.23028.ST), (.L__movme_cp.80), (.L__pc.23028.ST)
	.L__pc.23028.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23029
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.23029: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.23030
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23030: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23031
	
	// CG.LOAD4 [.L__movme_cp.102} => .L__movme_tmp.0
	.L__pc.23031: Dma_PatchSrc (.L__pc.23031.LD), (.L__movme_cp.102), (.L__pc.23031.LD)
	.p2align 4
	.L__pc.23031.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23032
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23032: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.23033
	.L__pc.23033: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.23034
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.96 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.23034: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23035: Dma_PatchSrc (.L__pc.23035.LD), (.L__movme_tmp.1), (.L__pc.23035.LD)
	.p2align 4
	.L__pc.23035.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23036
	
	// CG.REG.STORE1 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23036: Dma_ByteCopy ((.L__movme.reg.eax+0)+1), (.L__movme_cp.23), 3, .L__pc.23037
	.L__pc.23037: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 1, .L__pc.23038
	
	.L__pc.23038: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 1, .L__pc.23039
	
	.p2align 4
	.L__pc.23039: Dma_PatchDst (.L__pc.23039.ST), (.L__movme_cp.102), (.L__pc.23039.ST)
	.L__pc.23039.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23040
	
	// CG.LOAD4 [.L__movme_cp.76} => .L__movme_tmp.0
	.L__pc.23040: Dma_PatchSrc (.L__pc.23040.LD), (.L__movme_cp.76), (.L__pc.23040.LD)
	.p2align 4
	.L__pc.23040.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23041
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23041: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23042
	
	// CG.LOAD4 [.L__movme_cp.80} => .L__movme_tmp.0
	.L__pc.23042: Dma_PatchSrc (.L__pc.23042.LD), (.L__movme_cp.80), (.L__pc.23042.LD)
	.p2align 4
	.L__pc.23042.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23043
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23043: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23044
	
	.L__pc.23044: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23045
	
	.p2align 4
	.L__pc.23045: Dma_PatchDst (.L__pc.23045.ST), ((.L__movme.reg.eax+0)), (.L__pc.23045.ST)
	.L__pc.23045.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23046
	
	// CG.LOAD4 [.L__movme_cp.60} => .L__movme_tmp.0
	.L__pc.23046: Dma_PatchSrc (.L__pc.23046.LD), (.L__movme_cp.60), (.L__pc.23046.LD)
	.p2align 4
	.L__pc.23046.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23047
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23047: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23048
	
	.L__pc.23048: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23049
	
	.p2align 4
	.L__pc.23049: Dma_PatchDst (.L__pc.23049.ST), (.L__movme_cp.8), (.L__pc.23049.ST)
	.L__pc.23049.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23050
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.23050: Dma_PatchSrc (.L__pc.23050.LD), (.L__movme_cp.9), (.L__pc.23050.LD)
	.p2align 4
	.L__pc.23050.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23051
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23051: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23052
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.23052: Dma_PatchSrc (.L__pc.23052.LD), (.L__movme_cp.8), (.L__pc.23052.LD)
	.p2align 4
	.L__pc.23052.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23053
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23053: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23054
	
	.L__pc.23054: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23055
	
	.p2align 4
	.L__pc.23055: Dma_PatchDst (.L__pc.23055.ST), (.L__movme_cp.21), (.L__pc.23055.ST)
	.L__pc.23055.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23056
	
	.L__pc.23056: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23057
	
	.p2align 4
	.L__pc.23057: Dma_PatchDst (.L__pc.23057.ST), (.L__movme_cp.22), (.L__pc.23057.ST)
	.L__pc.23057.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23058
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.23058: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.23059
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23059: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23060
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.23060: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.23061
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.23061: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.23062
	
	// CG.COPY4 .L__movme_cp.52 => .L__movme_tmp.0
	.L__pc.23062: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.52), 4, .L__pc.23063
	
	.p2align 4
	.L__pc.23063: Dma_PatchDst (.L__pc.23063.ST), (.L__movme_cp.24), (.L__pc.23063.ST)
	.L__pc.23063.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23064
	
	// CG.LOAD4 [.L__movme_cp.25} => .L__movme_tmp.0
	.L__pc.23064: Dma_PatchSrc (.L__pc.23064.LD), (.L__movme_cp.25), (.L__pc.23064.LD)
	.p2align 4
	.L__pc.23064.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23065
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23065: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.23066
	.L__pc.23066: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.23067
	
	// CG.LOAD4 [.L__movme_cp.26} => .L__movme_tmp.0
	.L__pc.23067: Dma_PatchSrc (.L__pc.23067.LD), (.L__movme_cp.26), (.L__pc.23067.LD)
	.p2align 4
	.L__pc.23067.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23068
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.23068: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.23069
	.L__pc.23069: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.23070
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.23070: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23071: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23072: Dma_PatchSrc (.L__pc.23072.LD), (.L__movme_tmp.1), (.L__pc.23072.LD)
	.p2align 4
	.L__pc.23072.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23073
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.23073: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.23074
	.L__pc.23074: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.23075
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.23075: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23076: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23077: Dma_PatchSrc (.L__pc.23077.LD), (.L__movme_tmp.1), (.L__pc.23077.LD)
	.p2align 4
	.L__pc.23077.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23078
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23078: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23079
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.23079: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23080: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23081: Dma_PatchSrc (.L__pc.23081.LD), (.L__movme_tmp.1), (.L__pc.23081.LD)
	.p2align 4
	.L__pc.23081.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23082
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23082: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23083
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23083: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23084: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23085: Dma_PatchSrc (.L__pc.23085.LD), (.L__movme_tmp.1), (.L__pc.23085.LD)
	.p2align 4
	.L__pc.23085.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23086
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23086: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23087
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.23087: Dma_PatchSrc (.L__pc.23087.LD), (.L__movme_cp.24), (.L__pc.23087.LD)
	.p2align 4
	.L__pc.23087.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23088
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.23088: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.23089
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.23089: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23090: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23091: Dma_PatchSrc (.L__pc.23091.LD), (.L__movme_tmp.1), (.L__pc.23091.LD)
	.p2align 4
	.L__pc.23091.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23092
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23092: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23093
	
	.L__pc.23093: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.23094
	
	.p2align 4
	.L__pc.23094: Dma_PatchDst (.L__pc.23094.ST), (.L__movme_cp.29), (.L__pc.23094.ST)
	.L__pc.23094.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23095
	
	.L__pc.23095: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23096
	
	.p2align 4
	.L__pc.23096: Dma_PatchDst (.L__pc.23096.ST), (.L__movme_cp.54), (.L__pc.23096.ST)
	.L__pc.23096.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23097
	
	// CG.LOAD4 [.L__movme_cp.30} => .L__movme_tmp.0
	.L__pc.23097: Dma_PatchSrc (.L__pc.23097.LD), (.L__movme_cp.30), (.L__pc.23097.LD)
	.p2align 4
	.L__pc.23097.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23098
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23098: Dma_ByteCopy ((.L__movme.reg.eax+0)+2), (.L__movme_cp.23), 2, .L__pc.23099
	.L__pc.23099: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 2, .L__pc.23100
	
	// CG.LOAD4 [.L__movme_cp.31} => .L__movme_tmp.0
	.L__pc.23100: Dma_PatchSrc (.L__pc.23100.LD), (.L__movme_cp.31), (.L__pc.23100.LD)
	.p2align 4
	.L__pc.23100.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23101
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.23101: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.23102
	.L__pc.23102: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.23103
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 2 => .L__movme_tmp.2
	.L__pc.23103: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.53 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23104: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23105: Dma_PatchSrc (.L__pc.23105.LD), (.L__movme_tmp.1), (.L__pc.23105.LD)
	.p2align 4
	.L__pc.23105.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23106
	
	// CG.REG.STORE2 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.23106: Dma_ByteCopy ((.L__movme.reg.ecx+0)+2), (.L__movme_cp.23), 2, .L__pc.23107
	.L__pc.23107: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 2, .L__pc.23108
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.eax+0) * 4 => .L__movme_tmp.2
	.L__pc.23108: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23109: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23110: Dma_PatchSrc (.L__pc.23110.LD), (.L__movme_tmp.1), (.L__pc.23110.LD)
	.p2align 4
	.L__pc.23110.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23111
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23111: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23112
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.23112: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23113: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23114: Dma_PatchSrc (.L__pc.23114.LD), (.L__movme_tmp.1), (.L__pc.23114.LD)
	.p2align 4
	.L__pc.23114.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23115
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23115: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23116
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23116: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.27 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23117: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23118: Dma_PatchSrc (.L__pc.23118.LD), (.L__movme_tmp.1), (.L__pc.23118.LD)
	.p2align 4
	.L__pc.23118.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23119
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23119: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23120
	
	// CG.LOAD4 [.L__movme_cp.24} => .L__movme_tmp.0
	.L__pc.23120: Dma_PatchSrc (.L__pc.23120.LD), (.L__movme_cp.24), (.L__pc.23120.LD)
	.p2align 4
	.L__pc.23120.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23121
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.ecx+0)
	.L__pc.23121: Dma_ByteCopy ((.L__movme.reg.ecx+0)), (.L__movme_tmp.0), 4, .L__pc.23122
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.ecx+0) * 4 => .L__movme_tmp.2
	.L__pc.23122: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD (.L__movme.reg.edx+0) + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23123: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23124: Dma_PatchSrc (.L__pc.23124.LD), (.L__movme_tmp.1), (.L__pc.23124.LD)
	.p2align 4
	.L__pc.23124.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23125
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23125: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23126
	
	.L__pc.23126: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 2, .L__pc.23127
	
	.p2align 4
	.L__pc.23127: Dma_PatchDst (.L__pc.23127.ST), (.L__movme_cp.32), (.L__pc.23127.ST)
	.L__pc.23127.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23128
	
	.L__pc.23128: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23129
	
	.p2align 4
	.L__pc.23129: Dma_PatchDst (.L__pc.23129.ST), (.L__movme_cp.54), (.L__pc.23129.ST)
	.L__pc.23129.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23130
	
	// CG.LOAD4 [.L__movme_cp.33} => .L__movme_tmp.0
	.L__pc.23130: Dma_PatchSrc (.L__pc.23130.LD), (.L__movme_cp.33), (.L__pc.23130.LD)
	.p2align 4
	.L__pc.23130.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23131
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23131: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23132
	
	.L__pc.23132: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23133
	
	.p2align 4
	.L__pc.23133: Dma_PatchDst (.L__pc.23133.ST), (.L__movme_cp.9), (.L__pc.23133.ST)
	.L__pc.23133.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23134
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.23134: Dma_PatchSrc (.L__pc.23134.LD), (.L__movme_cp.0), (.L__pc.23134.LD)
	.p2align 4
	.L__pc.23134.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23135
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23135: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23136
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.23136: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23137: Dma_PatchSrc (.L__pc.23137.LD), (.L__movme_tmp.1), (.L__pc.23137.LD)
	.p2align 4
	.L__pc.23137.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23138
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23138: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23139
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23139: Dma_PatchSrc (.L__pc.23139.LD), (.L__movme_cp.3), (.L__pc.23139.LD)
	.p2align 4
	.L__pc.23139.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23140
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23140: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23141
	
	.L__pc.23141: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23142
	
	.p2align 4
	.L__pc.23142: Dma_PatchDst (.L__pc.23142.ST), (.L__movme_cp.4), (.L__pc.23142.ST)
	.L__pc.23142.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23143
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23143: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23144: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23145: Dma_PatchSrc (.L__pc.23145.LD), (.L__movme_tmp.1), (.L__pc.23145.LD)
	.p2align 4
	.L__pc.23145.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23146
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23146: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23147
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.23147: Dma_PatchSrc (.L__pc.23147.LD), (.L__movme_cp.9), (.L__pc.23147.LD)
	.p2align 4
	.L__pc.23147.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23148
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23148: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23149
	
	.L__pc.23149: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23150
	
	.p2align 4
	.L__pc.23150: Dma_PatchDst (.L__pc.23150.ST), ((.L__movme.reg.eax+0)), (.L__pc.23150.ST)
	.L__pc.23150.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23151
	
	// LABEL .LCI16
	.LCI16:
	
	// LABEL .LCI15
	.LCI15:
	
	// CG.COPY4 .L__movme_cp.34 => .L__movme_tmp.0
	.L__pc.23151: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.34), 4, .L__pc.23152
	
	.p2align 4
	.L__pc.23152: Dma_PatchDst (.L__pc.23152.ST), (.L__movme_cp.9), (.L__pc.23152.ST)
	.L__pc.23152.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23153
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.23153: Dma_PatchSrc (.L__pc.23153.LD), (.L__movme_cp.0), (.L__pc.23153.LD)
	.p2align 4
	.L__pc.23153.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23154
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23154: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23155
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.6 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.23155: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23156: Dma_PatchSrc (.L__pc.23156.LD), (.L__movme_tmp.1), (.L__pc.23156.LD)
	.p2align 4
	.L__pc.23156.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23157
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23157: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23158
	
	.L__pc.23158: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23159
	
	.p2align 4
	.L__pc.23159: Dma_PatchDst (.L__pc.23159.ST), (.L__movme_cp.8), (.L__pc.23159.ST)
	.L__pc.23159.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23160
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.23160: Dma_PatchSrc (.L__pc.23160.LD), (.L__movme_cp.8), (.L__pc.23160.LD)
	.p2align 4
	.L__pc.23160.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23161
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23161: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23162
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23162: Dma_PatchSrc (.L__pc.23162.LD), (.L__movme_cp.3), (.L__pc.23162.LD)
	.p2align 4
	.L__pc.23162.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23163
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23163: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23164
	
	.L__pc.23164: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23165
	
	.p2align 4
	.L__pc.23165: Dma_PatchDst (.L__pc.23165.ST), (.L__movme_cp.4), (.L__pc.23165.ST)
	.L__pc.23165.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23166
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23166: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23167: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23168: Dma_PatchSrc (.L__pc.23168.LD), (.L__movme_tmp.1), (.L__pc.23168.LD)
	.p2align 4
	.L__pc.23168.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23169
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23169: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23170
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.23170: Dma_PatchSrc (.L__pc.23170.LD), ((.L__movme.reg.eax+0)), (.L__pc.23170.LD)
	.p2align 4
	.L__pc.23170.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23171
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23171: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23172
	
	.L__pc.23172: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23173
	
	.p2align 4
	.L__pc.23173: Dma_PatchDst (.L__pc.23173.ST), (.L__movme_cp.8), (.L__pc.23173.ST)
	.L__pc.23173.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23174
	
	// CG.LOAD4 [.L__movme_cp.9} => .L__movme_tmp.0
	.L__pc.23174: Dma_PatchSrc (.L__pc.23174.LD), (.L__movme_cp.9), (.L__pc.23174.LD)
	.p2align 4
	.L__pc.23174.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23175
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23175: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23176
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23176: Dma_PatchSrc (.L__pc.23176.LD), (.L__movme_cp.3), (.L__pc.23176.LD)
	.p2align 4
	.L__pc.23176.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23177
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23177: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23178
	
	.L__pc.23178: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23179
	
	.p2align 4
	.L__pc.23179: Dma_PatchDst (.L__pc.23179.ST), (.L__movme_cp.4), (.L__pc.23179.ST)
	.L__pc.23179.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23180
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23180: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23181: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23182: Dma_PatchSrc (.L__pc.23182.LD), (.L__movme_tmp.1), (.L__pc.23182.LD)
	.p2align 4
	.L__pc.23182.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23183
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23183: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23184
	
	// CG.LOAD4 [.L__movme_cp.8} => .L__movme_tmp.0
	.L__pc.23184: Dma_PatchSrc (.L__pc.23184.LD), (.L__movme_cp.8), (.L__pc.23184.LD)
	.p2align 4
	.L__pc.23184.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23185
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23185: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23186
	
	.L__pc.23186: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23187
	
	.p2align 4
	.L__pc.23187: Dma_PatchDst (.L__pc.23187.ST), ((.L__movme.reg.eax+0)), (.L__pc.23187.ST)
	.L__pc.23187.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23188
	
	// LABEL .LCI12
	.LCI12:
	
	// LABEL .LCI10
	.LCI10:
	
	// JMP imm.4(.LCI9)
	.L__pc.23188: Dma_PatchLink (.L__pc.23188.J), (.L__movme_cp.106), (.L__pc.23188.J)
	.p2align 4
	.L__pc.23188.J: Dma_ByteCopy  (.L__movme_tmp.0), (.L__movme_tmp.0), 1, .L__pc.23189
	
	// CG.COPY4 .L__movme_cp.23 => .L__movme_tmp.0
	.L__pc.23189: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.23), 4, .L__pc.23190
	
	.p2align 4
	.L__pc.23190: Dma_PatchDst (.L__pc.23190.ST), (.L__movme_cp.35), (.L__pc.23190.ST)
	.L__pc.23190.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23191
	
	// LABEL .LCI7
	.LCI7:
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.23191: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.23192
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23192: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23193
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23193: Dma_PatchSrc (.L__pc.23193.LD), (.L__movme_cp.3), (.L__pc.23193.LD)
	.p2align 4
	.L__pc.23193.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23194
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23194: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23195
	
	.L__pc.23195: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23196
	
	.p2align 4
	.L__pc.23196: Dma_PatchDst (.L__pc.23196.ST), (.L__movme_cp.4), (.L__pc.23196.ST)
	.L__pc.23196.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23197
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23197: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23198: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23199: Dma_PatchSrc (.L__pc.23199.LD), (.L__movme_tmp.1), (.L__pc.23199.LD)
	.p2align 4
	.L__pc.23199.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23200
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23200: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23201
	
	// CG.LOAD4 [.L__movme_cp.0} => .L__movme_tmp.0
	.L__pc.23201: Dma_PatchSrc (.L__pc.23201.LD), (.L__movme_cp.0), (.L__pc.23201.LD)
	.p2align 4
	.L__pc.23201.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23202
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23202: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23203
	
	.L__pc.23203: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23204
	
	.p2align 4
	.L__pc.23204: Dma_PatchDst (.L__pc.23204.ST), ((.L__movme.reg.eax+0)), (.L__pc.23204.ST)
	.L__pc.23204.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23205
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23205: Dma_PatchSrc (.L__pc.23205.LD), (.L__movme_cp.2), (.L__pc.23205.LD)
	.p2align 4
	.L__pc.23205.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23206
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23206: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23207
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.23207: Dma_PatchSrc (.L__pc.23207.LD), ((.L__movme.reg.eax+0)), (.L__pc.23207.LD)
	.p2align 4
	.L__pc.23207.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23208
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23208: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23209
	
	.L__pc.23209: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23210
	
	.p2align 4
	.L__pc.23210: Dma_PatchDst (.L__pc.23210.ST), (.L__movme_cp.1), (.L__pc.23210.ST)
	.L__pc.23210.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23211
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.23211: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23212: Dma_PatchSrc (.L__pc.23212.LD), (.L__movme_tmp.1), (.L__pc.23212.LD)
	.p2align 4
	.L__pc.23212.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23213
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23213: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23214
	
	.L__pc.23214: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23215
	
	.p2align 4
	.L__pc.23215: Dma_PatchDst (.L__pc.23215.ST), (.L__movme_cp.14), (.L__pc.23215.ST)
	.L__pc.23215.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23216
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.23216: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.23217
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23217: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23218
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23218: Dma_PatchSrc (.L__pc.23218.LD), (.L__movme_cp.3), (.L__pc.23218.LD)
	.p2align 4
	.L__pc.23218.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23219
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23219: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23220
	
	.L__pc.23220: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23221
	
	.p2align 4
	.L__pc.23221: Dma_PatchDst (.L__pc.23221.ST), (.L__movme_cp.4), (.L__pc.23221.ST)
	.L__pc.23221.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23222
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23222: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23223: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23224: Dma_PatchSrc (.L__pc.23224.LD), (.L__movme_tmp.1), (.L__pc.23224.LD)
	.p2align 4
	.L__pc.23224.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23225
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23225: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23226
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23226: Dma_PatchSrc (.L__pc.23226.LD), (.L__movme_cp.2), (.L__pc.23226.LD)
	.p2align 4
	.L__pc.23226.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23227
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23227: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23228
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.23228: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23229: Dma_PatchSrc (.L__pc.23229.LD), (.L__movme_tmp.1), (.L__pc.23229.LD)
	.p2align 4
	.L__pc.23229.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23230
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23230: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23231
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.23231: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23232: Dma_PatchSrc (.L__pc.23232.LD), (.L__movme_tmp.1), (.L__pc.23232.LD)
	.p2align 4
	.L__pc.23232.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23233
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23233: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23234
	
	.L__pc.23234: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23235
	
	.p2align 4
	.L__pc.23235: Dma_PatchDst (.L__pc.23235.ST), ((.L__movme.reg.eax+0)), (.L__pc.23235.ST)
	.L__pc.23235.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23236
	
	// CG.COPY4 .L__movme_cp.16 => .L__movme_tmp.0
	.L__pc.23236: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.16), 4, .L__pc.23237
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23237: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23238
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23238: Dma_PatchSrc (.L__pc.23238.LD), (.L__movme_cp.3), (.L__pc.23238.LD)
	.p2align 4
	.L__pc.23238.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23239
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23239: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23240
	
	.L__pc.23240: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23241
	
	.p2align 4
	.L__pc.23241: Dma_PatchDst (.L__pc.23241.ST), (.L__movme_cp.4), (.L__pc.23241.ST)
	.L__pc.23241.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23242
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23242: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23243: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23244: Dma_PatchSrc (.L__pc.23244.LD), (.L__movme_tmp.1), (.L__pc.23244.LD)
	.p2align 4
	.L__pc.23244.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23245
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23245: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23246
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.23246: Dma_PatchSrc (.L__pc.23246.LD), (.L__movme_cp.1), (.L__pc.23246.LD)
	.p2align 4
	.L__pc.23246.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23247
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23247: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23248
	
	.L__pc.23248: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23249
	
	.p2align 4
	.L__pc.23249: Dma_PatchDst (.L__pc.23249.ST), ((.L__movme.reg.eax+0)), (.L__pc.23249.ST)
	.L__pc.23249.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23250
	
	// CG.LOAD4 [.L__movme_cp.14} => .L__movme_tmp.0
	.L__pc.23250: Dma_PatchSrc (.L__pc.23250.LD), (.L__movme_cp.14), (.L__pc.23250.LD)
	.p2align 4
	.L__pc.23250.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23251
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23251: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23252
	
	.L__pc.23252: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23253
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.23253: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	.p2align 4
	.L__pc.23254: Dma_PatchDst (.L__pc.23254.ST), (.L__movme_tmp.1), (.L__pc.23254.ST)
	.L__pc.23254.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23255
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23255: Dma_PatchSrc (.L__pc.23255.LD), (.L__movme_cp.2), (.L__pc.23255.LD)
	.p2align 4
	.L__pc.23255.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23256
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23256: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23257
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.23257: Dma_PatchSrc (.L__pc.23257.LD), ((.L__movme.reg.eax+0)), (.L__pc.23257.LD)
	.p2align 4
	.L__pc.23257.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23258
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23258: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23259
	
	.L__pc.23259: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23260
	
	.p2align 4
	.L__pc.23260: Dma_PatchDst (.L__pc.23260.ST), (.L__movme_cp.1), (.L__pc.23260.ST)
	.L__pc.23260.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23261
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.23261: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23262: Dma_PatchSrc (.L__pc.23262.LD), (.L__movme_tmp.1), (.L__pc.23262.LD)
	.p2align 4
	.L__pc.23262.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23263
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23263: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23264
	
	.L__pc.23264: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23265
	
	.p2align 4
	.L__pc.23265: Dma_PatchDst (.L__pc.23265.ST), (.L__movme_cp.14), (.L__pc.23265.ST)
	.L__pc.23265.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23266
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.23266: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.23267
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23267: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23268
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23268: Dma_PatchSrc (.L__pc.23268.LD), (.L__movme_cp.3), (.L__pc.23268.LD)
	.p2align 4
	.L__pc.23268.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23269
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23269: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23270
	
	.L__pc.23270: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23271
	
	.p2align 4
	.L__pc.23271: Dma_PatchDst (.L__pc.23271.ST), (.L__movme_cp.4), (.L__pc.23271.ST)
	.L__pc.23271.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23272
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23272: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23273: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23274: Dma_PatchSrc (.L__pc.23274.LD), (.L__movme_tmp.1), (.L__pc.23274.LD)
	.p2align 4
	.L__pc.23274.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23275
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23275: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23276
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23276: Dma_PatchSrc (.L__pc.23276.LD), (.L__movme_cp.2), (.L__pc.23276.LD)
	.p2align 4
	.L__pc.23276.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23277
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23277: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23278
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.23278: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23279: Dma_PatchSrc (.L__pc.23279.LD), (.L__movme_tmp.1), (.L__pc.23279.LD)
	.p2align 4
	.L__pc.23279.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23280
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23280: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23281
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.23281: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23282: Dma_PatchSrc (.L__pc.23282.LD), (.L__movme_tmp.1), (.L__pc.23282.LD)
	.p2align 4
	.L__pc.23282.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23283
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23283: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23284
	
	.L__pc.23284: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23285
	
	.p2align 4
	.L__pc.23285: Dma_PatchDst (.L__pc.23285.ST), ((.L__movme.reg.eax+0)), (.L__pc.23285.ST)
	.L__pc.23285.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23286
	
	// CG.COPY4 .L__movme_cp.12 => .L__movme_tmp.0
	.L__pc.23286: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.12), 4, .L__pc.23287
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23287: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23288
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23288: Dma_PatchSrc (.L__pc.23288.LD), (.L__movme_cp.3), (.L__pc.23288.LD)
	.p2align 4
	.L__pc.23288.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23289
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23289: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23290
	
	.L__pc.23290: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23291
	
	.p2align 4
	.L__pc.23291: Dma_PatchDst (.L__pc.23291.ST), (.L__movme_cp.4), (.L__pc.23291.ST)
	.L__pc.23291.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23292
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23292: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23293: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23294: Dma_PatchSrc (.L__pc.23294.LD), (.L__movme_tmp.1), (.L__pc.23294.LD)
	.p2align 4
	.L__pc.23294.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23295
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23295: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23296
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.23296: Dma_PatchSrc (.L__pc.23296.LD), (.L__movme_cp.1), (.L__pc.23296.LD)
	.p2align 4
	.L__pc.23296.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23297
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23297: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23298
	
	.L__pc.23298: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23299
	
	.p2align 4
	.L__pc.23299: Dma_PatchDst (.L__pc.23299.ST), ((.L__movme.reg.eax+0)), (.L__pc.23299.ST)
	.L__pc.23299.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23300
	
	// CG.LOAD4 [.L__movme_cp.14} => .L__movme_tmp.0
	.L__pc.23300: Dma_PatchSrc (.L__pc.23300.LD), (.L__movme_cp.14), (.L__pc.23300.LD)
	.p2align 4
	.L__pc.23300.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23301
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23301: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23302
	
	.L__pc.23302: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23303
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.15 + (.L__movme.reg.eax+0) => .L__movme_tmp.1
	.L__pc.23303: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	.p2align 4
	.L__pc.23304: Dma_PatchDst (.L__pc.23304.ST), (.L__movme_tmp.1), (.L__pc.23304.ST)
	.L__pc.23304.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23305
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23305: Dma_PatchSrc (.L__pc.23305.LD), (.L__movme_cp.2), (.L__pc.23305.LD)
	.p2align 4
	.L__pc.23305.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23306
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23306: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23307
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.23307: Dma_PatchSrc (.L__pc.23307.LD), ((.L__movme.reg.eax+0)), (.L__pc.23307.LD)
	.p2align 4
	.L__pc.23307.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23308
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23308: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23309
	
	.L__pc.23309: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23310
	
	.p2align 4
	.L__pc.23310: Dma_PatchDst (.L__pc.23310.ST), (.L__movme_cp.1), (.L__pc.23310.ST)
	.L__pc.23310.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23311
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.23311: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.23312
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23312: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23313
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23313: Dma_PatchSrc (.L__pc.23313.LD), (.L__movme_cp.3), (.L__pc.23313.LD)
	.p2align 4
	.L__pc.23313.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23314
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23314: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23315
	
	.L__pc.23315: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23316
	
	.p2align 4
	.L__pc.23316: Dma_PatchDst (.L__pc.23316.ST), (.L__movme_cp.4), (.L__pc.23316.ST)
	.L__pc.23316.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23317
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23317: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23318: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23319: Dma_PatchSrc (.L__pc.23319.LD), (.L__movme_tmp.1), (.L__pc.23319.LD)
	.p2align 4
	.L__pc.23319.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23320
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23320: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23321
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23321: Dma_PatchSrc (.L__pc.23321.LD), (.L__movme_cp.2), (.L__pc.23321.LD)
	.p2align 4
	.L__pc.23321.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23322
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23322: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23323
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.23323: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23324: Dma_PatchSrc (.L__pc.23324.LD), (.L__movme_tmp.1), (.L__pc.23324.LD)
	.p2align 4
	.L__pc.23324.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23325
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23325: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23326
	
	.L__pc.23326: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23327
	
	.p2align 4
	.L__pc.23327: Dma_PatchDst (.L__pc.23327.ST), ((.L__movme.reg.eax+0)), (.L__pc.23327.ST)
	.L__pc.23327.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23328
	
	// CG.COPY4 .L__movme_cp.11 => .L__movme_tmp.0
	.L__pc.23328: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.11), 4, .L__pc.23329
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23329: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23330
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23330: Dma_PatchSrc (.L__pc.23330.LD), (.L__movme_cp.3), (.L__pc.23330.LD)
	.p2align 4
	.L__pc.23330.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23331
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23331: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23332
	
	.L__pc.23332: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23333
	
	.p2align 4
	.L__pc.23333: Dma_PatchDst (.L__pc.23333.ST), (.L__movme_cp.4), (.L__pc.23333.ST)
	.L__pc.23333.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23334
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23334: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23335: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23336: Dma_PatchSrc (.L__pc.23336.LD), (.L__movme_tmp.1), (.L__pc.23336.LD)
	.p2align 4
	.L__pc.23336.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23337
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23337: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23338
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.23338: Dma_PatchSrc (.L__pc.23338.LD), (.L__movme_cp.1), (.L__pc.23338.LD)
	.p2align 4
	.L__pc.23338.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23339
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23339: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23340
	
	.L__pc.23340: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23341
	
	.p2align 4
	.L__pc.23341: Dma_PatchDst (.L__pc.23341.ST), ((.L__movme.reg.eax+0)), (.L__pc.23341.ST)
	.L__pc.23341.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23342
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23342: Dma_PatchSrc (.L__pc.23342.LD), (.L__movme_cp.2), (.L__pc.23342.LD)
	.p2align 4
	.L__pc.23342.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23343
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23343: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23344
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.23344: Dma_PatchSrc (.L__pc.23344.LD), ((.L__movme.reg.eax+0)), (.L__pc.23344.LD)
	.p2align 4
	.L__pc.23344.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23345
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23345: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23346
	
	.L__pc.23346: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23347
	
	.p2align 4
	.L__pc.23347: Dma_PatchDst (.L__pc.23347.ST), (.L__movme_cp.1), (.L__pc.23347.ST)
	.L__pc.23347.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23348
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.23348: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.23349
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23349: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23350
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23350: Dma_PatchSrc (.L__pc.23350.LD), (.L__movme_cp.3), (.L__pc.23350.LD)
	.p2align 4
	.L__pc.23350.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23351
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23351: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23352
	
	.L__pc.23352: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23353
	
	.p2align 4
	.L__pc.23353: Dma_PatchDst (.L__pc.23353.ST), (.L__movme_cp.4), (.L__pc.23353.ST)
	.L__pc.23353.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23354
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23354: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23355: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23356: Dma_PatchSrc (.L__pc.23356.LD), (.L__movme_tmp.1), (.L__pc.23356.LD)
	.p2align 4
	.L__pc.23356.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23357
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23357: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23358
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23358: Dma_PatchSrc (.L__pc.23358.LD), (.L__movme_cp.2), (.L__pc.23358.LD)
	.p2align 4
	.L__pc.23358.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23359
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23359: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23360
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.23360: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23361: Dma_PatchSrc (.L__pc.23361.LD), (.L__movme_tmp.1), (.L__pc.23361.LD)
	.p2align 4
	.L__pc.23361.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23362
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23362: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23363
	
	.L__pc.23363: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23364
	
	.p2align 4
	.L__pc.23364: Dma_PatchDst (.L__pc.23364.ST), ((.L__movme.reg.eax+0)), (.L__pc.23364.ST)
	.L__pc.23364.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23365
	
	// CG.COPY4 .L__movme_cp.10 => .L__movme_tmp.0
	.L__pc.23365: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.10), 4, .L__pc.23366
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23366: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23367
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23367: Dma_PatchSrc (.L__pc.23367.LD), (.L__movme_cp.3), (.L__pc.23367.LD)
	.p2align 4
	.L__pc.23367.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23368
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23368: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23369
	
	.L__pc.23369: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23370
	
	.p2align 4
	.L__pc.23370: Dma_PatchDst (.L__pc.23370.ST), (.L__movme_cp.4), (.L__pc.23370.ST)
	.L__pc.23370.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23371
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23371: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23372: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23373: Dma_PatchSrc (.L__pc.23373.LD), (.L__movme_tmp.1), (.L__pc.23373.LD)
	.p2align 4
	.L__pc.23373.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23374
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23374: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23375
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.23375: Dma_PatchSrc (.L__pc.23375.LD), (.L__movme_cp.1), (.L__pc.23375.LD)
	.p2align 4
	.L__pc.23375.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23376
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23376: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23377
	
	.L__pc.23377: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23378
	
	.p2align 4
	.L__pc.23378: Dma_PatchDst (.L__pc.23378.ST), ((.L__movme.reg.eax+0)), (.L__pc.23378.ST)
	.L__pc.23378.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23379
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23379: Dma_PatchSrc (.L__pc.23379.LD), (.L__movme_cp.2), (.L__pc.23379.LD)
	.p2align 4
	.L__pc.23379.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23380
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23380: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23381
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.23381: Dma_PatchSrc (.L__pc.23381.LD), ((.L__movme.reg.eax+0)), (.L__pc.23381.LD)
	.p2align 4
	.L__pc.23381.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23382
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23382: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23383
	
	.L__pc.23383: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23384
	
	.p2align 4
	.L__pc.23384: Dma_PatchDst (.L__pc.23384.ST), (.L__movme_cp.1), (.L__pc.23384.ST)
	.L__pc.23384.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23385
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.23385: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.23386
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23386: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23387
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23387: Dma_PatchSrc (.L__pc.23387.LD), (.L__movme_cp.3), (.L__pc.23387.LD)
	.p2align 4
	.L__pc.23387.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23388
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23388: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23389
	
	.L__pc.23389: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23390
	
	.p2align 4
	.L__pc.23390: Dma_PatchDst (.L__pc.23390.ST), (.L__movme_cp.4), (.L__pc.23390.ST)
	.L__pc.23390.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23391
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23391: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23392: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23393: Dma_PatchSrc (.L__pc.23393.LD), (.L__movme_tmp.1), (.L__pc.23393.LD)
	.p2align 4
	.L__pc.23393.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23394
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23394: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23395
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23395: Dma_PatchSrc (.L__pc.23395.LD), (.L__movme_cp.2), (.L__pc.23395.LD)
	.p2align 4
	.L__pc.23395.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23396
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23396: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23397
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.23397: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23398: Dma_PatchSrc (.L__pc.23398.LD), (.L__movme_tmp.1), (.L__pc.23398.LD)
	.p2align 4
	.L__pc.23398.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23399
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23399: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23400
	
	.L__pc.23400: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23401
	
	.p2align 4
	.L__pc.23401: Dma_PatchDst (.L__pc.23401.ST), ((.L__movme.reg.eax+0)), (.L__pc.23401.ST)
	.L__pc.23401.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23402
	
	// CG.COPY4 .L__movme_cp.9 => .L__movme_tmp.0
	.L__pc.23402: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.9), 4, .L__pc.23403
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23403: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23404
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23404: Dma_PatchSrc (.L__pc.23404.LD), (.L__movme_cp.3), (.L__pc.23404.LD)
	.p2align 4
	.L__pc.23404.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23405
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23405: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23406
	
	.L__pc.23406: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23407
	
	.p2align 4
	.L__pc.23407: Dma_PatchDst (.L__pc.23407.ST), (.L__movme_cp.4), (.L__pc.23407.ST)
	.L__pc.23407.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23408
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23408: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23409: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23410: Dma_PatchSrc (.L__pc.23410.LD), (.L__movme_tmp.1), (.L__pc.23410.LD)
	.p2align 4
	.L__pc.23410.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23411
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23411: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23412
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.23412: Dma_PatchSrc (.L__pc.23412.LD), (.L__movme_cp.1), (.L__pc.23412.LD)
	.p2align 4
	.L__pc.23412.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23413
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23413: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23414
	
	.L__pc.23414: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23415
	
	.p2align 4
	.L__pc.23415: Dma_PatchDst (.L__pc.23415.ST), ((.L__movme.reg.eax+0)), (.L__pc.23415.ST)
	.L__pc.23415.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23416
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23416: Dma_PatchSrc (.L__pc.23416.LD), (.L__movme_cp.2), (.L__pc.23416.LD)
	.p2align 4
	.L__pc.23416.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23417
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23417: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23418
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.23418: Dma_PatchSrc (.L__pc.23418.LD), ((.L__movme.reg.eax+0)), (.L__pc.23418.LD)
	.p2align 4
	.L__pc.23418.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23419
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23419: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23420
	
	.L__pc.23420: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23421
	
	.p2align 4
	.L__pc.23421: Dma_PatchDst (.L__pc.23421.ST), (.L__movme_cp.1), (.L__pc.23421.ST)
	.L__pc.23421.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23422
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.23422: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.23423
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23423: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23424
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23424: Dma_PatchSrc (.L__pc.23424.LD), (.L__movme_cp.3), (.L__pc.23424.LD)
	.p2align 4
	.L__pc.23424.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23425
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23425: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23426
	
	.L__pc.23426: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23427
	
	.p2align 4
	.L__pc.23427: Dma_PatchDst (.L__pc.23427.ST), (.L__movme_cp.4), (.L__pc.23427.ST)
	.L__pc.23427.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23428
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23428: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23429: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23430: Dma_PatchSrc (.L__pc.23430.LD), (.L__movme_tmp.1), (.L__pc.23430.LD)
	.p2align 4
	.L__pc.23430.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23431
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23431: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23432
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23432: Dma_PatchSrc (.L__pc.23432.LD), (.L__movme_cp.2), (.L__pc.23432.LD)
	.p2align 4
	.L__pc.23432.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23433
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23433: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23434
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.23434: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23435: Dma_PatchSrc (.L__pc.23435.LD), (.L__movme_tmp.1), (.L__pc.23435.LD)
	.p2align 4
	.L__pc.23435.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23436
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23436: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23437
	
	.L__pc.23437: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23438
	
	.p2align 4
	.L__pc.23438: Dma_PatchDst (.L__pc.23438.ST), ((.L__movme.reg.eax+0)), (.L__pc.23438.ST)
	.L__pc.23438.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23439
	
	// CG.COPY4 .L__movme_cp.8 => .L__movme_tmp.0
	.L__pc.23439: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.8), 4, .L__pc.23440
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23440: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23441
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23441: Dma_PatchSrc (.L__pc.23441.LD), (.L__movme_cp.3), (.L__pc.23441.LD)
	.p2align 4
	.L__pc.23441.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23442
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23442: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23443
	
	.L__pc.23443: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23444
	
	.p2align 4
	.L__pc.23444: Dma_PatchDst (.L__pc.23444.ST), (.L__movme_cp.4), (.L__pc.23444.ST)
	.L__pc.23444.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23445
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23445: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23446: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23447: Dma_PatchSrc (.L__pc.23447.LD), (.L__movme_tmp.1), (.L__pc.23447.LD)
	.p2align 4
	.L__pc.23447.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23448
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23448: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23449
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.23449: Dma_PatchSrc (.L__pc.23449.LD), (.L__movme_cp.1), (.L__pc.23449.LD)
	.p2align 4
	.L__pc.23449.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23450
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23450: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23451
	
	.L__pc.23451: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23452
	
	.p2align 4
	.L__pc.23452: Dma_PatchDst (.L__pc.23452.ST), ((.L__movme.reg.eax+0)), (.L__pc.23452.ST)
	.L__pc.23452.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23453
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23453: Dma_PatchSrc (.L__pc.23453.LD), (.L__movme_cp.2), (.L__pc.23453.LD)
	.p2align 4
	.L__pc.23453.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23454
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23454: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23455
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.23455: Dma_PatchSrc (.L__pc.23455.LD), ((.L__movme.reg.eax+0)), (.L__pc.23455.LD)
	.p2align 4
	.L__pc.23455.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23456
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23456: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23457
	
	.L__pc.23457: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23458
	
	.p2align 4
	.L__pc.23458: Dma_PatchDst (.L__pc.23458.ST), (.L__movme_cp.1), (.L__pc.23458.ST)
	.L__pc.23458.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23459
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.23459: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.23460
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23460: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23461
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23461: Dma_PatchSrc (.L__pc.23461.LD), (.L__movme_cp.3), (.L__pc.23461.LD)
	.p2align 4
	.L__pc.23461.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23462
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23462: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23463
	
	.L__pc.23463: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23464
	
	.p2align 4
	.L__pc.23464: Dma_PatchDst (.L__pc.23464.ST), (.L__movme_cp.4), (.L__pc.23464.ST)
	.L__pc.23464.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23465
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23465: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23466: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23467: Dma_PatchSrc (.L__pc.23467.LD), (.L__movme_tmp.1), (.L__pc.23467.LD)
	.p2align 4
	.L__pc.23467.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23468
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23468: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23469
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23469: Dma_PatchSrc (.L__pc.23469.LD), (.L__movme_cp.2), (.L__pc.23469.LD)
	.p2align 4
	.L__pc.23469.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23470
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23470: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23471
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.23471: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23472: Dma_PatchSrc (.L__pc.23472.LD), (.L__movme_tmp.1), (.L__pc.23472.LD)
	.p2align 4
	.L__pc.23472.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23473
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23473: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23474
	
	.L__pc.23474: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23475
	
	.p2align 4
	.L__pc.23475: Dma_PatchDst (.L__pc.23475.ST), ((.L__movme.reg.eax+0)), (.L__pc.23475.ST)
	.L__pc.23475.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23476
	
	// CG.COPY4 .L__movme_cp.7 => .L__movme_tmp.0
	.L__pc.23476: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.7), 4, .L__pc.23477
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23477: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23478
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23478: Dma_PatchSrc (.L__pc.23478.LD), (.L__movme_cp.3), (.L__pc.23478.LD)
	.p2align 4
	.L__pc.23478.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23479
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23479: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23480
	
	.L__pc.23480: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23481
	
	.p2align 4
	.L__pc.23481: Dma_PatchDst (.L__pc.23481.ST), (.L__movme_cp.4), (.L__pc.23481.ST)
	.L__pc.23481.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23482
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23482: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23483: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23484: Dma_PatchSrc (.L__pc.23484.LD), (.L__movme_tmp.1), (.L__pc.23484.LD)
	.p2align 4
	.L__pc.23484.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23485
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23485: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23486
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.23486: Dma_PatchSrc (.L__pc.23486.LD), (.L__movme_cp.1), (.L__pc.23486.LD)
	.p2align 4
	.L__pc.23486.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23487
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23487: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23488
	
	.L__pc.23488: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23489
	
	.p2align 4
	.L__pc.23489: Dma_PatchDst (.L__pc.23489.ST), ((.L__movme.reg.eax+0)), (.L__pc.23489.ST)
	.L__pc.23489.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23490
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23490: Dma_PatchSrc (.L__pc.23490.LD), (.L__movme_cp.2), (.L__pc.23490.LD)
	.p2align 4
	.L__pc.23490.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23491
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23491: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23492
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.23492: Dma_PatchSrc (.L__pc.23492.LD), ((.L__movme.reg.eax+0)), (.L__pc.23492.LD)
	.p2align 4
	.L__pc.23492.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23493
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23493: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23494
	
	.L__pc.23494: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23495
	
	.p2align 4
	.L__pc.23495: Dma_PatchDst (.L__pc.23495.ST), (.L__movme_cp.1), (.L__pc.23495.ST)
	.L__pc.23495.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23496
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.23496: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.23497
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23497: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23498
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23498: Dma_PatchSrc (.L__pc.23498.LD), (.L__movme_cp.3), (.L__pc.23498.LD)
	.p2align 4
	.L__pc.23498.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23499
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23499: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23500
	
	.L__pc.23500: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23501
	
	.p2align 4
	.L__pc.23501: Dma_PatchDst (.L__pc.23501.ST), (.L__movme_cp.4), (.L__pc.23501.ST)
	.L__pc.23501.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23502
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23502: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23503: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23504: Dma_PatchSrc (.L__pc.23504.LD), (.L__movme_tmp.1), (.L__pc.23504.LD)
	.p2align 4
	.L__pc.23504.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23505
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23505: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23506
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23506: Dma_PatchSrc (.L__pc.23506.LD), (.L__movme_cp.2), (.L__pc.23506.LD)
	.p2align 4
	.L__pc.23506.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23507
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23507: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23508
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.23508: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23509: Dma_PatchSrc (.L__pc.23509.LD), (.L__movme_tmp.1), (.L__pc.23509.LD)
	.p2align 4
	.L__pc.23509.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23510
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23510: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23511
	
	.L__pc.23511: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23512
	
	.p2align 4
	.L__pc.23512: Dma_PatchDst (.L__pc.23512.ST), ((.L__movme.reg.eax+0)), (.L__pc.23512.ST)
	.L__pc.23512.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23513
	
	// CG.COPY4 .L__movme_cp.0 => .L__movme_tmp.0
	.L__pc.23513: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.0), 4, .L__pc.23514
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23514: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23515
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23515: Dma_PatchSrc (.L__pc.23515.LD), (.L__movme_cp.3), (.L__pc.23515.LD)
	.p2align 4
	.L__pc.23515.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23516
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23516: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23517
	
	.L__pc.23517: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23518
	
	.p2align 4
	.L__pc.23518: Dma_PatchDst (.L__pc.23518.ST), (.L__movme_cp.4), (.L__pc.23518.ST)
	.L__pc.23518.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23519
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23519: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23520: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23521: Dma_PatchSrc (.L__pc.23521.LD), (.L__movme_tmp.1), (.L__pc.23521.LD)
	.p2align 4
	.L__pc.23521.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23522
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23522: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23523
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.23523: Dma_PatchSrc (.L__pc.23523.LD), (.L__movme_cp.1), (.L__pc.23523.LD)
	.p2align 4
	.L__pc.23523.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23524
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23524: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23525
	
	.L__pc.23525: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23526
	
	.p2align 4
	.L__pc.23526: Dma_PatchDst (.L__pc.23526.ST), ((.L__movme.reg.eax+0)), (.L__pc.23526.ST)
	.L__pc.23526.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23527
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23527: Dma_PatchSrc (.L__pc.23527.LD), (.L__movme_cp.2), (.L__pc.23527.LD)
	.p2align 4
	.L__pc.23527.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23528
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23528: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23529
	
	// CG.LOAD4 [(.L__movme.reg.eax+0)} => .L__movme_tmp.0
	.L__pc.23529: Dma_PatchSrc (.L__pc.23529.LD), ((.L__movme.reg.eax+0)), (.L__pc.23529.LD)
	.p2align 4
	.L__pc.23529.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23530
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23530: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23531
	
	.L__pc.23531: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23532
	
	.p2align 4
	.L__pc.23532: Dma_PatchDst (.L__pc.23532.ST), (.L__movme_cp.1), (.L__pc.23532.ST)
	.L__pc.23532.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23533
	
	// CG.COPY4 .L__movme_cp.2 => .L__movme_tmp.0
	.L__pc.23533: Dma_ByteCopy (.L__movme_tmp.0), (.L__movme_cp.2), 4, .L__pc.23534
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23534: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23535
	
	// CG.LOAD4 [.L__movme_cp.3} => .L__movme_tmp.0
	.L__pc.23535: Dma_PatchSrc (.L__pc.23535.LD), (.L__movme_cp.3), (.L__pc.23535.LD)
	.p2align 4
	.L__pc.23535.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23536
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23536: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23537
	
	.L__pc.23537: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.eax+0)), 4, .L__pc.23538
	
	.p2align 4
	.L__pc.23538: Dma_PatchDst (.L__pc.23538.ST), (.L__movme_cp.4), (.L__pc.23538.ST)
	.L__pc.23538.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23539
	
	// CG.UNIMPLEMENTED: CG.SCALE (.L__movme.reg.edx+0) * 4 => .L__movme_tmp.2
	.L__pc.23539: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.5 + .L__movme_tmp.2 => .L__movme_tmp.1
	.L__pc.23540: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23541: Dma_PatchSrc (.L__pc.23541.LD), (.L__movme_tmp.1), (.L__pc.23541.LD)
	.p2align 4
	.L__pc.23541.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23542
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23542: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23543
	
	// CG.LOAD4 [.L__movme_cp.2} => .L__movme_tmp.0
	.L__pc.23543: Dma_PatchSrc (.L__pc.23543.LD), (.L__movme_cp.2), (.L__pc.23543.LD)
	.p2align 4
	.L__pc.23543.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23544
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23544: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23545
	
	// CG.UNIMPLEMENTED: CG.ADD .L__movme_cp.19 + (.L__movme.reg.edx+0) => .L__movme_tmp.1
	.L__pc.23545: Dma_ByteCopy (__movme.bad), (__movme.bad), 4, __movme.bad
	
	// CG.LOAD4 [.L__movme_tmp.1} => .L__movme_tmp.0
	.L__pc.23546: Dma_PatchSrc (.L__pc.23546.LD), (.L__movme_tmp.1), (.L__pc.23546.LD)
	.p2align 4
	.L__pc.23546.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23547
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23547: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23548
	
	.L__pc.23548: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23549
	
	.p2align 4
	.L__pc.23549: Dma_PatchDst (.L__pc.23549.ST), ((.L__movme.reg.eax+0)), (.L__pc.23549.ST)
	.L__pc.23549.ST: Dma_ByteCopy (__movme.bad), (.L__movme_tmp.0), 4, .L__pc.23550
	
	// CG.LOAD4 [.L__movme_cp.1} => .L__movme_tmp.0
	.L__pc.23550: Dma_PatchSrc (.L__pc.23550.LD), (.L__movme_cp.1), (.L__pc.23550.LD)
	.p2align 4
	.L__pc.23550.LD: Dma_ByteCopy (.L__movme_tmp.0), (__movme.bad), 4, .L__pc.23551
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.edx+0)
	.L__pc.23551: Dma_ByteCopy ((.L__movme.reg.edx+0)), (.L__movme_tmp.0), 4, .L__pc.23552
	
	.L__pc.23552: Dma_ByteCopy (.L__movme_tmp.0), ((.L__movme.reg.edx+0)), 4, .L__pc.23553
	
	// CG.REG.STORE4 .L__movme_tmp.0 => (.L__movme.reg.eax+0)
	.L__pc.23553: Dma_ByteCopy ((.L__movme.reg.eax+0)), (.L__movme_tmp.0), 4, .L__pc.23554
	
	// JMP reg.4(eax)
	.L__pc.23554: Dma_PatchLink (.L__pc.23554.J), ((.L__movme.reg.eax+0)), (.L__pc.23554.J)
	.p2align 4
	.L__pc.23554.J: Dma_ByteCopy  (.L__movme_tmp.0), (.L__movme_tmp.0), 1, .L__pc.23555
	
	// LABEL .Lf19
	.Lf19:
	
	// LABEL .LCS8
	.LCS8:
	
	// DATA byte 0x74
	.byte 0x74
	
	// DATA byte 0x68
	.byte 0x68
	
	// DATA byte 0x65
	.byte 0x65
	
	// DATA byte 0x20
	.byte 0x20
	
	// DATA byte 0x77
	.byte 0x77
	
	// DATA byte 0x6f
	.byte 0x6f
	
	// DATA byte 0x72
	.byte 0x72
	
	// DATA byte 0x6c
	.byte 0x6c
	
	// DATA byte 0x64
	.byte 0x64
	
	// DATA byte 0x20
	.byte 0x20
	
	// DATA byte 0x69
	.byte 0x69
	
	// DATA byte 0x73
	.byte 0x73
	
	// DATA byte 0x20
	.byte 0x20
	
	// DATA byte 0x61
	.byte 0x61
	
	// DATA byte 0x20
	.byte 0x20
	
	// DATA byte 0x6d
	.byte 0x6d
	
	// DATA byte 0x6f
	.byte 0x6f
	
	// DATA byte 0x76
	.byte 0x76
	
	// DATA byte 0x69
	.byte 0x69
	
	// DATA byte 0x6e
	.byte 0x6e
	
	// DATA byte 0x67
	.byte 0x67
	
	// DATA byte 0x20
	.byte 0x20
	
	// DATA byte 0x74
	.byte 0x74
	
	// DATA byte 0x61
	.byte 0x61
	
	// DATA byte 0x72
	.byte 0x72
	
	// DATA byte 0x67
	.byte 0x67
	
	// DATA byte 0x65
	.byte 0x65
	
	// DATA byte 0x74
	.byte 0x74
	
	// DATA byte 0x20
	.byte 0x20
	
	// DATA byte 0x2e
	.byte 0x2e
	
	// DATA byte 0x2e
	.byte 0x2e
	
	// DATA byte 0x2e
	.byte 0x2e
	
	// DATA byte 0x2e
	.byte 0x2e
	
	// DATA byte 0xd
	.byte 0xd
	
	// DATA byte 0xa
	.byte 0xa
	
	// DATA byte 0x0
	.byte 0x0
	
	.pushsection ".data", "aw", "progbits"
	.p2align 2
	
	// Register block
	.L__movme.reg.eax: .fill 4
	.L__movme.reg.ebx: .fill 4
	.L__movme.reg.ecx: .fill 4
	.L__movme.reg.edx: .fill 4
	
	// Temporary variables
	.pushsection ".data", "aw", "progbits"
	.p2align 2
	
	.L__movme_tmp.0: .fill 4
	.L__movme_tmp.1: .fill 4
	.L__movme_tmp.2: .fill 4
	.L__movme_tmp.3: .fill 4
	.popsection
	
	// Constant pool
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.0: .long (fp)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.1: .long (stack_temp)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.2: .long (sp)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.3: .long (on)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.4: .long (data_p)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.5: .long (sel_data)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.6: .long (push)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.7: .long (R1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.8: .long (R2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.9: .long (R3)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.10: .long (F1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.11: .long (F2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.12: .long (D1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.13: .long (D1+4)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.14: .long (stack_temp+4)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.15: .long (4)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.16: .long (D2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.17: .long (D2+4)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.18: .long (.LCI4)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.19: .long (pop)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.20: .long (1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.21: .long (alu_x)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.22: .long (alu_y)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.23: .long (0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.24: .long (alu_c)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.25: .long (alu_x+0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.26: .long (alu_y+0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.27: .long (alu_add16)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.28: .long (alu_c+2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.29: .long (alu_s+0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.30: .long (alu_x+2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.31: .long (alu_y+2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.32: .long (alu_s+2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.33: .long (alu_s)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.34: .long (0x40000000)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.35: .long (R0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.36: .long (alu_sex8)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.37: .long (255)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.38: .long (alu_band8)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.39: .long (alu_x+1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.40: .long (alu_y+1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.41: .long (alu_s+1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.42: .long (alu_x+3)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.43: .long (alu_y+3)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.44: .long (alu_s+3)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.45: .long (.LCS8)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.46: .long (.LCI18)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.47: .long (print)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.48: .long (.LCI10)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.49: .long (0x40000004)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.50: .long (97)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.51: .long (122)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.52: .long (0x1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.53: .long (alu_inv16)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.54: .long (alu_c-2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.55: .long (13)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.56: .long (26)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.57: .long (alu_n)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.58: .long (alu_d)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.59: .long (alu_q)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.60: .long (alu_r)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.61: .long (alu_n+3)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.62: .long (alu_b7)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.63: .long (alu_r+0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.64: .long (alu_div_shl3_8_d)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.65: .long (alu_div_shl1_8_c_d)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.66: .long (alu_r+1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.67: .long (alu_r+2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.68: .long (alu_r+3)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.69: .long (alu_t+0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.70: .long (alu_t+2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.71: .long (alu_true)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.72: .long (alu_t)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.73: .long (alu_sel_r)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.74: .long (alu_psel_r)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.75: .long (alu_sel_q)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.76: .long (alu_psel_q)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.77: .long (alu_sr)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.78: .long (alu_sr+0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.79: .long (alu_sr+2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.80: .long (alu_sq)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.81: .long (alu_sq+3)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.82: .long (alu_b_s_7)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.83: .long (alu_b6)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.84: .long (alu_b_s_6)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.85: .long (alu_b5)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.86: .long (alu_b_s_5)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.87: .long (alu_b4)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.88: .long (alu_b_s_4)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.89: .long (alu_b3)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.90: .long (alu_b_s_3)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.91: .long (alu_b2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.92: .long (alu_b_s_2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.93: .long (alu_b1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.94: .long (alu_b_s_1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.95: .long (alu_b0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.96: .long (alu_b_s_0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.97: .long (alu_n+2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.98: .long (alu_sq+2)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.99: .long (alu_n+1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.100: .long (alu_sq+1)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.101: .long (alu_n+0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.102: .long (alu_sq+0)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.103: .long (.LCI15)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.104: .long (65)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.105: .long (90)
	.popsection
	.pushsection ".rodata.__movme.cp", "aM", "progbits", 4
	.p2align 2
	.L__movme_cp.106: .long (.LCI9)
	.popsection
	
	// Bad access trap
	.set __movme.bad, 0x0BADC0DE
	.set .L__pc.23555, 0x0BADC1DE
